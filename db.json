{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1550558008149},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1550558008149},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1550558008154},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1550558008150},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1550558008154},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1550558008155},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1550558008156},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1550558008156},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1550558008157},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1550558008158},{"_id":"themes/next/README.cn.md","hash":"58ffe752bc4b7f0069fcd6304bbc2d5ff7b80f89","modified":1550558008159},{"_id":"themes/next/README.md","hash":"898213e66d34a46c3cf8446bf693bd50db0d3269","modified":1550558008160},{"_id":"themes/next/_config.yml","hash":"e3ced8544324e3d92a7dbaaef8f8beb1d2489b27","modified":1557802044571},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1550558008161},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1550558008162},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1550558008223},{"_id":"source/tags/index.md","hash":"c0107f65ab18b27aa24eba9f030748e1b9bb5108","modified":1550563680962},{"_id":"source/_posts/Mysql-index.md","hash":"65cedcaf1504c7e6e07286b714bd09ffba54ee21","modified":1556184658607},{"_id":"source/_posts/Mysql-others.md","hash":"e49982686a079e85a84e1ad3e27c4996b1be4fed","modified":1556184737061},{"_id":"source/_posts/Mysql-redo-binlog-master-slave.md","hash":"12a8b81925569b08f022647e416e619dc97b1f15","modified":1555934035865},{"_id":"source/_posts/Mysql-isolation-level.md","hash":"fcccb1ad7c15aa49412a7787e9daa243e89fe4f3","modified":1555914955841},{"_id":"source/_posts/NGINX-4xx-5xx-状态码构造.md","hash":"e6d0982a7ae14f8fb7bcaff3282428a8fe941ef8","modified":1550559290710},{"_id":"source/_posts/Redis-handle-client.md","hash":"3edda9cd3e7f7bf37f4ded642b9d29724b7f5575","modified":1557480965336},{"_id":"source/_posts/NGINX-HTTP2-处理流程.md","hash":"bd5f17f54fa7ab9c969abc8d9ae7913c58785b47","modified":1550560281579},{"_id":"source/_posts/Redis module开发.md","hash":"1207c1ae2977ccc04f9b4e9e3fb6d0923908303c","modified":1555503347398},{"_id":"source/_posts/Redis-scan命令原理.md","hash":"2c9913412371cbcd47da8f7d5d3ae20773491ccc","modified":1550558008116},{"_id":"source/_posts/Redis中查找大key.md","hash":"ea32b2057a732880c40f2bb272e4b8d0a894fffc","modified":1550558008117},{"_id":"source/_posts/Redis-懒删除-lazy-free-简史.md","hash":"25310e6ed3f2fac7760b60d615568258e00c5032","modified":1550558008117},{"_id":"source/_posts/Redis-stream.md","hash":"9f66ee3a6f1d3c4c34e3d6ab2b1b2890854cf17b","modified":1556635779862},{"_id":"source/_posts/Redis中的lru算法实现.md","hash":"843cd3517e10c11f1fe3bc868af3ebf0ec8efa49","modified":1550558008118},{"_id":"source/_posts/Redis单机版本框架.md","hash":"955b1fba6cfae7a1bbfe78c3f8edabb3f48a5c0c","modified":1550558008118},{"_id":"source/_posts/Redis有序集合指令学习.md","hash":"14f24d00e6c7af86a3ce748a3057c989d48b1a22","modified":1550558008119},{"_id":"source/_posts/Redis的一个历史bug及其后续改进.md","hash":"6b61ca01ec09de32a86978aa25100b5f478289a6","modified":1556982717311},{"_id":"source/_posts/Redis的resp协议.md","hash":"3b69dfd3ef02a4fbacf9a0dd2a701140cd8ef2ac","modified":1555120783891},{"_id":"source/_posts/Sqlite Write-Ahead Logging .md","hash":"35dcea24cde109e7d6a65460de904c57ba7a56ed","modified":1555414758159},{"_id":"source/_posts/go-sync.md","hash":"abe8e5635ea701e0f53b1fb8bb7ed331008a64cb","modified":1558344766475},{"_id":"source/_posts/codis-proxy处理流程.md","hash":"9da50537228e192960d98af16179c701d490d7c7","modified":1550560808196},{"_id":"source/_posts/go-context.md","hash":"8e5df188109d76429955ccdc3755f4fae2c6af7f","modified":1558236230648},{"_id":"source/_posts/Sqlite如何实现ACID中的原子性.md","hash":"5f6b029bd170cd75975d7f9dd327bac1c006f588","modified":1555414585372},{"_id":"source/_posts/how-to-design-a-effective-rpc-monitor-system.md","hash":"1d86a06c1ee2837e0be8890f61470a3d4e8e2634","modified":1558083880541},{"_id":"themes/next/.git/HEAD","hash":"a780c414ba6f3ad96e9dcc330dbf7d7350d0be24","modified":1550563442847},{"_id":"source/_posts/how-to-design-ab-system.md","hash":"848b5ac9e44f95bb80a2084284a7d002a7e1e062","modified":1557829493453},{"_id":"source/_posts/how-to-design-a-log-system.md","hash":"a223e13677b178acf6efcdd4e0d6e6cae1cc3750","modified":1557888657672},{"_id":"themes/next/.git/config","hash":"510faaf0899b89e8a0a0a7ebeff0d4b0aa5ad38f","modified":1550546634328},{"_id":"themes/next/.git/COMMIT_EDITMSG","hash":"73dda3d5aa9e95bf64c98c9a14ea6e68e1bd4611","modified":1550563442725},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1550546581854},{"_id":"themes/next/.git/packed-refs","hash":"69237944e31c16fe545d1f47b0b1e5b1d99660da","modified":1550546749630},{"_id":"themes/next/.git/index","hash":"2442ff461f7441ff6e224ca02e73deb3800d4a15","modified":1550563435663},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1550558008151},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1550558008151},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1550558008152},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1550558008153},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1550558008164},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1550558008163},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1550558008164},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1550558008163},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1550558008165},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1550558008167},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1550558008166},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1550558008168},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1550558008168},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1550558008171},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1550558008169},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1550558008169},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1550558008170},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1550558008172},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1550558008172},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1550558008172},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1550558008174},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1550558008219},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1550558008219},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1550558008220},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1550558008221},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1550558008222},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1550558008221},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1550558008222},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1550558008224},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1550558008224},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1550558008404},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1550558008402},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1550558008403},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008298},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1550546581856},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1550546581855},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1550546581857},{"_id":"themes/next/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1550546581856},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1550546581855},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1550546581858},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1550546581855},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1550546581858},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1550546581854},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1550546581859},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1550546581856},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1550546581857},{"_id":"themes/next/.git/logs/HEAD","hash":"e635c99a18370226b26c2d186d6a31465c900673","modified":1550563442847},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1550558008173},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1550558008175},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1550558008174},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1550558008176},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1550558008173},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1550558008175},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1550558008176},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1550558008177},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1550563173117},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1550558008180},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1550558008178},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1550558008178},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1550558008181},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1550558008180},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1550558008181},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1550558008188},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1550558008188},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1550558008191},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1550558008208},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1550558008210},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1550558008209},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1550558008210},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1550558008211},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1550558008212},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1550558008212},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1550558008225},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1550558008226},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1550558008226},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1550558008227},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1550558008229},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1550558008229},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1550558008230},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1550558008231},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1550558008232},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1550558008297},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1550558008300},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1550558008299},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1550558008300},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1550558008301},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1550558008302},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1550558008302},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1550558008303},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1550558008304},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1550558008303},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1550558008305},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1550558008306},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1550558008307},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1550558008304},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1550558008310},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1550558008308},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1550558008310},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1550558008311},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1550558008309},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008190},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008190},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008276},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008276},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008277},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008294},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1550558008297},{"_id":"themes/next/.git/objects/10/50fe56ad5fd891763bd734d27be6306bd7f830","hash":"c53ea8b1e1997e2db82eda26bf1f35d6ecaa4b7d","modified":1550563442847},{"_id":"themes/next/.git/objects/85/bcdbfa33fc45484b79b1c8c9b22f449dea9bc2","hash":"7167c929066a0860cfa1b7db7b12cdc561008336","modified":1550563435662},{"_id":"themes/next/.git/objects/2e/d0336f3cad3909b0a425ba49d026ab137a36d3","hash":"ee88b781a5f43746e244ef28fd74fe4f4f5b5b7d","modified":1550563435661},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1550558008179},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1550558008179},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1550558008182},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1550558008183},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1550558008183},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1550558008184},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1550558008185},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1550558008187},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1550558008186},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1550558008189},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1550558008190},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1550558008192},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1550558008190},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1550558008192},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1550558008193},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1550558008194},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1550558008195},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"4aa55cd424389cf5626aa019c15ef6f3e4da09f2","modified":1550564154029},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1550558008195},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1550558008196},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1550558008197},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1550558008198},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1550558008198},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1550558008200},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1550558008199},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1550558008201},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1550558008202},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1550558008203},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1550558008204},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1550558008204},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1550558008205},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1550558008205},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1550558008206},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1550558008207},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1550558008216},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1550558008217},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1550558008218},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1550558008218},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1550558008276},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1550558008276},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1550558008277},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1550558008277},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1550558008294},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1550558008295},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1550558008294},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1550558008296},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1550558008313},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1550558008312},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1550558008312},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1550558008314},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1550558008312},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1550558008315},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1550558008313},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1550558008315},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1550558008317},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1550558008318},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1550558008319},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1550558008328},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1550558008333},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1550558008334},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1550546749703},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1550546749703},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1550558008340},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1550558008341},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1550558008342},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1550558008341},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1550558008344},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1550558008343},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1550558008345},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1550558008345},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1550558008345},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1550558008368},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1550558008368},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1550558008365},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1550558008369},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1550558008370},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1550558008369},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1550558008370},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1550558008371},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1550558008373},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1550558008372},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1550558008372},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1550558008374},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1550558008375},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1550558008375},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1550558008376},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1550558008376},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1550558008377},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1550558008378},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1550558008378},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1550558008379},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1550558008380},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1550558008379},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1550558008381},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1550558008380},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1550558008383},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1550558008385},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1550558008382},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1550558008392},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1550558008393},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1550558008397},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1550558008400},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1550558008401},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1550558008367},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1550546749632},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1550558008215},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1550558008214},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1550558008233},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1550558008233},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1550558008234},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1550558008234},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1550558008235},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1550558008247},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1550558008260},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1550558008272},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1550558008273},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1550558008274},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1550558008273},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1550558008274},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1550558008275},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1550558008275},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1550558008278},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1550558008279},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1550558008279},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1550558008279},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1550558008280},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1550558008281},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1550558008280},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1550558008282},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1550558008287},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1550558008284},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1550558008286},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1550558008285},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1550558008291},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1550558008288},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1550558008290},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1550558008290},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1550558008293},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1550558008292},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1550558008293},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1550558008326},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1550558008327},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1550558008316},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1550558008334},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1550558008334},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1550558008335},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1550558008335},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1550558008335},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1550558008335},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1550558008338},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1550558008339},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1550558008339},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1550558008342},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1550558008343},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1550558008347},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1550558008348},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1550558008346},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1550558008391},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1550558008391},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1550558008323},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1550558008363},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1550558008365},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1550558008396},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"a8fbb8c375de8902725447a0b6fef819860b1db2","modified":1550546749632},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1550558008236},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1550558008239},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1550558008237},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1550558008238},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1550558008239},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1550558008242},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1550558008240},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1550558008241},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1550558008244},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1550558008245},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1550558008245},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1550558008246},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1550558008247},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1550558008246},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1550558008248},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1550558008249},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1550558008250},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1550558008249},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1550558008251},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1550558008252},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1550558008250},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1550558008252},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1550558008251},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1550558008252},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1550558008253},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1550558008253},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1550558008254},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1550558008255},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1550558008254},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1550558008254},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1550558008256},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1550558008256},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1550558008256},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1550558008257},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1550558008258},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1550558008259},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1550558008258},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1550558008259},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1550558008260},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1550558008262},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1550558008262},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1550558008261},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1550558008263},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1550558008264},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1550558008263},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1550558008264},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1550558008265},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1550558008265},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1550558008266},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1550558008267},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1550558008267},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1550558008270},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1550558008269},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1550558008270},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1550558008268},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1550558008271},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1550558008271},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1550558008272},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1550558008283},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1550558008283},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1550558008289},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1550558008319},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1550558008320},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1550558008321},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1550558008321},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1550558008322},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1550558008336},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1550558008336},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1550558008336},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1550558008337},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1550558008337},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1550558008337},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1550558008350},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1550558008361},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1550558008324},{"_id":"themes/next/.git/objects/pack/pack-13d3290b0a8eb9f96d0dc2f0c5a41d909767d903.idx","hash":"2b30388a8c5c0c181a2818b330b9b6b2e8c01ac4","modified":1550546749270},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1550558008353},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1550558008331},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1550558008390},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1550558008358},{"_id":"themes/next/.git/objects/pack/pack-13d3290b0a8eb9f96d0dc2f0c5a41d909767d903.pack","hash":"c9801325247a531b0818f555008af87249b5b3f1","modified":1550546749263},{"_id":"public/tags/index.html","hash":"946f5b0a2800feaf3e812d45ccbf45a4f943920a","modified":1558344647592},{"_id":"public/archives/page/3/index.html","hash":"321489e18f51a1aacd41357a038310a9bbb0a069","modified":1558344647592},{"_id":"public/archives/2018/index.html","hash":"1ad579033d189e0cbbfe45b935e7c5e59b6a66b0","modified":1558344647592},{"_id":"public/archives/2018/06/index.html","hash":"357d1d9c3831b47b5096e4a55e3bfe31ebdac33d","modified":1558344647592},{"_id":"public/archives/2018/07/index.html","hash":"d74184cd8cc75e51979732a9fab4465c9727e902","modified":1558344647592},{"_id":"public/archives/2018/09/index.html","hash":"a9d83573668d5b1e66fe66fba91c027b8c50d6c7","modified":1558344647592},{"_id":"public/archives/2018/12/index.html","hash":"524932677b574d8be61a6d8bd263c85bbd04a89d","modified":1558344647592},{"_id":"public/archives/2019/01/index.html","hash":"9e8351018d244750a57d040e8d5f511d6363bc18","modified":1558344647592},{"_id":"public/archives/2019/02/index.html","hash":"e7a1f555c391e19351d904e171500c015dc29df8","modified":1558344647592},{"_id":"public/archives/2019/05/index.html","hash":"ea8637889827056b1fefe242fd42a08bbb197ef9","modified":1558344647592},{"_id":"public/tags/Mysql/index.html","hash":"79c55606f44862b97885cf600c332efd3257fe30","modified":1558344647592},{"_id":"public/tags/NGINX/index.html","hash":"96466844b1803ac42231bc001784568f86e57cce","modified":1558344647592},{"_id":"public/tags/Redis/page/2/index.html","hash":"7b76ec84df7e702662cacc98c4a106f03cb4edd2","modified":1558344647593},{"_id":"public/tags/go/index.html","hash":"6dd99b54153d1375ad55177f407f355ace3f0db4","modified":1558344647593},{"_id":"public/tags/architecture/index.html","hash":"05e3b6c755a010611bd03793b2a8a31e6464faf1","modified":1558344647593},{"_id":"public/tags/Sqlite/index.html","hash":"9ad307df6b30c6955ca08b6fd0398de28ad51aa3","modified":1558344647593},{"_id":"public/tags/codis/index.html","hash":"ea8026b893ae3b067f6ad6c2adcb1576cd483b29","modified":1558344647593},{"_id":"public/2019/05/19/go-sync/index.html","hash":"e51f67a82409674de81306d5e2b1fc361252b943","modified":1558344782554},{"_id":"public/2019/05/19/go-context/index.html","hash":"90ae05c51cdcd7b4cd1c4f804e9a48f88a880e82","modified":1558344647593},{"_id":"public/2019/05/17/how-to-design-a-effective-rpc-monitor-system/index.html","hash":"a60097c0fe43b004c19ec14905bf22b10f09cc6a","modified":1558344647593},{"_id":"public/2019/05/14/how-to-design-ab-system/index.html","hash":"f3c3380f641502f5345ced1a30cc5d282d0c5035","modified":1558344647593},{"_id":"public/2019/05/13/how-to-design-a-log-system/index.html","hash":"818db721a0262084ac0e97a6ec105c50ebcb6c1d","modified":1558344647593},{"_id":"public/2019/05/10/Redis-handle-client/index.html","hash":"acb5e42198eb9303ee4b4046a0460f8855491a1d","modified":1558344647593},{"_id":"public/2019/04/30/Redis-stream/index.html","hash":"cfea69b05ed11551466ad015a3d3590bb9c4d771","modified":1558344647593},{"_id":"public/2019/04/25/Mysql-others/index.html","hash":"921bfce5ef00306471fbb7e0e3009430be707004","modified":1558344647593},{"_id":"public/2019/04/22/Mysql-index/index.html","hash":"fd12854ff9defc6ef08c781526764fb068e5f9f7","modified":1558344647593},{"_id":"public/2019/04/22/Mysql-redo-binlog-master-slave/index.html","hash":"648bec6d1e5b84caa889e0bf9fe6245cb33444f5","modified":1558344647593},{"_id":"public/2019/04/20/Mysql-isolation-level/index.html","hash":"621c15fe8153a53cea84f5b3cf77aff9971f9038","modified":1558344647593},{"_id":"public/2019/04/17/Redis module开发/index.html","hash":"bfad9f688e2a351c5cdc31303bc7cf06bee780b6","modified":1558344647593},{"_id":"public/2019/04/16/Sqlite Write-Ahead Logging /index.html","hash":"625ac5ca9382ea725d8d7be6580ccb547810adfd","modified":1558344647594},{"_id":"public/2019/04/15/Redis的一个历史bug及其后续改进/index.html","hash":"559cd6ab46221a57bbcdbc539e051982663d4ecc","modified":1558344647594},{"_id":"public/2019/04/13/Sqlite如何实现ACID中的原子性/index.html","hash":"78bda90e9e304964c73c066dce9cf12b5abb3ea5","modified":1558344647594},{"_id":"public/2019/01/31/Redis的resp协议/index.html","hash":"0467ecc4d411029cc1ac64c8b47c5f246dc8852f","modified":1558344647594},{"_id":"public/2019/01/10/codis-proxy处理流程/index.html","hash":"c7d9b3e6252cecebc0f4de784a005566ba4415c4","modified":1558344647594},{"_id":"public/2018/12/21/Redis中的lru算法实现/index.html","hash":"6ba63e9672519f0b921fcd780259b39531a9a1de","modified":1558344647594},{"_id":"public/2018/12/15/Redis-懒删除-lazy-free-简史/index.html","hash":"91808a658ad3ab458ff6f9d9c20bf781cde71840","modified":1558344647594},{"_id":"public/2018/12/11/NGINX-HTTP2-处理流程/index.html","hash":"74b18cf237d0b36a1463540b569bfa22d1f72900","modified":1558344647594},{"_id":"public/2018/09/18/NGINX-4xx-5xx-状态码构造/index.html","hash":"22353f80149041f6329ea20d604404b7718c3846","modified":1558344647594},{"_id":"public/2018/07/11/Redis有序集合指令学习/index.html","hash":"5288f247a3bffe9e5386e37d51fdcb97672cd539","modified":1558344647594},{"_id":"public/2018/06/22/Redis-scan命令原理/index.html","hash":"5c9dbf24e355857dd72f350f946b4eb56003ac45","modified":1558344647594},{"_id":"public/2018/06/07/Redis单机版本框架/index.html","hash":"bf8fbd25728c24e22170ad1bb21793fe0b0108de","modified":1558344647594},{"_id":"public/index.html","hash":"2991e28ce16208f9bc425cc0486615756cb0e9e5","modified":1558344647594},{"_id":"public/page/2/index.html","hash":"25b194bf1cb4d934130aed5f9caa82dd10820c8b","modified":1558344647594},{"_id":"public/page/3/index.html","hash":"65dec12a598bf23019a23b6b2720893829719e2a","modified":1558344647594},{"_id":"public/archives/index.html","hash":"6d5df604d7a8d5bf5eca675d429f586ff21eeaec","modified":1558344647594},{"_id":"public/archives/page/2/index.html","hash":"4180373541d7bea337def0080b6335dbc867bb26","modified":1558344647594},{"_id":"public/archives/2019/index.html","hash":"300d351868f928beca98015d2ee1b1a79e937076","modified":1558344647594},{"_id":"public/archives/2019/page/2/index.html","hash":"9d3e8fd49a6344141ec35314fd1471c64c044533","modified":1558344647595},{"_id":"public/archives/2019/04/index.html","hash":"a68dbd19776c5d7fd378c88a5b3dbf6c903d878a","modified":1558344647595},{"_id":"public/tags/Redis/index.html","hash":"ccc73fe64e8689c1059b51827a264c8bcd71b894","modified":1558344647595},{"_id":"public/2019/02/13/Redis中查找大key/index.html","hash":"c0cf83d0fb5e5455a82aa1dd32f08d3ef6669780","modified":1558344647595},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1558344647599},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1558344647599},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1558344647599},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1558344647599},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1558344647599},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1558344647599},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1558344647600},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1558344647600},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1558344647600},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1558344647600},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1558344647600},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1558344647600},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1558344647600},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1558344647600},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1558344647600},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1558344647600},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1558344647600},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1558344647600},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1558344647600},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1558344647600},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1558344647600},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1558344647600},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1558344647600},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1558344647600},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1558344647601},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1558344648004},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1558344648007},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1558344648008},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1558344648009},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1558344648009},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1558344648009},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1558344648009},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1558344648009},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1558344648014},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1558344648015},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1558344648015},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1558344648016},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1558344648016},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1558344648016},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1558344648016},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1558344648016},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1558344648016},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1558344648016},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1558344648016},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1558344648016},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1558344648016},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1558344648016},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1558344648016},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1558344648016},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1558344648016},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1558344648017},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1558344648017},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1558344648017},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1558344648017},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1558344648017},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1558344648017},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1558344648017},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1558344648017},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1558344648017},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1558344648017},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1558344648017},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1558344648017},{"_id":"public/css/main.css","hash":"b2001a2c8ea36dc4f65a7abb6a562bd21cc810c7","modified":1558344648017},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1558344648017},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1558344648017},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1558344648024},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1558344648024},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1558344648025},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1558344648025},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1558344648025},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1558344648025},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1558344648025},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1558344648025},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1558344648025},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1558344648025},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1558344648025},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1558344648025},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1558344648025},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1558344648025},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1558344648025},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1558344648025},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1558344648028},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1558344648032},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1558344648033},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1558344648035},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1558344648038},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1558344648038},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1558344648039},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1558344648039},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1558344648039},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1558344648039},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1558344648039},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1558344648042},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1558344648042},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1558344648042},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1558344648043},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1558344648044},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1558344648047},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1558344648047},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1558344648049},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1558344648055},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1558344648059}],"Category":[],"Data":[],"Page":[{"title":"tags","date":"2019-02-19T08:07:23.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-02-19 16:07:23\ntype: \"tags\"\n---\n","updated":"2019-02-19T08:08:00.962Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjvw65z8v0000bms6davwmbug","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Mysql 索引","date":"2019-04-21T16:00:00.000Z","_content":"## 引言\n理解Mysql的索引\n参考极客时间**mysql45讲**之第4讲,5讲,9讲,10讲,11讲,18讲\n\n### 不同的索引\n||哈希索引|有序数组|树|\n|-------|-------|----|\n|增  |最快\t|   慢\t|   快|  \n|查 | 最快\t|\t快\t|\t快|\n|范围查 | 慢\t|\t快\t|\t快|\n\n### B+树索引的类别\n#### B+树保存数据的层数\n磁盘随机读取需要10ms的时间\n\nMysql每页默认大小16KB,整型占据4字节+9字节(辅助字段）= 13字节,16Kb/13 = 1260,即整型索引每个节点可以保存1260,即1260叉树.三层为1260^3 约等于20亿条数据\n增大page可以增加节点个数,减少层数\n\n#### B+树索引类型\n* 叶子节点保存数据为聚簇索引\n* 叶子节点保存主键为二级索引\n\n\n```\nmysql> create table T(\nid int primary key, \nk int not null, \nname varchar(16),\nindex (k))engine=InnoDB;\n\n```\n基于二级索引需要回表\n\n\n#### B+树的页分裂与合并\n分裂影响性能,也影响磁盘使用率（分裂完后每个page只使用50%）\n自增主键有如下两点好处:\n* 顺序增加,不易造成分裂\n* 二级索引会保存主键,自增主键4或8个字节,比较小,省存储空间\n\n#### 覆盖索引\n*  优点:加速查询,不需要回表\n*  缺点:二级索引需要保存冗余信息,浪费磁盘空间 \n\n#### 最左前缀\n建立联合索引的时候如何决定字段顺序\n* 如果通过调整顺序,可以少维护一个索引,这是优先考虑的（有(a,b)联合索引后,不需要单独维护（a）这个索引）\n\n* 空间 如果要实现有单独a,单独b,和(a,b)联合的索引,那么看a,b哪个占用空间大,从而决定使用(a),(b,a)还是(b),(a,b).\n\n#### 索引下推 (ICP index condition pushdown)\n\nwhere的过滤条件如果在联合索引中存在,可以直接过滤,省去回表过滤的过程\n\n#### 普通索引和唯一索引\n结论:如果业务能够保证唯一,尽量用普通索引\n原因:普通索引可以用到change buffer,change buffer可以减少磁盘的随机读.即假设一个page不在内存中,当更新或者插入时,不需要load page,只需要把更新放到change buffer中,有后台线程会定期merge change buffer 和 旧页.当下次需要读取旧page时,load到内存中后也会直接merge\n\nchange buffer减少了磁盘io,更新和插入变为了直接操作内存.但不适用于写入之后就立马读取的业务场景,这样不仅未减少io,还增加了merge的过程\n\n唯一索引不会用到change buffer,需要每次读取page中的数据然后校验唯一性 \n\n#### 字符串字段加索引\n\n增加前缀索引,例如邮箱上边\n```\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n\n```\n要点:\n* 定义好前缀长度,使其区分度足够高,这样既能节省空间,又不用增加太多的查询成本\n* 前缀长度短,省空间,但区分度不够,增加查询和回表的次数\n* 前缀长度长,查询成本低但是浪费空间\n* 另外,前缀索引必须回表查,用不上覆盖索引的优化\n\n计算区分度\n```\nmysql> select count(distinct email) as L from SUser;\nmysql> select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n\n```\n\n特例:如果不需要范围查询,只需要等值查询,可以使用如下方法:\n* 倒序存储.例如身份证号只取前六位区分度不高,则可以使用倒序之后的六位\n* 哈希存储.新增加哈希字段,文中为crc32,则查询时首先走crc32字段的索引查,然后精确匹配(防止冲突)\n\n\n\n## 索引使用注意事项\n```\n表结构\nmysql> CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n\n```\n索引字段做函数操作\n```\n不会用到id索引\nselect * from tradelog where id + 1 = 10000\n不会用到t_modified索引\nselect count(*) from tradelog where month(t_modified)=7;\nmonth替换为substr(t_modified,1,2)这样更易理解.即函数会破坏掉索引的有序性,MySQL认为扫描索引不再有效\n```\n隐式类型转换\n```\ntradeid为varchar(32)\nmysql> select * from tradelog where tradeid=110717;\n```\nmysql中的转换规则是字符串转数字,于是上述语句相当于\n```\nmysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;\n```\n隐式编码类型转换\n\n一个表是utfmb4,一个是uft8,mysql会将utf8中的字段转换为uft8mb4,还是会触发上边的规则\n\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Mysql-index.md","raw":"---\ntitle: Mysql 索引\ndate: 2019-04-22\ntags: Mysql\n---\n## 引言\n理解Mysql的索引\n参考极客时间**mysql45讲**之第4讲,5讲,9讲,10讲,11讲,18讲\n\n### 不同的索引\n||哈希索引|有序数组|树|\n|-------|-------|----|\n|增  |最快\t|   慢\t|   快|  \n|查 | 最快\t|\t快\t|\t快|\n|范围查 | 慢\t|\t快\t|\t快|\n\n### B+树索引的类别\n#### B+树保存数据的层数\n磁盘随机读取需要10ms的时间\n\nMysql每页默认大小16KB,整型占据4字节+9字节(辅助字段）= 13字节,16Kb/13 = 1260,即整型索引每个节点可以保存1260,即1260叉树.三层为1260^3 约等于20亿条数据\n增大page可以增加节点个数,减少层数\n\n#### B+树索引类型\n* 叶子节点保存数据为聚簇索引\n* 叶子节点保存主键为二级索引\n\n\n```\nmysql> create table T(\nid int primary key, \nk int not null, \nname varchar(16),\nindex (k))engine=InnoDB;\n\n```\n基于二级索引需要回表\n\n\n#### B+树的页分裂与合并\n分裂影响性能,也影响磁盘使用率（分裂完后每个page只使用50%）\n自增主键有如下两点好处:\n* 顺序增加,不易造成分裂\n* 二级索引会保存主键,自增主键4或8个字节,比较小,省存储空间\n\n#### 覆盖索引\n*  优点:加速查询,不需要回表\n*  缺点:二级索引需要保存冗余信息,浪费磁盘空间 \n\n#### 最左前缀\n建立联合索引的时候如何决定字段顺序\n* 如果通过调整顺序,可以少维护一个索引,这是优先考虑的（有(a,b)联合索引后,不需要单独维护（a）这个索引）\n\n* 空间 如果要实现有单独a,单独b,和(a,b)联合的索引,那么看a,b哪个占用空间大,从而决定使用(a),(b,a)还是(b),(a,b).\n\n#### 索引下推 (ICP index condition pushdown)\n\nwhere的过滤条件如果在联合索引中存在,可以直接过滤,省去回表过滤的过程\n\n#### 普通索引和唯一索引\n结论:如果业务能够保证唯一,尽量用普通索引\n原因:普通索引可以用到change buffer,change buffer可以减少磁盘的随机读.即假设一个page不在内存中,当更新或者插入时,不需要load page,只需要把更新放到change buffer中,有后台线程会定期merge change buffer 和 旧页.当下次需要读取旧page时,load到内存中后也会直接merge\n\nchange buffer减少了磁盘io,更新和插入变为了直接操作内存.但不适用于写入之后就立马读取的业务场景,这样不仅未减少io,还增加了merge的过程\n\n唯一索引不会用到change buffer,需要每次读取page中的数据然后校验唯一性 \n\n#### 字符串字段加索引\n\n增加前缀索引,例如邮箱上边\n```\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n\n```\n要点:\n* 定义好前缀长度,使其区分度足够高,这样既能节省空间,又不用增加太多的查询成本\n* 前缀长度短,省空间,但区分度不够,增加查询和回表的次数\n* 前缀长度长,查询成本低但是浪费空间\n* 另外,前缀索引必须回表查,用不上覆盖索引的优化\n\n计算区分度\n```\nmysql> select count(distinct email) as L from SUser;\nmysql> select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n\n```\n\n特例:如果不需要范围查询,只需要等值查询,可以使用如下方法:\n* 倒序存储.例如身份证号只取前六位区分度不高,则可以使用倒序之后的六位\n* 哈希存储.新增加哈希字段,文中为crc32,则查询时首先走crc32字段的索引查,然后精确匹配(防止冲突)\n\n\n\n## 索引使用注意事项\n```\n表结构\nmysql> CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n\n```\n索引字段做函数操作\n```\n不会用到id索引\nselect * from tradelog where id + 1 = 10000\n不会用到t_modified索引\nselect count(*) from tradelog where month(t_modified)=7;\nmonth替换为substr(t_modified,1,2)这样更易理解.即函数会破坏掉索引的有序性,MySQL认为扫描索引不再有效\n```\n隐式类型转换\n```\ntradeid为varchar(32)\nmysql> select * from tradelog where tradeid=110717;\n```\nmysql中的转换规则是字符串转数字,于是上述语句相当于\n```\nmysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;\n```\n隐式编码类型转换\n\n一个表是utfmb4,一个是uft8,mysql会将utf8中的字段转换为uft8mb4,还是会触发上边的规则\n\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Mysql-index","published":1,"updated":"2019-04-25T09:30:58.607Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z8y0001bms655opvvqr","content":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的索引<br>参考极客时间<strong>mysql45讲</strong>之第4讲,5讲,9讲,10讲,11讲,18讲</p>\n<h3 id=\"不同的索引\"><a href=\"#不同的索引\" class=\"headerlink\" title=\"不同的索引\"></a>不同的索引</h3><table>\n<thead>\n<tr>\n<th></th>\n<th>哈希索引</th>\n<th>有序数组</th>\n<th>树</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>增</td>\n<td>最快</td>\n<td>慢</td>\n<td>快</td>\n</tr>\n<tr>\n<td>查</td>\n<td>最快</td>\n<td>快</td>\n<td>快</td>\n</tr>\n<tr>\n<td>范围查</td>\n<td>慢</td>\n<td>快</td>\n<td>快</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"B-树索引的类别\"><a href=\"#B-树索引的类别\" class=\"headerlink\" title=\"B+树索引的类别\"></a>B+树索引的类别</h3><h4 id=\"B-树保存数据的层数\"><a href=\"#B-树保存数据的层数\" class=\"headerlink\" title=\"B+树保存数据的层数\"></a>B+树保存数据的层数</h4><p>磁盘随机读取需要10ms的时间</p>\n<p>Mysql每页默认大小16KB,整型占据4字节+9字节(辅助字段）= 13字节,16Kb/13 = 1260,即整型索引每个节点可以保存1260,即1260叉树.三层为1260^3 约等于20亿条数据<br>增大page可以增加节点个数,减少层数</p>\n<h4 id=\"B-树索引类型\"><a href=\"#B-树索引类型\" class=\"headerlink\" title=\"B+树索引类型\"></a>B+树索引类型</h4><ul>\n<li>叶子节点保存数据为聚簇索引</li>\n<li>叶子节点保存主键为二级索引</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; create table T(</span><br><span class=\"line\">id int primary key, </span><br><span class=\"line\">k int not null, </span><br><span class=\"line\">name varchar(16),</span><br><span class=\"line\">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure>\n<p>基于二级索引需要回表</p>\n<h4 id=\"B-树的页分裂与合并\"><a href=\"#B-树的页分裂与合并\" class=\"headerlink\" title=\"B+树的页分裂与合并\"></a>B+树的页分裂与合并</h4><p>分裂影响性能,也影响磁盘使用率（分裂完后每个page只使用50%）<br>自增主键有如下两点好处:</p>\n<ul>\n<li>顺序增加,不易造成分裂</li>\n<li>二级索引会保存主键,自增主键4或8个字节,比较小,省存储空间</li>\n</ul>\n<h4 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h4><ul>\n<li>优点:加速查询,不需要回表</li>\n<li>缺点:二级索引需要保存冗余信息,浪费磁盘空间 </li>\n</ul>\n<h4 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h4><p>建立联合索引的时候如何决定字段顺序</p>\n<ul>\n<li><p>如果通过调整顺序,可以少维护一个索引,这是优先考虑的（有(a,b)联合索引后,不需要单独维护（a）这个索引）</p>\n</li>\n<li><p>空间 如果要实现有单独a,单独b,和(a,b)联合的索引,那么看a,b哪个占用空间大,从而决定使用(a),(b,a)还是(b),(a,b).</p>\n</li>\n</ul>\n<h4 id=\"索引下推-ICP-index-condition-pushdown\"><a href=\"#索引下推-ICP-index-condition-pushdown\" class=\"headerlink\" title=\"索引下推 (ICP index condition pushdown)\"></a>索引下推 (ICP index condition pushdown)</h4><p>where的过滤条件如果在联合索引中存在,可以直接过滤,省去回表过滤的过程</p>\n<h4 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h4><p>结论:如果业务能够保证唯一,尽量用普通索引<br>原因:普通索引可以用到change buffer,change buffer可以减少磁盘的随机读.即假设一个page不在内存中,当更新或者插入时,不需要load page,只需要把更新放到change buffer中,有后台线程会定期merge change buffer 和 旧页.当下次需要读取旧page时,load到内存中后也会直接merge</p>\n<p>change buffer减少了磁盘io,更新和插入变为了直接操作内存.但不适用于写入之后就立马读取的业务场景,这样不仅未减少io,还增加了merge的过程</p>\n<p>唯一索引不会用到change buffer,需要每次读取page中的数据然后校验唯一性 </p>\n<h4 id=\"字符串字段加索引\"><a href=\"#字符串字段加索引\" class=\"headerlink\" title=\"字符串字段加索引\"></a>字符串字段加索引</h4><p>增加前缀索引,例如邮箱上边<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; alter table SUser add index index1(email);</span><br><span class=\"line\">或</span><br><span class=\"line\">mysql&gt; alter table SUser add index index2(email(6));</span><br></pre></td></tr></table></figure></p>\n<p>要点:</p>\n<ul>\n<li>定义好前缀长度,使其区分度足够高,这样既能节省空间,又不用增加太多的查询成本</li>\n<li>前缀长度短,省空间,但区分度不够,增加查询和回表的次数</li>\n<li>前缀长度长,查询成本低但是浪费空间</li>\n<li>另外,前缀索引必须回表查,用不上覆盖索引的优化</li>\n</ul>\n<p>计算区分度<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select count(distinct email) as L from SUser;</span><br><span class=\"line\">mysql&gt; select </span><br><span class=\"line\">  count(distinct left(email,4)）as L4,</span><br><span class=\"line\">  count(distinct left(email,5)）as L5,</span><br><span class=\"line\">  count(distinct left(email,6)）as L6,</span><br><span class=\"line\">  count(distinct left(email,7)）as L7,</span><br><span class=\"line\">from SUser;</span><br></pre></td></tr></table></figure></p>\n<p>特例:如果不需要范围查询,只需要等值查询,可以使用如下方法:</p>\n<ul>\n<li>倒序存储.例如身份证号只取前六位区分度不高,则可以使用倒序之后的六位</li>\n<li>哈希存储.新增加哈希字段,文中为crc32,则查询时首先走crc32字段的索引查,然后精确匹配(防止冲突)</li>\n</ul>\n<h2 id=\"索引使用注意事项\"><a href=\"#索引使用注意事项\" class=\"headerlink\" title=\"索引使用注意事项\"></a>索引使用注意事项</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">表结构</span><br><span class=\"line\">mysql&gt; CREATE TABLE `tradelog` (</span><br><span class=\"line\">  `id` int(11) NOT NULL,</span><br><span class=\"line\">  `tradeid` varchar(32) DEFAULT NULL,</span><br><span class=\"line\">  `operator` int(11) DEFAULT NULL,</span><br><span class=\"line\">  `t_modified` datetime DEFAULT NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  KEY `tradeid` (`tradeid`),</span><br><span class=\"line\">  KEY `t_modified` (`t_modified`)</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure>\n<p>索引字段做函数操作<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">不会用到id索引</span><br><span class=\"line\">select * from tradelog where id + 1 = 10000</span><br><span class=\"line\">不会用到t_modified索引</span><br><span class=\"line\">select count(*) from tradelog where month(t_modified)=7;</span><br><span class=\"line\">month替换为substr(t_modified,1,2)这样更易理解.即函数会破坏掉索引的有序性,MySQL认为扫描索引不再有效</span><br></pre></td></tr></table></figure></p>\n<p>隐式类型转换<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tradeid为varchar(32)</span><br><span class=\"line\">mysql&gt; select * from tradelog where tradeid=110717;</span><br></pre></td></tr></table></figure></p>\n<p>mysql中的转换规则是字符串转数字,于是上述语句相当于<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select * from tradelog where  CAST(tradid AS signed int) = 110717;</span><br></pre></td></tr></table></figure></p>\n<p>隐式编码类型转换</p>\n<p>一个表是utfmb4,一个是uft8,mysql会将utf8中的字段转换为uft8mb4,还是会触发上边的规则</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的索引<br>参考极客时间<strong>mysql45讲</strong>之第4讲,5讲,9讲,10讲,11讲,18讲</p>\n<h3 id=\"不同的索引\"><a href=\"#不同的索引\" class=\"headerlink\" title=\"不同的索引\"></a>不同的索引</h3><table>\n<thead>\n<tr>\n<th></th>\n<th>哈希索引</th>\n<th>有序数组</th>\n<th>树</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>增</td>\n<td>最快</td>\n<td>慢</td>\n<td>快</td>\n</tr>\n<tr>\n<td>查</td>\n<td>最快</td>\n<td>快</td>\n<td>快</td>\n</tr>\n<tr>\n<td>范围查</td>\n<td>慢</td>\n<td>快</td>\n<td>快</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"B-树索引的类别\"><a href=\"#B-树索引的类别\" class=\"headerlink\" title=\"B+树索引的类别\"></a>B+树索引的类别</h3><h4 id=\"B-树保存数据的层数\"><a href=\"#B-树保存数据的层数\" class=\"headerlink\" title=\"B+树保存数据的层数\"></a>B+树保存数据的层数</h4><p>磁盘随机读取需要10ms的时间</p>\n<p>Mysql每页默认大小16KB,整型占据4字节+9字节(辅助字段）= 13字节,16Kb/13 = 1260,即整型索引每个节点可以保存1260,即1260叉树.三层为1260^3 约等于20亿条数据<br>增大page可以增加节点个数,减少层数</p>\n<h4 id=\"B-树索引类型\"><a href=\"#B-树索引类型\" class=\"headerlink\" title=\"B+树索引类型\"></a>B+树索引类型</h4><ul>\n<li>叶子节点保存数据为聚簇索引</li>\n<li>叶子节点保存主键为二级索引</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; create table T(</span><br><span class=\"line\">id int primary key, </span><br><span class=\"line\">k int not null, </span><br><span class=\"line\">name varchar(16),</span><br><span class=\"line\">index (k))engine=InnoDB;</span><br></pre></td></tr></table></figure>\n<p>基于二级索引需要回表</p>\n<h4 id=\"B-树的页分裂与合并\"><a href=\"#B-树的页分裂与合并\" class=\"headerlink\" title=\"B+树的页分裂与合并\"></a>B+树的页分裂与合并</h4><p>分裂影响性能,也影响磁盘使用率（分裂完后每个page只使用50%）<br>自增主键有如下两点好处:</p>\n<ul>\n<li>顺序增加,不易造成分裂</li>\n<li>二级索引会保存主键,自增主键4或8个字节,比较小,省存储空间</li>\n</ul>\n<h4 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h4><ul>\n<li>优点:加速查询,不需要回表</li>\n<li>缺点:二级索引需要保存冗余信息,浪费磁盘空间 </li>\n</ul>\n<h4 id=\"最左前缀\"><a href=\"#最左前缀\" class=\"headerlink\" title=\"最左前缀\"></a>最左前缀</h4><p>建立联合索引的时候如何决定字段顺序</p>\n<ul>\n<li><p>如果通过调整顺序,可以少维护一个索引,这是优先考虑的（有(a,b)联合索引后,不需要单独维护（a）这个索引）</p>\n</li>\n<li><p>空间 如果要实现有单独a,单独b,和(a,b)联合的索引,那么看a,b哪个占用空间大,从而决定使用(a),(b,a)还是(b),(a,b).</p>\n</li>\n</ul>\n<h4 id=\"索引下推-ICP-index-condition-pushdown\"><a href=\"#索引下推-ICP-index-condition-pushdown\" class=\"headerlink\" title=\"索引下推 (ICP index condition pushdown)\"></a>索引下推 (ICP index condition pushdown)</h4><p>where的过滤条件如果在联合索引中存在,可以直接过滤,省去回表过滤的过程</p>\n<h4 id=\"普通索引和唯一索引\"><a href=\"#普通索引和唯一索引\" class=\"headerlink\" title=\"普通索引和唯一索引\"></a>普通索引和唯一索引</h4><p>结论:如果业务能够保证唯一,尽量用普通索引<br>原因:普通索引可以用到change buffer,change buffer可以减少磁盘的随机读.即假设一个page不在内存中,当更新或者插入时,不需要load page,只需要把更新放到change buffer中,有后台线程会定期merge change buffer 和 旧页.当下次需要读取旧page时,load到内存中后也会直接merge</p>\n<p>change buffer减少了磁盘io,更新和插入变为了直接操作内存.但不适用于写入之后就立马读取的业务场景,这样不仅未减少io,还增加了merge的过程</p>\n<p>唯一索引不会用到change buffer,需要每次读取page中的数据然后校验唯一性 </p>\n<h4 id=\"字符串字段加索引\"><a href=\"#字符串字段加索引\" class=\"headerlink\" title=\"字符串字段加索引\"></a>字符串字段加索引</h4><p>增加前缀索引,例如邮箱上边<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; alter table SUser add index index1(email);</span><br><span class=\"line\">或</span><br><span class=\"line\">mysql&gt; alter table SUser add index index2(email(6));</span><br></pre></td></tr></table></figure></p>\n<p>要点:</p>\n<ul>\n<li>定义好前缀长度,使其区分度足够高,这样既能节省空间,又不用增加太多的查询成本</li>\n<li>前缀长度短,省空间,但区分度不够,增加查询和回表的次数</li>\n<li>前缀长度长,查询成本低但是浪费空间</li>\n<li>另外,前缀索引必须回表查,用不上覆盖索引的优化</li>\n</ul>\n<p>计算区分度<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select count(distinct email) as L from SUser;</span><br><span class=\"line\">mysql&gt; select </span><br><span class=\"line\">  count(distinct left(email,4)）as L4,</span><br><span class=\"line\">  count(distinct left(email,5)）as L5,</span><br><span class=\"line\">  count(distinct left(email,6)）as L6,</span><br><span class=\"line\">  count(distinct left(email,7)）as L7,</span><br><span class=\"line\">from SUser;</span><br></pre></td></tr></table></figure></p>\n<p>特例:如果不需要范围查询,只需要等值查询,可以使用如下方法:</p>\n<ul>\n<li>倒序存储.例如身份证号只取前六位区分度不高,则可以使用倒序之后的六位</li>\n<li>哈希存储.新增加哈希字段,文中为crc32,则查询时首先走crc32字段的索引查,然后精确匹配(防止冲突)</li>\n</ul>\n<h2 id=\"索引使用注意事项\"><a href=\"#索引使用注意事项\" class=\"headerlink\" title=\"索引使用注意事项\"></a>索引使用注意事项</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">表结构</span><br><span class=\"line\">mysql&gt; CREATE TABLE `tradelog` (</span><br><span class=\"line\">  `id` int(11) NOT NULL,</span><br><span class=\"line\">  `tradeid` varchar(32) DEFAULT NULL,</span><br><span class=\"line\">  `operator` int(11) DEFAULT NULL,</span><br><span class=\"line\">  `t_modified` datetime DEFAULT NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  KEY `tradeid` (`tradeid`),</span><br><span class=\"line\">  KEY `t_modified` (`t_modified`)</span><br><span class=\"line\">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure>\n<p>索引字段做函数操作<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">不会用到id索引</span><br><span class=\"line\">select * from tradelog where id + 1 = 10000</span><br><span class=\"line\">不会用到t_modified索引</span><br><span class=\"line\">select count(*) from tradelog where month(t_modified)=7;</span><br><span class=\"line\">month替换为substr(t_modified,1,2)这样更易理解.即函数会破坏掉索引的有序性,MySQL认为扫描索引不再有效</span><br></pre></td></tr></table></figure></p>\n<p>隐式类型转换<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tradeid为varchar(32)</span><br><span class=\"line\">mysql&gt; select * from tradelog where tradeid=110717;</span><br></pre></td></tr></table></figure></p>\n<p>mysql中的转换规则是字符串转数字,于是上述语句相当于<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select * from tradelog where  CAST(tradid AS signed int) = 110717;</span><br></pre></td></tr></table></figure></p>\n<p>隐式编码类型转换</p>\n<p>一个表是utfmb4,一个是uft8,mysql会将utf8中的字段转换为uft8mb4,还是会触发上边的规则</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n"},{"title":"Mysql 其他","date":"2019-04-24T16:00:00.000Z","_content":"## 引言\n理解Mysql的 order by,count(*),MDL语句,onlineDDl,insert及自增主键\n参考极客时间**mysql45讲**之第6讲,13讲,14讲,16讲,17讲,29讲,31讲,33讲,39讲,40讲\n\n## 重建表\n```\n可以减少数据空洞,将复用的page清除掉\nalter table t engine=InnoDB；\n```\n* 持有MDL写锁\n* 降为MDL读锁\n* 做DDL操作\n* 升级成MDL写锁\n* 释放MDL锁\nonlineDDL\n重建过程中不再持有MDL写锁,而是将更新记录到一个临时缓冲区,最后重放.DDL操作过程中可以正常进行读写\n\n## 统计总行数\n* Myisam直接记录了总行数,innodb为什么不直接记录呢?\n    **innodb实现了mvcc,同一行对不同事务可见性不同,因此在不同事务中统计的总行数也不同**\n* show table status也可以显示table_rows,但是不准确.通过在N个page中统计行数取平均值然后乘以总的page数来计算\n\n* 那么,如何保存计数呢?首先需求是这样的,获取计数并且展示最新的100条数据.\n* 缓存保存:redis中保存计数,MySQL中保存数据.并发情况下会有计数中有但是数据没有或者反之的情况.\n* 将计数更新和数据插入放入一个事务中,由事务的隔离性保证\n\n### count(*),count(1),count(id),count(field)差别\n* count语义:聚合函数,根据字段返回值判断,如果不是null,+1\n\ncount(id),count(field)innodb会将id和field取出来传给server层,server层做统计\ncount（1)不需要取值\ncount（*)有做专门的优化,意思为取行数\n所以 count(*) 约等于 count(1) > count(id) > count(field)\n\n**聚合是在server层做的?**\n\n## 排序\n* sort_buffer_size决定排序空间,如果排序数据太大,则使用文件\n* max_length_for_sort_data该值决定需要查询的字段超过多长时会使用rowid排序\n\n\n排序分为如下两种:\n* 全字段排序 所有需要查询的字段都放到排序空间中,排序完成后直接返回\n* rowid排序 只将主键和需要排序的字段放入排序空间,排序完成后通过主键回表查询获取需要查询的字段然后返回.多了一个回表的过程,但会减少或不适用文件排序\n\nmysql优先选择全字段排序,因为回表会造成多余的io\n\n## 随机取值\n* order by rand()的实现原理\n```\nmysql> select word from words order by rand() limit 3;\n```\n1. 创建临时表,memory引擎,两字段,第一个字段是double类型随机数,依次取一个word生成随机数插入一行\n2. 取出临时表中数据根据随机数字段排序\n3. 取出排序后前三个位置的位置信息,从临时表取出返回\n**这个方法随着行数增加很耗时**\n\n\n直观考虑:\n生成三个行数范围内的随机数,依次取出.例如三个数分别为X1,X2,X3\n```\nselect word from words limit X1,1;\nselect word from words limit X2,1;\nselect word from words limit X3,1;\n```\n\n可优化为:\n假设X1,X2,X3最小为X1,最大为X3\n```\nselect word from words limit X1,X3-X1+1;\n```\n或者\n```\nselect id1,word from words limit X1,1;\nselect id2,word from words where id > id1 limit X2-X1,1\nselect id3,word from words where id > id2 limit X3-X2,1\n```\n\n**这些方法也是大数据分页时常用的套路**\n\nlimit N,如果N比较小的时候,5.6以后会使用优先队列排序算法,通过构造元素为N的最大或者最小堆,遍历一遍数据,就能获取到limit指定的N条数据\n\n## 如何判断一个数据库有故障\n\n* 外部检测不够及时\n* 直接select 1不行,因为无法判断innodb层是否可用\n```\ninnodb的并发线程上限,达到之后会阻塞其他线程.进入锁等待的线程不计入该计数\nset global innodb_thread_concurrency=3\n```\n* 查询语句不行,因为不能判断出来磁盘满这种情况\n* 只能通过写入语句判断\n\n* 内部检测\n```\n统计单次IO请求时间是否超过200ms\nmysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;\n```\n\n因为该统计值影响性能,所以只开启需要的统计\n```\nmysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';\n```\n## 误删库处理\n\n### 通过delete删除\n如果开启binlog_format=row和binlog_row_image=FULL,通过flashback可以恢复(修改binlog,反向操作,删改为insert)\n如何预防呢?\n* 将sql_safe_updates=on,delete或者update不带where或者where条件没有索引的话报错\n* SQL审计,开启general log,查看每一条sql\n\n### 通过truncate/drop删除\n\n不能通过flashback,只能使用 全量备份+mysqlbinlog（跳过清表语句）\n* mysqlbinlog 只能指定 -database但没法指定表\n* 只能单线程执行\n\n### 预防方法\n* 搭建延迟备库 CHANGE MASTER TO MASTER_DELAY = N,保持跟主库有N秒的延迟\n\n* 账号权限管控\n1. 开发只有DML权限,不给truncate/drop权限\n2. 通常只使用只读权限账号\n\n* 操作只能通过管理平台进行\n1. 删除表前必须先对表做改名操作,例如增加后缀 _to_be_deleted\n2. 只能通过管理平台删除,并且只能删除固定后缀的表\n\n### rm删除数据\n\n* 数据做跨机房、跨城市备份\n\n## show processlit\n* \"sending to client\" 客户端可能要求的数据多,处理逻辑慢,返回一条处理一把.通过设置服务端的net_buffer_length可以缓解,因为该状态是mysql的状态,如果调大该值,能完全保存数据,则认为已经发完了.或者客户端使用mysql_store_result将数据都保存到本地后再执行处理逻辑\n* \"sending data\"  一个查询开始后就会将状态置为此,所以有可能是执行语句在进行锁等待等情况 \n\n* lru策略:分为young/old两段,young区默认占5/8,新插入的page放到该处\n  old区策略:\n  ```\n  innodb_old_blocks_time\n  ```\n  该参数控制一个old区的page如果多长时间内被用到则移动到young区,默认1s\n\n## 自增主键能保证连续递增吗\n* 自增id什么时候分配?如果是insert执行的时候分配,那么t1插一行,t2插两行(t1插入在t2的两条插入之间),此时rollback t2,那么t1的id会变为  id id+1 id+3 id+5这种类型\n* 手动指定值插入id,也会造成不连续\n* 自增id的分配在唯一键的校验之前,当唯一键冲突时也会造成自增id不连续\n```\ninnodb_autoinc_lock_mode = 1\n0.自增锁语句执行完毕之后才释放\n1.自增锁申请之后立即释放.但是在insert into .. select ...或者load data ...或者 replace ..select...语句下等语句执行完才释放\n2.不论何种情况自增锁申请之后都立即释放 并发性能好但是需要保证binlog_format = row,在statement格式下会造成主备自增id不同\n```\ninsert into .. values (),(),()情况下会一次性将所有自增id分配\ninsert into ... select ...时会按1个2个4个级数递增的情况分配,如果分配多余就会造成自增id不连续\n\n如果binlog_format = statement,那么insert into ... select ...会将select的表加行锁和gap锁\n否则可能造成主备数据不一致\n\n\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Mysql-others.md","raw":"---\ntitle: Mysql 其他\ndate: 2019-04-25\ntags: Mysql\n---\n## 引言\n理解Mysql的 order by,count(*),MDL语句,onlineDDl,insert及自增主键\n参考极客时间**mysql45讲**之第6讲,13讲,14讲,16讲,17讲,29讲,31讲,33讲,39讲,40讲\n\n## 重建表\n```\n可以减少数据空洞,将复用的page清除掉\nalter table t engine=InnoDB；\n```\n* 持有MDL写锁\n* 降为MDL读锁\n* 做DDL操作\n* 升级成MDL写锁\n* 释放MDL锁\nonlineDDL\n重建过程中不再持有MDL写锁,而是将更新记录到一个临时缓冲区,最后重放.DDL操作过程中可以正常进行读写\n\n## 统计总行数\n* Myisam直接记录了总行数,innodb为什么不直接记录呢?\n    **innodb实现了mvcc,同一行对不同事务可见性不同,因此在不同事务中统计的总行数也不同**\n* show table status也可以显示table_rows,但是不准确.通过在N个page中统计行数取平均值然后乘以总的page数来计算\n\n* 那么,如何保存计数呢?首先需求是这样的,获取计数并且展示最新的100条数据.\n* 缓存保存:redis中保存计数,MySQL中保存数据.并发情况下会有计数中有但是数据没有或者反之的情况.\n* 将计数更新和数据插入放入一个事务中,由事务的隔离性保证\n\n### count(*),count(1),count(id),count(field)差别\n* count语义:聚合函数,根据字段返回值判断,如果不是null,+1\n\ncount(id),count(field)innodb会将id和field取出来传给server层,server层做统计\ncount（1)不需要取值\ncount（*)有做专门的优化,意思为取行数\n所以 count(*) 约等于 count(1) > count(id) > count(field)\n\n**聚合是在server层做的?**\n\n## 排序\n* sort_buffer_size决定排序空间,如果排序数据太大,则使用文件\n* max_length_for_sort_data该值决定需要查询的字段超过多长时会使用rowid排序\n\n\n排序分为如下两种:\n* 全字段排序 所有需要查询的字段都放到排序空间中,排序完成后直接返回\n* rowid排序 只将主键和需要排序的字段放入排序空间,排序完成后通过主键回表查询获取需要查询的字段然后返回.多了一个回表的过程,但会减少或不适用文件排序\n\nmysql优先选择全字段排序,因为回表会造成多余的io\n\n## 随机取值\n* order by rand()的实现原理\n```\nmysql> select word from words order by rand() limit 3;\n```\n1. 创建临时表,memory引擎,两字段,第一个字段是double类型随机数,依次取一个word生成随机数插入一行\n2. 取出临时表中数据根据随机数字段排序\n3. 取出排序后前三个位置的位置信息,从临时表取出返回\n**这个方法随着行数增加很耗时**\n\n\n直观考虑:\n生成三个行数范围内的随机数,依次取出.例如三个数分别为X1,X2,X3\n```\nselect word from words limit X1,1;\nselect word from words limit X2,1;\nselect word from words limit X3,1;\n```\n\n可优化为:\n假设X1,X2,X3最小为X1,最大为X3\n```\nselect word from words limit X1,X3-X1+1;\n```\n或者\n```\nselect id1,word from words limit X1,1;\nselect id2,word from words where id > id1 limit X2-X1,1\nselect id3,word from words where id > id2 limit X3-X2,1\n```\n\n**这些方法也是大数据分页时常用的套路**\n\nlimit N,如果N比较小的时候,5.6以后会使用优先队列排序算法,通过构造元素为N的最大或者最小堆,遍历一遍数据,就能获取到limit指定的N条数据\n\n## 如何判断一个数据库有故障\n\n* 外部检测不够及时\n* 直接select 1不行,因为无法判断innodb层是否可用\n```\ninnodb的并发线程上限,达到之后会阻塞其他线程.进入锁等待的线程不计入该计数\nset global innodb_thread_concurrency=3\n```\n* 查询语句不行,因为不能判断出来磁盘满这种情况\n* 只能通过写入语句判断\n\n* 内部检测\n```\n统计单次IO请求时间是否超过200ms\nmysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;\n```\n\n因为该统计值影响性能,所以只开启需要的统计\n```\nmysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';\n```\n## 误删库处理\n\n### 通过delete删除\n如果开启binlog_format=row和binlog_row_image=FULL,通过flashback可以恢复(修改binlog,反向操作,删改为insert)\n如何预防呢?\n* 将sql_safe_updates=on,delete或者update不带where或者where条件没有索引的话报错\n* SQL审计,开启general log,查看每一条sql\n\n### 通过truncate/drop删除\n\n不能通过flashback,只能使用 全量备份+mysqlbinlog（跳过清表语句）\n* mysqlbinlog 只能指定 -database但没法指定表\n* 只能单线程执行\n\n### 预防方法\n* 搭建延迟备库 CHANGE MASTER TO MASTER_DELAY = N,保持跟主库有N秒的延迟\n\n* 账号权限管控\n1. 开发只有DML权限,不给truncate/drop权限\n2. 通常只使用只读权限账号\n\n* 操作只能通过管理平台进行\n1. 删除表前必须先对表做改名操作,例如增加后缀 _to_be_deleted\n2. 只能通过管理平台删除,并且只能删除固定后缀的表\n\n### rm删除数据\n\n* 数据做跨机房、跨城市备份\n\n## show processlit\n* \"sending to client\" 客户端可能要求的数据多,处理逻辑慢,返回一条处理一把.通过设置服务端的net_buffer_length可以缓解,因为该状态是mysql的状态,如果调大该值,能完全保存数据,则认为已经发完了.或者客户端使用mysql_store_result将数据都保存到本地后再执行处理逻辑\n* \"sending data\"  一个查询开始后就会将状态置为此,所以有可能是执行语句在进行锁等待等情况 \n\n* lru策略:分为young/old两段,young区默认占5/8,新插入的page放到该处\n  old区策略:\n  ```\n  innodb_old_blocks_time\n  ```\n  该参数控制一个old区的page如果多长时间内被用到则移动到young区,默认1s\n\n## 自增主键能保证连续递增吗\n* 自增id什么时候分配?如果是insert执行的时候分配,那么t1插一行,t2插两行(t1插入在t2的两条插入之间),此时rollback t2,那么t1的id会变为  id id+1 id+3 id+5这种类型\n* 手动指定值插入id,也会造成不连续\n* 自增id的分配在唯一键的校验之前,当唯一键冲突时也会造成自增id不连续\n```\ninnodb_autoinc_lock_mode = 1\n0.自增锁语句执行完毕之后才释放\n1.自增锁申请之后立即释放.但是在insert into .. select ...或者load data ...或者 replace ..select...语句下等语句执行完才释放\n2.不论何种情况自增锁申请之后都立即释放 并发性能好但是需要保证binlog_format = row,在statement格式下会造成主备自增id不同\n```\ninsert into .. values (),(),()情况下会一次性将所有自增id分配\ninsert into ... select ...时会按1个2个4个级数递增的情况分配,如果分配多余就会造成自增id不连续\n\n如果binlog_format = statement,那么insert into ... select ...会将select的表加行锁和gap锁\n否则可能造成主备数据不一致\n\n\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Mysql-others","published":1,"updated":"2019-04-25T09:32:17.061Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z940002bms6ajm914lj","content":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的 order by,count(*),MDL语句,onlineDDl,insert及自增主键<br>参考极客时间<strong>mysql45讲</strong>之第6讲,13讲,14讲,16讲,17讲,29讲,31讲,33讲,39讲,40讲</p>\n<h2 id=\"重建表\"><a href=\"#重建表\" class=\"headerlink\" title=\"重建表\"></a>重建表</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">可以减少数据空洞,将复用的page清除掉</span><br><span class=\"line\">alter table t engine=InnoDB；</span><br></pre></td></tr></table></figure>\n<ul>\n<li>持有MDL写锁</li>\n<li>降为MDL读锁</li>\n<li>做DDL操作</li>\n<li>升级成MDL写锁</li>\n<li>释放MDL锁<br>onlineDDL<br>重建过程中不再持有MDL写锁,而是将更新记录到一个临时缓冲区,最后重放.DDL操作过程中可以正常进行读写</li>\n</ul>\n<h2 id=\"统计总行数\"><a href=\"#统计总行数\" class=\"headerlink\" title=\"统计总行数\"></a>统计总行数</h2><ul>\n<li>Myisam直接记录了总行数,innodb为什么不直接记录呢?<br>  <strong>innodb实现了mvcc,同一行对不同事务可见性不同,因此在不同事务中统计的总行数也不同</strong></li>\n<li><p>show table status也可以显示table_rows,但是不准确.通过在N个page中统计行数取平均值然后乘以总的page数来计算</p>\n</li>\n<li><p>那么,如何保存计数呢?首先需求是这样的,获取计数并且展示最新的100条数据.</p>\n</li>\n<li>缓存保存:redis中保存计数,MySQL中保存数据.并发情况下会有计数中有但是数据没有或者反之的情况.</li>\n<li>将计数更新和数据插入放入一个事务中,由事务的隔离性保证</li>\n</ul>\n<h3 id=\"count-count-1-count-id-count-field-差别\"><a href=\"#count-count-1-count-id-count-field-差别\" class=\"headerlink\" title=\"count(*),count(1),count(id),count(field)差别\"></a>count(*),count(1),count(id),count(field)差别</h3><ul>\n<li>count语义:聚合函数,根据字段返回值判断,如果不是null,+1</li>\n</ul>\n<p>count(id),count(field)innodb会将id和field取出来传给server层,server层做统计<br>count（1)不需要取值<br>count（<em>)有做专门的优化,意思为取行数<br>所以 count(</em>) 约等于 count(1) &gt; count(id) &gt; count(field)</p>\n<p><strong>聚合是在server层做的?</strong></p>\n<h2 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h2><ul>\n<li>sort_buffer_size决定排序空间,如果排序数据太大,则使用文件</li>\n<li>max_length_for_sort_data该值决定需要查询的字段超过多长时会使用rowid排序</li>\n</ul>\n<p>排序分为如下两种:</p>\n<ul>\n<li>全字段排序 所有需要查询的字段都放到排序空间中,排序完成后直接返回</li>\n<li>rowid排序 只将主键和需要排序的字段放入排序空间,排序完成后通过主键回表查询获取需要查询的字段然后返回.多了一个回表的过程,但会减少或不适用文件排序</li>\n</ul>\n<p>mysql优先选择全字段排序,因为回表会造成多余的io</p>\n<h2 id=\"随机取值\"><a href=\"#随机取值\" class=\"headerlink\" title=\"随机取值\"></a>随机取值</h2><ul>\n<li>order by rand()的实现原理<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select word from words order by rand() limit 3;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li>创建临时表,memory引擎,两字段,第一个字段是double类型随机数,依次取一个word生成随机数插入一行</li>\n<li>取出临时表中数据根据随机数字段排序</li>\n<li>取出排序后前三个位置的位置信息,从临时表取出返回<br><strong>这个方法随着行数增加很耗时</strong></li>\n</ol>\n<p>直观考虑:<br>生成三个行数范围内的随机数,依次取出.例如三个数分别为X1,X2,X3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select word from words limit X1,1;</span><br><span class=\"line\">select word from words limit X2,1;</span><br><span class=\"line\">select word from words limit X3,1;</span><br></pre></td></tr></table></figure></p>\n<p>可优化为:<br>假设X1,X2,X3最小为X1,最大为X3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select word from words limit X1,X3-X1+1;</span><br></pre></td></tr></table></figure></p>\n<p>或者<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select id1,word from words limit X1,1;</span><br><span class=\"line\">select id2,word from words where id &gt; id1 limit X2-X1,1</span><br><span class=\"line\">select id3,word from words where id &gt; id2 limit X3-X2,1</span><br></pre></td></tr></table></figure></p>\n<p><strong>这些方法也是大数据分页时常用的套路</strong></p>\n<p>limit N,如果N比较小的时候,5.6以后会使用优先队列排序算法,通过构造元素为N的最大或者最小堆,遍历一遍数据,就能获取到limit指定的N条数据</p>\n<h2 id=\"如何判断一个数据库有故障\"><a href=\"#如何判断一个数据库有故障\" class=\"headerlink\" title=\"如何判断一个数据库有故障\"></a>如何判断一个数据库有故障</h2><ul>\n<li>外部检测不够及时</li>\n<li><p>直接select 1不行,因为无法判断innodb层是否可用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb的并发线程上限,达到之后会阻塞其他线程.进入锁等待的线程不计入该计数</span><br><span class=\"line\">set global innodb_thread_concurrency=3</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查询语句不行,因为不能判断出来磁盘满这种情况</p>\n</li>\n<li><p>只能通过写入语句判断</p>\n</li>\n<li><p>内部检测</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">统计单次IO请求时间是否超过200ms</span><br><span class=\"line\">mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in (&apos;wait/io/file/innodb/innodb_log_file&apos;,&apos;wait/io/file/sql/binlog&apos;) and MAX_TIMER_WAIT&gt;200*1000000000;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>因为该统计值影响性能,所以只开启需要的统计<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; update setup_instruments set ENABLED=&apos;YES&apos;, Timed=&apos;YES&apos; where name like &apos;%wait/io/file/innodb/innodb_log_file%&apos;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"误删库处理\"><a href=\"#误删库处理\" class=\"headerlink\" title=\"误删库处理\"></a>误删库处理</h2><h3 id=\"通过delete删除\"><a href=\"#通过delete删除\" class=\"headerlink\" title=\"通过delete删除\"></a>通过delete删除</h3><p>如果开启binlog_format=row和binlog_row_image=FULL,通过flashback可以恢复(修改binlog,反向操作,删改为insert)<br>如何预防呢?</p>\n<ul>\n<li>将sql_safe_updates=on,delete或者update不带where或者where条件没有索引的话报错</li>\n<li>SQL审计,开启general log,查看每一条sql</li>\n</ul>\n<h3 id=\"通过truncate-drop删除\"><a href=\"#通过truncate-drop删除\" class=\"headerlink\" title=\"通过truncate/drop删除\"></a>通过truncate/drop删除</h3><p>不能通过flashback,只能使用 全量备份+mysqlbinlog（跳过清表语句）</p>\n<ul>\n<li>mysqlbinlog 只能指定 -database但没法指定表</li>\n<li>只能单线程执行</li>\n</ul>\n<h3 id=\"预防方法\"><a href=\"#预防方法\" class=\"headerlink\" title=\"预防方法\"></a>预防方法</h3><ul>\n<li><p>搭建延迟备库 CHANGE MASTER TO MASTER_DELAY = N,保持跟主库有N秒的延迟</p>\n</li>\n<li><p>账号权限管控</p>\n</li>\n</ul>\n<ol>\n<li>开发只有DML权限,不给truncate/drop权限</li>\n<li>通常只使用只读权限账号</li>\n</ol>\n<ul>\n<li>操作只能通过管理平台进行</li>\n</ul>\n<ol>\n<li>删除表前必须先对表做改名操作,例如增加后缀 _to_be_deleted</li>\n<li>只能通过管理平台删除,并且只能删除固定后缀的表</li>\n</ol>\n<h3 id=\"rm删除数据\"><a href=\"#rm删除数据\" class=\"headerlink\" title=\"rm删除数据\"></a>rm删除数据</h3><ul>\n<li>数据做跨机房、跨城市备份</li>\n</ul>\n<h2 id=\"show-processlit\"><a href=\"#show-processlit\" class=\"headerlink\" title=\"show processlit\"></a>show processlit</h2><ul>\n<li>“sending to client” 客户端可能要求的数据多,处理逻辑慢,返回一条处理一把.通过设置服务端的net_buffer_length可以缓解,因为该状态是mysql的状态,如果调大该值,能完全保存数据,则认为已经发完了.或者客户端使用mysql_store_result将数据都保存到本地后再执行处理逻辑</li>\n<li><p>“sending data”  一个查询开始后就会将状态置为此,所以有可能是执行语句在进行锁等待等情况 </p>\n</li>\n<li><p>lru策略:分为young/old两段,young区默认占5/8,新插入的page放到该处<br>old区策略:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_old_blocks_time</span><br></pre></td></tr></table></figure>\n<p>该参数控制一个old区的page如果多长时间内被用到则移动到young区,默认1s</p>\n</li>\n</ul>\n<h2 id=\"自增主键能保证连续递增吗\"><a href=\"#自增主键能保证连续递增吗\" class=\"headerlink\" title=\"自增主键能保证连续递增吗\"></a>自增主键能保证连续递增吗</h2><ul>\n<li>自增id什么时候分配?如果是insert执行的时候分配,那么t1插一行,t2插两行(t1插入在t2的两条插入之间),此时rollback t2,那么t1的id会变为  id id+1 id+3 id+5这种类型</li>\n<li>手动指定值插入id,也会造成不连续</li>\n<li>自增id的分配在唯一键的校验之前,当唯一键冲突时也会造成自增id不连续<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_autoinc_lock_mode = 1</span><br><span class=\"line\">0.自增锁语句执行完毕之后才释放</span><br><span class=\"line\">1.自增锁申请之后立即释放.但是在insert into .. select ...或者load data ...或者 replace ..select...语句下等语句执行完才释放</span><br><span class=\"line\">2.不论何种情况自增锁申请之后都立即释放 并发性能好但是需要保证binlog_format = row,在statement格式下会造成主备自增id不同</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>insert into .. values (),(),()情况下会一次性将所有自增id分配<br>insert into … select …时会按1个2个4个级数递增的情况分配,如果分配多余就会造成自增id不连续</p>\n<p>如果binlog_format = statement,那么insert into … select …会将select的表加行锁和gap锁<br>否则可能造成主备数据不一致</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n<p><code>`</code></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的 order by,count(*),MDL语句,onlineDDl,insert及自增主键<br>参考极客时间<strong>mysql45讲</strong>之第6讲,13讲,14讲,16讲,17讲,29讲,31讲,33讲,39讲,40讲</p>\n<h2 id=\"重建表\"><a href=\"#重建表\" class=\"headerlink\" title=\"重建表\"></a>重建表</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">可以减少数据空洞,将复用的page清除掉</span><br><span class=\"line\">alter table t engine=InnoDB；</span><br></pre></td></tr></table></figure>\n<ul>\n<li>持有MDL写锁</li>\n<li>降为MDL读锁</li>\n<li>做DDL操作</li>\n<li>升级成MDL写锁</li>\n<li>释放MDL锁<br>onlineDDL<br>重建过程中不再持有MDL写锁,而是将更新记录到一个临时缓冲区,最后重放.DDL操作过程中可以正常进行读写</li>\n</ul>\n<h2 id=\"统计总行数\"><a href=\"#统计总行数\" class=\"headerlink\" title=\"统计总行数\"></a>统计总行数</h2><ul>\n<li>Myisam直接记录了总行数,innodb为什么不直接记录呢?<br>  <strong>innodb实现了mvcc,同一行对不同事务可见性不同,因此在不同事务中统计的总行数也不同</strong></li>\n<li><p>show table status也可以显示table_rows,但是不准确.通过在N个page中统计行数取平均值然后乘以总的page数来计算</p>\n</li>\n<li><p>那么,如何保存计数呢?首先需求是这样的,获取计数并且展示最新的100条数据.</p>\n</li>\n<li>缓存保存:redis中保存计数,MySQL中保存数据.并发情况下会有计数中有但是数据没有或者反之的情况.</li>\n<li>将计数更新和数据插入放入一个事务中,由事务的隔离性保证</li>\n</ul>\n<h3 id=\"count-count-1-count-id-count-field-差别\"><a href=\"#count-count-1-count-id-count-field-差别\" class=\"headerlink\" title=\"count(*),count(1),count(id),count(field)差别\"></a>count(*),count(1),count(id),count(field)差别</h3><ul>\n<li>count语义:聚合函数,根据字段返回值判断,如果不是null,+1</li>\n</ul>\n<p>count(id),count(field)innodb会将id和field取出来传给server层,server层做统计<br>count（1)不需要取值<br>count（<em>)有做专门的优化,意思为取行数<br>所以 count(</em>) 约等于 count(1) &gt; count(id) &gt; count(field)</p>\n<p><strong>聚合是在server层做的?</strong></p>\n<h2 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h2><ul>\n<li>sort_buffer_size决定排序空间,如果排序数据太大,则使用文件</li>\n<li>max_length_for_sort_data该值决定需要查询的字段超过多长时会使用rowid排序</li>\n</ul>\n<p>排序分为如下两种:</p>\n<ul>\n<li>全字段排序 所有需要查询的字段都放到排序空间中,排序完成后直接返回</li>\n<li>rowid排序 只将主键和需要排序的字段放入排序空间,排序完成后通过主键回表查询获取需要查询的字段然后返回.多了一个回表的过程,但会减少或不适用文件排序</li>\n</ul>\n<p>mysql优先选择全字段排序,因为回表会造成多余的io</p>\n<h2 id=\"随机取值\"><a href=\"#随机取值\" class=\"headerlink\" title=\"随机取值\"></a>随机取值</h2><ul>\n<li>order by rand()的实现原理<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; select word from words order by rand() limit 3;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li>创建临时表,memory引擎,两字段,第一个字段是double类型随机数,依次取一个word生成随机数插入一行</li>\n<li>取出临时表中数据根据随机数字段排序</li>\n<li>取出排序后前三个位置的位置信息,从临时表取出返回<br><strong>这个方法随着行数增加很耗时</strong></li>\n</ol>\n<p>直观考虑:<br>生成三个行数范围内的随机数,依次取出.例如三个数分别为X1,X2,X3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select word from words limit X1,1;</span><br><span class=\"line\">select word from words limit X2,1;</span><br><span class=\"line\">select word from words limit X3,1;</span><br></pre></td></tr></table></figure></p>\n<p>可优化为:<br>假设X1,X2,X3最小为X1,最大为X3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select word from words limit X1,X3-X1+1;</span><br></pre></td></tr></table></figure></p>\n<p>或者<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select id1,word from words limit X1,1;</span><br><span class=\"line\">select id2,word from words where id &gt; id1 limit X2-X1,1</span><br><span class=\"line\">select id3,word from words where id &gt; id2 limit X3-X2,1</span><br></pre></td></tr></table></figure></p>\n<p><strong>这些方法也是大数据分页时常用的套路</strong></p>\n<p>limit N,如果N比较小的时候,5.6以后会使用优先队列排序算法,通过构造元素为N的最大或者最小堆,遍历一遍数据,就能获取到limit指定的N条数据</p>\n<h2 id=\"如何判断一个数据库有故障\"><a href=\"#如何判断一个数据库有故障\" class=\"headerlink\" title=\"如何判断一个数据库有故障\"></a>如何判断一个数据库有故障</h2><ul>\n<li>外部检测不够及时</li>\n<li><p>直接select 1不行,因为无法判断innodb层是否可用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb的并发线程上限,达到之后会阻塞其他线程.进入锁等待的线程不计入该计数</span><br><span class=\"line\">set global innodb_thread_concurrency=3</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查询语句不行,因为不能判断出来磁盘满这种情况</p>\n</li>\n<li><p>只能通过写入语句判断</p>\n</li>\n<li><p>内部检测</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">统计单次IO请求时间是否超过200ms</span><br><span class=\"line\">mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in (&apos;wait/io/file/innodb/innodb_log_file&apos;,&apos;wait/io/file/sql/binlog&apos;) and MAX_TIMER_WAIT&gt;200*1000000000;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>因为该统计值影响性能,所以只开启需要的统计<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; update setup_instruments set ENABLED=&apos;YES&apos;, Timed=&apos;YES&apos; where name like &apos;%wait/io/file/innodb/innodb_log_file%&apos;;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"误删库处理\"><a href=\"#误删库处理\" class=\"headerlink\" title=\"误删库处理\"></a>误删库处理</h2><h3 id=\"通过delete删除\"><a href=\"#通过delete删除\" class=\"headerlink\" title=\"通过delete删除\"></a>通过delete删除</h3><p>如果开启binlog_format=row和binlog_row_image=FULL,通过flashback可以恢复(修改binlog,反向操作,删改为insert)<br>如何预防呢?</p>\n<ul>\n<li>将sql_safe_updates=on,delete或者update不带where或者where条件没有索引的话报错</li>\n<li>SQL审计,开启general log,查看每一条sql</li>\n</ul>\n<h3 id=\"通过truncate-drop删除\"><a href=\"#通过truncate-drop删除\" class=\"headerlink\" title=\"通过truncate/drop删除\"></a>通过truncate/drop删除</h3><p>不能通过flashback,只能使用 全量备份+mysqlbinlog（跳过清表语句）</p>\n<ul>\n<li>mysqlbinlog 只能指定 -database但没法指定表</li>\n<li>只能单线程执行</li>\n</ul>\n<h3 id=\"预防方法\"><a href=\"#预防方法\" class=\"headerlink\" title=\"预防方法\"></a>预防方法</h3><ul>\n<li><p>搭建延迟备库 CHANGE MASTER TO MASTER_DELAY = N,保持跟主库有N秒的延迟</p>\n</li>\n<li><p>账号权限管控</p>\n</li>\n</ul>\n<ol>\n<li>开发只有DML权限,不给truncate/drop权限</li>\n<li>通常只使用只读权限账号</li>\n</ol>\n<ul>\n<li>操作只能通过管理平台进行</li>\n</ul>\n<ol>\n<li>删除表前必须先对表做改名操作,例如增加后缀 _to_be_deleted</li>\n<li>只能通过管理平台删除,并且只能删除固定后缀的表</li>\n</ol>\n<h3 id=\"rm删除数据\"><a href=\"#rm删除数据\" class=\"headerlink\" title=\"rm删除数据\"></a>rm删除数据</h3><ul>\n<li>数据做跨机房、跨城市备份</li>\n</ul>\n<h2 id=\"show-processlit\"><a href=\"#show-processlit\" class=\"headerlink\" title=\"show processlit\"></a>show processlit</h2><ul>\n<li>“sending to client” 客户端可能要求的数据多,处理逻辑慢,返回一条处理一把.通过设置服务端的net_buffer_length可以缓解,因为该状态是mysql的状态,如果调大该值,能完全保存数据,则认为已经发完了.或者客户端使用mysql_store_result将数据都保存到本地后再执行处理逻辑</li>\n<li><p>“sending data”  一个查询开始后就会将状态置为此,所以有可能是执行语句在进行锁等待等情况 </p>\n</li>\n<li><p>lru策略:分为young/old两段,young区默认占5/8,新插入的page放到该处<br>old区策略:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_old_blocks_time</span><br></pre></td></tr></table></figure>\n<p>该参数控制一个old区的page如果多长时间内被用到则移动到young区,默认1s</p>\n</li>\n</ul>\n<h2 id=\"自增主键能保证连续递增吗\"><a href=\"#自增主键能保证连续递增吗\" class=\"headerlink\" title=\"自增主键能保证连续递增吗\"></a>自增主键能保证连续递增吗</h2><ul>\n<li>自增id什么时候分配?如果是insert执行的时候分配,那么t1插一行,t2插两行(t1插入在t2的两条插入之间),此时rollback t2,那么t1的id会变为  id id+1 id+3 id+5这种类型</li>\n<li>手动指定值插入id,也会造成不连续</li>\n<li>自增id的分配在唯一键的校验之前,当唯一键冲突时也会造成自增id不连续<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_autoinc_lock_mode = 1</span><br><span class=\"line\">0.自增锁语句执行完毕之后才释放</span><br><span class=\"line\">1.自增锁申请之后立即释放.但是在insert into .. select ...或者load data ...或者 replace ..select...语句下等语句执行完才释放</span><br><span class=\"line\">2.不论何种情况自增锁申请之后都立即释放 并发性能好但是需要保证binlog_format = row,在statement格式下会造成主备自增id不同</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>insert into .. values (),(),()情况下会一次性将所有自增id分配<br>insert into … select …时会按1个2个4个级数递增的情况分配,如果分配多余就会造成自增id不连续</p>\n<p>如果binlog_format = statement,那么insert into … select …会将select的表加行锁和gap锁<br>否则可能造成主备数据不一致</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n<p><code>`</code></p>\n"},{"title":"Mysql redo binlog 主从及其延迟","date":"2019-04-21T16:00:00.000Z","_content":"## 引言\n理解Mysql的redo log,binlog,主从及其延迟\n参考极客时间**mysql45讲**之第2讲,12讲,15讲,23讲,24讲,25讲,26讲,27讲,28讲\n\n## redolog与binlog\n\n### redolog\n* 固定大小,循环写入\n* redolog相比直接在磁盘中写入修改的好处是将随机写转换为顺序写,并且有组提交的优化\n* checkpoint是redo中的一个位置,该位置之前的redolog可以覆盖掉,因为已经写入了磁盘\n\n### binlog\n* statement 完整的语句\n* row 行的内容 update时是一行修改前的一行修改后的  insert和delete也是会将完整的数据记录下来\n* 因为statement格式可能会导致主从上执行该语句时产生不一致,所以有了row格式.但是row格式占用空间过大,所以有了mixed格式,由Mysql决定是使用statement还是row\n* row格式有个好处是会保存完整的数据,所以只要反向操作就可以恢复数据.因此还是建议保存为row格式\n* 事务提交的时候才会刷binlog,如果一个事务很大,必须等事务执行完成才写binlog,才会传给从,会导致主从延迟过大\n```\n回放mysql binlog\nmysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n```\n\n### redolog与binlog的差异\n\n* 一个是引擎层的日志,一个是server层的日志\n* 一个是物理日志,即某个数据页做了什么修改;一个是逻辑日志,记录语句的原始逻辑\n* 一个是循环写,一个是追加写\n\n### 两阶段提交\n* 写入redolog,处于prepare状态\n* 写入binlog\n* 提交事务,处于commit状态\n\n处于commit状态的直接恢复,如果处于prepare但是未commit的,根据XID找binlog中的事务是否完整,完整则认为该事务是可以提交的,如果不完整则回滚之\n```\ninnodb_flush_log_at_trx_commit = 1 即每次事务提交时的redolog都落盘\ninnodb_flush_log_at_trx_commit = 0 即每次事务提交时的redolog都只在redo log buffer中\ninnodb_flush_log_at_trx_commit = 2 即每次事务提交时的redolog都只write,在操作系统的page cache中\ninnodb有一个后台线程会定期将redo log buffer中的数据write到page cache,然后fsync到磁盘.即使一个事务未提交也会刷盘\n\n\nsync_binlog = 1 每次事务的binlog都落盘\nsync_binlog = 0 只write不fsync,由操作系统定期去fsync\nsync_binlog = N (N>=2)只write,累计N个事务后才会fsync\n```\n### fsync的优化\n由于fsync很耗时,所以redo有一个组提交的优化,刷新时会将其他事务写的log一起刷新到磁盘\n\n\n## MySQL为什么有时候会\"抖\"一下\n\n为什么某条SQL语句会突然变慢了\n* redo过小,导致write pos即将超出checkpoint,所以需要刷新脏页,推进checkpoint\n* 内存空间buffer pool过小,导致需要刷脏页 \n  mysql中如果内存中有数据,则数据肯定是最新的,如果内存中没有数据,则磁盘中的文件是新的(得经过change buffer merge之后)\n\n注意还有两种情况也会刷新脏页:\n* 系统空闲时,刷脏页频率快导致\n* 正常关机也会刷脏页\n\n```\ninnodb_io_capacity 该参数定义mysql所在主机的io能力 SSD可设置为20000,机械硬盘为300\ninnodb_max_dirty_pages_pct控制脏页比例上限\nInnodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total计算脏页比例\n根据最新写入日志的lsn(log sequence number)和checkpoint相减的值判断checkpoint进度\ninnodb_flush_neighbors控制是否在刷脏页的时候刷新邻居页,SSD建议关闭\n```\n\n## 主从延迟\n* 备库配置差\n* 备库配置同主库,但压力过大,例如执行了大量的报表查询及备份等工作.可以通过设置一主多从来分摊压力\n* 大事务,即如果主上边执行10分钟,从上也可能执行10分钟,导致延迟.例如删除大量数据,再例如大表的DDL,会占着表的MDL写锁,导致没法对该表进行读写,导致主从延迟\n* 从库的并行复制能力\n\n### 并行复制\n* io thread负责将内容写入relay log,sql thread负责回放\n* slave_parallel_workers设置5.6之后并行回放的线程个数\n基本原则:\n* 以transaction为基本单位,否则会影响事务的隔离性\n* 对同一行更新操作的不同事务需要放到同一个worker\n\n按表分发:\n* 每个worker有一个hash表,记录db-table:事务个数\n* 分发时,如果没有任何冲突,直接分配给空闲worker\n* 如果有多个worker有table的更新,则等待直到只有一个worker更新该表\n* 分配给该worker\n\n如果碰到热点表,会退化为单线程模式\n\n按行分发:\n* 每个worker同样有hash表,记录db-table:各个唯一键+各个唯一值.有多少唯一值记录多少项\n\n\nmysql5.7:\nslave-parallel-type\n* DATABASE 按库并行复制\n* LOGICAL_CLOCK 模拟主库的组提交,同时处于commit状态的肯定可以并行\n\n##主从切换\n\n找同步位点\n\n主动跳过一个事务:\n```\nset global sql_slave_skip_counter=1;\nstart slave;\n\n```\n```\nslave_skip_errors 跳过1032/1062错误,即插入时唯一键冲突/删除时找不到行\n```\n上述两种方式tricky,并且容易造成错误\n\n5.6可以开启gtid:\n```\ngtid_mode=on\nenforce_gtid_consistency=on\n```\n开启gtid模式\n如果有冲突,跳过冲突的gtid方法:\n```\nset gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';\nbegin;\ncommit;\nset gtid_next=automatic;\nstart slave;\n```\n该事务aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10就以空事务的状态加入了从的已执行事务集合中\n\n有了gtid,备库不需要指定位点,由主库根据差集取出备库需要执行的gtid,然后开始主从同步\n\n## 解决过期读的问题\n\n* 强制走主\n* 判断sbm,seconds_behind_master,当没有延迟时再去读,但是间隔是s,可能会不精确\n* 对比位点,确保同步过来的已经全部执行.只能确定已经同步的执行完了,有可能还有未同步的\n* 对比获取到的gtid_set和回放到的gtid_set,判断是否已经全部执行,只能确定已经同步的执行完了,有可能还有未同步的\n* 结合semi-sync(主的binlog必须已经传给至少一个从,从回复ack),一主多从不适用.\n* 上述除了强制走主的方案,如果并发量大,可能会看到位点,sbm,gtid一直不同步的情况\n终极大法:\n* 等主库位点\n```\nselect master_pos_wait(file, pos[, timeout]);\n```\n如果能够知道某条命令执行后的位点,在从库执行该命令,异常返回null,超过Ns返回-1,已经执行过返回0\n所以如果>=0,则可以在从库开始查询了,否则放弃或者走主\n\n5.7.6开始允许执行完后把gtid返回客户端\n```\n select wait_for_executed_gtid_set(gtid_set, 1);\n session_track_gtids = OWN_GTID\n但得从API中解析出来,具体得看相应的API接口\n```\n超时返回1,执行返回0\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n","source":"_posts/Mysql-redo-binlog-master-slave.md","raw":"---\ntitle: Mysql redo binlog 主从及其延迟\ndate: 2019-04-22 \ntags: Mysql\n---\n## 引言\n理解Mysql的redo log,binlog,主从及其延迟\n参考极客时间**mysql45讲**之第2讲,12讲,15讲,23讲,24讲,25讲,26讲,27讲,28讲\n\n## redolog与binlog\n\n### redolog\n* 固定大小,循环写入\n* redolog相比直接在磁盘中写入修改的好处是将随机写转换为顺序写,并且有组提交的优化\n* checkpoint是redo中的一个位置,该位置之前的redolog可以覆盖掉,因为已经写入了磁盘\n\n### binlog\n* statement 完整的语句\n* row 行的内容 update时是一行修改前的一行修改后的  insert和delete也是会将完整的数据记录下来\n* 因为statement格式可能会导致主从上执行该语句时产生不一致,所以有了row格式.但是row格式占用空间过大,所以有了mixed格式,由Mysql决定是使用statement还是row\n* row格式有个好处是会保存完整的数据,所以只要反向操作就可以恢复数据.因此还是建议保存为row格式\n* 事务提交的时候才会刷binlog,如果一个事务很大,必须等事务执行完成才写binlog,才会传给从,会导致主从延迟过大\n```\n回放mysql binlog\nmysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n```\n\n### redolog与binlog的差异\n\n* 一个是引擎层的日志,一个是server层的日志\n* 一个是物理日志,即某个数据页做了什么修改;一个是逻辑日志,记录语句的原始逻辑\n* 一个是循环写,一个是追加写\n\n### 两阶段提交\n* 写入redolog,处于prepare状态\n* 写入binlog\n* 提交事务,处于commit状态\n\n处于commit状态的直接恢复,如果处于prepare但是未commit的,根据XID找binlog中的事务是否完整,完整则认为该事务是可以提交的,如果不完整则回滚之\n```\ninnodb_flush_log_at_trx_commit = 1 即每次事务提交时的redolog都落盘\ninnodb_flush_log_at_trx_commit = 0 即每次事务提交时的redolog都只在redo log buffer中\ninnodb_flush_log_at_trx_commit = 2 即每次事务提交时的redolog都只write,在操作系统的page cache中\ninnodb有一个后台线程会定期将redo log buffer中的数据write到page cache,然后fsync到磁盘.即使一个事务未提交也会刷盘\n\n\nsync_binlog = 1 每次事务的binlog都落盘\nsync_binlog = 0 只write不fsync,由操作系统定期去fsync\nsync_binlog = N (N>=2)只write,累计N个事务后才会fsync\n```\n### fsync的优化\n由于fsync很耗时,所以redo有一个组提交的优化,刷新时会将其他事务写的log一起刷新到磁盘\n\n\n## MySQL为什么有时候会\"抖\"一下\n\n为什么某条SQL语句会突然变慢了\n* redo过小,导致write pos即将超出checkpoint,所以需要刷新脏页,推进checkpoint\n* 内存空间buffer pool过小,导致需要刷脏页 \n  mysql中如果内存中有数据,则数据肯定是最新的,如果内存中没有数据,则磁盘中的文件是新的(得经过change buffer merge之后)\n\n注意还有两种情况也会刷新脏页:\n* 系统空闲时,刷脏页频率快导致\n* 正常关机也会刷脏页\n\n```\ninnodb_io_capacity 该参数定义mysql所在主机的io能力 SSD可设置为20000,机械硬盘为300\ninnodb_max_dirty_pages_pct控制脏页比例上限\nInnodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total计算脏页比例\n根据最新写入日志的lsn(log sequence number)和checkpoint相减的值判断checkpoint进度\ninnodb_flush_neighbors控制是否在刷脏页的时候刷新邻居页,SSD建议关闭\n```\n\n## 主从延迟\n* 备库配置差\n* 备库配置同主库,但压力过大,例如执行了大量的报表查询及备份等工作.可以通过设置一主多从来分摊压力\n* 大事务,即如果主上边执行10分钟,从上也可能执行10分钟,导致延迟.例如删除大量数据,再例如大表的DDL,会占着表的MDL写锁,导致没法对该表进行读写,导致主从延迟\n* 从库的并行复制能力\n\n### 并行复制\n* io thread负责将内容写入relay log,sql thread负责回放\n* slave_parallel_workers设置5.6之后并行回放的线程个数\n基本原则:\n* 以transaction为基本单位,否则会影响事务的隔离性\n* 对同一行更新操作的不同事务需要放到同一个worker\n\n按表分发:\n* 每个worker有一个hash表,记录db-table:事务个数\n* 分发时,如果没有任何冲突,直接分配给空闲worker\n* 如果有多个worker有table的更新,则等待直到只有一个worker更新该表\n* 分配给该worker\n\n如果碰到热点表,会退化为单线程模式\n\n按行分发:\n* 每个worker同样有hash表,记录db-table:各个唯一键+各个唯一值.有多少唯一值记录多少项\n\n\nmysql5.7:\nslave-parallel-type\n* DATABASE 按库并行复制\n* LOGICAL_CLOCK 模拟主库的组提交,同时处于commit状态的肯定可以并行\n\n##主从切换\n\n找同步位点\n\n主动跳过一个事务:\n```\nset global sql_slave_skip_counter=1;\nstart slave;\n\n```\n```\nslave_skip_errors 跳过1032/1062错误,即插入时唯一键冲突/删除时找不到行\n```\n上述两种方式tricky,并且容易造成错误\n\n5.6可以开启gtid:\n```\ngtid_mode=on\nenforce_gtid_consistency=on\n```\n开启gtid模式\n如果有冲突,跳过冲突的gtid方法:\n```\nset gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';\nbegin;\ncommit;\nset gtid_next=automatic;\nstart slave;\n```\n该事务aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10就以空事务的状态加入了从的已执行事务集合中\n\n有了gtid,备库不需要指定位点,由主库根据差集取出备库需要执行的gtid,然后开始主从同步\n\n## 解决过期读的问题\n\n* 强制走主\n* 判断sbm,seconds_behind_master,当没有延迟时再去读,但是间隔是s,可能会不精确\n* 对比位点,确保同步过来的已经全部执行.只能确定已经同步的执行完了,有可能还有未同步的\n* 对比获取到的gtid_set和回放到的gtid_set,判断是否已经全部执行,只能确定已经同步的执行完了,有可能还有未同步的\n* 结合semi-sync(主的binlog必须已经传给至少一个从,从回复ack),一主多从不适用.\n* 上述除了强制走主的方案,如果并发量大,可能会看到位点,sbm,gtid一直不同步的情况\n终极大法:\n* 等主库位点\n```\nselect master_pos_wait(file, pos[, timeout]);\n```\n如果能够知道某条命令执行后的位点,在从库执行该命令,异常返回null,超过Ns返回-1,已经执行过返回0\n所以如果>=0,则可以在从库开始查询了,否则放弃或者走主\n\n5.7.6开始允许执行完后把gtid返回客户端\n```\n select wait_for_executed_gtid_set(gtid_set, 1);\n session_track_gtids = OWN_GTID\n但得从API中解析出来,具体得看相应的API接口\n```\n超时返回1,执行返回0\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n","slug":"Mysql-redo-binlog-master-slave","published":1,"updated":"2019-04-22T11:53:55.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z990004bms687o8v4l8","content":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的redo log,binlog,主从及其延迟<br>参考极客时间<strong>mysql45讲</strong>之第2讲,12讲,15讲,23讲,24讲,25讲,26讲,27讲,28讲</p>\n<h2 id=\"redolog与binlog\"><a href=\"#redolog与binlog\" class=\"headerlink\" title=\"redolog与binlog\"></a>redolog与binlog</h2><h3 id=\"redolog\"><a href=\"#redolog\" class=\"headerlink\" title=\"redolog\"></a>redolog</h3><ul>\n<li>固定大小,循环写入</li>\n<li>redolog相比直接在磁盘中写入修改的好处是将随机写转换为顺序写,并且有组提交的优化</li>\n<li>checkpoint是redo中的一个位置,该位置之前的redolog可以覆盖掉,因为已经写入了磁盘</li>\n</ul>\n<h3 id=\"binlog\"><a href=\"#binlog\" class=\"headerlink\" title=\"binlog\"></a>binlog</h3><ul>\n<li>statement 完整的语句</li>\n<li>row 行的内容 update时是一行修改前的一行修改后的  insert和delete也是会将完整的数据记录下来</li>\n<li>因为statement格式可能会导致主从上执行该语句时产生不一致,所以有了row格式.但是row格式占用空间过大,所以有了mixed格式,由Mysql决定是使用statement还是row</li>\n<li>row格式有个好处是会保存完整的数据,所以只要反向操作就可以恢复数据.因此还是建议保存为row格式</li>\n<li>事务提交的时候才会刷binlog,如果一个事务很大,必须等事务执行完成才写binlog,才会传给从,会导致主从延迟过大<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">回放mysql binlog</span><br><span class=\"line\">mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"redolog与binlog的差异\"><a href=\"#redolog与binlog的差异\" class=\"headerlink\" title=\"redolog与binlog的差异\"></a>redolog与binlog的差异</h3><ul>\n<li>一个是引擎层的日志,一个是server层的日志</li>\n<li>一个是物理日志,即某个数据页做了什么修改;一个是逻辑日志,记录语句的原始逻辑</li>\n<li>一个是循环写,一个是追加写</li>\n</ul>\n<h3 id=\"两阶段提交\"><a href=\"#两阶段提交\" class=\"headerlink\" title=\"两阶段提交\"></a>两阶段提交</h3><ul>\n<li>写入redolog,处于prepare状态</li>\n<li>写入binlog</li>\n<li>提交事务,处于commit状态</li>\n</ul>\n<p>处于commit状态的直接恢复,如果处于prepare但是未commit的,根据XID找binlog中的事务是否完整,完整则认为该事务是可以提交的,如果不完整则回滚之<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit = 1 即每次事务提交时的redolog都落盘</span><br><span class=\"line\">innodb_flush_log_at_trx_commit = 0 即每次事务提交时的redolog都只在redo log buffer中</span><br><span class=\"line\">innodb_flush_log_at_trx_commit = 2 即每次事务提交时的redolog都只write,在操作系统的page cache中</span><br><span class=\"line\">innodb有一个后台线程会定期将redo log buffer中的数据write到page cache,然后fsync到磁盘.即使一个事务未提交也会刷盘</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sync_binlog = 1 每次事务的binlog都落盘</span><br><span class=\"line\">sync_binlog = 0 只write不fsync,由操作系统定期去fsync</span><br><span class=\"line\">sync_binlog = N (N&gt;=2)只write,累计N个事务后才会fsync</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"fsync的优化\"><a href=\"#fsync的优化\" class=\"headerlink\" title=\"fsync的优化\"></a>fsync的优化</h3><p>由于fsync很耗时,所以redo有一个组提交的优化,刷新时会将其他事务写的log一起刷新到磁盘</p>\n<h2 id=\"MySQL为什么有时候会”抖”一下\"><a href=\"#MySQL为什么有时候会”抖”一下\" class=\"headerlink\" title=\"MySQL为什么有时候会”抖”一下\"></a>MySQL为什么有时候会”抖”一下</h2><p>为什么某条SQL语句会突然变慢了</p>\n<ul>\n<li>redo过小,导致write pos即将超出checkpoint,所以需要刷新脏页,推进checkpoint</li>\n<li>内存空间buffer pool过小,导致需要刷脏页<br>mysql中如果内存中有数据,则数据肯定是最新的,如果内存中没有数据,则磁盘中的文件是新的(得经过change buffer merge之后)</li>\n</ul>\n<p>注意还有两种情况也会刷新脏页:</p>\n<ul>\n<li>系统空闲时,刷脏页频率快导致</li>\n<li>正常关机也会刷脏页</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_io_capacity 该参数定义mysql所在主机的io能力 SSD可设置为20000,机械硬盘为300</span><br><span class=\"line\">innodb_max_dirty_pages_pct控制脏页比例上限</span><br><span class=\"line\">Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total计算脏页比例</span><br><span class=\"line\">根据最新写入日志的lsn(log sequence number)和checkpoint相减的值判断checkpoint进度</span><br><span class=\"line\">innodb_flush_neighbors控制是否在刷脏页的时候刷新邻居页,SSD建议关闭</span><br></pre></td></tr></table></figure>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><ul>\n<li>备库配置差</li>\n<li>备库配置同主库,但压力过大,例如执行了大量的报表查询及备份等工作.可以通过设置一主多从来分摊压力</li>\n<li>大事务,即如果主上边执行10分钟,从上也可能执行10分钟,导致延迟.例如删除大量数据,再例如大表的DDL,会占着表的MDL写锁,导致没法对该表进行读写,导致主从延迟</li>\n<li>从库的并行复制能力</li>\n</ul>\n<h3 id=\"并行复制\"><a href=\"#并行复制\" class=\"headerlink\" title=\"并行复制\"></a>并行复制</h3><ul>\n<li>io thread负责将内容写入relay log,sql thread负责回放</li>\n<li>slave_parallel_workers设置5.6之后并行回放的线程个数<br>基本原则:</li>\n<li>以transaction为基本单位,否则会影响事务的隔离性</li>\n<li>对同一行更新操作的不同事务需要放到同一个worker</li>\n</ul>\n<p>按表分发:</p>\n<ul>\n<li>每个worker有一个hash表,记录db-table:事务个数</li>\n<li>分发时,如果没有任何冲突,直接分配给空闲worker</li>\n<li>如果有多个worker有table的更新,则等待直到只有一个worker更新该表</li>\n<li>分配给该worker</li>\n</ul>\n<p>如果碰到热点表,会退化为单线程模式</p>\n<p>按行分发:</p>\n<ul>\n<li>每个worker同样有hash表,记录db-table:各个唯一键+各个唯一值.有多少唯一值记录多少项</li>\n</ul>\n<p>mysql5.7:<br>slave-parallel-type</p>\n<ul>\n<li>DATABASE 按库并行复制</li>\n<li>LOGICAL_CLOCK 模拟主库的组提交,同时处于commit状态的肯定可以并行</li>\n</ul>\n<p>##主从切换</p>\n<p>找同步位点</p>\n<p>主动跳过一个事务:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set global sql_slave_skip_counter=1;</span><br><span class=\"line\">start slave;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slave_skip_errors 跳过1032/1062错误,即插入时唯一键冲突/删除时找不到行</span><br></pre></td></tr></table></figure>\n<p>上述两种方式tricky,并且容易造成错误</p>\n<p>5.6可以开启gtid:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gtid_mode=on</span><br><span class=\"line\">enforce_gtid_consistency=on</span><br></pre></td></tr></table></figure></p>\n<p>开启gtid模式<br>如果有冲突,跳过冲突的gtid方法:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set gtid_next=&apos;aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10&apos;;</span><br><span class=\"line\">begin;</span><br><span class=\"line\">commit;</span><br><span class=\"line\">set gtid_next=automatic;</span><br><span class=\"line\">start slave;</span><br></pre></td></tr></table></figure></p>\n<p>该事务aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10就以空事务的状态加入了从的已执行事务集合中</p>\n<p>有了gtid,备库不需要指定位点,由主库根据差集取出备库需要执行的gtid,然后开始主从同步</p>\n<h2 id=\"解决过期读的问题\"><a href=\"#解决过期读的问题\" class=\"headerlink\" title=\"解决过期读的问题\"></a>解决过期读的问题</h2><ul>\n<li>强制走主</li>\n<li>判断sbm,seconds_behind_master,当没有延迟时再去读,但是间隔是s,可能会不精确</li>\n<li>对比位点,确保同步过来的已经全部执行.只能确定已经同步的执行完了,有可能还有未同步的</li>\n<li>对比获取到的gtid_set和回放到的gtid_set,判断是否已经全部执行,只能确定已经同步的执行完了,有可能还有未同步的</li>\n<li>结合semi-sync(主的binlog必须已经传给至少一个从,从回复ack),一主多从不适用.</li>\n<li>上述除了强制走主的方案,如果并发量大,可能会看到位点,sbm,gtid一直不同步的情况<br>终极大法:</li>\n<li>等主库位点<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select master_pos_wait(file, pos[, timeout]);</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>如果能够知道某条命令执行后的位点,在从库执行该命令,异常返回null,超过Ns返回-1,已经执行过返回0<br>所以如果&gt;=0,则可以在从库开始查询了,否则放弃或者走主</p>\n<p>5.7.6开始允许执行完后把gtid返回客户端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> select wait_for_executed_gtid_set(gtid_set, 1);</span><br><span class=\"line\"> session_track_gtids = OWN_GTID</span><br><span class=\"line\">但得从API中解析出来,具体得看相应的API接口</span><br></pre></td></tr></table></figure></p>\n<p>超时返回1,执行返回0</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>理解Mysql的redo log,binlog,主从及其延迟<br>参考极客时间<strong>mysql45讲</strong>之第2讲,12讲,15讲,23讲,24讲,25讲,26讲,27讲,28讲</p>\n<h2 id=\"redolog与binlog\"><a href=\"#redolog与binlog\" class=\"headerlink\" title=\"redolog与binlog\"></a>redolog与binlog</h2><h3 id=\"redolog\"><a href=\"#redolog\" class=\"headerlink\" title=\"redolog\"></a>redolog</h3><ul>\n<li>固定大小,循环写入</li>\n<li>redolog相比直接在磁盘中写入修改的好处是将随机写转换为顺序写,并且有组提交的优化</li>\n<li>checkpoint是redo中的一个位置,该位置之前的redolog可以覆盖掉,因为已经写入了磁盘</li>\n</ul>\n<h3 id=\"binlog\"><a href=\"#binlog\" class=\"headerlink\" title=\"binlog\"></a>binlog</h3><ul>\n<li>statement 完整的语句</li>\n<li>row 行的内容 update时是一行修改前的一行修改后的  insert和delete也是会将完整的数据记录下来</li>\n<li>因为statement格式可能会导致主从上执行该语句时产生不一致,所以有了row格式.但是row格式占用空间过大,所以有了mixed格式,由Mysql决定是使用statement还是row</li>\n<li>row格式有个好处是会保存完整的数据,所以只要反向操作就可以恢复数据.因此还是建议保存为row格式</li>\n<li>事务提交的时候才会刷binlog,如果一个事务很大,必须等事务执行完成才写binlog,才会传给从,会导致主从延迟过大<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">回放mysql binlog</span><br><span class=\"line\">mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"redolog与binlog的差异\"><a href=\"#redolog与binlog的差异\" class=\"headerlink\" title=\"redolog与binlog的差异\"></a>redolog与binlog的差异</h3><ul>\n<li>一个是引擎层的日志,一个是server层的日志</li>\n<li>一个是物理日志,即某个数据页做了什么修改;一个是逻辑日志,记录语句的原始逻辑</li>\n<li>一个是循环写,一个是追加写</li>\n</ul>\n<h3 id=\"两阶段提交\"><a href=\"#两阶段提交\" class=\"headerlink\" title=\"两阶段提交\"></a>两阶段提交</h3><ul>\n<li>写入redolog,处于prepare状态</li>\n<li>写入binlog</li>\n<li>提交事务,处于commit状态</li>\n</ul>\n<p>处于commit状态的直接恢复,如果处于prepare但是未commit的,根据XID找binlog中的事务是否完整,完整则认为该事务是可以提交的,如果不完整则回滚之<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit = 1 即每次事务提交时的redolog都落盘</span><br><span class=\"line\">innodb_flush_log_at_trx_commit = 0 即每次事务提交时的redolog都只在redo log buffer中</span><br><span class=\"line\">innodb_flush_log_at_trx_commit = 2 即每次事务提交时的redolog都只write,在操作系统的page cache中</span><br><span class=\"line\">innodb有一个后台线程会定期将redo log buffer中的数据write到page cache,然后fsync到磁盘.即使一个事务未提交也会刷盘</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sync_binlog = 1 每次事务的binlog都落盘</span><br><span class=\"line\">sync_binlog = 0 只write不fsync,由操作系统定期去fsync</span><br><span class=\"line\">sync_binlog = N (N&gt;=2)只write,累计N个事务后才会fsync</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"fsync的优化\"><a href=\"#fsync的优化\" class=\"headerlink\" title=\"fsync的优化\"></a>fsync的优化</h3><p>由于fsync很耗时,所以redo有一个组提交的优化,刷新时会将其他事务写的log一起刷新到磁盘</p>\n<h2 id=\"MySQL为什么有时候会”抖”一下\"><a href=\"#MySQL为什么有时候会”抖”一下\" class=\"headerlink\" title=\"MySQL为什么有时候会”抖”一下\"></a>MySQL为什么有时候会”抖”一下</h2><p>为什么某条SQL语句会突然变慢了</p>\n<ul>\n<li>redo过小,导致write pos即将超出checkpoint,所以需要刷新脏页,推进checkpoint</li>\n<li>内存空间buffer pool过小,导致需要刷脏页<br>mysql中如果内存中有数据,则数据肯定是最新的,如果内存中没有数据,则磁盘中的文件是新的(得经过change buffer merge之后)</li>\n</ul>\n<p>注意还有两种情况也会刷新脏页:</p>\n<ul>\n<li>系统空闲时,刷脏页频率快导致</li>\n<li>正常关机也会刷脏页</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_io_capacity 该参数定义mysql所在主机的io能力 SSD可设置为20000,机械硬盘为300</span><br><span class=\"line\">innodb_max_dirty_pages_pct控制脏页比例上限</span><br><span class=\"line\">Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total计算脏页比例</span><br><span class=\"line\">根据最新写入日志的lsn(log sequence number)和checkpoint相减的值判断checkpoint进度</span><br><span class=\"line\">innodb_flush_neighbors控制是否在刷脏页的时候刷新邻居页,SSD建议关闭</span><br></pre></td></tr></table></figure>\n<h2 id=\"主从延迟\"><a href=\"#主从延迟\" class=\"headerlink\" title=\"主从延迟\"></a>主从延迟</h2><ul>\n<li>备库配置差</li>\n<li>备库配置同主库,但压力过大,例如执行了大量的报表查询及备份等工作.可以通过设置一主多从来分摊压力</li>\n<li>大事务,即如果主上边执行10分钟,从上也可能执行10分钟,导致延迟.例如删除大量数据,再例如大表的DDL,会占着表的MDL写锁,导致没法对该表进行读写,导致主从延迟</li>\n<li>从库的并行复制能力</li>\n</ul>\n<h3 id=\"并行复制\"><a href=\"#并行复制\" class=\"headerlink\" title=\"并行复制\"></a>并行复制</h3><ul>\n<li>io thread负责将内容写入relay log,sql thread负责回放</li>\n<li>slave_parallel_workers设置5.6之后并行回放的线程个数<br>基本原则:</li>\n<li>以transaction为基本单位,否则会影响事务的隔离性</li>\n<li>对同一行更新操作的不同事务需要放到同一个worker</li>\n</ul>\n<p>按表分发:</p>\n<ul>\n<li>每个worker有一个hash表,记录db-table:事务个数</li>\n<li>分发时,如果没有任何冲突,直接分配给空闲worker</li>\n<li>如果有多个worker有table的更新,则等待直到只有一个worker更新该表</li>\n<li>分配给该worker</li>\n</ul>\n<p>如果碰到热点表,会退化为单线程模式</p>\n<p>按行分发:</p>\n<ul>\n<li>每个worker同样有hash表,记录db-table:各个唯一键+各个唯一值.有多少唯一值记录多少项</li>\n</ul>\n<p>mysql5.7:<br>slave-parallel-type</p>\n<ul>\n<li>DATABASE 按库并行复制</li>\n<li>LOGICAL_CLOCK 模拟主库的组提交,同时处于commit状态的肯定可以并行</li>\n</ul>\n<p>##主从切换</p>\n<p>找同步位点</p>\n<p>主动跳过一个事务:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set global sql_slave_skip_counter=1;</span><br><span class=\"line\">start slave;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">slave_skip_errors 跳过1032/1062错误,即插入时唯一键冲突/删除时找不到行</span><br></pre></td></tr></table></figure>\n<p>上述两种方式tricky,并且容易造成错误</p>\n<p>5.6可以开启gtid:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gtid_mode=on</span><br><span class=\"line\">enforce_gtid_consistency=on</span><br></pre></td></tr></table></figure></p>\n<p>开启gtid模式<br>如果有冲突,跳过冲突的gtid方法:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set gtid_next=&apos;aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10&apos;;</span><br><span class=\"line\">begin;</span><br><span class=\"line\">commit;</span><br><span class=\"line\">set gtid_next=automatic;</span><br><span class=\"line\">start slave;</span><br></pre></td></tr></table></figure></p>\n<p>该事务aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10就以空事务的状态加入了从的已执行事务集合中</p>\n<p>有了gtid,备库不需要指定位点,由主库根据差集取出备库需要执行的gtid,然后开始主从同步</p>\n<h2 id=\"解决过期读的问题\"><a href=\"#解决过期读的问题\" class=\"headerlink\" title=\"解决过期读的问题\"></a>解决过期读的问题</h2><ul>\n<li>强制走主</li>\n<li>判断sbm,seconds_behind_master,当没有延迟时再去读,但是间隔是s,可能会不精确</li>\n<li>对比位点,确保同步过来的已经全部执行.只能确定已经同步的执行完了,有可能还有未同步的</li>\n<li>对比获取到的gtid_set和回放到的gtid_set,判断是否已经全部执行,只能确定已经同步的执行完了,有可能还有未同步的</li>\n<li>结合semi-sync(主的binlog必须已经传给至少一个从,从回复ack),一主多从不适用.</li>\n<li>上述除了强制走主的方案,如果并发量大,可能会看到位点,sbm,gtid一直不同步的情况<br>终极大法:</li>\n<li>等主库位点<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">select master_pos_wait(file, pos[, timeout]);</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>如果能够知道某条命令执行后的位点,在从库执行该命令,异常返回null,超过Ns返回-1,已经执行过返回0<br>所以如果&gt;=0,则可以在从库开始查询了,否则放弃或者走主</p>\n<p>5.7.6开始允许执行完后把gtid返回客户端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> select wait_for_executed_gtid_set(gtid_set, 1);</span><br><span class=\"line\"> session_track_gtids = OWN_GTID</span><br><span class=\"line\">但得从API中解析出来,具体得看相应的API接口</span><br></pre></td></tr></table></figure></p>\n<p>超时返回1,执行返回0</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n"},{"title":"Mysql 隔离级别、锁、MVCC示例","date":"2019-04-19T16:00:00.000Z","_content":"## 引言\n通过构造示例,理解Mysql的隔离级别及其锁和MVCC的实现\n参考极客时间**mysql45讲**之第3讲,7讲和8讲,19讲,20讲\n\n## 事务隔离级别 \n\n* RU 读未提交\n* RC 读已提交\n* RR 可重复读\n* S  顺序读\n\n```\n表结构\ncreate table T(c int) engine=InnoDB;\ninsert into T(c) values (1);\n```\n\n**在四种模式下分别试验例子1**\n\n```\n例子1:\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.查询得到值1 \t\t\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2\n3.查询得到值v1\t\n\t\t\t   4.提交事务B\n4.查询得到值v2\n5.提交事务A\n6.查询得到值v3\n\n```\n\n* s顺序读 读加读锁 写加写锁 写锁必须等待读锁完成. 事务B的第三部阻塞,v1,v2都是1,v3是2,简单但是并发性能不好\n* RR   V1,v2都是1,v3是2 读不加锁 mvcc\n会有大量的undo log,并且如果有大量的事务会大致读取时遍历undolog导致读取性能下降\n* RC   V1是1,v2是2,v3是2 会导致不可重复读 \n* RU   v1,v2,v3都是2  会导致脏读\n\n\n## 重点看RR:\n* 如果事务A的第2步挪到事务B的第三步之后,效果如何.即读取视图是从何时开始的,应该是从第一个查询语句开始 （此时如果在A的第2步之前再加一个update语句会如何）\n\n查询时才会开启一个事务\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2\n\t\t\t   4.提交事务B\n2.查询得到值2\t\t\n3.查询得到值v1\t\n4.查询得到值v2\n5.提交事务A\n6.查询得到值v3\n\n```\n\n* 如果在A中update之后在B中再次update,会如何\n\n修改一下:\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成3\n3.查询得到值3\t\t\n\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 where c=1 (因为c已经被修改为2,更新的时候是先读后写,读是当前读,而不是快照读)\n4.提交事务A\n\t\t\t   4.提交事务B\n5.查询得到值3    5.查询得到值3\n\n```\n**写代码的时候需要判断影响行数,即是否真正执行了更新**\n再修改一下:最后得到的值是2\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成3\n3.查询得到值3\t\t\n\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 \n4.提交事务A\n\t\t\t   4.提交事务B\n5.查询得到值2    5.查询得到值2\n\n```\n* 上边示例中同时更新一行会有行锁,我们演示一下行锁\n\n行锁在事务开始时加,但并不是语句结束后就释放, 而是事务结束后才释放,称之为两阶段锁协议.所以在一个事务中将最可能造成锁争用的语句放到事务最后执行\n\n行锁通过锁索引记录来实现,如果没有索引,锁全表.\n```\ndelete from T;\ninsert into T values (1),(5);\n```\n\n事务A更新1,事务B更新5\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 (因为c字段上边没有索引,所以是锁全表,此时无法更新)\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n\n修改c增加uniq index\ncreate unique index u_index_c on T (`c`);\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 \n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n事务A在1字段的唯一索引上加锁,所以事务B的第2条语句不会被阻塞\n\ndrop index u_index_c on T;\ncreate  index u_index_c on T (`c`);\n\n修改c增加 index\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 \n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n此时的加锁原则是等值加锁,向右查找到第一个不满足条件的记录后退化为gap锁\n但如果第2条语句换成插入3 例如insert into T values (3);会被阻塞\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.插入值3 (阻塞)\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,3,5  4.查询得到值2,3,5\n\n```\n\n如果有3条记录,1,2,5 那么插入记录3是可以插入的\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.插入值3 （不阻塞）\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,3,5  4.查询得到值2,3,5\n\n```\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Mysql-isolation-level.md","raw":"---\ntitle: Mysql 隔离级别、锁、MVCC示例\ndate: 2019-04-20 \ntags: Mysql\n---\n## 引言\n通过构造示例,理解Mysql的隔离级别及其锁和MVCC的实现\n参考极客时间**mysql45讲**之第3讲,7讲和8讲,19讲,20讲\n\n## 事务隔离级别 \n\n* RU 读未提交\n* RC 读已提交\n* RR 可重复读\n* S  顺序读\n\n```\n表结构\ncreate table T(c int) engine=InnoDB;\ninsert into T(c) values (1);\n```\n\n**在四种模式下分别试验例子1**\n\n```\n例子1:\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.查询得到值1 \t\t\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2\n3.查询得到值v1\t\n\t\t\t   4.提交事务B\n4.查询得到值v2\n5.提交事务A\n6.查询得到值v3\n\n```\n\n* s顺序读 读加读锁 写加写锁 写锁必须等待读锁完成. 事务B的第三部阻塞,v1,v2都是1,v3是2,简单但是并发性能不好\n* RR   V1,v2都是1,v3是2 读不加锁 mvcc\n会有大量的undo log,并且如果有大量的事务会大致读取时遍历undolog导致读取性能下降\n* RC   V1是1,v2是2,v3是2 会导致不可重复读 \n* RU   v1,v2,v3都是2  会导致脏读\n\n\n## 重点看RR:\n* 如果事务A的第2步挪到事务B的第三步之后,效果如何.即读取视图是从何时开始的,应该是从第一个查询语句开始 （此时如果在A的第2步之前再加一个update语句会如何）\n\n查询时才会开启一个事务\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2\n\t\t\t   4.提交事务B\n2.查询得到值2\t\t\n3.查询得到值v1\t\n4.查询得到值v2\n5.提交事务A\n6.查询得到值v3\n\n```\n\n* 如果在A中update之后在B中再次update,会如何\n\n修改一下:\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成3\n3.查询得到值3\t\t\n\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 where c=1 (因为c已经被修改为2,更新的时候是先读后写,读是当前读,而不是快照读)\n4.提交事务A\n\t\t\t   4.提交事务B\n5.查询得到值3    5.查询得到值3\n\n```\n**写代码的时候需要判断影响行数,即是否真正执行了更新**\n再修改一下:最后得到的值是2\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成3\n3.查询得到值3\t\t\n\n\t\t\t   2.查询得到值1\n\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 \n4.提交事务A\n\t\t\t   4.提交事务B\n5.查询得到值2    5.查询得到值2\n\n```\n* 上边示例中同时更新一行会有行锁,我们演示一下行锁\n\n行锁在事务开始时加,但并不是语句结束后就释放, 而是事务结束后才释放,称之为两阶段锁协议.所以在一个事务中将最可能造成锁争用的语句放到事务最后执行\n\n行锁通过锁索引记录来实现,如果没有索引,锁全表.\n```\ndelete from T;\ninsert into T values (1),(5);\n```\n\n事务A更新1,事务B更新5\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 (因为c字段上边没有索引,所以是锁全表,此时无法更新)\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n\n修改c增加uniq index\ncreate unique index u_index_c on T (`c`);\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 \n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n事务A在1字段的唯一索引上加锁,所以事务B的第2条语句不会被阻塞\n\ndrop index u_index_c on T;\ncreate  index u_index_c on T (`c`);\n\n修改c增加 index\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.将5改成6 \n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,6  4.查询得到值2,6\n\n```\n此时的加锁原则是等值加锁,向右查找到第一个不满足条件的记录后退化为gap锁\n但如果第2条语句换成插入3 例如insert into T values (3);会被阻塞\n\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.插入值3 (阻塞)\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,3,5  4.查询得到值2,3,5\n\n```\n\n如果有3条记录,1,2,5 那么插入记录3是可以插入的\n```\n事务A          事务B\n1.开启事务\t\t1.开启事务\n2.将1改成2\n3.查询得到值2,5\t\t\n\n\t\t\t   2.插入值3 （不阻塞）\n4.提交事务A \n\t\t\t   3.提交事务B\n5.查询得到值2,3,5  4.查询得到值2,3,5\n\n```\n\n## 参考链接\n![mysql](/img/mysql.jpeg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"Mysql-isolation-level","published":1,"updated":"2019-04-22T06:35:55.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9b0005bms6udsmnojj","content":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>通过构造示例,理解Mysql的隔离级别及其锁和MVCC的实现<br>参考极客时间<strong>mysql45讲</strong>之第3讲,7讲和8讲,19讲,20讲</p>\n<h2 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h2><ul>\n<li>RU 读未提交</li>\n<li>RC 读已提交</li>\n<li>RR 可重复读</li>\n<li>S  顺序读</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">表结构</span><br><span class=\"line\">create table T(c int) engine=InnoDB;</span><br><span class=\"line\">insert into T(c) values (1);</span><br></pre></td></tr></table></figure>\n<p><strong>在四种模式下分别试验例子1</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子1:</span><br><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.查询得到值1 \t\t</span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2</span><br><span class=\"line\">3.查询得到值v1\t</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">4.查询得到值v2</span><br><span class=\"line\">5.提交事务A</span><br><span class=\"line\">6.查询得到值v3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>s顺序读 读加读锁 写加写锁 写锁必须等待读锁完成. 事务B的第三部阻塞,v1,v2都是1,v3是2,简单但是并发性能不好</li>\n<li>RR   V1,v2都是1,v3是2 读不加锁 mvcc<br>会有大量的undo log,并且如果有大量的事务会大致读取时遍历undolog导致读取性能下降</li>\n<li>RC   V1是1,v2是2,v3是2 会导致不可重复读 </li>\n<li>RU   v1,v2,v3都是2  会导致脏读</li>\n</ul>\n<h2 id=\"重点看RR\"><a href=\"#重点看RR\" class=\"headerlink\" title=\"重点看RR:\"></a>重点看RR:</h2><ul>\n<li>如果事务A的第2步挪到事务B的第三步之后,效果如何.即读取视图是从何时开始的,应该是从第一个查询语句开始 （此时如果在A的第2步之前再加一个update语句会如何）</li>\n</ul>\n<p>查询时才会开启一个事务<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">2.查询得到值2\t\t</span><br><span class=\"line\">3.查询得到值v1\t</span><br><span class=\"line\">4.查询得到值v2</span><br><span class=\"line\">5.提交事务A</span><br><span class=\"line\">6.查询得到值v3</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>如果在A中update之后在B中再次update,会如何</li>\n</ul>\n<p>修改一下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成3</span><br><span class=\"line\">3.查询得到值3\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 where c=1 (因为c已经被修改为2,更新的时候是先读后写,读是当前读,而不是快照读)</span><br><span class=\"line\">4.提交事务A</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">5.查询得到值3    5.查询得到值3</span><br></pre></td></tr></table></figure>\n<p><strong>写代码的时候需要判断影响行数,即是否真正执行了更新</strong><br>再修改一下:最后得到的值是2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成3</span><br><span class=\"line\">3.查询得到值3\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 </span><br><span class=\"line\">4.提交事务A</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">5.查询得到值2    5.查询得到值2</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>上边示例中同时更新一行会有行锁,我们演示一下行锁</li>\n</ul>\n<p>行锁在事务开始时加,但并不是语句结束后就释放, 而是事务结束后才释放,称之为两阶段锁协议.所以在一个事务中将最可能造成锁争用的语句放到事务最后执行</p>\n<p>行锁通过锁索引记录来实现,如果没有索引,锁全表.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete from T;</span><br><span class=\"line\">insert into T values (1),(5);</span><br></pre></td></tr></table></figure></p>\n<p>事务A更新1,事务B更新5</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 (因为c字段上边没有索引,所以是锁全表,此时无法更新)</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure>\n<p>修改c增加uniq index<br>create unique index u_index_c on T (<code>c</code>);<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 </span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure></p>\n<p>事务A在1字段的唯一索引上加锁,所以事务B的第2条语句不会被阻塞</p>\n<p>drop index u_index_c on T;<br>create  index u_index_c on T (<code>c</code>);</p>\n<p>修改c增加 index</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 </span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure>\n<p>此时的加锁原则是等值加锁,向右查找到第一个不满足条件的记录后退化为gap锁<br>但如果第2条语句换成插入3 例如insert into T values (3);会被阻塞</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.插入值3 (阻塞)</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,3,5  4.查询得到值2,3,5</span><br></pre></td></tr></table></figure>\n<p>如果有3条记录,1,2,5 那么插入记录3是可以插入的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.插入值3 （不阻塞）</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,3,5  4.查询得到值2,3,5</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><p>通过构造示例,理解Mysql的隔离级别及其锁和MVCC的实现<br>参考极客时间<strong>mysql45讲</strong>之第3讲,7讲和8讲,19讲,20讲</p>\n<h2 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h2><ul>\n<li>RU 读未提交</li>\n<li>RC 读已提交</li>\n<li>RR 可重复读</li>\n<li>S  顺序读</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">表结构</span><br><span class=\"line\">create table T(c int) engine=InnoDB;</span><br><span class=\"line\">insert into T(c) values (1);</span><br></pre></td></tr></table></figure>\n<p><strong>在四种模式下分别试验例子1</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">例子1:</span><br><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.查询得到值1 \t\t</span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2</span><br><span class=\"line\">3.查询得到值v1\t</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">4.查询得到值v2</span><br><span class=\"line\">5.提交事务A</span><br><span class=\"line\">6.查询得到值v3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>s顺序读 读加读锁 写加写锁 写锁必须等待读锁完成. 事务B的第三部阻塞,v1,v2都是1,v3是2,简单但是并发性能不好</li>\n<li>RR   V1,v2都是1,v3是2 读不加锁 mvcc<br>会有大量的undo log,并且如果有大量的事务会大致读取时遍历undolog导致读取性能下降</li>\n<li>RC   V1是1,v2是2,v3是2 会导致不可重复读 </li>\n<li>RU   v1,v2,v3都是2  会导致脏读</li>\n</ul>\n<h2 id=\"重点看RR\"><a href=\"#重点看RR\" class=\"headerlink\" title=\"重点看RR:\"></a>重点看RR:</h2><ul>\n<li>如果事务A的第2步挪到事务B的第三步之后,效果如何.即读取视图是从何时开始的,应该是从第一个查询语句开始 （此时如果在A的第2步之前再加一个update语句会如何）</li>\n</ul>\n<p>查询时才会开启一个事务<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">2.查询得到值2\t\t</span><br><span class=\"line\">3.查询得到值v1\t</span><br><span class=\"line\">4.查询得到值v2</span><br><span class=\"line\">5.提交事务A</span><br><span class=\"line\">6.查询得到值v3</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>如果在A中update之后在B中再次update,会如何</li>\n</ul>\n<p>修改一下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成3</span><br><span class=\"line\">3.查询得到值3\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 where c=1 (因为c已经被修改为2,更新的时候是先读后写,读是当前读,而不是快照读)</span><br><span class=\"line\">4.提交事务A</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">5.查询得到值3    5.查询得到值3</span><br></pre></td></tr></table></figure>\n<p><strong>写代码的时候需要判断影响行数,即是否真正执行了更新</strong><br>再修改一下:最后得到的值是2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成3</span><br><span class=\"line\">3.查询得到值3\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.查询得到值1</span><br><span class=\"line\">\t\t\t   3.将1改成2  阻塞....  有行锁 update T set c=2 </span><br><span class=\"line\">4.提交事务A</span><br><span class=\"line\">\t\t\t   4.提交事务B</span><br><span class=\"line\">5.查询得到值2    5.查询得到值2</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>上边示例中同时更新一行会有行锁,我们演示一下行锁</li>\n</ul>\n<p>行锁在事务开始时加,但并不是语句结束后就释放, 而是事务结束后才释放,称之为两阶段锁协议.所以在一个事务中将最可能造成锁争用的语句放到事务最后执行</p>\n<p>行锁通过锁索引记录来实现,如果没有索引,锁全表.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">delete from T;</span><br><span class=\"line\">insert into T values (1),(5);</span><br></pre></td></tr></table></figure></p>\n<p>事务A更新1,事务B更新5</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 (因为c字段上边没有索引,所以是锁全表,此时无法更新)</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure>\n<p>修改c增加uniq index<br>create unique index u_index_c on T (<code>c</code>);<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 </span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure></p>\n<p>事务A在1字段的唯一索引上加锁,所以事务B的第2条语句不会被阻塞</p>\n<p>drop index u_index_c on T;<br>create  index u_index_c on T (<code>c</code>);</p>\n<p>修改c增加 index</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.将5改成6 </span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,6  4.查询得到值2,6</span><br></pre></td></tr></table></figure>\n<p>此时的加锁原则是等值加锁,向右查找到第一个不满足条件的记录后退化为gap锁<br>但如果第2条语句换成插入3 例如insert into T values (3);会被阻塞</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.插入值3 (阻塞)</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,3,5  4.查询得到值2,3,5</span><br></pre></td></tr></table></figure>\n<p>如果有3条记录,1,2,5 那么插入记录3是可以插入的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">事务A          事务B</span><br><span class=\"line\">1.开启事务\t\t1.开启事务</span><br><span class=\"line\">2.将1改成2</span><br><span class=\"line\">3.查询得到值2,5\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t   2.插入值3 （不阻塞）</span><br><span class=\"line\">4.提交事务A </span><br><span class=\"line\">\t\t\t   3.提交事务B</span><br><span class=\"line\">5.查询得到值2,3,5  4.查询得到值2,3,5</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><img src=\"/img/mysql.jpeg\" alt=\"mysql\"></p>\n"},{"title":"NGINX 4xx 5xx 状态码构造","date":"2018-09-18T06:48:22.000Z","_content":"## nginx配置\n```\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       8070;\n        server_name  10.96.79.14;\n        limit_req zone=one;\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n        location = /abc.html {\n            root html;\n            auth_basic           \"opened site\";\n            auth_basic_user_file conf/htpasswd;\n        }\n         location ~ \\.php$ {\n            root /home/xiaoju/nginx-1.14.0/html;\n            fastcgi_index index.php;\n            fastcgi_pass 127.0.0.1:9000;\n            fastcgi_param       SCRIPT_FILENAME  /home/xiaoju/nginx-1.14.0/html$fastcgi_script_name;\n            include fastcgi.conf;\n            fastcgi_connect_timeout 300;\n            fastcgi_send_timeout 300;\n            fastcgi_read_timeout 300;\n        }\n    }\n}\n```\n\n```\nindex.php\n \n<?php\necho \"124\";\n```\n\n## 4xx系列\n### 400 \n\nNGX_HTTP_BAD_REQUEST\n\n```\nHost头不合法\n \ncurl localhost:8070  -H 'Host:123/com'\n\n\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n \nContent-Length头重复\ncurl localhost:8070  -H 'Content-Length:1'  -H 'Content-Length:2'\n\n\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 401\n\nNGX_HTTP_UNAUTHORIZED\n\n```\n参考如上nginx配置,访问abc.html需要认证\n \ncurl localhost:8070/abc.html\n\n\n<html>\n<head><title>401 Authorization Required</title></head>\n<body bgcolor=\"white\">\n<center><h1>401 Authorization Required</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 403\n\nNGX_HTTP_FORBIDDEN\n\n```\nchmod 222 index.html\n将index.html设置为不可读\n \ncurl localhost:8070\n\n\n<html>\n<head><title>403 Forbidden</title></head>\n<body bgcolor=\"white\">\n<center><h1>403 Forbidden</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 404\n\nNGX_HTTP_NOT_FOUND\n\n```\n\ncurl localhost:8070/cde.html\n\n\n<html>\n<head><title>404 Not Found</title></head>\n<body bgcolor=\"white\">\n<center><h1>404 Not Found</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 405\n\nNGX_HTTP_NOT_ALLOWED\n\n```\n使用非GET/POST/HEAD方法访问一个静态文件\ncurl -X DELETE localhost:8070/index.html -I\n\n\nHTTP/1.1 405 Not Allowed\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 10:02:22 GMT\nContent-Type: text/html\nContent-Length: 173\nConnection: keep-alive\n```\n\n## 5xx系列\n\n### 500\n\nNGX_HTTP_INTERNAL_SERVER_ERROR\n\n```\n修改index.php为\n\n<?php\necho \"124\"\n \n缺少引号,语法错误\n```\n\n```\n\ncurl localhost:8070/index.php -I\n\n\nHTTP/1.1 500 Internal Server Error\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:29:19 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: keep-alive\nSet-Cookie: PHPSESSID=aoesvcuvbh1nh95kdkp152r9e1; path=/\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate\nPragma: no-cache\n```\n\n### 501\nNGX_HTTP_NOT_IMPLEMENTED\n\n```\n\nnginx的transfer-encoding现在只支持chunked,如果客户端随意设置这个值,会报501\n \ncurl localhost:8070  -H 'Transfer-Encoding:1'\n\n\n<html>\n<head><title>501 Not Implemented</title></head>\n<body bgcolor=\"white\">\n<center><h1>501 Not Implemented</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 502\n\nNGX_HTTP_BAD_GATEWAY\n\n```\n修改nginx配置为\nfastcgi_pass 127.0.0.1:8000;\n\n\n指向一个未监听的端口\n```\n\n```\ncurl localhost:8070/index.php -I\n\n\nHTTP/1.1 502 Bad Gateway\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:28:17 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n### 503\n\nNGX_HTTP_SERVICE_UNAVAILABLE\n\n```\n修改nginx配置,限速为每分钟10个请求\n \nlimit_req_zone $binary_remote_addr zone=one:10m rate=10r/m;\nlimit_req zone=one;\n```\n\n```\n连续发送两个请求，第二请求会报503\ncurl localhost:8070/index.php -I\n\nHTTP/1.1 503 Service Temporarily Unavailable\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:31:43 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n### 504\n\nNGX_HTTP_GATEWAY_TIME_OUT\n\n```\n\n修改index.php为\n<?php\necho \"124\";\nsleep(5);\n休息5秒钟\n \n修改nginx配置为\n三秒钟读超时\nfastcgi_read_timeout 3;\n\n```\n\n```\n\ncurl localhost:8070/index.php -I\n\nHTTP/1.1 504 Gateway Time-out\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 12:17:57 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n\n### 505\n\nNGX_HTTP_VERSION_NOT_SUPPORTED\n\n```\ntelnet8070端口,输入GET /index.html HTTP/2.1\n不支持http/2.1,会报505\n \n$telnet localhost 8070\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nGET /index.html HTTP/2.1\nHTTP/1.1 505 HTTP Version Not Supported\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 12:26:35 GMT\nContent-Type: text/html\nContent-Length: 203\nConnection: close\n<html>\n<head><title>505 HTTP Version Not Supported</title></head>\n<body bgcolor=\"white\">\n<center><h1>505 HTTP Version Not Supported</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n","source":"_posts/NGINX-4xx-5xx-状态码构造.md","raw":"---\ntitle: NGINX 4xx 5xx 状态码构造\ndate: 2018-09-18 14:48:22\ntags: NGINX\n---\n## nginx配置\n```\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       8070;\n        server_name  10.96.79.14;\n        limit_req zone=one;\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n        location = /abc.html {\n            root html;\n            auth_basic           \"opened site\";\n            auth_basic_user_file conf/htpasswd;\n        }\n         location ~ \\.php$ {\n            root /home/xiaoju/nginx-1.14.0/html;\n            fastcgi_index index.php;\n            fastcgi_pass 127.0.0.1:9000;\n            fastcgi_param       SCRIPT_FILENAME  /home/xiaoju/nginx-1.14.0/html$fastcgi_script_name;\n            include fastcgi.conf;\n            fastcgi_connect_timeout 300;\n            fastcgi_send_timeout 300;\n            fastcgi_read_timeout 300;\n        }\n    }\n}\n```\n\n```\nindex.php\n \n<?php\necho \"124\";\n```\n\n## 4xx系列\n### 400 \n\nNGX_HTTP_BAD_REQUEST\n\n```\nHost头不合法\n \ncurl localhost:8070  -H 'Host:123/com'\n\n\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n \nContent-Length头重复\ncurl localhost:8070  -H 'Content-Length:1'  -H 'Content-Length:2'\n\n\n<html>\n<head><title>400 Bad Request</title></head>\n<body bgcolor=\"white\">\n<center><h1>400 Bad Request</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 401\n\nNGX_HTTP_UNAUTHORIZED\n\n```\n参考如上nginx配置,访问abc.html需要认证\n \ncurl localhost:8070/abc.html\n\n\n<html>\n<head><title>401 Authorization Required</title></head>\n<body bgcolor=\"white\">\n<center><h1>401 Authorization Required</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 403\n\nNGX_HTTP_FORBIDDEN\n\n```\nchmod 222 index.html\n将index.html设置为不可读\n \ncurl localhost:8070\n\n\n<html>\n<head><title>403 Forbidden</title></head>\n<body bgcolor=\"white\">\n<center><h1>403 Forbidden</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 404\n\nNGX_HTTP_NOT_FOUND\n\n```\n\ncurl localhost:8070/cde.html\n\n\n<html>\n<head><title>404 Not Found</title></head>\n<body bgcolor=\"white\">\n<center><h1>404 Not Found</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 405\n\nNGX_HTTP_NOT_ALLOWED\n\n```\n使用非GET/POST/HEAD方法访问一个静态文件\ncurl -X DELETE localhost:8070/index.html -I\n\n\nHTTP/1.1 405 Not Allowed\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 10:02:22 GMT\nContent-Type: text/html\nContent-Length: 173\nConnection: keep-alive\n```\n\n## 5xx系列\n\n### 500\n\nNGX_HTTP_INTERNAL_SERVER_ERROR\n\n```\n修改index.php为\n\n<?php\necho \"124\"\n \n缺少引号,语法错误\n```\n\n```\n\ncurl localhost:8070/index.php -I\n\n\nHTTP/1.1 500 Internal Server Error\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:29:19 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: keep-alive\nSet-Cookie: PHPSESSID=aoesvcuvbh1nh95kdkp152r9e1; path=/\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate\nPragma: no-cache\n```\n\n### 501\nNGX_HTTP_NOT_IMPLEMENTED\n\n```\n\nnginx的transfer-encoding现在只支持chunked,如果客户端随意设置这个值,会报501\n \ncurl localhost:8070  -H 'Transfer-Encoding:1'\n\n\n<html>\n<head><title>501 Not Implemented</title></head>\n<body bgcolor=\"white\">\n<center><h1>501 Not Implemented</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n\n### 502\n\nNGX_HTTP_BAD_GATEWAY\n\n```\n修改nginx配置为\nfastcgi_pass 127.0.0.1:8000;\n\n\n指向一个未监听的端口\n```\n\n```\ncurl localhost:8070/index.php -I\n\n\nHTTP/1.1 502 Bad Gateway\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:28:17 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n### 503\n\nNGX_HTTP_SERVICE_UNAVAILABLE\n\n```\n修改nginx配置,限速为每分钟10个请求\n \nlimit_req_zone $binary_remote_addr zone=one:10m rate=10r/m;\nlimit_req zone=one;\n```\n\n```\n连续发送两个请求，第二请求会报503\ncurl localhost:8070/index.php -I\n\nHTTP/1.1 503 Service Temporarily Unavailable\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 11:31:43 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n### 504\n\nNGX_HTTP_GATEWAY_TIME_OUT\n\n```\n\n修改index.php为\n<?php\necho \"124\";\nsleep(5);\n休息5秒钟\n \n修改nginx配置为\n三秒钟读超时\nfastcgi_read_timeout 3;\n\n```\n\n```\n\ncurl localhost:8070/index.php -I\n\nHTTP/1.1 504 Gateway Time-out\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 12:17:57 GMT\nContent-Type: text/html\nContent-Length: 537\nConnection: keep-alive\nETag: \"5ad6113c-219\"\n```\n\n\n### 505\n\nNGX_HTTP_VERSION_NOT_SUPPORTED\n\n```\ntelnet8070端口,输入GET /index.html HTTP/2.1\n不支持http/2.1,会报505\n \n$telnet localhost 8070\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nGET /index.html HTTP/2.1\nHTTP/1.1 505 HTTP Version Not Supported\nServer: nginx/1.14.0\nDate: Tue, 18 Sep 2018 12:26:35 GMT\nContent-Type: text/html\nContent-Length: 203\nConnection: close\n<html>\n<head><title>505 HTTP Version Not Supported</title></head>\n<body bgcolor=\"white\">\n<center><h1>505 HTTP Version Not Supported</h1></center>\n<hr><center>nginx/1.14.0</center>\n</body>\n</html>\n```\n","slug":"NGINX-4xx-5xx-状态码构造","published":1,"updated":"2019-02-19T06:54:50.710Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9d0006bms69z2on2dk","content":"<h2 id=\"nginx配置\"><a href=\"#nginx配置\" class=\"headerlink\" title=\"nginx配置\"></a>nginx配置</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_processes  1;</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">    worker_connections  1024;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http &#123;</span><br><span class=\"line\">    include       mime.types;</span><br><span class=\"line\">    default_type  application/octet-stream;</span><br><span class=\"line\">    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;</span><br><span class=\"line\">    sendfile        on;</span><br><span class=\"line\">    keepalive_timeout  65;</span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen       8070;</span><br><span class=\"line\">        server_name  10.96.79.14;</span><br><span class=\"line\">        limit_req zone=one;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root   html;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        error_page   500 502 503 504  /50x.html;</span><br><span class=\"line\">        location = /50x.html &#123;</span><br><span class=\"line\">            root   html;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        location = /abc.html &#123;</span><br><span class=\"line\">            root html;</span><br><span class=\"line\">            auth_basic           &quot;opened site&quot;;</span><br><span class=\"line\">            auth_basic_user_file conf/htpasswd;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">         location ~ \\.php$ &#123;</span><br><span class=\"line\">            root /home/xiaoju/nginx-1.14.0/html;</span><br><span class=\"line\">            fastcgi_index index.php;</span><br><span class=\"line\">            fastcgi_pass 127.0.0.1:9000;</span><br><span class=\"line\">            fastcgi_param       SCRIPT_FILENAME  /home/xiaoju/nginx-1.14.0/html$fastcgi_script_name;</span><br><span class=\"line\">            include fastcgi.conf;</span><br><span class=\"line\">            fastcgi_connect_timeout 300;</span><br><span class=\"line\">            fastcgi_send_timeout 300;</span><br><span class=\"line\">            fastcgi_read_timeout 300;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index.php</span><br><span class=\"line\"> </span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4xx系列\"><a href=\"#4xx系列\" class=\"headerlink\" title=\"4xx系列\"></a>4xx系列</h2><h3 id=\"400\"><a href=\"#400\" class=\"headerlink\" title=\"400\"></a>400</h3><p>NGX_HTTP_BAD_REQUEST</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host头不合法</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070  -H &apos;Host:123/com&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br><span class=\"line\"> </span><br><span class=\"line\">Content-Length头重复</span><br><span class=\"line\">curl localhost:8070  -H &apos;Content-Length:1&apos;  -H &apos;Content-Length:2&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"401\"><a href=\"#401\" class=\"headerlink\" title=\"401\"></a>401</h3><p>NGX_HTTP_UNAUTHORIZED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">参考如上nginx配置,访问abc.html需要认证</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070/abc.html</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"403\"><a href=\"#403\" class=\"headerlink\" title=\"403\"></a>403</h3><p>NGX_HTTP_FORBIDDEN</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 222 index.html</span><br><span class=\"line\">将index.html设置为不可读</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"404\"><a href=\"#404\" class=\"headerlink\" title=\"404\"></a>404</h3><p>NGX_HTTP_NOT_FOUND</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/cde.html</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"405\"><a href=\"#405\" class=\"headerlink\" title=\"405\"></a>405</h3><p>NGX_HTTP_NOT_ALLOWED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">使用非GET/POST/HEAD方法访问一个静态文件</span><br><span class=\"line\">curl -X DELETE localhost:8070/index.html -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 405 Not Allowed</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 10:02:22 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 173</span><br><span class=\"line\">Connection: keep-alive</span><br></pre></td></tr></table></figure>\n<h2 id=\"5xx系列\"><a href=\"#5xx系列\" class=\"headerlink\" title=\"5xx系列\"></a>5xx系列</h2><h3 id=\"500\"><a href=\"#500\" class=\"headerlink\" title=\"500\"></a>500</h3><p>NGX_HTTP_INTERNAL_SERVER_ERROR</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改index.php为</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;</span><br><span class=\"line\"> </span><br><span class=\"line\">缺少引号,语法错误</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 500 Internal Server Error</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:29:19 GMT</span><br><span class=\"line\">Content-Type: text/html; charset=UTF-8</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">Set-Cookie: PHPSESSID=aoesvcuvbh1nh95kdkp152r9e1; path=/</span><br><span class=\"line\">Expires: Thu, 19 Nov 1981 08:52:00 GMT</span><br><span class=\"line\">Cache-Control: no-store, no-cache, must-revalidate</span><br><span class=\"line\">Pragma: no-cache</span><br></pre></td></tr></table></figure>\n<h3 id=\"501\"><a href=\"#501\" class=\"headerlink\" title=\"501\"></a>501</h3><p>NGX_HTTP_NOT_IMPLEMENTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">nginx的transfer-encoding现在只支持chunked,如果客户端随意设置这个值,会报501</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070  -H &apos;Transfer-Encoding:1&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;501 Not Implemented&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;501 Not Implemented&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"502\"><a href=\"#502\" class=\"headerlink\" title=\"502\"></a>502</h3><p>NGX_HTTP_BAD_GATEWAY</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改nginx配置为</span><br><span class=\"line\">fastcgi_pass 127.0.0.1:8000;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">指向一个未监听的端口</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 502 Bad Gateway</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:28:17 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"503\"><a href=\"#503\" class=\"headerlink\" title=\"503\"></a>503</h3><p>NGX_HTTP_SERVICE_UNAVAILABLE</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改nginx配置,限速为每分钟10个请求</span><br><span class=\"line\"> </span><br><span class=\"line\">limit_req_zone $binary_remote_addr zone=one:10m rate=10r/m;</span><br><span class=\"line\">limit_req zone=one;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">连续发送两个请求，第二请求会报503</span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 503 Service Temporarily Unavailable</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:31:43 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"504\"><a href=\"#504\" class=\"headerlink\" title=\"504\"></a>504</h3><p>NGX_HTTP_GATEWAY_TIME_OUT</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">修改index.php为</span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;;</span><br><span class=\"line\">sleep(5);</span><br><span class=\"line\">休息5秒钟</span><br><span class=\"line\"> </span><br><span class=\"line\">修改nginx配置为</span><br><span class=\"line\">三秒钟读超时</span><br><span class=\"line\">fastcgi_read_timeout 3;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 504 Gateway Time-out</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 12:17:57 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"505\"><a href=\"#505\" class=\"headerlink\" title=\"505\"></a>505</h3><p>NGX_HTTP_VERSION_NOT_SUPPORTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">telnet8070端口,输入GET /index.html HTTP/2.1</span><br><span class=\"line\">不支持http/2.1,会报505</span><br><span class=\"line\"> </span><br><span class=\"line\">$telnet localhost 8070</span><br><span class=\"line\">Trying 127.0.0.1...</span><br><span class=\"line\">Connected to localhost.</span><br><span class=\"line\">Escape character is &apos;^]&apos;.</span><br><span class=\"line\">GET /index.html HTTP/2.1</span><br><span class=\"line\">HTTP/1.1 505 HTTP Version Not Supported</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 12:26:35 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 203</span><br><span class=\"line\">Connection: close</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;505 HTTP Version Not Supported&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;505 HTTP Version Not Supported&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"nginx配置\"><a href=\"#nginx配置\" class=\"headerlink\" title=\"nginx配置\"></a>nginx配置</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">worker_processes  1;</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">    worker_connections  1024;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http &#123;</span><br><span class=\"line\">    include       mime.types;</span><br><span class=\"line\">    default_type  application/octet-stream;</span><br><span class=\"line\">    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;</span><br><span class=\"line\">    sendfile        on;</span><br><span class=\"line\">    keepalive_timeout  65;</span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">        listen       8070;</span><br><span class=\"line\">        server_name  10.96.79.14;</span><br><span class=\"line\">        limit_req zone=one;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root   html;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        error_page   500 502 503 504  /50x.html;</span><br><span class=\"line\">        location = /50x.html &#123;</span><br><span class=\"line\">            root   html;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        location = /abc.html &#123;</span><br><span class=\"line\">            root html;</span><br><span class=\"line\">            auth_basic           &quot;opened site&quot;;</span><br><span class=\"line\">            auth_basic_user_file conf/htpasswd;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">         location ~ \\.php$ &#123;</span><br><span class=\"line\">            root /home/xiaoju/nginx-1.14.0/html;</span><br><span class=\"line\">            fastcgi_index index.php;</span><br><span class=\"line\">            fastcgi_pass 127.0.0.1:9000;</span><br><span class=\"line\">            fastcgi_param       SCRIPT_FILENAME  /home/xiaoju/nginx-1.14.0/html$fastcgi_script_name;</span><br><span class=\"line\">            include fastcgi.conf;</span><br><span class=\"line\">            fastcgi_connect_timeout 300;</span><br><span class=\"line\">            fastcgi_send_timeout 300;</span><br><span class=\"line\">            fastcgi_read_timeout 300;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index.php</span><br><span class=\"line\"> </span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4xx系列\"><a href=\"#4xx系列\" class=\"headerlink\" title=\"4xx系列\"></a>4xx系列</h2><h3 id=\"400\"><a href=\"#400\" class=\"headerlink\" title=\"400\"></a>400</h3><p>NGX_HTTP_BAD_REQUEST</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host头不合法</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070  -H &apos;Host:123/com&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br><span class=\"line\"> </span><br><span class=\"line\">Content-Length头重复</span><br><span class=\"line\">curl localhost:8070  -H &apos;Content-Length:1&apos;  -H &apos;Content-Length:2&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"401\"><a href=\"#401\" class=\"headerlink\" title=\"401\"></a>401</h3><p>NGX_HTTP_UNAUTHORIZED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">参考如上nginx配置,访问abc.html需要认证</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070/abc.html</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"403\"><a href=\"#403\" class=\"headerlink\" title=\"403\"></a>403</h3><p>NGX_HTTP_FORBIDDEN</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 222 index.html</span><br><span class=\"line\">将index.html设置为不可读</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"404\"><a href=\"#404\" class=\"headerlink\" title=\"404\"></a>404</h3><p>NGX_HTTP_NOT_FOUND</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/cde.html</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"405\"><a href=\"#405\" class=\"headerlink\" title=\"405\"></a>405</h3><p>NGX_HTTP_NOT_ALLOWED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">使用非GET/POST/HEAD方法访问一个静态文件</span><br><span class=\"line\">curl -X DELETE localhost:8070/index.html -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 405 Not Allowed</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 10:02:22 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 173</span><br><span class=\"line\">Connection: keep-alive</span><br></pre></td></tr></table></figure>\n<h2 id=\"5xx系列\"><a href=\"#5xx系列\" class=\"headerlink\" title=\"5xx系列\"></a>5xx系列</h2><h3 id=\"500\"><a href=\"#500\" class=\"headerlink\" title=\"500\"></a>500</h3><p>NGX_HTTP_INTERNAL_SERVER_ERROR</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改index.php为</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;</span><br><span class=\"line\"> </span><br><span class=\"line\">缺少引号,语法错误</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 500 Internal Server Error</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:29:19 GMT</span><br><span class=\"line\">Content-Type: text/html; charset=UTF-8</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">Set-Cookie: PHPSESSID=aoesvcuvbh1nh95kdkp152r9e1; path=/</span><br><span class=\"line\">Expires: Thu, 19 Nov 1981 08:52:00 GMT</span><br><span class=\"line\">Cache-Control: no-store, no-cache, must-revalidate</span><br><span class=\"line\">Pragma: no-cache</span><br></pre></td></tr></table></figure>\n<h3 id=\"501\"><a href=\"#501\" class=\"headerlink\" title=\"501\"></a>501</h3><p>NGX_HTTP_NOT_IMPLEMENTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">nginx的transfer-encoding现在只支持chunked,如果客户端随意设置这个值,会报501</span><br><span class=\"line\"> </span><br><span class=\"line\">curl localhost:8070  -H &apos;Transfer-Encoding:1&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;501 Not Implemented&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;501 Not Implemented&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"502\"><a href=\"#502\" class=\"headerlink\" title=\"502\"></a>502</h3><p>NGX_HTTP_BAD_GATEWAY</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改nginx配置为</span><br><span class=\"line\">fastcgi_pass 127.0.0.1:8000;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">指向一个未监听的端口</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 502 Bad Gateway</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:28:17 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"503\"><a href=\"#503\" class=\"headerlink\" title=\"503\"></a>503</h3><p>NGX_HTTP_SERVICE_UNAVAILABLE</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改nginx配置,限速为每分钟10个请求</span><br><span class=\"line\"> </span><br><span class=\"line\">limit_req_zone $binary_remote_addr zone=one:10m rate=10r/m;</span><br><span class=\"line\">limit_req zone=one;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">连续发送两个请求，第二请求会报503</span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 503 Service Temporarily Unavailable</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 11:31:43 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"504\"><a href=\"#504\" class=\"headerlink\" title=\"504\"></a>504</h3><p>NGX_HTTP_GATEWAY_TIME_OUT</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">修改index.php为</span><br><span class=\"line\">&lt;?php</span><br><span class=\"line\">echo &quot;124&quot;;</span><br><span class=\"line\">sleep(5);</span><br><span class=\"line\">休息5秒钟</span><br><span class=\"line\"> </span><br><span class=\"line\">修改nginx配置为</span><br><span class=\"line\">三秒钟读超时</span><br><span class=\"line\">fastcgi_read_timeout 3;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl localhost:8070/index.php -I</span><br><span class=\"line\"></span><br><span class=\"line\">HTTP/1.1 504 Gateway Time-out</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 12:17:57 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 537</span><br><span class=\"line\">Connection: keep-alive</span><br><span class=\"line\">ETag: &quot;5ad6113c-219&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"505\"><a href=\"#505\" class=\"headerlink\" title=\"505\"></a>505</h3><p>NGX_HTTP_VERSION_NOT_SUPPORTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">telnet8070端口,输入GET /index.html HTTP/2.1</span><br><span class=\"line\">不支持http/2.1,会报505</span><br><span class=\"line\"> </span><br><span class=\"line\">$telnet localhost 8070</span><br><span class=\"line\">Trying 127.0.0.1...</span><br><span class=\"line\">Connected to localhost.</span><br><span class=\"line\">Escape character is &apos;^]&apos;.</span><br><span class=\"line\">GET /index.html HTTP/2.1</span><br><span class=\"line\">HTTP/1.1 505 HTTP Version Not Supported</span><br><span class=\"line\">Server: nginx/1.14.0</span><br><span class=\"line\">Date: Tue, 18 Sep 2018 12:26:35 GMT</span><br><span class=\"line\">Content-Type: text/html</span><br><span class=\"line\">Content-Length: 203</span><br><span class=\"line\">Connection: close</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;&lt;title&gt;505 HTTP Version Not Supported&lt;/title&gt;&lt;/head&gt;</span><br><span class=\"line\">&lt;body bgcolor=&quot;white&quot;&gt;</span><br><span class=\"line\">&lt;center&gt;&lt;h1&gt;505 HTTP Version Not Supported&lt;/h1&gt;&lt;/center&gt;</span><br><span class=\"line\">&lt;hr&gt;&lt;center&gt;nginx/1.14.0&lt;/center&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n"},{"title":"Redis连接处理","date":"2019-05-09T16:00:00.000Z","_content":"本文从网络层视角看一下客户端连接,超时,输入输出缓冲区相关的一些知识\n\n## 连接\n客户端连接之后做如下处理:\n* 设置socket为non-blocking\n* 设置socket为TCP_NODELAY\n* 注册读取事件准备读取客户端请求\n\n但如果已经超出maxclients配置的最大连接数,则会发送错误后断开连接\n**注意是在连接已经建立之后才检测maxclients,为何不在accept的时候直接比较?**\n因为直接断开对客户端不太友好,客户端没法知道到底是什么原因导致的连接不了.该比较在连接之后并且是将client的fd设置为non-blocking之后,这样可以无阻塞的写入客户端错误原因\n\n代码参考:\n```\nstatic void acceptCommonHandler(int fd, int flags, char *ip) {\n    client *c;\n    if ((c = createClient(fd)) == NULL) {\n        ...\n    }\n    ...\n    if (listLength(server.clients) > server.maxclients) {\n        ...\n    }\n    ...\n}\n```\n## 处理顺序\n\nredis处理时有如下两点:\n* 当客户端socket有新数据时,只执行一次read()的系统调用(不会循环读取直到读取完).防止请求量小的客户端被饿死\n* 待确认?\n\n## 最大连接数\n不设置maxclients时默认是10000的并发连接数限制\nRedis内部需要使用32个文件描述符,如果32+maxclients超出操作系统设置的单进程最大能够打开的文件描述符(检查soft limit),则会在日志中打出\n\n系统层面(Linux)可以按如下两方法设置:\n* ulimit -Sn 100000 # This will only work if hard limit is big enough.\n* sysctl -w fs.file-max=100000\n\n## 输出缓冲区\nRedis中可以设置输出缓冲区的大小:\n* hard limit:达到该值直接断开客户端连接\n* soft limit:连续时间t内一直大于某个数值m,则断开连接\n\n不同类型客户端的默认值:\n* normal clients:不限制\n* pub/sub clients: hard limit 32M,soft limit 8M 60s\n* slaves: hard limit 256M,soft limit 64M 60s\n\n代码详见:\n```\nint checkClientOutputBufferLimits(client *c) {\n   ...\n    if (server.client_obuf_limits[class].hard_limit_bytes &&\n        used_mem >= server.client_obuf_limits[class].hard_limit_bytes)\n        hard = 1;\n    if (server.client_obuf_limits[class].soft_limit_bytes &&\n        used_mem >= server.client_obuf_limits[class].soft_limit_bytes)\n        soft = 1;\n\n    ...\n    if (soft) {\n        if (c->obuf_soft_limit_reached_time == 0) {\n            c->obuf_soft_limit_reached_time = server.unixtime;\n            soft = 0; /* First time we see the soft limit reached */\n        } else {\n            time_t elapsed = server.unixtime - c->obuf_soft_limit_reached_time;\n\n            if (elapsed <=\n                server.client_obuf_limits[class].soft_limit_seconds) {\n                soft = 0; /* The client still did not reached the max number of\n                             seconds for the soft limit to be considered\n                             reached. */\n            }\n        }\n    } else {\n        c->obuf_soft_limit_reached_time = 0;\n    }\n    return soft || hard;\n}\n```\n\n## 输入缓冲区\n硬性限制为1GB,超出之后会断开连接\n\n## 超时\n默认没有空闲超时时间,但可以在redis.conf或者config set timeout value\n注意超时只针对 normal clients,pub/sub模式下不计算该超时\nRedis不会设置定时器去检查并且不会每次都顺序检查,而是增量式的检查.所以超时如果设置为10s,12s之后才断开也是正常的\n\n调用代码详见:\n```\nint clientsCronHandleTimeout(client *c, mstime_t now_ms) {\n    time_t now = now_ms/1000;\n\n    if (server.maxidletime &&\n        !(c->flags & CLIENT_SLAVE) &&    /* no timeout for slaves */\n        !(c->flags & CLIENT_MASTER) &&   /* no timeout for masters */\n        !(c->flags & CLIENT_BLOCKED) &&  /* no timeout for BLPOP */\n        !(c->flags & CLIENT_PUBSUB) &&   /* no timeout for Pub/Sub clients */\n        (now - c->lastinteraction > server.maxidletime))\n    {\n        ...\n    }\n```\n此处注意如何实现的增量式检查,代码如下:\n```\nvoid clientsCron(void) {\n    //每次只遍历iterations次,不会检查所有clients\n    while(listLength(server.clients) && iterations--) {\n        //rotate clients的链表,将最后一个node放到头部\n        listRotate(server.clients);\n        head = listFirst(server.clients);\n        c = listNodeValue(head);\n        //检查是否超时\n        if (clientsCronHandleTimeout(c,now)) continue;\n        ...\n    }\n}\n```\n可以看到每次都不会进行遍历,而是增量式取固定个数去执行检测\n\n## client命令\n```\n显示客户端状态\nclient lists\n```\n* addr 客户端地址\n* fd  句柄号\n* name 客户端名称-通过client setname设置\n* age  连接存在时间\n* idle 连接空闲时间\n* flags 客户端类型 n代表normal clients\n* omem  输出缓冲区内存使用大小\n* cmd 客户端最后执行的命令\n\n```\nkill一个客户端 \nclient kill\n```\n\n\n## tcp keepalive\n3.2以上版本会设置tcp keepalive ,时间为300s\n该机制能够检测出dead peers,并且如果客户端和服务端的中间代理有超时设置,可以避免被断开\n\n## 参考链接\n\n* https://redis.io/topics/clients","source":"_posts/Redis-handle-client.md","raw":"---\ntitle: Redis连接处理\ndate: 2019-05-10\ntags: Redis\n---\n本文从网络层视角看一下客户端连接,超时,输入输出缓冲区相关的一些知识\n\n## 连接\n客户端连接之后做如下处理:\n* 设置socket为non-blocking\n* 设置socket为TCP_NODELAY\n* 注册读取事件准备读取客户端请求\n\n但如果已经超出maxclients配置的最大连接数,则会发送错误后断开连接\n**注意是在连接已经建立之后才检测maxclients,为何不在accept的时候直接比较?**\n因为直接断开对客户端不太友好,客户端没法知道到底是什么原因导致的连接不了.该比较在连接之后并且是将client的fd设置为non-blocking之后,这样可以无阻塞的写入客户端错误原因\n\n代码参考:\n```\nstatic void acceptCommonHandler(int fd, int flags, char *ip) {\n    client *c;\n    if ((c = createClient(fd)) == NULL) {\n        ...\n    }\n    ...\n    if (listLength(server.clients) > server.maxclients) {\n        ...\n    }\n    ...\n}\n```\n## 处理顺序\n\nredis处理时有如下两点:\n* 当客户端socket有新数据时,只执行一次read()的系统调用(不会循环读取直到读取完).防止请求量小的客户端被饿死\n* 待确认?\n\n## 最大连接数\n不设置maxclients时默认是10000的并发连接数限制\nRedis内部需要使用32个文件描述符,如果32+maxclients超出操作系统设置的单进程最大能够打开的文件描述符(检查soft limit),则会在日志中打出\n\n系统层面(Linux)可以按如下两方法设置:\n* ulimit -Sn 100000 # This will only work if hard limit is big enough.\n* sysctl -w fs.file-max=100000\n\n## 输出缓冲区\nRedis中可以设置输出缓冲区的大小:\n* hard limit:达到该值直接断开客户端连接\n* soft limit:连续时间t内一直大于某个数值m,则断开连接\n\n不同类型客户端的默认值:\n* normal clients:不限制\n* pub/sub clients: hard limit 32M,soft limit 8M 60s\n* slaves: hard limit 256M,soft limit 64M 60s\n\n代码详见:\n```\nint checkClientOutputBufferLimits(client *c) {\n   ...\n    if (server.client_obuf_limits[class].hard_limit_bytes &&\n        used_mem >= server.client_obuf_limits[class].hard_limit_bytes)\n        hard = 1;\n    if (server.client_obuf_limits[class].soft_limit_bytes &&\n        used_mem >= server.client_obuf_limits[class].soft_limit_bytes)\n        soft = 1;\n\n    ...\n    if (soft) {\n        if (c->obuf_soft_limit_reached_time == 0) {\n            c->obuf_soft_limit_reached_time = server.unixtime;\n            soft = 0; /* First time we see the soft limit reached */\n        } else {\n            time_t elapsed = server.unixtime - c->obuf_soft_limit_reached_time;\n\n            if (elapsed <=\n                server.client_obuf_limits[class].soft_limit_seconds) {\n                soft = 0; /* The client still did not reached the max number of\n                             seconds for the soft limit to be considered\n                             reached. */\n            }\n        }\n    } else {\n        c->obuf_soft_limit_reached_time = 0;\n    }\n    return soft || hard;\n}\n```\n\n## 输入缓冲区\n硬性限制为1GB,超出之后会断开连接\n\n## 超时\n默认没有空闲超时时间,但可以在redis.conf或者config set timeout value\n注意超时只针对 normal clients,pub/sub模式下不计算该超时\nRedis不会设置定时器去检查并且不会每次都顺序检查,而是增量式的检查.所以超时如果设置为10s,12s之后才断开也是正常的\n\n调用代码详见:\n```\nint clientsCronHandleTimeout(client *c, mstime_t now_ms) {\n    time_t now = now_ms/1000;\n\n    if (server.maxidletime &&\n        !(c->flags & CLIENT_SLAVE) &&    /* no timeout for slaves */\n        !(c->flags & CLIENT_MASTER) &&   /* no timeout for masters */\n        !(c->flags & CLIENT_BLOCKED) &&  /* no timeout for BLPOP */\n        !(c->flags & CLIENT_PUBSUB) &&   /* no timeout for Pub/Sub clients */\n        (now - c->lastinteraction > server.maxidletime))\n    {\n        ...\n    }\n```\n此处注意如何实现的增量式检查,代码如下:\n```\nvoid clientsCron(void) {\n    //每次只遍历iterations次,不会检查所有clients\n    while(listLength(server.clients) && iterations--) {\n        //rotate clients的链表,将最后一个node放到头部\n        listRotate(server.clients);\n        head = listFirst(server.clients);\n        c = listNodeValue(head);\n        //检查是否超时\n        if (clientsCronHandleTimeout(c,now)) continue;\n        ...\n    }\n}\n```\n可以看到每次都不会进行遍历,而是增量式取固定个数去执行检测\n\n## client命令\n```\n显示客户端状态\nclient lists\n```\n* addr 客户端地址\n* fd  句柄号\n* name 客户端名称-通过client setname设置\n* age  连接存在时间\n* idle 连接空闲时间\n* flags 客户端类型 n代表normal clients\n* omem  输出缓冲区内存使用大小\n* cmd 客户端最后执行的命令\n\n```\nkill一个客户端 \nclient kill\n```\n\n\n## tcp keepalive\n3.2以上版本会设置tcp keepalive ,时间为300s\n该机制能够检测出dead peers,并且如果客户端和服务端的中间代理有超时设置,可以避免被断开\n\n## 参考链接\n\n* https://redis.io/topics/clients","slug":"Redis-handle-client","published":1,"updated":"2019-05-10T09:36:05.336Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9i0009bms6fk2fapwt","content":"<p>本文从网络层视角看一下客户端连接,超时,输入输出缓冲区相关的一些知识</p>\n<h2 id=\"连接\"><a href=\"#连接\" class=\"headerlink\" title=\"连接\"></a>连接</h2><p>客户端连接之后做如下处理:</p>\n<ul>\n<li>设置socket为non-blocking</li>\n<li>设置socket为TCP_NODELAY</li>\n<li>注册读取事件准备读取客户端请求</li>\n</ul>\n<p>但如果已经超出maxclients配置的最大连接数,则会发送错误后断开连接<br><strong>注意是在连接已经建立之后才检测maxclients,为何不在accept的时候直接比较?</strong><br>因为直接断开对客户端不太友好,客户端没法知道到底是什么原因导致的连接不了.该比较在连接之后并且是将client的fd设置为non-blocking之后,这样可以无阻塞的写入客户端错误原因</p>\n<p>代码参考:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static void acceptCommonHandler(int fd, int flags, char *ip) &#123;</span><br><span class=\"line\">    client *c;</span><br><span class=\"line\">    if ((c = createClient(fd)) == NULL) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    if (listLength(server.clients) &gt; server.maxclients) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"处理顺序\"><a href=\"#处理顺序\" class=\"headerlink\" title=\"处理顺序\"></a>处理顺序</h2><p>redis处理时有如下两点:</p>\n<ul>\n<li>当客户端socket有新数据时,只执行一次read()的系统调用(不会循环读取直到读取完).防止请求量小的客户端被饿死</li>\n<li>待确认?</li>\n</ul>\n<h2 id=\"最大连接数\"><a href=\"#最大连接数\" class=\"headerlink\" title=\"最大连接数\"></a>最大连接数</h2><p>不设置maxclients时默认是10000的并发连接数限制<br>Redis内部需要使用32个文件描述符,如果32+maxclients超出操作系统设置的单进程最大能够打开的文件描述符(检查soft limit),则会在日志中打出</p>\n<p>系统层面(Linux)可以按如下两方法设置:</p>\n<ul>\n<li>ulimit -Sn 100000 # This will only work if hard limit is big enough.</li>\n<li>sysctl -w fs.file-max=100000</li>\n</ul>\n<h2 id=\"输出缓冲区\"><a href=\"#输出缓冲区\" class=\"headerlink\" title=\"输出缓冲区\"></a>输出缓冲区</h2><p>Redis中可以设置输出缓冲区的大小:</p>\n<ul>\n<li>hard limit:达到该值直接断开客户端连接</li>\n<li>soft limit:连续时间t内一直大于某个数值m,则断开连接</li>\n</ul>\n<p>不同类型客户端的默认值:</p>\n<ul>\n<li>normal clients:不限制</li>\n<li>pub/sub clients: hard limit 32M,soft limit 8M 60s</li>\n<li>slaves: hard limit 256M,soft limit 64M 60s</li>\n</ul>\n<p>代码详见:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int checkClientOutputBufferLimits(client *c) &#123;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">    if (server.client_obuf_limits[class].hard_limit_bytes &amp;&amp;</span><br><span class=\"line\">        used_mem &gt;= server.client_obuf_limits[class].hard_limit_bytes)</span><br><span class=\"line\">        hard = 1;</span><br><span class=\"line\">    if (server.client_obuf_limits[class].soft_limit_bytes &amp;&amp;</span><br><span class=\"line\">        used_mem &gt;= server.client_obuf_limits[class].soft_limit_bytes)</span><br><span class=\"line\">        soft = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    if (soft) &#123;</span><br><span class=\"line\">        if (c-&gt;obuf_soft_limit_reached_time == 0) &#123;</span><br><span class=\"line\">            c-&gt;obuf_soft_limit_reached_time = server.unixtime;</span><br><span class=\"line\">            soft = 0; /* First time we see the soft limit reached */</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            time_t elapsed = server.unixtime - c-&gt;obuf_soft_limit_reached_time;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (elapsed &lt;=</span><br><span class=\"line\">                server.client_obuf_limits[class].soft_limit_seconds) &#123;</span><br><span class=\"line\">                soft = 0; /* The client still did not reached the max number of</span><br><span class=\"line\">                             seconds for the soft limit to be considered</span><br><span class=\"line\">                             reached. */</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        c-&gt;obuf_soft_limit_reached_time = 0;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return soft || hard;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"输入缓冲区\"><a href=\"#输入缓冲区\" class=\"headerlink\" title=\"输入缓冲区\"></a>输入缓冲区</h2><p>硬性限制为1GB,超出之后会断开连接</p>\n<h2 id=\"超时\"><a href=\"#超时\" class=\"headerlink\" title=\"超时\"></a>超时</h2><p>默认没有空闲超时时间,但可以在redis.conf或者config set timeout value<br>注意超时只针对 normal clients,pub/sub模式下不计算该超时<br>Redis不会设置定时器去检查并且不会每次都顺序检查,而是增量式的检查.所以超时如果设置为10s,12s之后才断开也是正常的</p>\n<p>调用代码详见:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int clientsCronHandleTimeout(client *c, mstime_t now_ms) &#123;</span><br><span class=\"line\">    time_t now = now_ms/1000;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (server.maxidletime &amp;&amp;</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_SLAVE) &amp;&amp;    /* no timeout for slaves */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp;   /* no timeout for masters */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_BLOCKED) &amp;&amp;  /* no timeout for BLPOP */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_PUBSUB) &amp;&amp;   /* no timeout for Pub/Sub clients */</span><br><span class=\"line\">        (now - c-&gt;lastinteraction &gt; server.maxidletime))</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>此处注意如何实现的增量式检查,代码如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void clientsCron(void) &#123;</span><br><span class=\"line\">    //每次只遍历iterations次,不会检查所有clients</span><br><span class=\"line\">    while(listLength(server.clients) &amp;&amp; iterations--) &#123;</span><br><span class=\"line\">        //rotate clients的链表,将最后一个node放到头部</span><br><span class=\"line\">        listRotate(server.clients);</span><br><span class=\"line\">        head = listFirst(server.clients);</span><br><span class=\"line\">        c = listNodeValue(head);</span><br><span class=\"line\">        //检查是否超时</span><br><span class=\"line\">        if (clientsCronHandleTimeout(c,now)) continue;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>可以看到每次都不会进行遍历,而是增量式取固定个数去执行检测</p>\n<h2 id=\"client命令\"><a href=\"#client命令\" class=\"headerlink\" title=\"client命令\"></a>client命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示客户端状态</span><br><span class=\"line\">client lists</span><br></pre></td></tr></table></figure>\n<ul>\n<li>addr 客户端地址</li>\n<li>fd  句柄号</li>\n<li>name 客户端名称-通过client setname设置</li>\n<li>age  连接存在时间</li>\n<li>idle 连接空闲时间</li>\n<li>flags 客户端类型 n代表normal clients</li>\n<li>omem  输出缓冲区内存使用大小</li>\n<li>cmd 客户端最后执行的命令</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kill一个客户端 </span><br><span class=\"line\">client kill</span><br></pre></td></tr></table></figure>\n<h2 id=\"tcp-keepalive\"><a href=\"#tcp-keepalive\" class=\"headerlink\" title=\"tcp keepalive\"></a>tcp keepalive</h2><p>3.2以上版本会设置tcp keepalive ,时间为300s<br>该机制能够检测出dead peers,并且如果客户端和服务端的中间代理有超时设置,可以避免被断开</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://redis.io/topics/clients\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/clients</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>本文从网络层视角看一下客户端连接,超时,输入输出缓冲区相关的一些知识</p>\n<h2 id=\"连接\"><a href=\"#连接\" class=\"headerlink\" title=\"连接\"></a>连接</h2><p>客户端连接之后做如下处理:</p>\n<ul>\n<li>设置socket为non-blocking</li>\n<li>设置socket为TCP_NODELAY</li>\n<li>注册读取事件准备读取客户端请求</li>\n</ul>\n<p>但如果已经超出maxclients配置的最大连接数,则会发送错误后断开连接<br><strong>注意是在连接已经建立之后才检测maxclients,为何不在accept的时候直接比较?</strong><br>因为直接断开对客户端不太友好,客户端没法知道到底是什么原因导致的连接不了.该比较在连接之后并且是将client的fd设置为non-blocking之后,这样可以无阻塞的写入客户端错误原因</p>\n<p>代码参考:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static void acceptCommonHandler(int fd, int flags, char *ip) &#123;</span><br><span class=\"line\">    client *c;</span><br><span class=\"line\">    if ((c = createClient(fd)) == NULL) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    if (listLength(server.clients) &gt; server.maxclients) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"处理顺序\"><a href=\"#处理顺序\" class=\"headerlink\" title=\"处理顺序\"></a>处理顺序</h2><p>redis处理时有如下两点:</p>\n<ul>\n<li>当客户端socket有新数据时,只执行一次read()的系统调用(不会循环读取直到读取完).防止请求量小的客户端被饿死</li>\n<li>待确认?</li>\n</ul>\n<h2 id=\"最大连接数\"><a href=\"#最大连接数\" class=\"headerlink\" title=\"最大连接数\"></a>最大连接数</h2><p>不设置maxclients时默认是10000的并发连接数限制<br>Redis内部需要使用32个文件描述符,如果32+maxclients超出操作系统设置的单进程最大能够打开的文件描述符(检查soft limit),则会在日志中打出</p>\n<p>系统层面(Linux)可以按如下两方法设置:</p>\n<ul>\n<li>ulimit -Sn 100000 # This will only work if hard limit is big enough.</li>\n<li>sysctl -w fs.file-max=100000</li>\n</ul>\n<h2 id=\"输出缓冲区\"><a href=\"#输出缓冲区\" class=\"headerlink\" title=\"输出缓冲区\"></a>输出缓冲区</h2><p>Redis中可以设置输出缓冲区的大小:</p>\n<ul>\n<li>hard limit:达到该值直接断开客户端连接</li>\n<li>soft limit:连续时间t内一直大于某个数值m,则断开连接</li>\n</ul>\n<p>不同类型客户端的默认值:</p>\n<ul>\n<li>normal clients:不限制</li>\n<li>pub/sub clients: hard limit 32M,soft limit 8M 60s</li>\n<li>slaves: hard limit 256M,soft limit 64M 60s</li>\n</ul>\n<p>代码详见:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int checkClientOutputBufferLimits(client *c) &#123;</span><br><span class=\"line\">   ...</span><br><span class=\"line\">    if (server.client_obuf_limits[class].hard_limit_bytes &amp;&amp;</span><br><span class=\"line\">        used_mem &gt;= server.client_obuf_limits[class].hard_limit_bytes)</span><br><span class=\"line\">        hard = 1;</span><br><span class=\"line\">    if (server.client_obuf_limits[class].soft_limit_bytes &amp;&amp;</span><br><span class=\"line\">        used_mem &gt;= server.client_obuf_limits[class].soft_limit_bytes)</span><br><span class=\"line\">        soft = 1;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    if (soft) &#123;</span><br><span class=\"line\">        if (c-&gt;obuf_soft_limit_reached_time == 0) &#123;</span><br><span class=\"line\">            c-&gt;obuf_soft_limit_reached_time = server.unixtime;</span><br><span class=\"line\">            soft = 0; /* First time we see the soft limit reached */</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            time_t elapsed = server.unixtime - c-&gt;obuf_soft_limit_reached_time;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (elapsed &lt;=</span><br><span class=\"line\">                server.client_obuf_limits[class].soft_limit_seconds) &#123;</span><br><span class=\"line\">                soft = 0; /* The client still did not reached the max number of</span><br><span class=\"line\">                             seconds for the soft limit to be considered</span><br><span class=\"line\">                             reached. */</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        c-&gt;obuf_soft_limit_reached_time = 0;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return soft || hard;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"输入缓冲区\"><a href=\"#输入缓冲区\" class=\"headerlink\" title=\"输入缓冲区\"></a>输入缓冲区</h2><p>硬性限制为1GB,超出之后会断开连接</p>\n<h2 id=\"超时\"><a href=\"#超时\" class=\"headerlink\" title=\"超时\"></a>超时</h2><p>默认没有空闲超时时间,但可以在redis.conf或者config set timeout value<br>注意超时只针对 normal clients,pub/sub模式下不计算该超时<br>Redis不会设置定时器去检查并且不会每次都顺序检查,而是增量式的检查.所以超时如果设置为10s,12s之后才断开也是正常的</p>\n<p>调用代码详见:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int clientsCronHandleTimeout(client *c, mstime_t now_ms) &#123;</span><br><span class=\"line\">    time_t now = now_ms/1000;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (server.maxidletime &amp;&amp;</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_SLAVE) &amp;&amp;    /* no timeout for slaves */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_MASTER) &amp;&amp;   /* no timeout for masters */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_BLOCKED) &amp;&amp;  /* no timeout for BLPOP */</span><br><span class=\"line\">        !(c-&gt;flags &amp; CLIENT_PUBSUB) &amp;&amp;   /* no timeout for Pub/Sub clients */</span><br><span class=\"line\">        (now - c-&gt;lastinteraction &gt; server.maxidletime))</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure></p>\n<p>此处注意如何实现的增量式检查,代码如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void clientsCron(void) &#123;</span><br><span class=\"line\">    //每次只遍历iterations次,不会检查所有clients</span><br><span class=\"line\">    while(listLength(server.clients) &amp;&amp; iterations--) &#123;</span><br><span class=\"line\">        //rotate clients的链表,将最后一个node放到头部</span><br><span class=\"line\">        listRotate(server.clients);</span><br><span class=\"line\">        head = listFirst(server.clients);</span><br><span class=\"line\">        c = listNodeValue(head);</span><br><span class=\"line\">        //检查是否超时</span><br><span class=\"line\">        if (clientsCronHandleTimeout(c,now)) continue;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>可以看到每次都不会进行遍历,而是增量式取固定个数去执行检测</p>\n<h2 id=\"client命令\"><a href=\"#client命令\" class=\"headerlink\" title=\"client命令\"></a>client命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示客户端状态</span><br><span class=\"line\">client lists</span><br></pre></td></tr></table></figure>\n<ul>\n<li>addr 客户端地址</li>\n<li>fd  句柄号</li>\n<li>name 客户端名称-通过client setname设置</li>\n<li>age  连接存在时间</li>\n<li>idle 连接空闲时间</li>\n<li>flags 客户端类型 n代表normal clients</li>\n<li>omem  输出缓冲区内存使用大小</li>\n<li>cmd 客户端最后执行的命令</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kill一个客户端 </span><br><span class=\"line\">client kill</span><br></pre></td></tr></table></figure>\n<h2 id=\"tcp-keepalive\"><a href=\"#tcp-keepalive\" class=\"headerlink\" title=\"tcp keepalive\"></a>tcp keepalive</h2><p>3.2以上版本会设置tcp keepalive ,时间为300s<br>该机制能够检测出dead peers,并且如果客户端和服务端的中间代理有超时设置,可以避免被断开</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://redis.io/topics/clients\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/clients</a></li>\n</ul>\n"},{"title":"Redis module开发","date":"2019-04-16T16:00:00.000Z","_content":"\n## module的作用\n\nredis通过对外提供一套API和一些数据类型, 可以供开发者开发自己的模块并且加载到redis中.通过API可以直接操作redis中的数据,也可以通过调用redis命令来操作数据(类似lua script).\n通过编写模块可以注册自己的命令到redis中.\n\n## 编写一个module\n\n我们通过编写一个简单的module来体验一下该功能.该module对外提供两个命令,一个是启动一个定时任务,每隔5s将redis持久化相关的信息发送到pinfo这个channel中,另一个是关闭该定时任务.\n\n注册该模块后,我们可以通过\"subscribe pinfo\"来订阅该渠道,然后就可以定时收到redis持久化相关的信息,以便做一些监控或相应的应对措施 \n\n### 注册命令到redis中\n```\n//每个模块都必须有该函数.该函数是redis加载模块的入口,我们通过该函数可以注册相关的命令进去\nint RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    REDISMODULE_NOT_USED(argv);\n    REDISMODULE_NOT_USED(argc);\n    //注册模块,模块名称为'pushpersistenceinfo'\n    if (RedisModule_Init(ctx,\"pushpersistenceinfo\",1,REDISMODULE_APIVER_1)\n        == REDISMODULE_ERR) return REDISMODULE_ERR;\n    //在redis中创建命令.第二部分为命令名称,第三部分为执行该命令时的回调函数\n    if (RedisModule_CreateCommand(ctx,\"pushpersistenceinfo.timer\",\n        TimerCommand_RedisCommand,\"readonly\",0,0,0) == REDISMODULE_ERR)\n        return REDISMODULE_ERR;\n\n    if (RedisModule_CreateCommand(ctx,\"pushpersistenceinfo.stop\",\n        TimerStopCommand_RedisCommand,\"readonly\",0,0,0) == REDISMODULE_ERR)\n        return REDISMODULE_ERR;\n\n    return REDISMODULE_OK;\n}\n```\n如上函数类似一个模板,只需要填充自己的模块名称和相应的命令即可.重点是调用RedisModule_CreateCommand时的第三个参数-即回调函数.\n\n### 定义回调函数\n```\n#define REDISMODULE_EXPERIMENTAL_API\n#include \"../redismodule.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <ctype.h>\n#include <string.h>\n#include <errno.h>\n\n\n\nRedisModuleString *infoStr;\nint off=0 ;//定时器开关\nvoid  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);\nvoid  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);\n\n/* Timer callback. */\n//时间任务的回调函数\nvoid timerHandler(RedisModuleCtx *ctx,void *data) {\n    if(off == 1) return;//如果关闭了定时器,则返回退出\n    REDISMODULE_NOT_USED(ctx);\n    getPersistenceStatus(ctx,&infoStr);//获取redis持久化相关的信息并放入infoStr中\n    publishPersistenceStatus(ctx,&infoStr);//publish redis持久化相关的信息到pinfo渠道\n    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行\n\n}\n\nint TimerCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    off = 0;\n    REDISMODULE_NOT_USED(argv);\n    REDISMODULE_NOT_USED(argc);\n    RedisModule_AutoMemory(ctx);//开启内存的自动管理\n    getPersistenceStatus(ctx,&infoStr);//获取redis持久化相关的信息并放入infoStr中\n    publishPersistenceStatus(ctx,&infoStr);//publish redis持久化相关的信息到pinfo渠道\n\n    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行.回调函数为timerHandler\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");//给客户端返回字符串\"OK\"\n}\nint TimerStopCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    off = 1;//关闭定时任务\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");//给客户端返回字符串\"OK\"\n}\n\nvoid  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr){\n    RedisModuleCallReply *reply;\n//调用info Persistence获取redis持久化相关的信息\n    reply = RedisModule_Call(ctx,\"info\",\"c\",\"Persistence\");\n\n    *infoStr = RedisModule_CreateStringFromCallReply(reply);\n}\n\nvoid  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr){\n      //调用publish pinfo xxxxx将持久化信息推送到pinfo渠道\n\n    RedisModule_Call(ctx,\"publish\",\"cs\",\"pinfo\",*infoStr);\n}\n```\n\n执行pushpersistenceinfo.timer和pushpersistenceinfo.stop命令后会分别回调TimerCommand_RedisCommand和TimerStopCommand_RedisCommand这两个回调函数.前者会创建一个定时任务,定时任务回调函数为timerHandler,如果off不为1,则回调函数中会再次创建定时任务;后者会将off置为1,不再执行定时任务.\n\n### 演示\n将模块置于redis源码目录的src/modules/目录中,然后执行如下命令编译模块\n\n```\ngcc -fPIC -std=gnu99 -c -o pushpersistenceinfo.o pushpersistenceinfo.c\nld -o pushpersistenceinfo.so pushpersistenceinfo.o -shared -Bsymbolic -lc\n\n```\n\n加载模块\n\n```\n127.0.0.1> module load $RedisSourcePath/src/modules/pushpersistenceinfo.so\nOK\n127.0.0.1> module list\n1) 1) \"name\"\n   2) \"pushpersistenceinfo\"\n   3) \"ver\"\n   4) (integer)\n```\n\n执行命令(首先订阅pinfo渠道)\n```\nredis-cli  subscribe pinfo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"pinfo\"\n3) (integer) 1\n```\n执行模块中的命令\n\n```\n127.0.0.1> PUSHPERSISTENCEINFO.timer\nOK\n```\n\n查看输出(可以看到,每隔5s会输出一次)\n```\n1) \"message\"\n2) \"pinfo\"\n3) \"# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n\"\n1) \"message\"\n2) \"pinfo\"\n3) \"# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n\"\n```\n\n停止定时器\n\n```\n127.0.0.1> PUSHPERSISTENCEINFO.stop\nOK\n```\n\n卸载模块\n\n```\n127.0.0.1> module unload pushpersistenceinfo\nOK\n```\n该模块代码地址:https://github.com/erpeng/redis-modules\n\n\n## 参考文档\n* https://redislabs.com/blog/writing-redis-modules/ \n* https://redis.io/topics/modules-intro\n* https://redis.io/topics/modules-api-ref\n* https://redis.io/topics/modules-native-types","source":"_posts/Redis module开发.md","raw":"---\ntitle: Redis module开发\ndate: 2019-04-17 \ntags: Redis\n---\n\n## module的作用\n\nredis通过对外提供一套API和一些数据类型, 可以供开发者开发自己的模块并且加载到redis中.通过API可以直接操作redis中的数据,也可以通过调用redis命令来操作数据(类似lua script).\n通过编写模块可以注册自己的命令到redis中.\n\n## 编写一个module\n\n我们通过编写一个简单的module来体验一下该功能.该module对外提供两个命令,一个是启动一个定时任务,每隔5s将redis持久化相关的信息发送到pinfo这个channel中,另一个是关闭该定时任务.\n\n注册该模块后,我们可以通过\"subscribe pinfo\"来订阅该渠道,然后就可以定时收到redis持久化相关的信息,以便做一些监控或相应的应对措施 \n\n### 注册命令到redis中\n```\n//每个模块都必须有该函数.该函数是redis加载模块的入口,我们通过该函数可以注册相关的命令进去\nint RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    REDISMODULE_NOT_USED(argv);\n    REDISMODULE_NOT_USED(argc);\n    //注册模块,模块名称为'pushpersistenceinfo'\n    if (RedisModule_Init(ctx,\"pushpersistenceinfo\",1,REDISMODULE_APIVER_1)\n        == REDISMODULE_ERR) return REDISMODULE_ERR;\n    //在redis中创建命令.第二部分为命令名称,第三部分为执行该命令时的回调函数\n    if (RedisModule_CreateCommand(ctx,\"pushpersistenceinfo.timer\",\n        TimerCommand_RedisCommand,\"readonly\",0,0,0) == REDISMODULE_ERR)\n        return REDISMODULE_ERR;\n\n    if (RedisModule_CreateCommand(ctx,\"pushpersistenceinfo.stop\",\n        TimerStopCommand_RedisCommand,\"readonly\",0,0,0) == REDISMODULE_ERR)\n        return REDISMODULE_ERR;\n\n    return REDISMODULE_OK;\n}\n```\n如上函数类似一个模板,只需要填充自己的模块名称和相应的命令即可.重点是调用RedisModule_CreateCommand时的第三个参数-即回调函数.\n\n### 定义回调函数\n```\n#define REDISMODULE_EXPERIMENTAL_API\n#include \"../redismodule.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <ctype.h>\n#include <string.h>\n#include <errno.h>\n\n\n\nRedisModuleString *infoStr;\nint off=0 ;//定时器开关\nvoid  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);\nvoid  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);\n\n/* Timer callback. */\n//时间任务的回调函数\nvoid timerHandler(RedisModuleCtx *ctx,void *data) {\n    if(off == 1) return;//如果关闭了定时器,则返回退出\n    REDISMODULE_NOT_USED(ctx);\n    getPersistenceStatus(ctx,&infoStr);//获取redis持久化相关的信息并放入infoStr中\n    publishPersistenceStatus(ctx,&infoStr);//publish redis持久化相关的信息到pinfo渠道\n    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行\n\n}\n\nint TimerCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    off = 0;\n    REDISMODULE_NOT_USED(argv);\n    REDISMODULE_NOT_USED(argc);\n    RedisModule_AutoMemory(ctx);//开启内存的自动管理\n    getPersistenceStatus(ctx,&infoStr);//获取redis持久化相关的信息并放入infoStr中\n    publishPersistenceStatus(ctx,&infoStr);//publish redis持久化相关的信息到pinfo渠道\n\n    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行.回调函数为timerHandler\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");//给客户端返回字符串\"OK\"\n}\nint TimerStopCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    off = 1;//关闭定时任务\n    return RedisModule_ReplyWithSimpleString(ctx, \"OK\");//给客户端返回字符串\"OK\"\n}\n\nvoid  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr){\n    RedisModuleCallReply *reply;\n//调用info Persistence获取redis持久化相关的信息\n    reply = RedisModule_Call(ctx,\"info\",\"c\",\"Persistence\");\n\n    *infoStr = RedisModule_CreateStringFromCallReply(reply);\n}\n\nvoid  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr){\n      //调用publish pinfo xxxxx将持久化信息推送到pinfo渠道\n\n    RedisModule_Call(ctx,\"publish\",\"cs\",\"pinfo\",*infoStr);\n}\n```\n\n执行pushpersistenceinfo.timer和pushpersistenceinfo.stop命令后会分别回调TimerCommand_RedisCommand和TimerStopCommand_RedisCommand这两个回调函数.前者会创建一个定时任务,定时任务回调函数为timerHandler,如果off不为1,则回调函数中会再次创建定时任务;后者会将off置为1,不再执行定时任务.\n\n### 演示\n将模块置于redis源码目录的src/modules/目录中,然后执行如下命令编译模块\n\n```\ngcc -fPIC -std=gnu99 -c -o pushpersistenceinfo.o pushpersistenceinfo.c\nld -o pushpersistenceinfo.so pushpersistenceinfo.o -shared -Bsymbolic -lc\n\n```\n\n加载模块\n\n```\n127.0.0.1> module load $RedisSourcePath/src/modules/pushpersistenceinfo.so\nOK\n127.0.0.1> module list\n1) 1) \"name\"\n   2) \"pushpersistenceinfo\"\n   3) \"ver\"\n   4) (integer)\n```\n\n执行命令(首先订阅pinfo渠道)\n```\nredis-cli  subscribe pinfo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"pinfo\"\n3) (integer) 1\n```\n执行模块中的命令\n\n```\n127.0.0.1> PUSHPERSISTENCEINFO.timer\nOK\n```\n\n查看输出(可以看到,每隔5s会输出一次)\n```\n1) \"message\"\n2) \"pinfo\"\n3) \"# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n\"\n1) \"message\"\n2) \"pinfo\"\n3) \"# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n\"\n```\n\n停止定时器\n\n```\n127.0.0.1> PUSHPERSISTENCEINFO.stop\nOK\n```\n\n卸载模块\n\n```\n127.0.0.1> module unload pushpersistenceinfo\nOK\n```\n该模块代码地址:https://github.com/erpeng/redis-modules\n\n\n## 参考文档\n* https://redislabs.com/blog/writing-redis-modules/ \n* https://redis.io/topics/modules-intro\n* https://redis.io/topics/modules-api-ref\n* https://redis.io/topics/modules-native-types","slug":"Redis module开发","published":1,"updated":"2019-04-17T12:15:47.398Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9k000bbms6g16w4wfd","content":"<h2 id=\"module的作用\"><a href=\"#module的作用\" class=\"headerlink\" title=\"module的作用\"></a>module的作用</h2><p>redis通过对外提供一套API和一些数据类型, 可以供开发者开发自己的模块并且加载到redis中.通过API可以直接操作redis中的数据,也可以通过调用redis命令来操作数据(类似lua script).<br>通过编写模块可以注册自己的命令到redis中.</p>\n<h2 id=\"编写一个module\"><a href=\"#编写一个module\" class=\"headerlink\" title=\"编写一个module\"></a>编写一个module</h2><p>我们通过编写一个简单的module来体验一下该功能.该module对外提供两个命令,一个是启动一个定时任务,每隔5s将redis持久化相关的信息发送到pinfo这个channel中,另一个是关闭该定时任务.</p>\n<p>注册该模块后,我们可以通过”subscribe pinfo”来订阅该渠道,然后就可以定时收到redis持久化相关的信息,以便做一些监控或相应的应对措施 </p>\n<h3 id=\"注册命令到redis中\"><a href=\"#注册命令到redis中\" class=\"headerlink\" title=\"注册命令到redis中\"></a>注册命令到redis中</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//每个模块都必须有该函数.该函数是redis加载模块的入口,我们通过该函数可以注册相关的命令进去</span><br><span class=\"line\">int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argv);</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argc);</span><br><span class=\"line\">    //注册模块,模块名称为&apos;pushpersistenceinfo&apos;</span><br><span class=\"line\">    if (RedisModule_Init(ctx,&quot;pushpersistenceinfo&quot;,1,REDISMODULE_APIVER_1)</span><br><span class=\"line\">        == REDISMODULE_ERR) return REDISMODULE_ERR;</span><br><span class=\"line\">    //在redis中创建命令.第二部分为命令名称,第三部分为执行该命令时的回调函数</span><br><span class=\"line\">    if (RedisModule_CreateCommand(ctx,&quot;pushpersistenceinfo.timer&quot;,</span><br><span class=\"line\">        TimerCommand_RedisCommand,&quot;readonly&quot;,0,0,0) == REDISMODULE_ERR)</span><br><span class=\"line\">        return REDISMODULE_ERR;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (RedisModule_CreateCommand(ctx,&quot;pushpersistenceinfo.stop&quot;,</span><br><span class=\"line\">        TimerStopCommand_RedisCommand,&quot;readonly&quot;,0,0,0) == REDISMODULE_ERR)</span><br><span class=\"line\">        return REDISMODULE_ERR;</span><br><span class=\"line\"></span><br><span class=\"line\">    return REDISMODULE_OK;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如上函数类似一个模板,只需要填充自己的模块名称和相应的命令即可.重点是调用RedisModule_CreateCommand时的第三个参数-即回调函数.</p>\n<h3 id=\"定义回调函数\"><a href=\"#定义回调函数\" class=\"headerlink\" title=\"定义回调函数\"></a>定义回调函数</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define REDISMODULE_EXPERIMENTAL_API</span><br><span class=\"line\">#include &quot;../redismodule.h&quot;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;ctype.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">RedisModuleString *infoStr;</span><br><span class=\"line\">int off=0 ;//定时器开关</span><br><span class=\"line\">void  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);</span><br><span class=\"line\">void  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);</span><br><span class=\"line\"></span><br><span class=\"line\">/* Timer callback. */</span><br><span class=\"line\">//时间任务的回调函数</span><br><span class=\"line\">void timerHandler(RedisModuleCtx *ctx,void *data) &#123;</span><br><span class=\"line\">    if(off == 1) return;//如果关闭了定时器,则返回退出</span><br><span class=\"line\">    REDISMODULE_NOT_USED(ctx);</span><br><span class=\"line\">    getPersistenceStatus(ctx,&amp;infoStr);//获取redis持久化相关的信息并放入infoStr中</span><br><span class=\"line\">    publishPersistenceStatus(ctx,&amp;infoStr);//publish redis持久化相关的信息到pinfo渠道</span><br><span class=\"line\">    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int TimerCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    off = 0;</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argv);</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argc);</span><br><span class=\"line\">    RedisModule_AutoMemory(ctx);//开启内存的自动管理</span><br><span class=\"line\">    getPersistenceStatus(ctx,&amp;infoStr);//获取redis持久化相关的信息并放入infoStr中</span><br><span class=\"line\">    publishPersistenceStatus(ctx,&amp;infoStr);//publish redis持久化相关的信息到pinfo渠道</span><br><span class=\"line\"></span><br><span class=\"line\">    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行.回调函数为timerHandler</span><br><span class=\"line\">    return RedisModule_ReplyWithSimpleString(ctx, &quot;OK&quot;);//给客户端返回字符串&quot;OK&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int TimerStopCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    off = 1;//关闭定时任务</span><br><span class=\"line\">    return RedisModule_ReplyWithSimpleString(ctx, &quot;OK&quot;);//给客户端返回字符串&quot;OK&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr)&#123;</span><br><span class=\"line\">    RedisModuleCallReply *reply;</span><br><span class=\"line\">//调用info Persistence获取redis持久化相关的信息</span><br><span class=\"line\">    reply = RedisModule_Call(ctx,&quot;info&quot;,&quot;c&quot;,&quot;Persistence&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    *infoStr = RedisModule_CreateStringFromCallReply(reply);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr)&#123;</span><br><span class=\"line\">      //调用publish pinfo xxxxx将持久化信息推送到pinfo渠道</span><br><span class=\"line\"></span><br><span class=\"line\">    RedisModule_Call(ctx,&quot;publish&quot;,&quot;cs&quot;,&quot;pinfo&quot;,*infoStr);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行pushpersistenceinfo.timer和pushpersistenceinfo.stop命令后会分别回调TimerCommand_RedisCommand和TimerStopCommand_RedisCommand这两个回调函数.前者会创建一个定时任务,定时任务回调函数为timerHandler,如果off不为1,则回调函数中会再次创建定时任务;后者会将off置为1,不再执行定时任务.</p>\n<h3 id=\"演示\"><a href=\"#演示\" class=\"headerlink\" title=\"演示\"></a>演示</h3><p>将模块置于redis源码目录的src/modules/目录中,然后执行如下命令编译模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -fPIC -std=gnu99 -c -o pushpersistenceinfo.o pushpersistenceinfo.c</span><br><span class=\"line\">ld -o pushpersistenceinfo.so pushpersistenceinfo.o -shared -Bsymbolic -lc</span><br></pre></td></tr></table></figure>\n<p>加载模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; module load $RedisSourcePath/src/modules/pushpersistenceinfo.so</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1&gt; module list</span><br><span class=\"line\">1) 1) &quot;name&quot;</span><br><span class=\"line\">   2) &quot;pushpersistenceinfo&quot;</span><br><span class=\"line\">   3) &quot;ver&quot;</span><br><span class=\"line\">   4) (integer)</span><br></pre></td></tr></table></figure>\n<p>执行命令(首先订阅pinfo渠道)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-cli  subscribe pinfo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br></pre></td></tr></table></figure></p>\n<p>执行模块中的命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; PUSHPERSISTENCEINFO.timer</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>查看输出(可以看到,每隔5s会输出一次)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) &quot;# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n&quot;</span><br><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) &quot;# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n&quot;</span><br></pre></td></tr></table></figure></p>\n<p>停止定时器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; PUSHPERSISTENCEINFO.stop</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>卸载模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; module unload pushpersistenceinfo</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>该模块代码地址:<a href=\"https://github.com/erpeng/redis-modules\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/redis-modules</a></p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><a href=\"https://redislabs.com/blog/writing-redis-modules/\" target=\"_blank\" rel=\"noopener\">https://redislabs.com/blog/writing-redis-modules/</a> </li>\n<li><a href=\"https://redis.io/topics/modules-intro\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-intro</a></li>\n<li><a href=\"https://redis.io/topics/modules-api-ref\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-api-ref</a></li>\n<li><a href=\"https://redis.io/topics/modules-native-types\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-native-types</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"module的作用\"><a href=\"#module的作用\" class=\"headerlink\" title=\"module的作用\"></a>module的作用</h2><p>redis通过对外提供一套API和一些数据类型, 可以供开发者开发自己的模块并且加载到redis中.通过API可以直接操作redis中的数据,也可以通过调用redis命令来操作数据(类似lua script).<br>通过编写模块可以注册自己的命令到redis中.</p>\n<h2 id=\"编写一个module\"><a href=\"#编写一个module\" class=\"headerlink\" title=\"编写一个module\"></a>编写一个module</h2><p>我们通过编写一个简单的module来体验一下该功能.该module对外提供两个命令,一个是启动一个定时任务,每隔5s将redis持久化相关的信息发送到pinfo这个channel中,另一个是关闭该定时任务.</p>\n<p>注册该模块后,我们可以通过”subscribe pinfo”来订阅该渠道,然后就可以定时收到redis持久化相关的信息,以便做一些监控或相应的应对措施 </p>\n<h3 id=\"注册命令到redis中\"><a href=\"#注册命令到redis中\" class=\"headerlink\" title=\"注册命令到redis中\"></a>注册命令到redis中</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//每个模块都必须有该函数.该函数是redis加载模块的入口,我们通过该函数可以注册相关的命令进去</span><br><span class=\"line\">int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argv);</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argc);</span><br><span class=\"line\">    //注册模块,模块名称为&apos;pushpersistenceinfo&apos;</span><br><span class=\"line\">    if (RedisModule_Init(ctx,&quot;pushpersistenceinfo&quot;,1,REDISMODULE_APIVER_1)</span><br><span class=\"line\">        == REDISMODULE_ERR) return REDISMODULE_ERR;</span><br><span class=\"line\">    //在redis中创建命令.第二部分为命令名称,第三部分为执行该命令时的回调函数</span><br><span class=\"line\">    if (RedisModule_CreateCommand(ctx,&quot;pushpersistenceinfo.timer&quot;,</span><br><span class=\"line\">        TimerCommand_RedisCommand,&quot;readonly&quot;,0,0,0) == REDISMODULE_ERR)</span><br><span class=\"line\">        return REDISMODULE_ERR;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (RedisModule_CreateCommand(ctx,&quot;pushpersistenceinfo.stop&quot;,</span><br><span class=\"line\">        TimerStopCommand_RedisCommand,&quot;readonly&quot;,0,0,0) == REDISMODULE_ERR)</span><br><span class=\"line\">        return REDISMODULE_ERR;</span><br><span class=\"line\"></span><br><span class=\"line\">    return REDISMODULE_OK;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>如上函数类似一个模板,只需要填充自己的模块名称和相应的命令即可.重点是调用RedisModule_CreateCommand时的第三个参数-即回调函数.</p>\n<h3 id=\"定义回调函数\"><a href=\"#定义回调函数\" class=\"headerlink\" title=\"定义回调函数\"></a>定义回调函数</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define REDISMODULE_EXPERIMENTAL_API</span><br><span class=\"line\">#include &quot;../redismodule.h&quot;</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;ctype.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">RedisModuleString *infoStr;</span><br><span class=\"line\">int off=0 ;//定时器开关</span><br><span class=\"line\">void  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);</span><br><span class=\"line\">void  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr);</span><br><span class=\"line\"></span><br><span class=\"line\">/* Timer callback. */</span><br><span class=\"line\">//时间任务的回调函数</span><br><span class=\"line\">void timerHandler(RedisModuleCtx *ctx,void *data) &#123;</span><br><span class=\"line\">    if(off == 1) return;//如果关闭了定时器,则返回退出</span><br><span class=\"line\">    REDISMODULE_NOT_USED(ctx);</span><br><span class=\"line\">    getPersistenceStatus(ctx,&amp;infoStr);//获取redis持久化相关的信息并放入infoStr中</span><br><span class=\"line\">    publishPersistenceStatus(ctx,&amp;infoStr);//publish redis持久化相关的信息到pinfo渠道</span><br><span class=\"line\">    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int TimerCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    off = 0;</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argv);</span><br><span class=\"line\">    REDISMODULE_NOT_USED(argc);</span><br><span class=\"line\">    RedisModule_AutoMemory(ctx);//开启内存的自动管理</span><br><span class=\"line\">    getPersistenceStatus(ctx,&amp;infoStr);//获取redis持久化相关的信息并放入infoStr中</span><br><span class=\"line\">    publishPersistenceStatus(ctx,&amp;infoStr);//publish redis持久化相关的信息到pinfo渠道</span><br><span class=\"line\"></span><br><span class=\"line\">    RedisModule_CreateTimer(ctx,5000,timerHandler,NULL);//创建定时任务,5s后执行.回调函数为timerHandler</span><br><span class=\"line\">    return RedisModule_ReplyWithSimpleString(ctx, &quot;OK&quot;);//给客户端返回字符串&quot;OK&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int TimerStopCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) &#123;</span><br><span class=\"line\">    off = 1;//关闭定时任务</span><br><span class=\"line\">    return RedisModule_ReplyWithSimpleString(ctx, &quot;OK&quot;);//给客户端返回字符串&quot;OK&quot;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void  getPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr)&#123;</span><br><span class=\"line\">    RedisModuleCallReply *reply;</span><br><span class=\"line\">//调用info Persistence获取redis持久化相关的信息</span><br><span class=\"line\">    reply = RedisModule_Call(ctx,&quot;info&quot;,&quot;c&quot;,&quot;Persistence&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    *infoStr = RedisModule_CreateStringFromCallReply(reply);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void  publishPersistenceStatus(RedisModuleCtx *ctx,RedisModuleString **infoStr)&#123;</span><br><span class=\"line\">      //调用publish pinfo xxxxx将持久化信息推送到pinfo渠道</span><br><span class=\"line\"></span><br><span class=\"line\">    RedisModule_Call(ctx,&quot;publish&quot;,&quot;cs&quot;,&quot;pinfo&quot;,*infoStr);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行pushpersistenceinfo.timer和pushpersistenceinfo.stop命令后会分别回调TimerCommand_RedisCommand和TimerStopCommand_RedisCommand这两个回调函数.前者会创建一个定时任务,定时任务回调函数为timerHandler,如果off不为1,则回调函数中会再次创建定时任务;后者会将off置为1,不再执行定时任务.</p>\n<h3 id=\"演示\"><a href=\"#演示\" class=\"headerlink\" title=\"演示\"></a>演示</h3><p>将模块置于redis源码目录的src/modules/目录中,然后执行如下命令编译模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gcc -fPIC -std=gnu99 -c -o pushpersistenceinfo.o pushpersistenceinfo.c</span><br><span class=\"line\">ld -o pushpersistenceinfo.so pushpersistenceinfo.o -shared -Bsymbolic -lc</span><br></pre></td></tr></table></figure>\n<p>加载模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; module load $RedisSourcePath/src/modules/pushpersistenceinfo.so</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1&gt; module list</span><br><span class=\"line\">1) 1) &quot;name&quot;</span><br><span class=\"line\">   2) &quot;pushpersistenceinfo&quot;</span><br><span class=\"line\">   3) &quot;ver&quot;</span><br><span class=\"line\">   4) (integer)</span><br></pre></td></tr></table></figure>\n<p>执行命令(首先订阅pinfo渠道)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-cli  subscribe pinfo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br></pre></td></tr></table></figure></p>\n<p>执行模块中的命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; PUSHPERSISTENCEINFO.timer</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>查看输出(可以看到,每隔5s会输出一次)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) &quot;# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n&quot;</span><br><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;pinfo&quot;</span><br><span class=\"line\">3) &quot;# Persistence\\r\\nloading:0\\r\\nrdb_changes_since_last_save:15\\r\\nrdb_bgsave_in_progress:0\\r\\nrdb_last_save_time:1555494610\\r\\nrdb_last_bgsave_status:ok\\r\\nrdb_last_bgsave_time_sec:-1\\r\\nrdb_current_bgsave_time_sec:-1\\r\\nrdb_last_cow_size:0\\r\\naof_enabled:1\\r\\naof_rewrite_in_progress:0\\r\\naof_rewrite_scheduled:0\\r\\naof_last_rewrite_time_sec:-1\\r\\naof_current_rewrite_time_sec:-1\\r\\naof_last_bgrewrite_status:ok\\r\\naof_last_write_status:ok\\r\\naof_last_cow_size:0\\r\\naof_current_size:631\\r\\naof_base_size:631\\r\\naof_pending_rewrite:0\\r\\naof_buffer_length:0\\r\\naof_rewrite_buffer_length:0\\r\\naof_pending_bio_fsync:0\\r\\naof_delayed_fsync:0\\r\\n&quot;</span><br></pre></td></tr></table></figure></p>\n<p>停止定时器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; PUSHPERSISTENCEINFO.stop</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>卸载模块</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1&gt; module unload pushpersistenceinfo</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>该模块代码地址:<a href=\"https://github.com/erpeng/redis-modules\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/redis-modules</a></p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><a href=\"https://redislabs.com/blog/writing-redis-modules/\" target=\"_blank\" rel=\"noopener\">https://redislabs.com/blog/writing-redis-modules/</a> </li>\n<li><a href=\"https://redis.io/topics/modules-intro\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-intro</a></li>\n<li><a href=\"https://redis.io/topics/modules-api-ref\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-api-ref</a></li>\n<li><a href=\"https://redis.io/topics/modules-native-types\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/modules-native-types</a></li>\n</ul>\n"},{"title":"Redis中查找大key","date":"2019-02-13T06:11:09.000Z","_content":"\n## redis-cli提供的方法\n注意以下所有试验基于redis 5.0.3版本\n\nredis-cli 提供一个bigkeys参数，可以扫描redis中的大key\n\n```\n  --bigkeys          Sample Redis keys looking for big keys.\n```\n执行之后输出如下所示:\n```\nbogon:sqlite didi$ redis-cli --bigkeys\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec\n# per 100 SCAN commands (not usually needed).\n[00.00%] Biggest zset   found so far 'testzset' with 129 members\n[00.00%] Biggest hash   found so far 'h2' with 513 fields\n[00.00%] Biggest set    found so far 'si1' with 5 members\n[00.00%] Biggest hash   found so far 'h4' with 514 fields\n[00.00%] Biggest string found so far 'key' with 9 bytes\n-------- summary -------\nSampled 9 keys in the keyspace!\nTotal key length in bytes is 27 (avg len 3.00)\nBiggest string found 'key' has 9 bytes\nBiggest    set found 'si1' has 5 members\nBiggest   hash found 'h4' has 514 fields\nBiggest   zset found 'testzset' has 129 members\n1 strings with 9 bytes (11.11% of keys, avg size 9.00)\n0 lists with 0 items (00.00% of keys, avg size 0.00)\n2 sets with 8 members (22.22% of keys, avg size 4.00)\n4 hashs with 1541 fields (44.44% of keys, avg size 385.25)\n2 zsets with 132 members (22.22% of keys, avg size 66.00)\n0 streams with 0 entries (00.00% of keys, avg size 0.00)\n```\n原理比较简单,使用scan命令去遍历所有的键，对每个键根据其类型执行\"STRLEN\",\"LLEN\",\"SCARD\",\"HLEN\",\"ZCARD\"这些命令获取其长度或者元素个数。\n\n该方法有两个缺点:\n\n1.线上使用:虽然scan命令通过游标遍历建空间并且在生产上可以通过对从服务执行该命令,但毕竟是一个线上操作\n\n2.set,zset,list以及hash类型只能获取有多少个元素。但其实元素多的不一定占用空间大\n\n所以有没有一种方法对线上没有影响，并且能直接以topn的形式输出每个键占用的空间大小呢？\n\n我们可以通过读取rdb文件的方式来试验一下，首先看看rdb文件的格式\n\n## rdb文件格式\n\nrdb是一种二进制文件格式,我们首先看看rdb文件的整体结构\n\n![rdb](/img/rdb1.png)\n\n首先是一个魔数,REDIS0009(redis5.0.3版本)。然后是一些附加属性字段,接着是db_num(0-15),然后是db和expire的字典大小(db和过期时间在Redis中是两个独立的hash table),接着是一个个key-value pairs，然后是一个EOF结束标志(0xFF),最后是8字节的checksum\n\nRedis中定义了一些opcode(1字节)，去标记opcode之后保存的是什么类型的数据。如下图所示\n\n![rdb](/img/rdb2.png)\n\nopcode 252标记一个过期时间,248和249分别表示lru或者lfu,接着是value_type,标记值的类型,接着就是一个个key和vlaue.我们看下value_type和redis中数据类型的对应关系\n\n\n数据类型 | 编码结构 | 值类型\n-------|------|-----\nOBJ_STRING(0)|OBJ_ENCODING_RAW(0)|RDB_TYPE_STRING(0)\nOBJ_LIST(1)|OBJ_ENCODING_QUICKLIST(9) |RDB_TYPE_LIST_QUICKLIST(14)\nOBJ_SET(2)|OBJ_ENCODING_INTSET(6)|RDB_TYPE_SET_INTSET(11)\nOBJ_SET(2)|OBJ_ENCODING_HT(2)|RDB_TYPE_SET(2)          \nOBJ_ZSET(3)|OBJ_ENCODING_ZIPLIST(5)|RDB_TYPE_ZSET_ZIPLIST(12)\nOBJ_ZSET(3)|OBJ_ENCODING_SKIPLIST(7)|RDB_TYPE_ZSET_2(5)\nOBJ_HASH(4)|OBJ_ENCODING_ZIPLIST(5)|RDB_TYPE_HASH_ZIPLIST(13)\nOBJ_HASH(4)|OBJ_ENCODING_HT(2)|RDB_TYPE_HASH(4)\n\nvalue_type就是值类型这一列，括号中的数字就是保存到rdb文件中时的实际使用数字\n\n知道了rdb的保存格式，我们可以写代码解析rdb文件,通过value_type去获取每个value的大小\n\n## godis-cli-bigkey使用方法\n代码地址如下:\n\nhttps://github.com/erpeng/godis-cli-bigkey\n\n下载之后在将rdb文件拷贝到项目根目录,按如下方式执行\n\n```\n\nbogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go -h\n  -debug\n    \topen debug mode  //debug模式，输出详细key/value信息\n  -topn int\n    \toutput topn keys (default 100)//默认输出top100的大key\n  -totallen\n    \tget total len (key and meta) or only value len (default true)//如果该选项设置为false,只输出rdb文件中value实际占用的大小\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t //默认为true,输出key、value和所有该key,value保存时使用的元数据总和\nexit status 2\n```\n\n我们具体执行一下，输出如下:\n\n```\nbogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go\nRdb Version:0009\nkey:k1,valueSize:9,valueType:0,expireTime:1549533396795,lfu:0,lru:0\nkey:key,valueSize:9,valueType:0,expireTime:0,lfu:0,lru:0\nkey:ss1,valueSize:14,valueType:2,expireTime:0,lfu:0,lru:0\nkey:si1,valueSize:23,valueType:11,expireTime:0,lfu:0,lru:0\nkey:l1,valueSize:28,valueType:14,expireTime:1549537004535,lfu:0,lru:0\nkey:h1,valueSize:33,valueType:13,expireTime:0,lfu:0,lru:0\nkey:z1,valueSize:67,valueType:12,expireTime:0,lfu:0,lru:0\nkey:testzset,valueSize:1303,valueType:5,expireTime:0,lfu:0,lru:0\nkey:h3,valueSize:8845,valueType:13,expireTime:0,lfu:0,lru:0\nkey:h2,valueSize:11680,valueType:4,expireTime:0,lfu:0,lru:0\nkey:h4,valueSize:11703,valueType:4,expireTime:0,lfu:0,lru:0\n```","source":"_posts/Redis中查找大key.md","raw":"---\ntitle: Redis中查找大key\ndate: 2019-02-13 14:11:09\ntags: Redis\n---\n\n## redis-cli提供的方法\n注意以下所有试验基于redis 5.0.3版本\n\nredis-cli 提供一个bigkeys参数，可以扫描redis中的大key\n\n```\n  --bigkeys          Sample Redis keys looking for big keys.\n```\n执行之后输出如下所示:\n```\nbogon:sqlite didi$ redis-cli --bigkeys\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec\n# per 100 SCAN commands (not usually needed).\n[00.00%] Biggest zset   found so far 'testzset' with 129 members\n[00.00%] Biggest hash   found so far 'h2' with 513 fields\n[00.00%] Biggest set    found so far 'si1' with 5 members\n[00.00%] Biggest hash   found so far 'h4' with 514 fields\n[00.00%] Biggest string found so far 'key' with 9 bytes\n-------- summary -------\nSampled 9 keys in the keyspace!\nTotal key length in bytes is 27 (avg len 3.00)\nBiggest string found 'key' has 9 bytes\nBiggest    set found 'si1' has 5 members\nBiggest   hash found 'h4' has 514 fields\nBiggest   zset found 'testzset' has 129 members\n1 strings with 9 bytes (11.11% of keys, avg size 9.00)\n0 lists with 0 items (00.00% of keys, avg size 0.00)\n2 sets with 8 members (22.22% of keys, avg size 4.00)\n4 hashs with 1541 fields (44.44% of keys, avg size 385.25)\n2 zsets with 132 members (22.22% of keys, avg size 66.00)\n0 streams with 0 entries (00.00% of keys, avg size 0.00)\n```\n原理比较简单,使用scan命令去遍历所有的键，对每个键根据其类型执行\"STRLEN\",\"LLEN\",\"SCARD\",\"HLEN\",\"ZCARD\"这些命令获取其长度或者元素个数。\n\n该方法有两个缺点:\n\n1.线上使用:虽然scan命令通过游标遍历建空间并且在生产上可以通过对从服务执行该命令,但毕竟是一个线上操作\n\n2.set,zset,list以及hash类型只能获取有多少个元素。但其实元素多的不一定占用空间大\n\n所以有没有一种方法对线上没有影响，并且能直接以topn的形式输出每个键占用的空间大小呢？\n\n我们可以通过读取rdb文件的方式来试验一下，首先看看rdb文件的格式\n\n## rdb文件格式\n\nrdb是一种二进制文件格式,我们首先看看rdb文件的整体结构\n\n![rdb](/img/rdb1.png)\n\n首先是一个魔数,REDIS0009(redis5.0.3版本)。然后是一些附加属性字段,接着是db_num(0-15),然后是db和expire的字典大小(db和过期时间在Redis中是两个独立的hash table),接着是一个个key-value pairs，然后是一个EOF结束标志(0xFF),最后是8字节的checksum\n\nRedis中定义了一些opcode(1字节)，去标记opcode之后保存的是什么类型的数据。如下图所示\n\n![rdb](/img/rdb2.png)\n\nopcode 252标记一个过期时间,248和249分别表示lru或者lfu,接着是value_type,标记值的类型,接着就是一个个key和vlaue.我们看下value_type和redis中数据类型的对应关系\n\n\n数据类型 | 编码结构 | 值类型\n-------|------|-----\nOBJ_STRING(0)|OBJ_ENCODING_RAW(0)|RDB_TYPE_STRING(0)\nOBJ_LIST(1)|OBJ_ENCODING_QUICKLIST(9) |RDB_TYPE_LIST_QUICKLIST(14)\nOBJ_SET(2)|OBJ_ENCODING_INTSET(6)|RDB_TYPE_SET_INTSET(11)\nOBJ_SET(2)|OBJ_ENCODING_HT(2)|RDB_TYPE_SET(2)          \nOBJ_ZSET(3)|OBJ_ENCODING_ZIPLIST(5)|RDB_TYPE_ZSET_ZIPLIST(12)\nOBJ_ZSET(3)|OBJ_ENCODING_SKIPLIST(7)|RDB_TYPE_ZSET_2(5)\nOBJ_HASH(4)|OBJ_ENCODING_ZIPLIST(5)|RDB_TYPE_HASH_ZIPLIST(13)\nOBJ_HASH(4)|OBJ_ENCODING_HT(2)|RDB_TYPE_HASH(4)\n\nvalue_type就是值类型这一列，括号中的数字就是保存到rdb文件中时的实际使用数字\n\n知道了rdb的保存格式，我们可以写代码解析rdb文件,通过value_type去获取每个value的大小\n\n## godis-cli-bigkey使用方法\n代码地址如下:\n\nhttps://github.com/erpeng/godis-cli-bigkey\n\n下载之后在将rdb文件拷贝到项目根目录,按如下方式执行\n\n```\n\nbogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go -h\n  -debug\n    \topen debug mode  //debug模式，输出详细key/value信息\n  -topn int\n    \toutput topn keys (default 100)//默认输出top100的大key\n  -totallen\n    \tget total len (key and meta) or only value len (default true)//如果该选项设置为false,只输出rdb文件中value实际占用的大小\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t //默认为true,输出key、value和所有该key,value保存时使用的元数据总和\nexit status 2\n```\n\n我们具体执行一下，输出如下:\n\n```\nbogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go\nRdb Version:0009\nkey:k1,valueSize:9,valueType:0,expireTime:1549533396795,lfu:0,lru:0\nkey:key,valueSize:9,valueType:0,expireTime:0,lfu:0,lru:0\nkey:ss1,valueSize:14,valueType:2,expireTime:0,lfu:0,lru:0\nkey:si1,valueSize:23,valueType:11,expireTime:0,lfu:0,lru:0\nkey:l1,valueSize:28,valueType:14,expireTime:1549537004535,lfu:0,lru:0\nkey:h1,valueSize:33,valueType:13,expireTime:0,lfu:0,lru:0\nkey:z1,valueSize:67,valueType:12,expireTime:0,lfu:0,lru:0\nkey:testzset,valueSize:1303,valueType:5,expireTime:0,lfu:0,lru:0\nkey:h3,valueSize:8845,valueType:13,expireTime:0,lfu:0,lru:0\nkey:h2,valueSize:11680,valueType:4,expireTime:0,lfu:0,lru:0\nkey:h4,valueSize:11703,valueType:4,expireTime:0,lfu:0,lru:0\n```","slug":"Redis中查找大key","published":1,"updated":"2019-02-19T06:33:28.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9m000ebms6pk1gs597","content":"<h2 id=\"redis-cli提供的方法\"><a href=\"#redis-cli提供的方法\" class=\"headerlink\" title=\"redis-cli提供的方法\"></a>redis-cli提供的方法</h2><p>注意以下所有试验基于redis 5.0.3版本</p>\n<p>redis-cli 提供一个bigkeys参数，可以扫描redis中的大key</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--bigkeys          Sample Redis keys looking for big keys.</span><br></pre></td></tr></table></figure>\n<p>执行之后输出如下所示:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bogon:sqlite didi$ redis-cli --bigkeys</span><br><span class=\"line\"># Scanning the entire keyspace to find biggest keys as well as</span><br><span class=\"line\"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span><br><span class=\"line\"># per 100 SCAN commands (not usually needed).</span><br><span class=\"line\">[00.00%] Biggest zset   found so far &apos;testzset&apos; with 129 members</span><br><span class=\"line\">[00.00%] Biggest hash   found so far &apos;h2&apos; with 513 fields</span><br><span class=\"line\">[00.00%] Biggest set    found so far &apos;si1&apos; with 5 members</span><br><span class=\"line\">[00.00%] Biggest hash   found so far &apos;h4&apos; with 514 fields</span><br><span class=\"line\">[00.00%] Biggest string found so far &apos;key&apos; with 9 bytes</span><br><span class=\"line\">-------- summary -------</span><br><span class=\"line\">Sampled 9 keys in the keyspace!</span><br><span class=\"line\">Total key length in bytes is 27 (avg len 3.00)</span><br><span class=\"line\">Biggest string found &apos;key&apos; has 9 bytes</span><br><span class=\"line\">Biggest    set found &apos;si1&apos; has 5 members</span><br><span class=\"line\">Biggest   hash found &apos;h4&apos; has 514 fields</span><br><span class=\"line\">Biggest   zset found &apos;testzset&apos; has 129 members</span><br><span class=\"line\">1 strings with 9 bytes (11.11% of keys, avg size 9.00)</span><br><span class=\"line\">0 lists with 0 items (00.00% of keys, avg size 0.00)</span><br><span class=\"line\">2 sets with 8 members (22.22% of keys, avg size 4.00)</span><br><span class=\"line\">4 hashs with 1541 fields (44.44% of keys, avg size 385.25)</span><br><span class=\"line\">2 zsets with 132 members (22.22% of keys, avg size 66.00)</span><br><span class=\"line\">0 streams with 0 entries (00.00% of keys, avg size 0.00)</span><br></pre></td></tr></table></figure></p>\n<p>原理比较简单,使用scan命令去遍历所有的键，对每个键根据其类型执行”STRLEN”,”LLEN”,”SCARD”,”HLEN”,”ZCARD”这些命令获取其长度或者元素个数。</p>\n<p>该方法有两个缺点:</p>\n<p>1.线上使用:虽然scan命令通过游标遍历建空间并且在生产上可以通过对从服务执行该命令,但毕竟是一个线上操作</p>\n<p>2.set,zset,list以及hash类型只能获取有多少个元素。但其实元素多的不一定占用空间大</p>\n<p>所以有没有一种方法对线上没有影响，并且能直接以topn的形式输出每个键占用的空间大小呢？</p>\n<p>我们可以通过读取rdb文件的方式来试验一下，首先看看rdb文件的格式</p>\n<h2 id=\"rdb文件格式\"><a href=\"#rdb文件格式\" class=\"headerlink\" title=\"rdb文件格式\"></a>rdb文件格式</h2><p>rdb是一种二进制文件格式,我们首先看看rdb文件的整体结构</p>\n<p><img src=\"/img/rdb1.png\" alt=\"rdb\"></p>\n<p>首先是一个魔数,REDIS0009(redis5.0.3版本)。然后是一些附加属性字段,接着是db_num(0-15),然后是db和expire的字典大小(db和过期时间在Redis中是两个独立的hash table),接着是一个个key-value pairs，然后是一个EOF结束标志(0xFF),最后是8字节的checksum</p>\n<p>Redis中定义了一些opcode(1字节)，去标记opcode之后保存的是什么类型的数据。如下图所示</p>\n<p><img src=\"/img/rdb2.png\" alt=\"rdb\"></p>\n<p>opcode 252标记一个过期时间,248和249分别表示lru或者lfu,接着是value_type,标记值的类型,接着就是一个个key和vlaue.我们看下value_type和redis中数据类型的对应关系</p>\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>编码结构</th>\n<th>值类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OBJ_STRING(0)</td>\n<td>OBJ_ENCODING_RAW(0)</td>\n<td>RDB_TYPE_STRING(0)</td>\n</tr>\n<tr>\n<td>OBJ_LIST(1)</td>\n<td>OBJ_ENCODING_QUICKLIST(9)</td>\n<td>RDB_TYPE_LIST_QUICKLIST(14)</td>\n</tr>\n<tr>\n<td>OBJ_SET(2)</td>\n<td>OBJ_ENCODING_INTSET(6)</td>\n<td>RDB_TYPE_SET_INTSET(11)</td>\n</tr>\n<tr>\n<td>OBJ_SET(2)</td>\n<td>OBJ_ENCODING_HT(2)</td>\n<td>RDB_TYPE_SET(2)          </td>\n</tr>\n<tr>\n<td>OBJ_ZSET(3)</td>\n<td>OBJ_ENCODING_ZIPLIST(5)</td>\n<td>RDB_TYPE_ZSET_ZIPLIST(12)</td>\n</tr>\n<tr>\n<td>OBJ_ZSET(3)</td>\n<td>OBJ_ENCODING_SKIPLIST(7)</td>\n<td>RDB_TYPE_ZSET_2(5)</td>\n</tr>\n<tr>\n<td>OBJ_HASH(4)</td>\n<td>OBJ_ENCODING_ZIPLIST(5)</td>\n<td>RDB_TYPE_HASH_ZIPLIST(13)</td>\n</tr>\n<tr>\n<td>OBJ_HASH(4)</td>\n<td>OBJ_ENCODING_HT(2)</td>\n<td>RDB_TYPE_HASH(4)</td>\n</tr>\n</tbody>\n</table>\n<p>value_type就是值类型这一列，括号中的数字就是保存到rdb文件中时的实际使用数字</p>\n<p>知道了rdb的保存格式，我们可以写代码解析rdb文件,通过value_type去获取每个value的大小</p>\n<h2 id=\"godis-cli-bigkey使用方法\"><a href=\"#godis-cli-bigkey使用方法\" class=\"headerlink\" title=\"godis-cli-bigkey使用方法\"></a>godis-cli-bigkey使用方法</h2><p>代码地址如下:</p>\n<p><a href=\"https://github.com/erpeng/godis-cli-bigkey\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/godis-cli-bigkey</a></p>\n<p>下载之后在将rdb文件拷贝到项目根目录,按如下方式执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">bogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go -h</span><br><span class=\"line\">  -debug</span><br><span class=\"line\">    \topen debug mode  //debug模式，输出详细key/value信息</span><br><span class=\"line\">  -topn int</span><br><span class=\"line\">    \toutput topn keys (default 100)//默认输出top100的大key</span><br><span class=\"line\">  -totallen</span><br><span class=\"line\">    \tget total len (key and meta) or only value len (default true)//如果该选项设置为false,只输出rdb文件中value实际占用的大小</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t //默认为true,输出key、value和所有该key,value保存时使用的元数据总和</span><br><span class=\"line\">exit status 2</span><br></pre></td></tr></table></figure>\n<p>我们具体执行一下，输出如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go</span><br><span class=\"line\">Rdb Version:0009</span><br><span class=\"line\">key:k1,valueSize:9,valueType:0,expireTime:1549533396795,lfu:0,lru:0</span><br><span class=\"line\">key:key,valueSize:9,valueType:0,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:ss1,valueSize:14,valueType:2,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:si1,valueSize:23,valueType:11,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:l1,valueSize:28,valueType:14,expireTime:1549537004535,lfu:0,lru:0</span><br><span class=\"line\">key:h1,valueSize:33,valueType:13,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:z1,valueSize:67,valueType:12,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:testzset,valueSize:1303,valueType:5,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h3,valueSize:8845,valueType:13,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h2,valueSize:11680,valueType:4,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h4,valueSize:11703,valueType:4,expireTime:0,lfu:0,lru:0</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"redis-cli提供的方法\"><a href=\"#redis-cli提供的方法\" class=\"headerlink\" title=\"redis-cli提供的方法\"></a>redis-cli提供的方法</h2><p>注意以下所有试验基于redis 5.0.3版本</p>\n<p>redis-cli 提供一个bigkeys参数，可以扫描redis中的大key</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--bigkeys          Sample Redis keys looking for big keys.</span><br></pre></td></tr></table></figure>\n<p>执行之后输出如下所示:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bogon:sqlite didi$ redis-cli --bigkeys</span><br><span class=\"line\"># Scanning the entire keyspace to find biggest keys as well as</span><br><span class=\"line\"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span><br><span class=\"line\"># per 100 SCAN commands (not usually needed).</span><br><span class=\"line\">[00.00%] Biggest zset   found so far &apos;testzset&apos; with 129 members</span><br><span class=\"line\">[00.00%] Biggest hash   found so far &apos;h2&apos; with 513 fields</span><br><span class=\"line\">[00.00%] Biggest set    found so far &apos;si1&apos; with 5 members</span><br><span class=\"line\">[00.00%] Biggest hash   found so far &apos;h4&apos; with 514 fields</span><br><span class=\"line\">[00.00%] Biggest string found so far &apos;key&apos; with 9 bytes</span><br><span class=\"line\">-------- summary -------</span><br><span class=\"line\">Sampled 9 keys in the keyspace!</span><br><span class=\"line\">Total key length in bytes is 27 (avg len 3.00)</span><br><span class=\"line\">Biggest string found &apos;key&apos; has 9 bytes</span><br><span class=\"line\">Biggest    set found &apos;si1&apos; has 5 members</span><br><span class=\"line\">Biggest   hash found &apos;h4&apos; has 514 fields</span><br><span class=\"line\">Biggest   zset found &apos;testzset&apos; has 129 members</span><br><span class=\"line\">1 strings with 9 bytes (11.11% of keys, avg size 9.00)</span><br><span class=\"line\">0 lists with 0 items (00.00% of keys, avg size 0.00)</span><br><span class=\"line\">2 sets with 8 members (22.22% of keys, avg size 4.00)</span><br><span class=\"line\">4 hashs with 1541 fields (44.44% of keys, avg size 385.25)</span><br><span class=\"line\">2 zsets with 132 members (22.22% of keys, avg size 66.00)</span><br><span class=\"line\">0 streams with 0 entries (00.00% of keys, avg size 0.00)</span><br></pre></td></tr></table></figure></p>\n<p>原理比较简单,使用scan命令去遍历所有的键，对每个键根据其类型执行”STRLEN”,”LLEN”,”SCARD”,”HLEN”,”ZCARD”这些命令获取其长度或者元素个数。</p>\n<p>该方法有两个缺点:</p>\n<p>1.线上使用:虽然scan命令通过游标遍历建空间并且在生产上可以通过对从服务执行该命令,但毕竟是一个线上操作</p>\n<p>2.set,zset,list以及hash类型只能获取有多少个元素。但其实元素多的不一定占用空间大</p>\n<p>所以有没有一种方法对线上没有影响，并且能直接以topn的形式输出每个键占用的空间大小呢？</p>\n<p>我们可以通过读取rdb文件的方式来试验一下，首先看看rdb文件的格式</p>\n<h2 id=\"rdb文件格式\"><a href=\"#rdb文件格式\" class=\"headerlink\" title=\"rdb文件格式\"></a>rdb文件格式</h2><p>rdb是一种二进制文件格式,我们首先看看rdb文件的整体结构</p>\n<p><img src=\"/img/rdb1.png\" alt=\"rdb\"></p>\n<p>首先是一个魔数,REDIS0009(redis5.0.3版本)。然后是一些附加属性字段,接着是db_num(0-15),然后是db和expire的字典大小(db和过期时间在Redis中是两个独立的hash table),接着是一个个key-value pairs，然后是一个EOF结束标志(0xFF),最后是8字节的checksum</p>\n<p>Redis中定义了一些opcode(1字节)，去标记opcode之后保存的是什么类型的数据。如下图所示</p>\n<p><img src=\"/img/rdb2.png\" alt=\"rdb\"></p>\n<p>opcode 252标记一个过期时间,248和249分别表示lru或者lfu,接着是value_type,标记值的类型,接着就是一个个key和vlaue.我们看下value_type和redis中数据类型的对应关系</p>\n<table>\n<thead>\n<tr>\n<th>数据类型</th>\n<th>编码结构</th>\n<th>值类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OBJ_STRING(0)</td>\n<td>OBJ_ENCODING_RAW(0)</td>\n<td>RDB_TYPE_STRING(0)</td>\n</tr>\n<tr>\n<td>OBJ_LIST(1)</td>\n<td>OBJ_ENCODING_QUICKLIST(9)</td>\n<td>RDB_TYPE_LIST_QUICKLIST(14)</td>\n</tr>\n<tr>\n<td>OBJ_SET(2)</td>\n<td>OBJ_ENCODING_INTSET(6)</td>\n<td>RDB_TYPE_SET_INTSET(11)</td>\n</tr>\n<tr>\n<td>OBJ_SET(2)</td>\n<td>OBJ_ENCODING_HT(2)</td>\n<td>RDB_TYPE_SET(2)          </td>\n</tr>\n<tr>\n<td>OBJ_ZSET(3)</td>\n<td>OBJ_ENCODING_ZIPLIST(5)</td>\n<td>RDB_TYPE_ZSET_ZIPLIST(12)</td>\n</tr>\n<tr>\n<td>OBJ_ZSET(3)</td>\n<td>OBJ_ENCODING_SKIPLIST(7)</td>\n<td>RDB_TYPE_ZSET_2(5)</td>\n</tr>\n<tr>\n<td>OBJ_HASH(4)</td>\n<td>OBJ_ENCODING_ZIPLIST(5)</td>\n<td>RDB_TYPE_HASH_ZIPLIST(13)</td>\n</tr>\n<tr>\n<td>OBJ_HASH(4)</td>\n<td>OBJ_ENCODING_HT(2)</td>\n<td>RDB_TYPE_HASH(4)</td>\n</tr>\n</tbody>\n</table>\n<p>value_type就是值类型这一列，括号中的数字就是保存到rdb文件中时的实际使用数字</p>\n<p>知道了rdb的保存格式，我们可以写代码解析rdb文件,通过value_type去获取每个value的大小</p>\n<h2 id=\"godis-cli-bigkey使用方法\"><a href=\"#godis-cli-bigkey使用方法\" class=\"headerlink\" title=\"godis-cli-bigkey使用方法\"></a>godis-cli-bigkey使用方法</h2><p>代码地址如下:</p>\n<p><a href=\"https://github.com/erpeng/godis-cli-bigkey\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/godis-cli-bigkey</a></p>\n<p>下载之后在将rdb文件拷贝到项目根目录,按如下方式执行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">bogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go -h</span><br><span class=\"line\">  -debug</span><br><span class=\"line\">    \topen debug mode  //debug模式，输出详细key/value信息</span><br><span class=\"line\">  -topn int</span><br><span class=\"line\">    \toutput topn keys (default 100)//默认输出top100的大key</span><br><span class=\"line\">  -totallen</span><br><span class=\"line\">    \tget total len (key and meta) or only value len (default true)//如果该选项设置为false,只输出rdb文件中value实际占用的大小</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t //默认为true,输出key、value和所有该key,value保存时使用的元数据总和</span><br><span class=\"line\">exit status 2</span><br></pre></td></tr></table></figure>\n<p>我们具体执行一下，输出如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bogon:godis-cli-bigkey didi$ go run godis-cli-bigkey.go</span><br><span class=\"line\">Rdb Version:0009</span><br><span class=\"line\">key:k1,valueSize:9,valueType:0,expireTime:1549533396795,lfu:0,lru:0</span><br><span class=\"line\">key:key,valueSize:9,valueType:0,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:ss1,valueSize:14,valueType:2,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:si1,valueSize:23,valueType:11,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:l1,valueSize:28,valueType:14,expireTime:1549537004535,lfu:0,lru:0</span><br><span class=\"line\">key:h1,valueSize:33,valueType:13,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:z1,valueSize:67,valueType:12,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:testzset,valueSize:1303,valueType:5,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h3,valueSize:8845,valueType:13,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h2,valueSize:11680,valueType:4,expireTime:0,lfu:0,lru:0</span><br><span class=\"line\">key:h4,valueSize:11703,valueType:4,expireTime:0,lfu:0,lru:0</span><br></pre></td></tr></table></figure>"},{"title":"Redis scan命令原理","date":"2018-06-22T14:57:39.000Z","_content":"\n## scan类型命令\n```\nSCAN cursor [MATCH pattern] [COUNT count]\n\nSSCAN KEY cursor [MATCH pattern] [COUNT count]\n\nHSCAN  KEY cursor [MATCH pattern] [COUNT count]\n\nZSCAN KEY cursor [MATCH pattern] [COUNT count]\n```\nscan:迭代当前库\n\nsscan:迭代一个 set 类型\n\nhscan:迭代一个hash类型,并返回相应的值\n\nzscan:迭代一个sorted set，并且返回相应的分数\n\nredis是单进程单线程模型,keys和smembers这种命令可能会阻塞服务器,所以出现了scan系列的命令,通过返回一个游标，可以增量式迭代.\n\n## scan类型命令的实现\nscan,sscan,hscan,zsan分别有自己的命令入口,入口中会进行参数检测和游标赋值,然后进入统一的入口函数:scanGenericCommand,以hscan命令为例:\n\n![hscan](/img/scan1.png)\n\nscanGenericCommand主要分四步:\n\n* 解析count和match参数.如果没有指定count,默认返回10条数据\n* 开始迭代集合,如果是key保存为ziplist或者intset,则一次性返回所有数据,没有游标(游标值直接返回0).由于redis设计只有数据量比较小的时候才会保存为ziplist或者intset,所以此处不会影响性能.\n游标在保存为hash的时候发挥作用,具体入口函数为dictScan,下文详细描述。\n* 根据match参数过滤返回值,并且如果这个键已经过期也会直接过滤掉(redis中键过期之后并不会立即删除)\n* 返回结果到客户端,是一个数组,第一个值是游标,第二个值是具体的键值对\n\n## dictScan中游标的实现\n当迭代一个哈希表时,存在三种情况：\n\n* 从迭代开始到结束,哈希表没有进行rehash\n* 从迭代开始到结束,哈希表进行了rehash,但是每次迭代时,哈希表要么没开始rehash,要么已经结束了rehash\n* 从迭代开始到结束,某次或某几次迭代时哈希表正在进行rehash\nredis中进行rehash时会存在两个哈希表，ht[0]与ht[1],并且是渐进式rehash(即不会一次性全部rehash);新的键值对会存放到ht[1]中并且会逐步将ht[0]的数据转移到ht[1].全部rehash完毕后,ht[1]赋值给ht[0]然后清空ht[1].\n\n因此游标的实现需要兼顾以上三种情况,以上三种情况的游标实现要求如下:\n\n* 第一种情况比较简单,假设redis的哈希表大小为4,则第一次游标为0,读取第一个bucket的数据,然后游标返回1,下次读取第二个bucket的位置,依次遍历\n* 第二种情况比较复杂,假设redis的哈希表大小为4,如果rehash完后size变成了8.如果仍然按照上边的思路返回游标,则如下图:\n\n![scan](/img/scan2.png)\n\n\n 假设bucket0读完之后返回了游标1,当客户端再次带着游标1返回时哈希表已经进行完rehash,并且size扩大了一倍变成了8.redis按如下方法计算一个键的bucket:\n\n``` c\nhash(key)&(size-1)\n```\n即如果size是4时,hash(key)&11,如果size是8时,hash(key)&111.因此当从4扩容到8时,原先在0bucket的数据会分散到0(000)与4(100)两个bucket,bucket对应关系表如下:\n\n![scan](/img/scan3.png)\n\n从二进制来看,当size为4时,hash(key)之后取低两位即 hash(key)&11即key的bucket位置,如果size为8时,bucket位置为 hash(key)&111，即取低三位,当低两位为00时,如果第三位为0,则为000,如果第三位为1,则为100,正好是4.其他槽位的类似.所以如果此时继续按第一种方法遍历,第四个bucket取到的值全部为重复值\n\n*  第三种情况，如果返回游标1时正在进行rehash,ht[0]中的bucket 1中的部分数据可能已经rehash到 ht[1]中的bucket[1]或者bucket[5]，此时必须将ht[0]和ht[1]中的相应bucket全部遍历,否则可能会有遗漏数据\n\n所以为了兼顾以上三种情况,做到不漏数据并且尽量不重复,redis使用了一种叫做reverse binary iteration的方法.具体的游标计算代码如下:\n\n![reverse binary](/img/scan4.png)\n\n代码逻辑很简单,下面示例从4变为8和从4变为16以及从8变为4和从16变为4时,这种方法为何能够做到不重不漏\n\n![transfer](/img/scan5.png)\n\n遍历size为4时的游标状态转移为0-2-1-3.\n\n同理,size为8时的游标状态转移为0-4-2-6-1-5-3-7.\n\nsize为16时的游标状态转义为0-8-4-12-2-10-6-14-1-9-5-13-3-11-7-15\n\n![transfer](/img/scan6.png)\n\n\n可以看出，当size由小变大时,所有原来的游标都能在大的hashTable中找到相应的位置,并且顺序一致,不会重复读取并且不会遗漏\n\n例如size原来是4变为了8,且第二次遍历时rehash已经完成.此时游标为2,根据图2,我们知道size为4时的bucket2会rehash到size为8时的2和6.而size为4时的bucket0rehash到size为8时的0和4\n\n由于bucket 0 已经遍历完,也即size为8时的0,4已经遍历,正好开始从2开始继续遍历,不重复也不会遗漏\n\n\n\n继续考虑size由大变小的情况.假设size由16变为了4,分两种情况,一种是游标为0,2,1,3中的一种,此时继续读取,也不会遗漏和重复\n\n但如果游标返回的不是这四种,例如返回了10,10&11之后变为了2,所以会从2开始继续遍历.但由于size为16时的bucket2已经读取过,并且2,10,6,14都会rehash到size为4的bucket2,所以会造成重复读取\n\nsize为16时的bucket2。即有重复但不会遗漏\n\n**总结一下:redis里边rehash从小到大时，scan系列命令不会重复也不会遗漏.而从大到小时,有可能会造成重复但不会遗漏.**\n\n截止目前,情况1和情况2已经比较完美的处理了。情况3看看如何处理\n\n情况3需要从ht[0]和ht[1]中都取出数据,主要的难点在于如何在size大的哈希表中找到应该取哪些bucket.redis代码如下:\n\n![transfer](/img/scan7.png)\n\n判断条件为:\n\n```\nv&(m0^m1)\n```\nsize 4的m0为00000011,size8的m1为00000111,二者异或之后取值为00000100,即取二者mask高位的值,然后&v,看游标是否在高位还有值\n\n下一个游标的取值方法为 \n```\nv = (  ((v | m0) +1)& ~m0) | ( v & m0)\n```\n右半部分 取v的低位,左半部分取v的高位。  （v&m0)取出v的低位 例如size = 4时为 v&00000011\n\n左半部分 （v|m0) + 1即将v的低位都置为1,然后+1之后会进位到v的高位,再次 & ~m0之后即取出了v的高位\n\n整体来看每次将游标v的高位加1.下边举例来看:\n\n假设游标返回了2,并且正在进行rehash,此时size由4变成了8 .则m0 = 00000011 v = 00000010\n\n根据公式计算出的下一个游标为 ( (( 00000010|00000011) +1 ) & (11111100) )| (00000010 & 00000011) = (00000100)&(11111100)|(00000010) = (00000110) 正好是6\n\n判断条件为 (00000010) & (00000011 ^ 00000111) = (00000010) & (00000100) = (00000000) 为0，结束循环","source":"_posts/Redis-scan命令原理.md","raw":"---\ntitle: Redis scan命令原理\ndate: 2018-06-22 22:57:39\ntags: Redis\n---\n\n## scan类型命令\n```\nSCAN cursor [MATCH pattern] [COUNT count]\n\nSSCAN KEY cursor [MATCH pattern] [COUNT count]\n\nHSCAN  KEY cursor [MATCH pattern] [COUNT count]\n\nZSCAN KEY cursor [MATCH pattern] [COUNT count]\n```\nscan:迭代当前库\n\nsscan:迭代一个 set 类型\n\nhscan:迭代一个hash类型,并返回相应的值\n\nzscan:迭代一个sorted set，并且返回相应的分数\n\nredis是单进程单线程模型,keys和smembers这种命令可能会阻塞服务器,所以出现了scan系列的命令,通过返回一个游标，可以增量式迭代.\n\n## scan类型命令的实现\nscan,sscan,hscan,zsan分别有自己的命令入口,入口中会进行参数检测和游标赋值,然后进入统一的入口函数:scanGenericCommand,以hscan命令为例:\n\n![hscan](/img/scan1.png)\n\nscanGenericCommand主要分四步:\n\n* 解析count和match参数.如果没有指定count,默认返回10条数据\n* 开始迭代集合,如果是key保存为ziplist或者intset,则一次性返回所有数据,没有游标(游标值直接返回0).由于redis设计只有数据量比较小的时候才会保存为ziplist或者intset,所以此处不会影响性能.\n游标在保存为hash的时候发挥作用,具体入口函数为dictScan,下文详细描述。\n* 根据match参数过滤返回值,并且如果这个键已经过期也会直接过滤掉(redis中键过期之后并不会立即删除)\n* 返回结果到客户端,是一个数组,第一个值是游标,第二个值是具体的键值对\n\n## dictScan中游标的实现\n当迭代一个哈希表时,存在三种情况：\n\n* 从迭代开始到结束,哈希表没有进行rehash\n* 从迭代开始到结束,哈希表进行了rehash,但是每次迭代时,哈希表要么没开始rehash,要么已经结束了rehash\n* 从迭代开始到结束,某次或某几次迭代时哈希表正在进行rehash\nredis中进行rehash时会存在两个哈希表，ht[0]与ht[1],并且是渐进式rehash(即不会一次性全部rehash);新的键值对会存放到ht[1]中并且会逐步将ht[0]的数据转移到ht[1].全部rehash完毕后,ht[1]赋值给ht[0]然后清空ht[1].\n\n因此游标的实现需要兼顾以上三种情况,以上三种情况的游标实现要求如下:\n\n* 第一种情况比较简单,假设redis的哈希表大小为4,则第一次游标为0,读取第一个bucket的数据,然后游标返回1,下次读取第二个bucket的位置,依次遍历\n* 第二种情况比较复杂,假设redis的哈希表大小为4,如果rehash完后size变成了8.如果仍然按照上边的思路返回游标,则如下图:\n\n![scan](/img/scan2.png)\n\n\n 假设bucket0读完之后返回了游标1,当客户端再次带着游标1返回时哈希表已经进行完rehash,并且size扩大了一倍变成了8.redis按如下方法计算一个键的bucket:\n\n``` c\nhash(key)&(size-1)\n```\n即如果size是4时,hash(key)&11,如果size是8时,hash(key)&111.因此当从4扩容到8时,原先在0bucket的数据会分散到0(000)与4(100)两个bucket,bucket对应关系表如下:\n\n![scan](/img/scan3.png)\n\n从二进制来看,当size为4时,hash(key)之后取低两位即 hash(key)&11即key的bucket位置,如果size为8时,bucket位置为 hash(key)&111，即取低三位,当低两位为00时,如果第三位为0,则为000,如果第三位为1,则为100,正好是4.其他槽位的类似.所以如果此时继续按第一种方法遍历,第四个bucket取到的值全部为重复值\n\n*  第三种情况，如果返回游标1时正在进行rehash,ht[0]中的bucket 1中的部分数据可能已经rehash到 ht[1]中的bucket[1]或者bucket[5]，此时必须将ht[0]和ht[1]中的相应bucket全部遍历,否则可能会有遗漏数据\n\n所以为了兼顾以上三种情况,做到不漏数据并且尽量不重复,redis使用了一种叫做reverse binary iteration的方法.具体的游标计算代码如下:\n\n![reverse binary](/img/scan4.png)\n\n代码逻辑很简单,下面示例从4变为8和从4变为16以及从8变为4和从16变为4时,这种方法为何能够做到不重不漏\n\n![transfer](/img/scan5.png)\n\n遍历size为4时的游标状态转移为0-2-1-3.\n\n同理,size为8时的游标状态转移为0-4-2-6-1-5-3-7.\n\nsize为16时的游标状态转义为0-8-4-12-2-10-6-14-1-9-5-13-3-11-7-15\n\n![transfer](/img/scan6.png)\n\n\n可以看出，当size由小变大时,所有原来的游标都能在大的hashTable中找到相应的位置,并且顺序一致,不会重复读取并且不会遗漏\n\n例如size原来是4变为了8,且第二次遍历时rehash已经完成.此时游标为2,根据图2,我们知道size为4时的bucket2会rehash到size为8时的2和6.而size为4时的bucket0rehash到size为8时的0和4\n\n由于bucket 0 已经遍历完,也即size为8时的0,4已经遍历,正好开始从2开始继续遍历,不重复也不会遗漏\n\n\n\n继续考虑size由大变小的情况.假设size由16变为了4,分两种情况,一种是游标为0,2,1,3中的一种,此时继续读取,也不会遗漏和重复\n\n但如果游标返回的不是这四种,例如返回了10,10&11之后变为了2,所以会从2开始继续遍历.但由于size为16时的bucket2已经读取过,并且2,10,6,14都会rehash到size为4的bucket2,所以会造成重复读取\n\nsize为16时的bucket2。即有重复但不会遗漏\n\n**总结一下:redis里边rehash从小到大时，scan系列命令不会重复也不会遗漏.而从大到小时,有可能会造成重复但不会遗漏.**\n\n截止目前,情况1和情况2已经比较完美的处理了。情况3看看如何处理\n\n情况3需要从ht[0]和ht[1]中都取出数据,主要的难点在于如何在size大的哈希表中找到应该取哪些bucket.redis代码如下:\n\n![transfer](/img/scan7.png)\n\n判断条件为:\n\n```\nv&(m0^m1)\n```\nsize 4的m0为00000011,size8的m1为00000111,二者异或之后取值为00000100,即取二者mask高位的值,然后&v,看游标是否在高位还有值\n\n下一个游标的取值方法为 \n```\nv = (  ((v | m0) +1)& ~m0) | ( v & m0)\n```\n右半部分 取v的低位,左半部分取v的高位。  （v&m0)取出v的低位 例如size = 4时为 v&00000011\n\n左半部分 （v|m0) + 1即将v的低位都置为1,然后+1之后会进位到v的高位,再次 & ~m0之后即取出了v的高位\n\n整体来看每次将游标v的高位加1.下边举例来看:\n\n假设游标返回了2,并且正在进行rehash,此时size由4变成了8 .则m0 = 00000011 v = 00000010\n\n根据公式计算出的下一个游标为 ( (( 00000010|00000011) +1 ) & (11111100) )| (00000010 & 00000011) = (00000100)&(11111100)|(00000010) = (00000110) 正好是6\n\n判断条件为 (00000010) & (00000011 ^ 00000111) = (00000010) & (00000100) = (00000000) 为0，结束循环","slug":"Redis-scan命令原理","published":1,"updated":"2019-02-19T06:33:28.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9o000fbms6m4bsbo21","content":"<h2 id=\"scan类型命令\"><a href=\"#scan类型命令\" class=\"headerlink\" title=\"scan类型命令\"></a>scan类型命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SCAN cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">SSCAN KEY cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">HSCAN  KEY cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">ZSCAN KEY cursor [MATCH pattern] [COUNT count]</span><br></pre></td></tr></table></figure>\n<p>scan:迭代当前库</p>\n<p>sscan:迭代一个 set 类型</p>\n<p>hscan:迭代一个hash类型,并返回相应的值</p>\n<p>zscan:迭代一个sorted set，并且返回相应的分数</p>\n<p>redis是单进程单线程模型,keys和smembers这种命令可能会阻塞服务器,所以出现了scan系列的命令,通过返回一个游标，可以增量式迭代.</p>\n<h2 id=\"scan类型命令的实现\"><a href=\"#scan类型命令的实现\" class=\"headerlink\" title=\"scan类型命令的实现\"></a>scan类型命令的实现</h2><p>scan,sscan,hscan,zsan分别有自己的命令入口,入口中会进行参数检测和游标赋值,然后进入统一的入口函数:scanGenericCommand,以hscan命令为例:</p>\n<p><img src=\"/img/scan1.png\" alt=\"hscan\"></p>\n<p>scanGenericCommand主要分四步:</p>\n<ul>\n<li>解析count和match参数.如果没有指定count,默认返回10条数据</li>\n<li>开始迭代集合,如果是key保存为ziplist或者intset,则一次性返回所有数据,没有游标(游标值直接返回0).由于redis设计只有数据量比较小的时候才会保存为ziplist或者intset,所以此处不会影响性能.<br>游标在保存为hash的时候发挥作用,具体入口函数为dictScan,下文详细描述。</li>\n<li>根据match参数过滤返回值,并且如果这个键已经过期也会直接过滤掉(redis中键过期之后并不会立即删除)</li>\n<li>返回结果到客户端,是一个数组,第一个值是游标,第二个值是具体的键值对</li>\n</ul>\n<h2 id=\"dictScan中游标的实现\"><a href=\"#dictScan中游标的实现\" class=\"headerlink\" title=\"dictScan中游标的实现\"></a>dictScan中游标的实现</h2><p>当迭代一个哈希表时,存在三种情况：</p>\n<ul>\n<li>从迭代开始到结束,哈希表没有进行rehash</li>\n<li>从迭代开始到结束,哈希表进行了rehash,但是每次迭代时,哈希表要么没开始rehash,要么已经结束了rehash</li>\n<li>从迭代开始到结束,某次或某几次迭代时哈希表正在进行rehash<br>redis中进行rehash时会存在两个哈希表，ht[0]与ht[1],并且是渐进式rehash(即不会一次性全部rehash);新的键值对会存放到ht[1]中并且会逐步将ht[0]的数据转移到ht[1].全部rehash完毕后,ht[1]赋值给ht[0]然后清空ht[1].</li>\n</ul>\n<p>因此游标的实现需要兼顾以上三种情况,以上三种情况的游标实现要求如下:</p>\n<ul>\n<li>第一种情况比较简单,假设redis的哈希表大小为4,则第一次游标为0,读取第一个bucket的数据,然后游标返回1,下次读取第二个bucket的位置,依次遍历</li>\n<li>第二种情况比较复杂,假设redis的哈希表大小为4,如果rehash完后size变成了8.如果仍然按照上边的思路返回游标,则如下图:</li>\n</ul>\n<p><img src=\"/img/scan2.png\" alt=\"scan\"></p>\n<p> 假设bucket0读完之后返回了游标1,当客户端再次带着游标1返回时哈希表已经进行完rehash,并且size扩大了一倍变成了8.redis按如下方法计算一个键的bucket:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hash(key)&amp;(size<span class=\"number\">-1</span>)</span><br></pre></td></tr></table></figure>\n<p>即如果size是4时,hash(key)&amp;11,如果size是8时,hash(key)&amp;111.因此当从4扩容到8时,原先在0bucket的数据会分散到0(000)与4(100)两个bucket,bucket对应关系表如下:</p>\n<p><img src=\"/img/scan3.png\" alt=\"scan\"></p>\n<p>从二进制来看,当size为4时,hash(key)之后取低两位即 hash(key)&amp;11即key的bucket位置,如果size为8时,bucket位置为 hash(key)&amp;111，即取低三位,当低两位为00时,如果第三位为0,则为000,如果第三位为1,则为100,正好是4.其他槽位的类似.所以如果此时继续按第一种方法遍历,第四个bucket取到的值全部为重复值</p>\n<ul>\n<li>第三种情况，如果返回游标1时正在进行rehash,ht[0]中的bucket 1中的部分数据可能已经rehash到 ht[1]中的bucket[1]或者bucket[5]，此时必须将ht[0]和ht[1]中的相应bucket全部遍历,否则可能会有遗漏数据</li>\n</ul>\n<p>所以为了兼顾以上三种情况,做到不漏数据并且尽量不重复,redis使用了一种叫做reverse binary iteration的方法.具体的游标计算代码如下:</p>\n<p><img src=\"/img/scan4.png\" alt=\"reverse binary\"></p>\n<p>代码逻辑很简单,下面示例从4变为8和从4变为16以及从8变为4和从16变为4时,这种方法为何能够做到不重不漏</p>\n<p><img src=\"/img/scan5.png\" alt=\"transfer\"></p>\n<p>遍历size为4时的游标状态转移为0-2-1-3.</p>\n<p>同理,size为8时的游标状态转移为0-4-2-6-1-5-3-7.</p>\n<p>size为16时的游标状态转义为0-8-4-12-2-10-6-14-1-9-5-13-3-11-7-15</p>\n<p><img src=\"/img/scan6.png\" alt=\"transfer\"></p>\n<p>可以看出，当size由小变大时,所有原来的游标都能在大的hashTable中找到相应的位置,并且顺序一致,不会重复读取并且不会遗漏</p>\n<p>例如size原来是4变为了8,且第二次遍历时rehash已经完成.此时游标为2,根据图2,我们知道size为4时的bucket2会rehash到size为8时的2和6.而size为4时的bucket0rehash到size为8时的0和4</p>\n<p>由于bucket 0 已经遍历完,也即size为8时的0,4已经遍历,正好开始从2开始继续遍历,不重复也不会遗漏</p>\n<p>继续考虑size由大变小的情况.假设size由16变为了4,分两种情况,一种是游标为0,2,1,3中的一种,此时继续读取,也不会遗漏和重复</p>\n<p>但如果游标返回的不是这四种,例如返回了10,10&amp;11之后变为了2,所以会从2开始继续遍历.但由于size为16时的bucket2已经读取过,并且2,10,6,14都会rehash到size为4的bucket2,所以会造成重复读取</p>\n<p>size为16时的bucket2。即有重复但不会遗漏</p>\n<p><strong>总结一下:redis里边rehash从小到大时，scan系列命令不会重复也不会遗漏.而从大到小时,有可能会造成重复但不会遗漏.</strong></p>\n<p>截止目前,情况1和情况2已经比较完美的处理了。情况3看看如何处理</p>\n<p>情况3需要从ht[0]和ht[1]中都取出数据,主要的难点在于如何在size大的哈希表中找到应该取哪些bucket.redis代码如下:</p>\n<p><img src=\"/img/scan7.png\" alt=\"transfer\"></p>\n<p>判断条件为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v&amp;(m0^m1)</span><br></pre></td></tr></table></figure>\n<p>size 4的m0为00000011,size8的m1为00000111,二者异或之后取值为00000100,即取二者mask高位的值,然后&amp;v,看游标是否在高位还有值</p>\n<p>下一个游标的取值方法为<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = (  ((v | m0) +1)&amp; ~m0) | ( v &amp; m0)</span><br></pre></td></tr></table></figure></p>\n<p>右半部分 取v的低位,左半部分取v的高位。  （v&amp;m0)取出v的低位 例如size = 4时为 v&amp;00000011</p>\n<p>左半部分 （v|m0) + 1即将v的低位都置为1,然后+1之后会进位到v的高位,再次 &amp; ~m0之后即取出了v的高位</p>\n<p>整体来看每次将游标v的高位加1.下边举例来看:</p>\n<p>假设游标返回了2,并且正在进行rehash,此时size由4变成了8 .则m0 = 00000011 v = 00000010</p>\n<p>根据公式计算出的下一个游标为 ( (( 00000010|00000011) +1 ) &amp; (11111100) )| (00000010 &amp; 00000011) = (00000100)&amp;(11111100)|(00000010) = (00000110) 正好是6</p>\n<p>判断条件为 (00000010) &amp; (00000011 ^ 00000111) = (00000010) &amp; (00000100) = (00000000) 为0，结束循环</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"scan类型命令\"><a href=\"#scan类型命令\" class=\"headerlink\" title=\"scan类型命令\"></a>scan类型命令</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SCAN cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">SSCAN KEY cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">HSCAN  KEY cursor [MATCH pattern] [COUNT count]</span><br><span class=\"line\"></span><br><span class=\"line\">ZSCAN KEY cursor [MATCH pattern] [COUNT count]</span><br></pre></td></tr></table></figure>\n<p>scan:迭代当前库</p>\n<p>sscan:迭代一个 set 类型</p>\n<p>hscan:迭代一个hash类型,并返回相应的值</p>\n<p>zscan:迭代一个sorted set，并且返回相应的分数</p>\n<p>redis是单进程单线程模型,keys和smembers这种命令可能会阻塞服务器,所以出现了scan系列的命令,通过返回一个游标，可以增量式迭代.</p>\n<h2 id=\"scan类型命令的实现\"><a href=\"#scan类型命令的实现\" class=\"headerlink\" title=\"scan类型命令的实现\"></a>scan类型命令的实现</h2><p>scan,sscan,hscan,zsan分别有自己的命令入口,入口中会进行参数检测和游标赋值,然后进入统一的入口函数:scanGenericCommand,以hscan命令为例:</p>\n<p><img src=\"/img/scan1.png\" alt=\"hscan\"></p>\n<p>scanGenericCommand主要分四步:</p>\n<ul>\n<li>解析count和match参数.如果没有指定count,默认返回10条数据</li>\n<li>开始迭代集合,如果是key保存为ziplist或者intset,则一次性返回所有数据,没有游标(游标值直接返回0).由于redis设计只有数据量比较小的时候才会保存为ziplist或者intset,所以此处不会影响性能.<br>游标在保存为hash的时候发挥作用,具体入口函数为dictScan,下文详细描述。</li>\n<li>根据match参数过滤返回值,并且如果这个键已经过期也会直接过滤掉(redis中键过期之后并不会立即删除)</li>\n<li>返回结果到客户端,是一个数组,第一个值是游标,第二个值是具体的键值对</li>\n</ul>\n<h2 id=\"dictScan中游标的实现\"><a href=\"#dictScan中游标的实现\" class=\"headerlink\" title=\"dictScan中游标的实现\"></a>dictScan中游标的实现</h2><p>当迭代一个哈希表时,存在三种情况：</p>\n<ul>\n<li>从迭代开始到结束,哈希表没有进行rehash</li>\n<li>从迭代开始到结束,哈希表进行了rehash,但是每次迭代时,哈希表要么没开始rehash,要么已经结束了rehash</li>\n<li>从迭代开始到结束,某次或某几次迭代时哈希表正在进行rehash<br>redis中进行rehash时会存在两个哈希表，ht[0]与ht[1],并且是渐进式rehash(即不会一次性全部rehash);新的键值对会存放到ht[1]中并且会逐步将ht[0]的数据转移到ht[1].全部rehash完毕后,ht[1]赋值给ht[0]然后清空ht[1].</li>\n</ul>\n<p>因此游标的实现需要兼顾以上三种情况,以上三种情况的游标实现要求如下:</p>\n<ul>\n<li>第一种情况比较简单,假设redis的哈希表大小为4,则第一次游标为0,读取第一个bucket的数据,然后游标返回1,下次读取第二个bucket的位置,依次遍历</li>\n<li>第二种情况比较复杂,假设redis的哈希表大小为4,如果rehash完后size变成了8.如果仍然按照上边的思路返回游标,则如下图:</li>\n</ul>\n<p><img src=\"/img/scan2.png\" alt=\"scan\"></p>\n<p> 假设bucket0读完之后返回了游标1,当客户端再次带着游标1返回时哈希表已经进行完rehash,并且size扩大了一倍变成了8.redis按如下方法计算一个键的bucket:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hash(key)&amp;(size<span class=\"number\">-1</span>)</span><br></pre></td></tr></table></figure>\n<p>即如果size是4时,hash(key)&amp;11,如果size是8时,hash(key)&amp;111.因此当从4扩容到8时,原先在0bucket的数据会分散到0(000)与4(100)两个bucket,bucket对应关系表如下:</p>\n<p><img src=\"/img/scan3.png\" alt=\"scan\"></p>\n<p>从二进制来看,当size为4时,hash(key)之后取低两位即 hash(key)&amp;11即key的bucket位置,如果size为8时,bucket位置为 hash(key)&amp;111，即取低三位,当低两位为00时,如果第三位为0,则为000,如果第三位为1,则为100,正好是4.其他槽位的类似.所以如果此时继续按第一种方法遍历,第四个bucket取到的值全部为重复值</p>\n<ul>\n<li>第三种情况，如果返回游标1时正在进行rehash,ht[0]中的bucket 1中的部分数据可能已经rehash到 ht[1]中的bucket[1]或者bucket[5]，此时必须将ht[0]和ht[1]中的相应bucket全部遍历,否则可能会有遗漏数据</li>\n</ul>\n<p>所以为了兼顾以上三种情况,做到不漏数据并且尽量不重复,redis使用了一种叫做reverse binary iteration的方法.具体的游标计算代码如下:</p>\n<p><img src=\"/img/scan4.png\" alt=\"reverse binary\"></p>\n<p>代码逻辑很简单,下面示例从4变为8和从4变为16以及从8变为4和从16变为4时,这种方法为何能够做到不重不漏</p>\n<p><img src=\"/img/scan5.png\" alt=\"transfer\"></p>\n<p>遍历size为4时的游标状态转移为0-2-1-3.</p>\n<p>同理,size为8时的游标状态转移为0-4-2-6-1-5-3-7.</p>\n<p>size为16时的游标状态转义为0-8-4-12-2-10-6-14-1-9-5-13-3-11-7-15</p>\n<p><img src=\"/img/scan6.png\" alt=\"transfer\"></p>\n<p>可以看出，当size由小变大时,所有原来的游标都能在大的hashTable中找到相应的位置,并且顺序一致,不会重复读取并且不会遗漏</p>\n<p>例如size原来是4变为了8,且第二次遍历时rehash已经完成.此时游标为2,根据图2,我们知道size为4时的bucket2会rehash到size为8时的2和6.而size为4时的bucket0rehash到size为8时的0和4</p>\n<p>由于bucket 0 已经遍历完,也即size为8时的0,4已经遍历,正好开始从2开始继续遍历,不重复也不会遗漏</p>\n<p>继续考虑size由大变小的情况.假设size由16变为了4,分两种情况,一种是游标为0,2,1,3中的一种,此时继续读取,也不会遗漏和重复</p>\n<p>但如果游标返回的不是这四种,例如返回了10,10&amp;11之后变为了2,所以会从2开始继续遍历.但由于size为16时的bucket2已经读取过,并且2,10,6,14都会rehash到size为4的bucket2,所以会造成重复读取</p>\n<p>size为16时的bucket2。即有重复但不会遗漏</p>\n<p><strong>总结一下:redis里边rehash从小到大时，scan系列命令不会重复也不会遗漏.而从大到小时,有可能会造成重复但不会遗漏.</strong></p>\n<p>截止目前,情况1和情况2已经比较完美的处理了。情况3看看如何处理</p>\n<p>情况3需要从ht[0]和ht[1]中都取出数据,主要的难点在于如何在size大的哈希表中找到应该取哪些bucket.redis代码如下:</p>\n<p><img src=\"/img/scan7.png\" alt=\"transfer\"></p>\n<p>判断条件为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v&amp;(m0^m1)</span><br></pre></td></tr></table></figure>\n<p>size 4的m0为00000011,size8的m1为00000111,二者异或之后取值为00000100,即取二者mask高位的值,然后&amp;v,看游标是否在高位还有值</p>\n<p>下一个游标的取值方法为<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">v = (  ((v | m0) +1)&amp; ~m0) | ( v &amp; m0)</span><br></pre></td></tr></table></figure></p>\n<p>右半部分 取v的低位,左半部分取v的高位。  （v&amp;m0)取出v的低位 例如size = 4时为 v&amp;00000011</p>\n<p>左半部分 （v|m0) + 1即将v的低位都置为1,然后+1之后会进位到v的高位,再次 &amp; ~m0之后即取出了v的高位</p>\n<p>整体来看每次将游标v的高位加1.下边举例来看:</p>\n<p>假设游标返回了2,并且正在进行rehash,此时size由4变成了8 .则m0 = 00000011 v = 00000010</p>\n<p>根据公式计算出的下一个游标为 ( (( 00000010|00000011) +1 ) &amp; (11111100) )| (00000010 &amp; 00000011) = (00000100)&amp;(11111100)|(00000010) = (00000110) 正好是6</p>\n<p>判断条件为 (00000010) &amp; (00000011 ^ 00000111) = (00000010) &amp; (00000100) = (00000000) 为0，结束循环</p>\n"},{"title":"Redis stream简介","date":"2019-04-29T16:00:00.000Z","_content":"## stream简介\nappend-only mode\n数据结构为一个前缀树加listpack,listpack的介绍详见 [Redis的一个历史bug及其后续改进]一文.\n前缀树中保存的为ID,ID由两部分组成,毫秒级时间戳+该ms内的递增计数.stream结构可以理解为如下三种模式:\n1. 一个sorted set,score是时间,member是一个hash,时间序列存储,可以按时间范围遍历\n2. 阻塞模式下,类似一个日志系统,可以按tail -f 查看日志\n3. 一个pub/sub模式的消息队列,但是可以将消息分区之后pub给消费组中的不同消费者(负载均衡);会保存数据,不像pub/sub,推送之后就删除了.\n\n\n## stream实现\n\n### xadd\n```\n增加条目,并且指定最大条目数.至少保存1000条,当listpack可以回收时才会释放多余的条目\nXADD mystream MAXLEN ~ 1000 * ... entry fields here ...\n```\n\n### xdel\n```\n删除指定的stream item.也会等待listpack可以回收时真实释放\nXDEL mystream 1526654999635-0\n```\n### xrange\n```\nxrange key  start end  count N\nstart:-,时间戳或者entry id\nend:+,时间戳或者entry id\n遍历 O(log(N))的时间复杂度,不需要XSCAN\n```\n### xrevrange\n```\n查看最后一条数据\n\nXREVRANGE mystream + - COUNT 1\n```\n\n\n### xread\n```\n读取mystream/otherstream中id大于max-id1/max-id2的entry\nXREAD COUNT 2 STREAMS mystream  otherstream max-id1 max-id2\n\n读取mystream,$表明读取从现在开始新产生的entry;阻塞读取,超时时间设置为0(即不超时)\nXREAD BLOCK 0 STREAMS mystream $ \n\n```\n\n### xgroup\n```\ngroup的增删改查\n在key为mystream的stream上创建一个消费组,名称为mygroup,从当前时间开始最新的entry开始消费\n$表示只消费最新消息,0表示消费所有历史消息,或者指定一个entryid,表明从该id开始消费\nXGROUP CREATE mystream mygroup $\n```\n\n### xreadgroup\n```\n消费信息\ngroup参数指定消费组,接着是消费者的唯一标识 >表明没有提供给其他消费者消费的信息\n如果不是>而是指定某一个entry id,表明要消费的是Alice没有xack的消息,即pending的消息\nXREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >\n\n```\n\n### xack\n\n```\n确认已经消费了某条信息\nXACK mystream mygroup 1526569495631-0\n```\n\n### xpending\n```\n显示出mystream中mygroup消费组pending的消息\nXPENDING mystream mygroup\n```\n\n### xclaim\n```\n将大于idle-time并且指定id的entry重新分配给consumer.分配完后idle time会重新计算\nXCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-2> ... <ID-N>\n\n```\n\n### xinfo\n\n```\n查看mystream相关的信息\nXINFO STREAM mystream\n\n查看mystream中消费组相关的信息\nXINFO GROUPS mystream\n\n查看mystream中的消费组mygroup的消费者相关的信息\nXINFO CONSUMERS mystream mygroup\n```\n\n\n### xtrim\n```\n修改mystream的最大保存节点个数为10\nXTRIM mystream MAXLEN 10\n\n```\n## stream其他\n \n* dead letter:根据投递次数,如果投递次数大于某个值可以认为该消息不需要继续处理,可以放入其他的stream中\n* xadd 中可以指定maxlen,指明stream中保存的最大条目个数\n\n\n\n## 参考文章\n* http://antirez.com/news/128\n* https://redis.io/topics/streams-intro\n","source":"_posts/Redis-stream.md","raw":"---\ntitle: Redis stream简介\ndate: 2019-04-30 \ntags: Redis\n---\n## stream简介\nappend-only mode\n数据结构为一个前缀树加listpack,listpack的介绍详见 [Redis的一个历史bug及其后续改进]一文.\n前缀树中保存的为ID,ID由两部分组成,毫秒级时间戳+该ms内的递增计数.stream结构可以理解为如下三种模式:\n1. 一个sorted set,score是时间,member是一个hash,时间序列存储,可以按时间范围遍历\n2. 阻塞模式下,类似一个日志系统,可以按tail -f 查看日志\n3. 一个pub/sub模式的消息队列,但是可以将消息分区之后pub给消费组中的不同消费者(负载均衡);会保存数据,不像pub/sub,推送之后就删除了.\n\n\n## stream实现\n\n### xadd\n```\n增加条目,并且指定最大条目数.至少保存1000条,当listpack可以回收时才会释放多余的条目\nXADD mystream MAXLEN ~ 1000 * ... entry fields here ...\n```\n\n### xdel\n```\n删除指定的stream item.也会等待listpack可以回收时真实释放\nXDEL mystream 1526654999635-0\n```\n### xrange\n```\nxrange key  start end  count N\nstart:-,时间戳或者entry id\nend:+,时间戳或者entry id\n遍历 O(log(N))的时间复杂度,不需要XSCAN\n```\n### xrevrange\n```\n查看最后一条数据\n\nXREVRANGE mystream + - COUNT 1\n```\n\n\n### xread\n```\n读取mystream/otherstream中id大于max-id1/max-id2的entry\nXREAD COUNT 2 STREAMS mystream  otherstream max-id1 max-id2\n\n读取mystream,$表明读取从现在开始新产生的entry;阻塞读取,超时时间设置为0(即不超时)\nXREAD BLOCK 0 STREAMS mystream $ \n\n```\n\n### xgroup\n```\ngroup的增删改查\n在key为mystream的stream上创建一个消费组,名称为mygroup,从当前时间开始最新的entry开始消费\n$表示只消费最新消息,0表示消费所有历史消息,或者指定一个entryid,表明从该id开始消费\nXGROUP CREATE mystream mygroup $\n```\n\n### xreadgroup\n```\n消费信息\ngroup参数指定消费组,接着是消费者的唯一标识 >表明没有提供给其他消费者消费的信息\n如果不是>而是指定某一个entry id,表明要消费的是Alice没有xack的消息,即pending的消息\nXREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >\n\n```\n\n### xack\n\n```\n确认已经消费了某条信息\nXACK mystream mygroup 1526569495631-0\n```\n\n### xpending\n```\n显示出mystream中mygroup消费组pending的消息\nXPENDING mystream mygroup\n```\n\n### xclaim\n```\n将大于idle-time并且指定id的entry重新分配给consumer.分配完后idle time会重新计算\nXCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-2> ... <ID-N>\n\n```\n\n### xinfo\n\n```\n查看mystream相关的信息\nXINFO STREAM mystream\n\n查看mystream中消费组相关的信息\nXINFO GROUPS mystream\n\n查看mystream中的消费组mygroup的消费者相关的信息\nXINFO CONSUMERS mystream mygroup\n```\n\n\n### xtrim\n```\n修改mystream的最大保存节点个数为10\nXTRIM mystream MAXLEN 10\n\n```\n## stream其他\n \n* dead letter:根据投递次数,如果投递次数大于某个值可以认为该消息不需要继续处理,可以放入其他的stream中\n* xadd 中可以指定maxlen,指明stream中保存的最大条目个数\n\n\n\n## 参考文章\n* http://antirez.com/news/128\n* https://redis.io/topics/streams-intro\n","slug":"Redis-stream","published":1,"updated":"2019-04-30T14:49:39.862Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9q000ibms6ju4frh5c","content":"<h2 id=\"stream简介\"><a href=\"#stream简介\" class=\"headerlink\" title=\"stream简介\"></a>stream简介</h2><p>append-only mode<br>数据结构为一个前缀树加listpack,listpack的介绍详见 [Redis的一个历史bug及其后续改进]一文.<br>前缀树中保存的为ID,ID由两部分组成,毫秒级时间戳+该ms内的递增计数.stream结构可以理解为如下三种模式:</p>\n<ol>\n<li>一个sorted set,score是时间,member是一个hash,时间序列存储,可以按时间范围遍历</li>\n<li>阻塞模式下,类似一个日志系统,可以按tail -f 查看日志</li>\n<li>一个pub/sub模式的消息队列,但是可以将消息分区之后pub给消费组中的不同消费者(负载均衡);会保存数据,不像pub/sub,推送之后就删除了.</li>\n</ol>\n<h2 id=\"stream实现\"><a href=\"#stream实现\" class=\"headerlink\" title=\"stream实现\"></a>stream实现</h2><h3 id=\"xadd\"><a href=\"#xadd\" class=\"headerlink\" title=\"xadd\"></a>xadd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">增加条目,并且指定最大条目数.至少保存1000条,当listpack可以回收时才会释放多余的条目</span><br><span class=\"line\">XADD mystream MAXLEN ~ 1000 * ... entry fields here ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"xdel\"><a href=\"#xdel\" class=\"headerlink\" title=\"xdel\"></a>xdel</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">删除指定的stream item.也会等待listpack可以回收时真实释放</span><br><span class=\"line\">XDEL mystream 1526654999635-0</span><br></pre></td></tr></table></figure>\n<h3 id=\"xrange\"><a href=\"#xrange\" class=\"headerlink\" title=\"xrange\"></a>xrange</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xrange key  start end  count N</span><br><span class=\"line\">start:-,时间戳或者entry id</span><br><span class=\"line\">end:+,时间戳或者entry id</span><br><span class=\"line\">遍历 O(log(N))的时间复杂度,不需要XSCAN</span><br></pre></td></tr></table></figure>\n<h3 id=\"xrevrange\"><a href=\"#xrevrange\" class=\"headerlink\" title=\"xrevrange\"></a>xrevrange</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查看最后一条数据</span><br><span class=\"line\"></span><br><span class=\"line\">XREVRANGE mystream + - COUNT 1</span><br></pre></td></tr></table></figure>\n<h3 id=\"xread\"><a href=\"#xread\" class=\"headerlink\" title=\"xread\"></a>xread</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读取mystream/otherstream中id大于max-id1/max-id2的entry</span><br><span class=\"line\">XREAD COUNT 2 STREAMS mystream  otherstream max-id1 max-id2</span><br><span class=\"line\"></span><br><span class=\"line\">读取mystream,$表明读取从现在开始新产生的entry;阻塞读取,超时时间设置为0(即不超时)</span><br><span class=\"line\">XREAD BLOCK 0 STREAMS mystream $</span><br></pre></td></tr></table></figure>\n<h3 id=\"xgroup\"><a href=\"#xgroup\" class=\"headerlink\" title=\"xgroup\"></a>xgroup</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">group的增删改查</span><br><span class=\"line\">在key为mystream的stream上创建一个消费组,名称为mygroup,从当前时间开始最新的entry开始消费</span><br><span class=\"line\">$表示只消费最新消息,0表示消费所有历史消息,或者指定一个entryid,表明从该id开始消费</span><br><span class=\"line\">XGROUP CREATE mystream mygroup $</span><br></pre></td></tr></table></figure>\n<h3 id=\"xreadgroup\"><a href=\"#xreadgroup\" class=\"headerlink\" title=\"xreadgroup\"></a>xreadgroup</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">消费信息</span><br><span class=\"line\">group参数指定消费组,接着是消费者的唯一标识 &gt;表明没有提供给其他消费者消费的信息</span><br><span class=\"line\">如果不是&gt;而是指定某一个entry id,表明要消费的是Alice没有xack的消息,即pending的消息</span><br><span class=\"line\">XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream &gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"xack\"><a href=\"#xack\" class=\"headerlink\" title=\"xack\"></a>xack</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">确认已经消费了某条信息</span><br><span class=\"line\">XACK mystream mygroup 1526569495631-0</span><br></pre></td></tr></table></figure>\n<h3 id=\"xpending\"><a href=\"#xpending\" class=\"headerlink\" title=\"xpending\"></a>xpending</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示出mystream中mygroup消费组pending的消息</span><br><span class=\"line\">XPENDING mystream mygroup</span><br></pre></td></tr></table></figure>\n<h3 id=\"xclaim\"><a href=\"#xclaim\" class=\"headerlink\" title=\"xclaim\"></a>xclaim</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">将大于idle-time并且指定id的entry重新分配给consumer.分配完后idle time会重新计算</span><br><span class=\"line\">XCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;ID-1&gt; &lt;ID-2&gt; ... &lt;ID-N&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"xinfo\"><a href=\"#xinfo\" class=\"headerlink\" title=\"xinfo\"></a>xinfo</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查看mystream相关的信息</span><br><span class=\"line\">XINFO STREAM mystream</span><br><span class=\"line\"></span><br><span class=\"line\">查看mystream中消费组相关的信息</span><br><span class=\"line\">XINFO GROUPS mystream</span><br><span class=\"line\"></span><br><span class=\"line\">查看mystream中的消费组mygroup的消费者相关的信息</span><br><span class=\"line\">XINFO CONSUMERS mystream mygroup</span><br></pre></td></tr></table></figure>\n<h3 id=\"xtrim\"><a href=\"#xtrim\" class=\"headerlink\" title=\"xtrim\"></a>xtrim</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改mystream的最大保存节点个数为10</span><br><span class=\"line\">XTRIM mystream MAXLEN 10</span><br></pre></td></tr></table></figure>\n<h2 id=\"stream其他\"><a href=\"#stream其他\" class=\"headerlink\" title=\"stream其他\"></a>stream其他</h2><ul>\n<li>dead letter:根据投递次数,如果投递次数大于某个值可以认为该消息不需要继续处理,可以放入其他的stream中</li>\n<li>xadd 中可以指定maxlen,指明stream中保存的最大条目个数</li>\n</ul>\n<h2 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h2><ul>\n<li><a href=\"http://antirez.com/news/128\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/128</a></li>\n<li><a href=\"https://redis.io/topics/streams-intro\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/streams-intro</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"stream简介\"><a href=\"#stream简介\" class=\"headerlink\" title=\"stream简介\"></a>stream简介</h2><p>append-only mode<br>数据结构为一个前缀树加listpack,listpack的介绍详见 [Redis的一个历史bug及其后续改进]一文.<br>前缀树中保存的为ID,ID由两部分组成,毫秒级时间戳+该ms内的递增计数.stream结构可以理解为如下三种模式:</p>\n<ol>\n<li>一个sorted set,score是时间,member是一个hash,时间序列存储,可以按时间范围遍历</li>\n<li>阻塞模式下,类似一个日志系统,可以按tail -f 查看日志</li>\n<li>一个pub/sub模式的消息队列,但是可以将消息分区之后pub给消费组中的不同消费者(负载均衡);会保存数据,不像pub/sub,推送之后就删除了.</li>\n</ol>\n<h2 id=\"stream实现\"><a href=\"#stream实现\" class=\"headerlink\" title=\"stream实现\"></a>stream实现</h2><h3 id=\"xadd\"><a href=\"#xadd\" class=\"headerlink\" title=\"xadd\"></a>xadd</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">增加条目,并且指定最大条目数.至少保存1000条,当listpack可以回收时才会释放多余的条目</span><br><span class=\"line\">XADD mystream MAXLEN ~ 1000 * ... entry fields here ...</span><br></pre></td></tr></table></figure>\n<h3 id=\"xdel\"><a href=\"#xdel\" class=\"headerlink\" title=\"xdel\"></a>xdel</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">删除指定的stream item.也会等待listpack可以回收时真实释放</span><br><span class=\"line\">XDEL mystream 1526654999635-0</span><br></pre></td></tr></table></figure>\n<h3 id=\"xrange\"><a href=\"#xrange\" class=\"headerlink\" title=\"xrange\"></a>xrange</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xrange key  start end  count N</span><br><span class=\"line\">start:-,时间戳或者entry id</span><br><span class=\"line\">end:+,时间戳或者entry id</span><br><span class=\"line\">遍历 O(log(N))的时间复杂度,不需要XSCAN</span><br></pre></td></tr></table></figure>\n<h3 id=\"xrevrange\"><a href=\"#xrevrange\" class=\"headerlink\" title=\"xrevrange\"></a>xrevrange</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查看最后一条数据</span><br><span class=\"line\"></span><br><span class=\"line\">XREVRANGE mystream + - COUNT 1</span><br></pre></td></tr></table></figure>\n<h3 id=\"xread\"><a href=\"#xread\" class=\"headerlink\" title=\"xread\"></a>xread</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">读取mystream/otherstream中id大于max-id1/max-id2的entry</span><br><span class=\"line\">XREAD COUNT 2 STREAMS mystream  otherstream max-id1 max-id2</span><br><span class=\"line\"></span><br><span class=\"line\">读取mystream,$表明读取从现在开始新产生的entry;阻塞读取,超时时间设置为0(即不超时)</span><br><span class=\"line\">XREAD BLOCK 0 STREAMS mystream $</span><br></pre></td></tr></table></figure>\n<h3 id=\"xgroup\"><a href=\"#xgroup\" class=\"headerlink\" title=\"xgroup\"></a>xgroup</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">group的增删改查</span><br><span class=\"line\">在key为mystream的stream上创建一个消费组,名称为mygroup,从当前时间开始最新的entry开始消费</span><br><span class=\"line\">$表示只消费最新消息,0表示消费所有历史消息,或者指定一个entryid,表明从该id开始消费</span><br><span class=\"line\">XGROUP CREATE mystream mygroup $</span><br></pre></td></tr></table></figure>\n<h3 id=\"xreadgroup\"><a href=\"#xreadgroup\" class=\"headerlink\" title=\"xreadgroup\"></a>xreadgroup</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">消费信息</span><br><span class=\"line\">group参数指定消费组,接着是消费者的唯一标识 &gt;表明没有提供给其他消费者消费的信息</span><br><span class=\"line\">如果不是&gt;而是指定某一个entry id,表明要消费的是Alice没有xack的消息,即pending的消息</span><br><span class=\"line\">XREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream &gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"xack\"><a href=\"#xack\" class=\"headerlink\" title=\"xack\"></a>xack</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">确认已经消费了某条信息</span><br><span class=\"line\">XACK mystream mygroup 1526569495631-0</span><br></pre></td></tr></table></figure>\n<h3 id=\"xpending\"><a href=\"#xpending\" class=\"headerlink\" title=\"xpending\"></a>xpending</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示出mystream中mygroup消费组pending的消息</span><br><span class=\"line\">XPENDING mystream mygroup</span><br></pre></td></tr></table></figure>\n<h3 id=\"xclaim\"><a href=\"#xclaim\" class=\"headerlink\" title=\"xclaim\"></a>xclaim</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">将大于idle-time并且指定id的entry重新分配给consumer.分配完后idle time会重新计算</span><br><span class=\"line\">XCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;ID-1&gt; &lt;ID-2&gt; ... &lt;ID-N&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"xinfo\"><a href=\"#xinfo\" class=\"headerlink\" title=\"xinfo\"></a>xinfo</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查看mystream相关的信息</span><br><span class=\"line\">XINFO STREAM mystream</span><br><span class=\"line\"></span><br><span class=\"line\">查看mystream中消费组相关的信息</span><br><span class=\"line\">XINFO GROUPS mystream</span><br><span class=\"line\"></span><br><span class=\"line\">查看mystream中的消费组mygroup的消费者相关的信息</span><br><span class=\"line\">XINFO CONSUMERS mystream mygroup</span><br></pre></td></tr></table></figure>\n<h3 id=\"xtrim\"><a href=\"#xtrim\" class=\"headerlink\" title=\"xtrim\"></a>xtrim</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">修改mystream的最大保存节点个数为10</span><br><span class=\"line\">XTRIM mystream MAXLEN 10</span><br></pre></td></tr></table></figure>\n<h2 id=\"stream其他\"><a href=\"#stream其他\" class=\"headerlink\" title=\"stream其他\"></a>stream其他</h2><ul>\n<li>dead letter:根据投递次数,如果投递次数大于某个值可以认为该消息不需要继续处理,可以放入其他的stream中</li>\n<li>xadd 中可以指定maxlen,指明stream中保存的最大条目个数</li>\n</ul>\n<h2 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h2><ul>\n<li><a href=\"http://antirez.com/news/128\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/128</a></li>\n<li><a href=\"https://redis.io/topics/streams-intro\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/streams-intro</a></li>\n</ul>\n"},{"title":"Redis单机版本框架","date":"2018-06-07T05:07:29.000Z","_content":"## Redis主流程伪代码\n```\ndef main():\n init_server()\n \n while server_is_not_shutdown():\n       time = aeSearchNearestTimer()\n       beforeSleep()\n       aeApiPoll(time)\n       processFileEvents()\n       processTimeEvents()\n \n clean_server()\n ```\n\n## Redis main函数调用流程图及关键节点\n![call](/img/rs1.jpg)\n\n## 一条简单的set命令的执行流程\n\n![flow](/img/rs2.jpg)\n\n## serverCron函数的功能\n\n![flow](/img/rs3.jpg)\n\n## Q&A\n1.bgsave执行时再次执行bgsave如何处理？\n\n直接返回,返回信息会通知正在执行.\n\n如果在aof rewrite时执行bgsave,会直接返回不能执行.\n\n看代码此处应该有bgsave schedule命令,如果此时在执行aof rewrite,则会在aof结束后在serverCron中执行。\n\n代码如下 \n\n![flow](/img/rs4.png)\n\n2.aof rewrite正在执行时再次发送bgrewriteaof会如何处理?\n\n直接返回,返回信息通知正在执行\n\n如果此时在执行rdbsave,则会在serverCron中在rdbsave结束之后执行aof rewrite.\n\n代码如下:\n\n![flow](/img/rs5.png)\n\n3.bgsave时如果master还在执行写入,由于linux COW机制,此时会给子进程拷贝一份数据,导致双倍内存。\n\n 待在测试环境验证是否会出现\n\n4.client端发送的命令能否在server端保证顺序?\n\n5.为什么redis本身支持分布式生产环境还在使用codis？","source":"_posts/Redis单机版本框架.md","raw":"---\ntitle: Redis单机版本框架\ndate: 2018-06-07 13:07:29\ntags: Redis\n---\n## Redis主流程伪代码\n```\ndef main():\n init_server()\n \n while server_is_not_shutdown():\n       time = aeSearchNearestTimer()\n       beforeSleep()\n       aeApiPoll(time)\n       processFileEvents()\n       processTimeEvents()\n \n clean_server()\n ```\n\n## Redis main函数调用流程图及关键节点\n![call](/img/rs1.jpg)\n\n## 一条简单的set命令的执行流程\n\n![flow](/img/rs2.jpg)\n\n## serverCron函数的功能\n\n![flow](/img/rs3.jpg)\n\n## Q&A\n1.bgsave执行时再次执行bgsave如何处理？\n\n直接返回,返回信息会通知正在执行.\n\n如果在aof rewrite时执行bgsave,会直接返回不能执行.\n\n看代码此处应该有bgsave schedule命令,如果此时在执行aof rewrite,则会在aof结束后在serverCron中执行。\n\n代码如下 \n\n![flow](/img/rs4.png)\n\n2.aof rewrite正在执行时再次发送bgrewriteaof会如何处理?\n\n直接返回,返回信息通知正在执行\n\n如果此时在执行rdbsave,则会在serverCron中在rdbsave结束之后执行aof rewrite.\n\n代码如下:\n\n![flow](/img/rs5.png)\n\n3.bgsave时如果master还在执行写入,由于linux COW机制,此时会给子进程拷贝一份数据,导致双倍内存。\n\n 待在测试环境验证是否会出现\n\n4.client端发送的命令能否在server端保证顺序?\n\n5.为什么redis本身支持分布式生产环境还在使用codis？","slug":"Redis单机版本框架","published":1,"updated":"2019-02-19T06:33:28.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9r000jbms6mujz2b0g","content":"<h2 id=\"Redis主流程伪代码\"><a href=\"#Redis主流程伪代码\" class=\"headerlink\" title=\"Redis主流程伪代码\"></a>Redis主流程伪代码</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def main():</span><br><span class=\"line\"> init_server()</span><br><span class=\"line\"> </span><br><span class=\"line\"> while server_is_not_shutdown():</span><br><span class=\"line\">       time = aeSearchNearestTimer()</span><br><span class=\"line\">       beforeSleep()</span><br><span class=\"line\">       aeApiPoll(time)</span><br><span class=\"line\">       processFileEvents()</span><br><span class=\"line\">       processTimeEvents()</span><br><span class=\"line\"> </span><br><span class=\"line\"> clean_server()</span><br></pre></td></tr></table></figure>\n<h2 id=\"Redis-main函数调用流程图及关键节点\"><a href=\"#Redis-main函数调用流程图及关键节点\" class=\"headerlink\" title=\"Redis main函数调用流程图及关键节点\"></a>Redis main函数调用流程图及关键节点</h2><p><img src=\"/img/rs1.jpg\" alt=\"call\"></p>\n<h2 id=\"一条简单的set命令的执行流程\"><a href=\"#一条简单的set命令的执行流程\" class=\"headerlink\" title=\"一条简单的set命令的执行流程\"></a>一条简单的set命令的执行流程</h2><p><img src=\"/img/rs2.jpg\" alt=\"flow\"></p>\n<h2 id=\"serverCron函数的功能\"><a href=\"#serverCron函数的功能\" class=\"headerlink\" title=\"serverCron函数的功能\"></a>serverCron函数的功能</h2><p><img src=\"/img/rs3.jpg\" alt=\"flow\"></p>\n<h2 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h2><p>1.bgsave执行时再次执行bgsave如何处理？</p>\n<p>直接返回,返回信息会通知正在执行.</p>\n<p>如果在aof rewrite时执行bgsave,会直接返回不能执行.</p>\n<p>看代码此处应该有bgsave schedule命令,如果此时在执行aof rewrite,则会在aof结束后在serverCron中执行。</p>\n<p>代码如下 </p>\n<p><img src=\"/img/rs4.png\" alt=\"flow\"></p>\n<p>2.aof rewrite正在执行时再次发送bgrewriteaof会如何处理?</p>\n<p>直接返回,返回信息通知正在执行</p>\n<p>如果此时在执行rdbsave,则会在serverCron中在rdbsave结束之后执行aof rewrite.</p>\n<p>代码如下:</p>\n<p><img src=\"/img/rs5.png\" alt=\"flow\"></p>\n<p>3.bgsave时如果master还在执行写入,由于linux COW机制,此时会给子进程拷贝一份数据,导致双倍内存。</p>\n<p> 待在测试环境验证是否会出现</p>\n<p>4.client端发送的命令能否在server端保证顺序?</p>\n<p>5.为什么redis本身支持分布式生产环境还在使用codis？</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Redis主流程伪代码\"><a href=\"#Redis主流程伪代码\" class=\"headerlink\" title=\"Redis主流程伪代码\"></a>Redis主流程伪代码</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def main():</span><br><span class=\"line\"> init_server()</span><br><span class=\"line\"> </span><br><span class=\"line\"> while server_is_not_shutdown():</span><br><span class=\"line\">       time = aeSearchNearestTimer()</span><br><span class=\"line\">       beforeSleep()</span><br><span class=\"line\">       aeApiPoll(time)</span><br><span class=\"line\">       processFileEvents()</span><br><span class=\"line\">       processTimeEvents()</span><br><span class=\"line\"> </span><br><span class=\"line\"> clean_server()</span><br></pre></td></tr></table></figure>\n<h2 id=\"Redis-main函数调用流程图及关键节点\"><a href=\"#Redis-main函数调用流程图及关键节点\" class=\"headerlink\" title=\"Redis main函数调用流程图及关键节点\"></a>Redis main函数调用流程图及关键节点</h2><p><img src=\"/img/rs1.jpg\" alt=\"call\"></p>\n<h2 id=\"一条简单的set命令的执行流程\"><a href=\"#一条简单的set命令的执行流程\" class=\"headerlink\" title=\"一条简单的set命令的执行流程\"></a>一条简单的set命令的执行流程</h2><p><img src=\"/img/rs2.jpg\" alt=\"flow\"></p>\n<h2 id=\"serverCron函数的功能\"><a href=\"#serverCron函数的功能\" class=\"headerlink\" title=\"serverCron函数的功能\"></a>serverCron函数的功能</h2><p><img src=\"/img/rs3.jpg\" alt=\"flow\"></p>\n<h2 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h2><p>1.bgsave执行时再次执行bgsave如何处理？</p>\n<p>直接返回,返回信息会通知正在执行.</p>\n<p>如果在aof rewrite时执行bgsave,会直接返回不能执行.</p>\n<p>看代码此处应该有bgsave schedule命令,如果此时在执行aof rewrite,则会在aof结束后在serverCron中执行。</p>\n<p>代码如下 </p>\n<p><img src=\"/img/rs4.png\" alt=\"flow\"></p>\n<p>2.aof rewrite正在执行时再次发送bgrewriteaof会如何处理?</p>\n<p>直接返回,返回信息通知正在执行</p>\n<p>如果此时在执行rdbsave,则会在serverCron中在rdbsave结束之后执行aof rewrite.</p>\n<p>代码如下:</p>\n<p><img src=\"/img/rs5.png\" alt=\"flow\"></p>\n<p>3.bgsave时如果master还在执行写入,由于linux COW机制,此时会给子进程拷贝一份数据,导致双倍内存。</p>\n<p> 待在测试环境验证是否会出现</p>\n<p>4.client端发送的命令能否在server端保证顺序?</p>\n<p>5.为什么redis本身支持分布式生产环境还在使用codis？</p>\n"},{"title":"Redis的resp协议","date":"2019-01-31T06:03:45.000Z","_content":"\n## resp协议\nredis客户端和服务端交互使用的是redis作者制定的一个协议，叫resp(REdis Serialization Protocol)。\n\n具体分如下几个层次\n\n* 基于tcp\n* 请求响应模式,但在两种情况下不再是简单的请求和响应模式(下文介绍)\n* 支持五种类型的数据，分别是简单字符串，错误，整型，bulk strings ,数组\n\n客户端发给服务端的命令都会序列化为array,而服务端返回给客户端的可以为如上任意一种类型，各简单举例如下\n\n* 简单字符串,第一个byte为 '+',例如  \"+OK\\r\\n\"\n* 错误，第一个byte为'-',例如 \"-Error message\\r\\n\"\n* 整型, 第一个byte为':\",例如 \":10\\r\\n\"\n\n* bulk strings,第一个byte为\"\\$\",例如 \"\\$6\\r\\nfoobar\\r\\n\"(此处为美元符号，没有前边的反斜杠)\n* 数组,第一个byte为'*',例如\"*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\"\n具体介绍参考:https://redis.io/topics/protocol\n\n## sub pattern\n请求响应模式有两种特殊情况\n\n* pipeline模式，客户端同时发送多条命令到服务端\n\n* sub pattern:当客户端执行subscribe命令后,不再要求客户端发送命令，当有其他客户端在订阅渠道上publish消息后,服务端会主动push信息到客户端\n\n我们拿redis-cli客户端试一下执行subscribe\n```\n127.0.0.1:6379> subscribe foo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"foo\"\n3) (integer) 1\n```\n\n可以看到,redis-cli会阻塞，当另起一个客户端,publish消息后，会收到该消息并打印\n```\nxiaoju@zsh_test ~$redis-cli\n127.0.0.1:6379> publish foo bar\n(integer) 1\n127.0.0.1:6379>\n\n\nxiaoju@zsh_test ~$redis-cli\n127.0.0.1:6379> subscribe foo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"foo\"\n3) (integer) 1\n1) \"message\"\n2) \"foo\"\n3) \"bar\"\n```\n\n直观感觉是服务端阻塞了，没有返回数据给客户端。但看redis源码，实际服务端并没有阻塞，并且可以在连接上继续接收并处理命令\n```\nvoid subscribeCommand(client *c) {\n    int j;\n\t//将订阅的渠道加入相应结构体并直接返回\n    for (j = 1; j < c->argc; j++)\n        pubsubSubscribeChannel(c,c->argv[j]);\n    //将客户端置CLINET_PUBSUB标记\n    c->flags |= CLIENT_PUBSUB;\n}\n```\n当客户端置了CLINET_PUBSUB标记后,命令处理会做如下特殊逻辑\n```\nint processCommand(client *c) {\n\t...\n\t//当置CLIENT_PUBSUB标记后,只有ping/subscribe/unsubscribe/psubscribe/punsubscribe命令能够执行\n\tif (c->flags & CLIENT_PUBSUB &&\n    \tc->cmd->proc != pingCommand &&\n    \tc->cmd->proc != subscribeCommand &&\n    \tc->cmd->proc != unsubscribeCommand &&\n    \tc->cmd->proc != psubscribeCommand &&\n    \tc->cmd->proc != punsubscribeCommand) {\n   \t \taddReplyError(c,\"only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\");\n   \t \treturn C_OK;\n\t}\n \t...\n}\n```\n\ngodis-cli\n如上文所示,当客户端执行subscribe命令后,实际上是可以继续订阅或者取消订阅渠道，并且可以执行ping命令。redis-cli客户端实际上是自己阻塞了，如下代码：\n```\nif (config.pubsub_mode) {\n    if (config.output != OUTPUT_RAW)\n        printf(\"Reading messages... (press Ctrl-C to quit)\\n\");\n\t//进入死循环，一直等待服务端发送消息\n    while (1) {\n        if (cliReadReply(output_raw) != REDIS_OK) exit(1);\n    }\n}\n```\n那么，我们可以拿go写一个不阻塞的版本，并且可以测试redis的subscribe 模式。效果如下\n```\n>bogon:godis-cli didi$ go run godis-cli.go\n> set k1 v1 \nOK\n> get k1\nv1\n> subscribe foo\nsubscribe foo 1\n[sub]>subscribe foo1//sub模式下可以继续订阅其他渠道\nsubscribe foo1 2\n[sub]> unsubscribe foo1//取消订阅\nunsubscribe foo1 1\n[sub]> ping//sub模式也可以执行ping\npong\n[sub]> get k1 //sub模式下不能执行get命令\nRedis Error: only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\n[sub]> exit\nexit sub pattern....\n>get k1//退出sub模式后可以继续正常执行get命令\nv1\n> exit\n\n```\n由于godis-cli直接实现了resp协议，虽然只是为了观察subscribe pattern的效果，但实际上可以支持所有redis命令的执行\n\n具体代码地址见:https://github.com/erpeng/godis-cli","source":"_posts/Redis的resp协议.md","raw":"---\ntitle: Redis的resp协议\ndate: 2019-01-31 14:03:45\ntags: Redis\n---\n\n## resp协议\nredis客户端和服务端交互使用的是redis作者制定的一个协议，叫resp(REdis Serialization Protocol)。\n\n具体分如下几个层次\n\n* 基于tcp\n* 请求响应模式,但在两种情况下不再是简单的请求和响应模式(下文介绍)\n* 支持五种类型的数据，分别是简单字符串，错误，整型，bulk strings ,数组\n\n客户端发给服务端的命令都会序列化为array,而服务端返回给客户端的可以为如上任意一种类型，各简单举例如下\n\n* 简单字符串,第一个byte为 '+',例如  \"+OK\\r\\n\"\n* 错误，第一个byte为'-',例如 \"-Error message\\r\\n\"\n* 整型, 第一个byte为':\",例如 \":10\\r\\n\"\n\n* bulk strings,第一个byte为\"\\$\",例如 \"\\$6\\r\\nfoobar\\r\\n\"(此处为美元符号，没有前边的反斜杠)\n* 数组,第一个byte为'*',例如\"*2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n\"\n具体介绍参考:https://redis.io/topics/protocol\n\n## sub pattern\n请求响应模式有两种特殊情况\n\n* pipeline模式，客户端同时发送多条命令到服务端\n\n* sub pattern:当客户端执行subscribe命令后,不再要求客户端发送命令，当有其他客户端在订阅渠道上publish消息后,服务端会主动push信息到客户端\n\n我们拿redis-cli客户端试一下执行subscribe\n```\n127.0.0.1:6379> subscribe foo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"foo\"\n3) (integer) 1\n```\n\n可以看到,redis-cli会阻塞，当另起一个客户端,publish消息后，会收到该消息并打印\n```\nxiaoju@zsh_test ~$redis-cli\n127.0.0.1:6379> publish foo bar\n(integer) 1\n127.0.0.1:6379>\n\n\nxiaoju@zsh_test ~$redis-cli\n127.0.0.1:6379> subscribe foo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"foo\"\n3) (integer) 1\n1) \"message\"\n2) \"foo\"\n3) \"bar\"\n```\n\n直观感觉是服务端阻塞了，没有返回数据给客户端。但看redis源码，实际服务端并没有阻塞，并且可以在连接上继续接收并处理命令\n```\nvoid subscribeCommand(client *c) {\n    int j;\n\t//将订阅的渠道加入相应结构体并直接返回\n    for (j = 1; j < c->argc; j++)\n        pubsubSubscribeChannel(c,c->argv[j]);\n    //将客户端置CLINET_PUBSUB标记\n    c->flags |= CLIENT_PUBSUB;\n}\n```\n当客户端置了CLINET_PUBSUB标记后,命令处理会做如下特殊逻辑\n```\nint processCommand(client *c) {\n\t...\n\t//当置CLIENT_PUBSUB标记后,只有ping/subscribe/unsubscribe/psubscribe/punsubscribe命令能够执行\n\tif (c->flags & CLIENT_PUBSUB &&\n    \tc->cmd->proc != pingCommand &&\n    \tc->cmd->proc != subscribeCommand &&\n    \tc->cmd->proc != unsubscribeCommand &&\n    \tc->cmd->proc != psubscribeCommand &&\n    \tc->cmd->proc != punsubscribeCommand) {\n   \t \taddReplyError(c,\"only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\");\n   \t \treturn C_OK;\n\t}\n \t...\n}\n```\n\ngodis-cli\n如上文所示,当客户端执行subscribe命令后,实际上是可以继续订阅或者取消订阅渠道，并且可以执行ping命令。redis-cli客户端实际上是自己阻塞了，如下代码：\n```\nif (config.pubsub_mode) {\n    if (config.output != OUTPUT_RAW)\n        printf(\"Reading messages... (press Ctrl-C to quit)\\n\");\n\t//进入死循环，一直等待服务端发送消息\n    while (1) {\n        if (cliReadReply(output_raw) != REDIS_OK) exit(1);\n    }\n}\n```\n那么，我们可以拿go写一个不阻塞的版本，并且可以测试redis的subscribe 模式。效果如下\n```\n>bogon:godis-cli didi$ go run godis-cli.go\n> set k1 v1 \nOK\n> get k1\nv1\n> subscribe foo\nsubscribe foo 1\n[sub]>subscribe foo1//sub模式下可以继续订阅其他渠道\nsubscribe foo1 2\n[sub]> unsubscribe foo1//取消订阅\nunsubscribe foo1 1\n[sub]> ping//sub模式也可以执行ping\npong\n[sub]> get k1 //sub模式下不能执行get命令\nRedis Error: only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context\n[sub]> exit\nexit sub pattern....\n>get k1//退出sub模式后可以继续正常执行get命令\nv1\n> exit\n\n```\n由于godis-cli直接实现了resp协议，虽然只是为了观察subscribe pattern的效果，但实际上可以支持所有redis命令的执行\n\n具体代码地址见:https://github.com/erpeng/godis-cli","slug":"Redis的resp协议","published":1,"updated":"2019-04-13T01:59:43.891Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9s000lbms6w2ldzcj5","content":"<h2 id=\"resp协议\"><a href=\"#resp协议\" class=\"headerlink\" title=\"resp协议\"></a>resp协议</h2><p>redis客户端和服务端交互使用的是redis作者制定的一个协议，叫resp(REdis Serialization Protocol)。</p>\n<p>具体分如下几个层次</p>\n<ul>\n<li>基于tcp</li>\n<li>请求响应模式,但在两种情况下不再是简单的请求和响应模式(下文介绍)</li>\n<li>支持五种类型的数据，分别是简单字符串，错误，整型，bulk strings ,数组</li>\n</ul>\n<p>客户端发给服务端的命令都会序列化为array,而服务端返回给客户端的可以为如上任意一种类型，各简单举例如下</p>\n<ul>\n<li>简单字符串,第一个byte为 ‘+’,例如  “+OK\\r\\n”</li>\n<li>错误，第一个byte为’-‘,例如 “-Error message\\r\\n”</li>\n<li><p>整型, 第一个byte为’:”,例如 “:10\\r\\n”</p>\n</li>\n<li><p>bulk strings,第一个byte为”\\$”,例如 “\\$6\\r\\nfoobar\\r\\n”(此处为美元符号，没有前边的反斜杠)</p>\n</li>\n<li>数组,第一个byte为’<em>‘,例如”</em>2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n”<br>具体介绍参考:<a href=\"https://redis.io/topics/protocol\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/protocol</a></li>\n</ul>\n<h2 id=\"sub-pattern\"><a href=\"#sub-pattern\" class=\"headerlink\" title=\"sub pattern\"></a>sub pattern</h2><p>请求响应模式有两种特殊情况</p>\n<ul>\n<li><p>pipeline模式，客户端同时发送多条命令到服务端</p>\n</li>\n<li><p>sub pattern:当客户端执行subscribe命令后,不再要求客户端发送命令，当有其他客户端在订阅渠道上publish消息后,服务端会主动push信息到客户端</p>\n</li>\n</ul>\n<p>我们拿redis-cli客户端试一下执行subscribe<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; subscribe foo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br></pre></td></tr></table></figure></p>\n<p>可以看到,redis-cli会阻塞，当另起一个客户端,publish消息后，会收到该消息并打印<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xiaoju@zsh_test ~$redis-cli</span><br><span class=\"line\">127.0.0.1:6379&gt; publish foo bar</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">xiaoju@zsh_test ~$redis-cli</span><br><span class=\"line\">127.0.0.1:6379&gt; subscribe foo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) &quot;bar&quot;</span><br></pre></td></tr></table></figure></p>\n<p>直观感觉是服务端阻塞了，没有返回数据给客户端。但看redis源码，实际服务端并没有阻塞，并且可以在连接上继续接收并处理命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void subscribeCommand(client *c) &#123;</span><br><span class=\"line\">    int j;</span><br><span class=\"line\">\t//将订阅的渠道加入相应结构体并直接返回</span><br><span class=\"line\">    for (j = 1; j &lt; c-&gt;argc; j++)</span><br><span class=\"line\">        pubsubSubscribeChannel(c,c-&gt;argv[j]);</span><br><span class=\"line\">    //将客户端置CLINET_PUBSUB标记</span><br><span class=\"line\">    c-&gt;flags |= CLIENT_PUBSUB;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>当客户端置了CLINET_PUBSUB标记后,命令处理会做如下特殊逻辑<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int processCommand(client *c) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//当置CLIENT_PUBSUB标记后,只有ping/subscribe/unsubscribe/psubscribe/punsubscribe命令能够执行</span><br><span class=\"line\">\tif (c-&gt;flags &amp; CLIENT_PUBSUB &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != pingCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != subscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != unsubscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != psubscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != punsubscribeCommand) &#123;</span><br><span class=\"line\">   \t \taddReplyError(c,&quot;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context&quot;);</span><br><span class=\"line\">   \t \treturn C_OK;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"> \t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>godis-cli<br>如上文所示,当客户端执行subscribe命令后,实际上是可以继续订阅或者取消订阅渠道，并且可以执行ping命令。redis-cli客户端实际上是自己阻塞了，如下代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (config.pubsub_mode) &#123;</span><br><span class=\"line\">    if (config.output != OUTPUT_RAW)</span><br><span class=\"line\">        printf(&quot;Reading messages... (press Ctrl-C to quit)\\n&quot;);</span><br><span class=\"line\">\t//进入死循环，一直等待服务端发送消息</span><br><span class=\"line\">    while (1) &#123;</span><br><span class=\"line\">        if (cliReadReply(output_raw) != REDIS_OK) exit(1);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>那么，我们可以拿go写一个不阻塞的版本，并且可以测试redis的subscribe 模式。效果如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;bogon:godis-cli didi$ go run godis-cli.go</span><br><span class=\"line\">&gt; set k1 v1 </span><br><span class=\"line\">OK</span><br><span class=\"line\">&gt; get k1</span><br><span class=\"line\">v1</span><br><span class=\"line\">&gt; subscribe foo</span><br><span class=\"line\">subscribe foo 1</span><br><span class=\"line\">[sub]&gt;subscribe foo1//sub模式下可以继续订阅其他渠道</span><br><span class=\"line\">subscribe foo1 2</span><br><span class=\"line\">[sub]&gt; unsubscribe foo1//取消订阅</span><br><span class=\"line\">unsubscribe foo1 1</span><br><span class=\"line\">[sub]&gt; ping//sub模式也可以执行ping</span><br><span class=\"line\">pong</span><br><span class=\"line\">[sub]&gt; get k1 //sub模式下不能执行get命令</span><br><span class=\"line\">Redis Error: only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context</span><br><span class=\"line\">[sub]&gt; exit</span><br><span class=\"line\">exit sub pattern....</span><br><span class=\"line\">&gt;get k1//退出sub模式后可以继续正常执行get命令</span><br><span class=\"line\">v1</span><br><span class=\"line\">&gt; exit</span><br></pre></td></tr></table></figure></p>\n<p>由于godis-cli直接实现了resp协议，虽然只是为了观察subscribe pattern的效果，但实际上可以支持所有redis命令的执行</p>\n<p>具体代码地址见:<a href=\"https://github.com/erpeng/godis-cli\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/godis-cli</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"resp协议\"><a href=\"#resp协议\" class=\"headerlink\" title=\"resp协议\"></a>resp协议</h2><p>redis客户端和服务端交互使用的是redis作者制定的一个协议，叫resp(REdis Serialization Protocol)。</p>\n<p>具体分如下几个层次</p>\n<ul>\n<li>基于tcp</li>\n<li>请求响应模式,但在两种情况下不再是简单的请求和响应模式(下文介绍)</li>\n<li>支持五种类型的数据，分别是简单字符串，错误，整型，bulk strings ,数组</li>\n</ul>\n<p>客户端发给服务端的命令都会序列化为array,而服务端返回给客户端的可以为如上任意一种类型，各简单举例如下</p>\n<ul>\n<li>简单字符串,第一个byte为 ‘+’,例如  “+OK\\r\\n”</li>\n<li>错误，第一个byte为’-‘,例如 “-Error message\\r\\n”</li>\n<li><p>整型, 第一个byte为’:”,例如 “:10\\r\\n”</p>\n</li>\n<li><p>bulk strings,第一个byte为”\\$”,例如 “\\$6\\r\\nfoobar\\r\\n”(此处为美元符号，没有前边的反斜杠)</p>\n</li>\n<li>数组,第一个byte为’<em>‘,例如”</em>2\\r\\n$3\\r\\nfoo\\r\\n$3\\r\\nbar\\r\\n”<br>具体介绍参考:<a href=\"https://redis.io/topics/protocol\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/protocol</a></li>\n</ul>\n<h2 id=\"sub-pattern\"><a href=\"#sub-pattern\" class=\"headerlink\" title=\"sub pattern\"></a>sub pattern</h2><p>请求响应模式有两种特殊情况</p>\n<ul>\n<li><p>pipeline模式，客户端同时发送多条命令到服务端</p>\n</li>\n<li><p>sub pattern:当客户端执行subscribe命令后,不再要求客户端发送命令，当有其他客户端在订阅渠道上publish消息后,服务端会主动push信息到客户端</p>\n</li>\n</ul>\n<p>我们拿redis-cli客户端试一下执行subscribe<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; subscribe foo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br></pre></td></tr></table></figure></p>\n<p>可以看到,redis-cli会阻塞，当另起一个客户端,publish消息后，会收到该消息并打印<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xiaoju@zsh_test ~$redis-cli</span><br><span class=\"line\">127.0.0.1:6379&gt; publish foo bar</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">xiaoju@zsh_test ~$redis-cli</span><br><span class=\"line\">127.0.0.1:6379&gt; subscribe foo</span><br><span class=\"line\">Reading messages... (press Ctrl-C to quit)</span><br><span class=\"line\">1) &quot;subscribe&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) (integer) 1</span><br><span class=\"line\">1) &quot;message&quot;</span><br><span class=\"line\">2) &quot;foo&quot;</span><br><span class=\"line\">3) &quot;bar&quot;</span><br></pre></td></tr></table></figure></p>\n<p>直观感觉是服务端阻塞了，没有返回数据给客户端。但看redis源码，实际服务端并没有阻塞，并且可以在连接上继续接收并处理命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void subscribeCommand(client *c) &#123;</span><br><span class=\"line\">    int j;</span><br><span class=\"line\">\t//将订阅的渠道加入相应结构体并直接返回</span><br><span class=\"line\">    for (j = 1; j &lt; c-&gt;argc; j++)</span><br><span class=\"line\">        pubsubSubscribeChannel(c,c-&gt;argv[j]);</span><br><span class=\"line\">    //将客户端置CLINET_PUBSUB标记</span><br><span class=\"line\">    c-&gt;flags |= CLIENT_PUBSUB;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>当客户端置了CLINET_PUBSUB标记后,命令处理会做如下特殊逻辑<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int processCommand(client *c) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//当置CLIENT_PUBSUB标记后,只有ping/subscribe/unsubscribe/psubscribe/punsubscribe命令能够执行</span><br><span class=\"line\">\tif (c-&gt;flags &amp; CLIENT_PUBSUB &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != pingCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != subscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != unsubscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != psubscribeCommand &amp;&amp;</span><br><span class=\"line\">    \tc-&gt;cmd-&gt;proc != punsubscribeCommand) &#123;</span><br><span class=\"line\">   \t \taddReplyError(c,&quot;only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context&quot;);</span><br><span class=\"line\">   \t \treturn C_OK;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"> \t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>godis-cli<br>如上文所示,当客户端执行subscribe命令后,实际上是可以继续订阅或者取消订阅渠道，并且可以执行ping命令。redis-cli客户端实际上是自己阻塞了，如下代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (config.pubsub_mode) &#123;</span><br><span class=\"line\">    if (config.output != OUTPUT_RAW)</span><br><span class=\"line\">        printf(&quot;Reading messages... (press Ctrl-C to quit)\\n&quot;);</span><br><span class=\"line\">\t//进入死循环，一直等待服务端发送消息</span><br><span class=\"line\">    while (1) &#123;</span><br><span class=\"line\">        if (cliReadReply(output_raw) != REDIS_OK) exit(1);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>那么，我们可以拿go写一个不阻塞的版本，并且可以测试redis的subscribe 模式。效果如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;bogon:godis-cli didi$ go run godis-cli.go</span><br><span class=\"line\">&gt; set k1 v1 </span><br><span class=\"line\">OK</span><br><span class=\"line\">&gt; get k1</span><br><span class=\"line\">v1</span><br><span class=\"line\">&gt; subscribe foo</span><br><span class=\"line\">subscribe foo 1</span><br><span class=\"line\">[sub]&gt;subscribe foo1//sub模式下可以继续订阅其他渠道</span><br><span class=\"line\">subscribe foo1 2</span><br><span class=\"line\">[sub]&gt; unsubscribe foo1//取消订阅</span><br><span class=\"line\">unsubscribe foo1 1</span><br><span class=\"line\">[sub]&gt; ping//sub模式也可以执行ping</span><br><span class=\"line\">pong</span><br><span class=\"line\">[sub]&gt; get k1 //sub模式下不能执行get命令</span><br><span class=\"line\">Redis Error: only (P)SUBSCRIBE / (P)UNSUBSCRIBE / PING / QUIT allowed in this context</span><br><span class=\"line\">[sub]&gt; exit</span><br><span class=\"line\">exit sub pattern....</span><br><span class=\"line\">&gt;get k1//退出sub模式后可以继续正常执行get命令</span><br><span class=\"line\">v1</span><br><span class=\"line\">&gt; exit</span><br></pre></td></tr></table></figure></p>\n<p>由于godis-cli直接实现了resp协议，虽然只是为了观察subscribe pattern的效果，但实际上可以支持所有redis命令的执行</p>\n<p>具体代码地址见:<a href=\"https://github.com/erpeng/godis-cli\" target=\"_blank\" rel=\"noopener\">https://github.com/erpeng/godis-cli</a></p>\n"},{"title":"go sync包源码分析","date":"2019-05-18T16:00:00.000Z","_content":">go的sync包中所有的结构都适用于goroutine并发执行的情况\n\n## sync.Once包\n\n### 一个示例\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n```\n\n虽然起10个goroutine去调用onceBody,但是使用once.Do函数将onceBody包裹之后,onceBody只会执行一次.运行该代码,结果如下:\n```\nOnly once\n```\n### 代码分析\n\n#### 设想一下原理\n\n应该是once结构体中有个bool值决定是否已经执行过该函数.如果没有执行,首先加锁,然后执行函数,执行完毕之后修改bool值并且释放锁\n\n#### sync.Once结构\n\n```\ntype Once struct {\n\tm    Mutex\n\tdone uint32\n}\n```\n一个锁,一个done的uint32值\n\n```\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n加锁,执行,最后置done标记.done为uint32估计是因为可以使用atomic包中的LoadUint32和StoreUint32原子性的加载和存储.\n\n## sync.Pool包\n\nNew字段定义如何生成对象,然后可以通过pool.Get()和pool.Put()获取和放回对象.一系列临时对象的对象池\n\n关键结构体如下:\n```\ntype Pool struct {\n\tnoCopy noCopy\n\n\tlocal     unsafe.Pointer  \n\tlocalSize uintptr        \n\tNew func() interface{}\n}\n```\nlocal可以理解为指向一个poolLocal数组,大小由localSize指定(localSize由cpu cores决定).\nNew指定一个函数,用来创建Pool中的对象\n\n```\ntype poolLocal struct {\n\tpoolLocalInternal\n\tpad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte\n}\ntype poolLocalInternal struct {\n\tprivate interface{}   // Can be used only by the respective P.\n\tshared  []interface{} // Can be used by any P.\n\tMutex                 // Protects shared.\n}\n```\npoolLocal中关键的字段为private和shared,private保存只能由相应的P(go调度器中概念,P/M/G)使用的对象.shared中保存可以由所有的P共同使用的对象\n\n我们看一下Put的代码\n```\nfunc (p *Pool) Put(x interface{}) {\n\tif x == nil {\n\t\treturn\n\t}\n\t...\n\tl := p.pin()\n\tif l.private == nil {\n\t\tl.private = x\n\t\tx = nil\n\t}\n\truntime_procUnpin()\n\tif x != nil {\n\t\tl.Lock()\n\t\tl.shared = append(l.shared, x)\n\t\tl.Unlock()\n\t}\n\t...\n}\n```\n关键路径为首先将要放回的对象放入poolLocal中的private,否则放入共享的shared结构.\n\n看一下Get()的代码路径\n```\nfunc (p *Pool) Get() interface{} {\n\t...\n\tl := p.pin()\n\tx := l.private\n\tl.private = nil\n\truntime_procUnpin()\n\tif x == nil {\n\t\tl.Lock()\n\t\tlast := len(l.shared) - 1\n\t\tif last >= 0 {\n\t\t\tx = l.shared[last]\n\t\t\tl.shared = l.shared[:last]\n\t\t}\n\t\tl.Unlock()\n\t\tif x == nil {\n\t\t\tx = p.getSlow()\n\t\t}\n\t}\n\t...\n\tif x == nil && p.New != nil {\n\t\tx = p.New()\n\t}\n\treturn x\n}\n```\n首先从poolLocal的private中获取,如果未获取到则获取shared的最后一个元素,否则调用getSlow函数.\n依然获取不到的话调用pool结构中的New函数生成.\n\n```\nfunc (p *Pool) getSlow() (x interface{}) {\n\tsize := atomic.LoadUintptr(&p.localSize) // load-acquire\n\tlocal := p.local                         // load-consume\n\tpid := runtime_procPin()\n\truntime_procUnpin()\n\tfor i := 0; i < int(size); i++ {\n\t\tl := indexLocal(local, (pid+i+1)%int(size))\n\t\tl.Lock()\n\t\tlast := len(l.shared) - 1\n\t\tif last >= 0 {\n\t\t\tx = l.shared[last]\n\t\t\tl.shared = l.shared[:last]\n\t\t\tl.Unlock()\n\t\t\tbreak\n\t\t}\n\t\tl.Unlock()\n\t}\n\treturn x\n}\n```\ngetSlow函数会从当前P的下一个P开始依次遍历其他poolLocal中的shared结构去获取对象.\n\n### 问题\n* runtime_procPin()会返回当前P的pid,需要了解go scheduler相关知识加深理解\n* pool中会注册一个runtime_registerPoolCleanup(poolCleanup),与Go GC相关,需了解go GC相关知识\n\n\n\n## sync.Cond包\n\n条件变量,控制goroutine间的同步位点\n通过NewCond生成一个Cond,调用cond.Wait()之后阻塞,其他goroutine调用cond.Signal()或者cond.Broadcast()唤醒wait的一个或者全部goroutine\n\n### 一个示例\n```\n    c.L.Lock()\n    for !condition() {\n        c.Wait()\n    }\n    ... make use of condition ...\n    c.L.Unlock()\n```\n\n一个goroutine中要执行Wait之前,首先将cond中的c.L.Lock()\n\n### 关键结构体和方法\n```\ntype Cond struct {\n\tnoCopy noCopy\n\t// L is held while observing or changing the condition\n\tL Locker\n\tnotify  notifyList\n\tchecker copyChecker\n}\n```\n\n```\nfunc NewCond(l Locker) *Cond {\n\treturn &Cond{L: l}\n}\n```\n调用NewCond需要传入一个实现了Locker接口的结构\n\n```\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\nWait函数首先调用runtime将c.notify加入notifyList,然后解锁,然后等待.当条件变量满足后首先获取锁后Wait才会返回\n\n```\n\nfunc (c *Cond) Signal() {\n\tc.checker.check()\n\truntime_notifyListNotifyOne(&c.notify)\n}\n```\nSignal()函数唤醒一个在等待的goroutine\n\n```\nfunc (c *Cond) Broadcast() {\n\tc.checker.check()\n\truntime_notifyListNotifyAll(&c.notify)\n}\n```\n\nBroadcast唤醒全部等待的goroutine\n\n### 问题\n\n* 进一步的实现依赖于runtime,需要熟悉runtime","source":"_posts/go-sync.md","raw":"---\ntitle: go sync包源码分析\ndate: 2019-05-19\ntags: go\n---\n>go的sync包中所有的结构都适用于goroutine并发执行的情况\n\n## sync.Once包\n\n### 一个示例\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar once sync.Once\n\tonceBody := func() {\n\t\tfmt.Println(\"Only once\")\n\t}\n\tdone := make(chan bool)\n\tfor i := 0; i < 10; i++ {\n\t\tgo func() {\n\t\t\tonce.Do(onceBody)\n\t\t\tdone <- true\n\t\t}()\n\t}\n\tfor i := 0; i < 10; i++ {\n\t\t<-done\n\t}\n}\n\n```\n\n虽然起10个goroutine去调用onceBody,但是使用once.Do函数将onceBody包裹之后,onceBody只会执行一次.运行该代码,结果如下:\n```\nOnly once\n```\n### 代码分析\n\n#### 设想一下原理\n\n应该是once结构体中有个bool值决定是否已经执行过该函数.如果没有执行,首先加锁,然后执行函数,执行完毕之后修改bool值并且释放锁\n\n#### sync.Once结构\n\n```\ntype Once struct {\n\tm    Mutex\n\tdone uint32\n}\n```\n一个锁,一个done的uint32值\n\n```\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&o.done) == 1 {\n\t\treturn\n\t}\n\t// Slow-path.\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&o.done, 1)\n\t\tf()\n\t}\n}\n```\n加锁,执行,最后置done标记.done为uint32估计是因为可以使用atomic包中的LoadUint32和StoreUint32原子性的加载和存储.\n\n## sync.Pool包\n\nNew字段定义如何生成对象,然后可以通过pool.Get()和pool.Put()获取和放回对象.一系列临时对象的对象池\n\n关键结构体如下:\n```\ntype Pool struct {\n\tnoCopy noCopy\n\n\tlocal     unsafe.Pointer  \n\tlocalSize uintptr        \n\tNew func() interface{}\n}\n```\nlocal可以理解为指向一个poolLocal数组,大小由localSize指定(localSize由cpu cores决定).\nNew指定一个函数,用来创建Pool中的对象\n\n```\ntype poolLocal struct {\n\tpoolLocalInternal\n\tpad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte\n}\ntype poolLocalInternal struct {\n\tprivate interface{}   // Can be used only by the respective P.\n\tshared  []interface{} // Can be used by any P.\n\tMutex                 // Protects shared.\n}\n```\npoolLocal中关键的字段为private和shared,private保存只能由相应的P(go调度器中概念,P/M/G)使用的对象.shared中保存可以由所有的P共同使用的对象\n\n我们看一下Put的代码\n```\nfunc (p *Pool) Put(x interface{}) {\n\tif x == nil {\n\t\treturn\n\t}\n\t...\n\tl := p.pin()\n\tif l.private == nil {\n\t\tl.private = x\n\t\tx = nil\n\t}\n\truntime_procUnpin()\n\tif x != nil {\n\t\tl.Lock()\n\t\tl.shared = append(l.shared, x)\n\t\tl.Unlock()\n\t}\n\t...\n}\n```\n关键路径为首先将要放回的对象放入poolLocal中的private,否则放入共享的shared结构.\n\n看一下Get()的代码路径\n```\nfunc (p *Pool) Get() interface{} {\n\t...\n\tl := p.pin()\n\tx := l.private\n\tl.private = nil\n\truntime_procUnpin()\n\tif x == nil {\n\t\tl.Lock()\n\t\tlast := len(l.shared) - 1\n\t\tif last >= 0 {\n\t\t\tx = l.shared[last]\n\t\t\tl.shared = l.shared[:last]\n\t\t}\n\t\tl.Unlock()\n\t\tif x == nil {\n\t\t\tx = p.getSlow()\n\t\t}\n\t}\n\t...\n\tif x == nil && p.New != nil {\n\t\tx = p.New()\n\t}\n\treturn x\n}\n```\n首先从poolLocal的private中获取,如果未获取到则获取shared的最后一个元素,否则调用getSlow函数.\n依然获取不到的话调用pool结构中的New函数生成.\n\n```\nfunc (p *Pool) getSlow() (x interface{}) {\n\tsize := atomic.LoadUintptr(&p.localSize) // load-acquire\n\tlocal := p.local                         // load-consume\n\tpid := runtime_procPin()\n\truntime_procUnpin()\n\tfor i := 0; i < int(size); i++ {\n\t\tl := indexLocal(local, (pid+i+1)%int(size))\n\t\tl.Lock()\n\t\tlast := len(l.shared) - 1\n\t\tif last >= 0 {\n\t\t\tx = l.shared[last]\n\t\t\tl.shared = l.shared[:last]\n\t\t\tl.Unlock()\n\t\t\tbreak\n\t\t}\n\t\tl.Unlock()\n\t}\n\treturn x\n}\n```\ngetSlow函数会从当前P的下一个P开始依次遍历其他poolLocal中的shared结构去获取对象.\n\n### 问题\n* runtime_procPin()会返回当前P的pid,需要了解go scheduler相关知识加深理解\n* pool中会注册一个runtime_registerPoolCleanup(poolCleanup),与Go GC相关,需了解go GC相关知识\n\n\n\n## sync.Cond包\n\n条件变量,控制goroutine间的同步位点\n通过NewCond生成一个Cond,调用cond.Wait()之后阻塞,其他goroutine调用cond.Signal()或者cond.Broadcast()唤醒wait的一个或者全部goroutine\n\n### 一个示例\n```\n    c.L.Lock()\n    for !condition() {\n        c.Wait()\n    }\n    ... make use of condition ...\n    c.L.Unlock()\n```\n\n一个goroutine中要执行Wait之前,首先将cond中的c.L.Lock()\n\n### 关键结构体和方法\n```\ntype Cond struct {\n\tnoCopy noCopy\n\t// L is held while observing or changing the condition\n\tL Locker\n\tnotify  notifyList\n\tchecker copyChecker\n}\n```\n\n```\nfunc NewCond(l Locker) *Cond {\n\treturn &Cond{L: l}\n}\n```\n调用NewCond需要传入一个实现了Locker接口的结构\n\n```\nfunc (c *Cond) Wait() {\n\tc.checker.check()\n\tt := runtime_notifyListAdd(&c.notify)\n\tc.L.Unlock()\n\truntime_notifyListWait(&c.notify, t)\n\tc.L.Lock()\n}\n```\nWait函数首先调用runtime将c.notify加入notifyList,然后解锁,然后等待.当条件变量满足后首先获取锁后Wait才会返回\n\n```\n\nfunc (c *Cond) Signal() {\n\tc.checker.check()\n\truntime_notifyListNotifyOne(&c.notify)\n}\n```\nSignal()函数唤醒一个在等待的goroutine\n\n```\nfunc (c *Cond) Broadcast() {\n\tc.checker.check()\n\truntime_notifyListNotifyAll(&c.notify)\n}\n```\n\nBroadcast唤醒全部等待的goroutine\n\n### 问题\n\n* 进一步的实现依赖于runtime,需要熟悉runtime","slug":"go-sync","published":1,"updated":"2019-05-20T09:32:46.475Z","_id":"cjvw65z9t000nbms6qzyvltk1","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>go的sync包中所有的结构都适用于goroutine并发执行的情况</p>\n</blockquote>\n<h2 id=\"sync-Once包\"><a href=\"#sync-Once包\" class=\"headerlink\" title=\"sync.Once包\"></a>sync.Once包</h2><h3 id=\"一个示例\"><a href=\"#一个示例\" class=\"headerlink\" title=\"一个示例\"></a>一个示例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar once sync.Once</span><br><span class=\"line\">\tonceBody := func() &#123;</span><br><span class=\"line\">\t\tfmt.Println(&quot;Only once&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := make(chan bool)</span><br><span class=\"line\">\tfor i := 0; i &lt; 10; i++ &#123;</span><br><span class=\"line\">\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- true</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor i := 0; i &lt; 10; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>虽然起10个goroutine去调用onceBody,但是使用once.Do函数将onceBody包裹之后,onceBody只会执行一次.运行该代码,结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Only once</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h3><h4 id=\"设想一下原理\"><a href=\"#设想一下原理\" class=\"headerlink\" title=\"设想一下原理\"></a>设想一下原理</h4><p>应该是once结构体中有个bool值决定是否已经执行过该函数.如果没有执行,首先加锁,然后执行函数,执行完毕之后修改bool值并且释放锁</p>\n<h4 id=\"sync-Once结构\"><a href=\"#sync-Once结构\" class=\"headerlink\" title=\"sync.Once结构\"></a>sync.Once结构</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Once struct &#123;</span><br><span class=\"line\">\tm    Mutex</span><br><span class=\"line\">\tdone uint32</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一个锁,一个done的uint32值</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (o *Once) Do(f func()) &#123;</span><br><span class=\"line\">\tif atomic.LoadUint32(&amp;o.done) == 1 &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Slow-path.</span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\tdefer o.m.Unlock()</span><br><span class=\"line\">\tif o.done == 0 &#123;</span><br><span class=\"line\">\t\tdefer atomic.StoreUint32(&amp;o.done, 1)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>加锁,执行,最后置done标记.done为uint32估计是因为可以使用atomic包中的LoadUint32和StoreUint32原子性的加载和存储.</p>\n<h2 id=\"sync-Pool包\"><a href=\"#sync-Pool包\" class=\"headerlink\" title=\"sync.Pool包\"></a>sync.Pool包</h2><p>New字段定义如何生成对象,然后可以通过pool.Get()和pool.Put()获取和放回对象.一系列临时对象的对象池</p>\n<p>关键结构体如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Pool struct &#123;</span><br><span class=\"line\">\tnoCopy noCopy</span><br><span class=\"line\"></span><br><span class=\"line\">\tlocal     unsafe.Pointer  </span><br><span class=\"line\">\tlocalSize uintptr        </span><br><span class=\"line\">\tNew func() interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>local可以理解为指向一个poolLocal数组,大小由localSize指定(localSize由cpu cores决定).<br>New指定一个函数,用来创建Pool中的对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type poolLocal struct &#123;</span><br><span class=\"line\">\tpoolLocalInternal</span><br><span class=\"line\">\tpad [128 - unsafe.Sizeof(poolLocalInternal&#123;&#125;)%128]byte</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">type poolLocalInternal struct &#123;</span><br><span class=\"line\">\tprivate interface&#123;&#125;   // Can be used only by the respective P.</span><br><span class=\"line\">\tshared  []interface&#123;&#125; // Can be used by any P.</span><br><span class=\"line\">\tMutex                 // Protects shared.</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>poolLocal中关键的字段为private和shared,private保存只能由相应的P(go调度器中概念,P/M/G)使用的对象.shared中保存可以由所有的P共同使用的对象</p>\n<p>我们看一下Put的代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) Put(x interface&#123;&#125;) &#123;</span><br><span class=\"line\">\tif x == nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tl := p.pin()</span><br><span class=\"line\">\tif l.private == nil &#123;</span><br><span class=\"line\">\t\tl.private = x</span><br><span class=\"line\">\t\tx = nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tif x != nil &#123;</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tl.shared = append(l.shared, x)</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>关键路径为首先将要放回的对象放入poolLocal中的private,否则放入共享的shared结构.</p>\n<p>看一下Get()的代码路径<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) Get() interface&#123;&#125; &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tl := p.pin()</span><br><span class=\"line\">\tx := l.private</span><br><span class=\"line\">\tl.private = nil</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tif x == nil &#123;</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tlast := len(l.shared) - 1</span><br><span class=\"line\">\t\tif last &gt;= 0 &#123;</span><br><span class=\"line\">\t\t\tx = l.shared[last]</span><br><span class=\"line\">\t\t\tl.shared = l.shared[:last]</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t\tif x == nil &#123;</span><br><span class=\"line\">\t\t\tx = p.getSlow()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tif x == nil &amp;&amp; p.New != nil &#123;</span><br><span class=\"line\">\t\tx = p.New()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn x</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>首先从poolLocal的private中获取,如果未获取到则获取shared的最后一个元素,否则调用getSlow函数.<br>依然获取不到的话调用pool结构中的New函数生成.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) getSlow() (x interface&#123;&#125;) &#123;</span><br><span class=\"line\">\tsize := atomic.LoadUintptr(&amp;p.localSize) // load-acquire</span><br><span class=\"line\">\tlocal := p.local                         // load-consume</span><br><span class=\"line\">\tpid := runtime_procPin()</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tfor i := 0; i &lt; int(size); i++ &#123;</span><br><span class=\"line\">\t\tl := indexLocal(local, (pid+i+1)%int(size))</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tlast := len(l.shared) - 1</span><br><span class=\"line\">\t\tif last &gt;= 0 &#123;</span><br><span class=\"line\">\t\t\tx = l.shared[last]</span><br><span class=\"line\">\t\t\tl.shared = l.shared[:last]</span><br><span class=\"line\">\t\t\tl.Unlock()</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn x</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>getSlow函数会从当前P的下一个P开始依次遍历其他poolLocal中的shared结构去获取对象.</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li>runtime_procPin()会返回当前P的pid,需要了解go scheduler相关知识加深理解</li>\n<li>pool中会注册一个runtime_registerPoolCleanup(poolCleanup),与Go GC相关,需了解go GC相关知识</li>\n</ul>\n<h2 id=\"sync-Cond包\"><a href=\"#sync-Cond包\" class=\"headerlink\" title=\"sync.Cond包\"></a>sync.Cond包</h2><p>条件变量,控制goroutine间的同步位点<br>通过NewCond生成一个Cond,调用cond.Wait()之后阻塞,其他goroutine调用cond.Signal()或者cond.Broadcast()唤醒wait的一个或者全部goroutine</p>\n<h3 id=\"一个示例-1\"><a href=\"#一个示例-1\" class=\"headerlink\" title=\"一个示例\"></a>一个示例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c.L.Lock()</span><br><span class=\"line\">for !condition() &#123;</span><br><span class=\"line\">    c.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">... make use of condition ...</span><br><span class=\"line\">c.L.Unlock()</span><br></pre></td></tr></table></figure>\n<p>一个goroutine中要执行Wait之前,首先将cond中的c.L.Lock()</p>\n<h3 id=\"关键结构体和方法\"><a href=\"#关键结构体和方法\" class=\"headerlink\" title=\"关键结构体和方法\"></a>关键结构体和方法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Cond struct &#123;</span><br><span class=\"line\">\tnoCopy noCopy</span><br><span class=\"line\">\t// L is held while observing or changing the condition</span><br><span class=\"line\">\tL Locker</span><br><span class=\"line\">\tnotify  notifyList</span><br><span class=\"line\">\tchecker copyChecker</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewCond(l Locker) *Cond &#123;</span><br><span class=\"line\">\treturn &amp;Cond&#123;L: l&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>调用NewCond需要传入一个实现了Locker接口的结构</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *Cond) Wait() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Wait函数首先调用runtime将c.notify加入notifyList,然后解锁,然后等待.当条件变量满足后首先获取锁后Wait才会返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">func (c *Cond) Signal() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\truntime_notifyListNotifyOne(&amp;c.notify)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Signal()函数唤醒一个在等待的goroutine</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *Cond) Broadcast() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\truntime_notifyListNotifyAll(&amp;c.notify)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Broadcast唤醒全部等待的goroutine</p>\n<h3 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li>进一步的实现依赖于runtime,需要熟悉runtime</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>go的sync包中所有的结构都适用于goroutine并发执行的情况</p>\n</blockquote>\n<h2 id=\"sync-Once包\"><a href=\"#sync-Once包\" class=\"headerlink\" title=\"sync.Once包\"></a>sync.Once包</h2><h3 id=\"一个示例\"><a href=\"#一个示例\" class=\"headerlink\" title=\"一个示例\"></a>一个示例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar once sync.Once</span><br><span class=\"line\">\tonceBody := func() &#123;</span><br><span class=\"line\">\t\tfmt.Println(&quot;Only once&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdone := make(chan bool)</span><br><span class=\"line\">\tfor i := 0; i &lt; 10; i++ &#123;</span><br><span class=\"line\">\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\tonce.Do(onceBody)</span><br><span class=\"line\">\t\t\tdone &lt;- true</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor i := 0; i &lt; 10; i++ &#123;</span><br><span class=\"line\">\t\t&lt;-done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>虽然起10个goroutine去调用onceBody,但是使用once.Do函数将onceBody包裹之后,onceBody只会执行一次.运行该代码,结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Only once</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h3><h4 id=\"设想一下原理\"><a href=\"#设想一下原理\" class=\"headerlink\" title=\"设想一下原理\"></a>设想一下原理</h4><p>应该是once结构体中有个bool值决定是否已经执行过该函数.如果没有执行,首先加锁,然后执行函数,执行完毕之后修改bool值并且释放锁</p>\n<h4 id=\"sync-Once结构\"><a href=\"#sync-Once结构\" class=\"headerlink\" title=\"sync.Once结构\"></a>sync.Once结构</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Once struct &#123;</span><br><span class=\"line\">\tm    Mutex</span><br><span class=\"line\">\tdone uint32</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>一个锁,一个done的uint32值</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (o *Once) Do(f func()) &#123;</span><br><span class=\"line\">\tif atomic.LoadUint32(&amp;o.done) == 1 &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// Slow-path.</span><br><span class=\"line\">\to.m.Lock()</span><br><span class=\"line\">\tdefer o.m.Unlock()</span><br><span class=\"line\">\tif o.done == 0 &#123;</span><br><span class=\"line\">\t\tdefer atomic.StoreUint32(&amp;o.done, 1)</span><br><span class=\"line\">\t\tf()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>加锁,执行,最后置done标记.done为uint32估计是因为可以使用atomic包中的LoadUint32和StoreUint32原子性的加载和存储.</p>\n<h2 id=\"sync-Pool包\"><a href=\"#sync-Pool包\" class=\"headerlink\" title=\"sync.Pool包\"></a>sync.Pool包</h2><p>New字段定义如何生成对象,然后可以通过pool.Get()和pool.Put()获取和放回对象.一系列临时对象的对象池</p>\n<p>关键结构体如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Pool struct &#123;</span><br><span class=\"line\">\tnoCopy noCopy</span><br><span class=\"line\"></span><br><span class=\"line\">\tlocal     unsafe.Pointer  </span><br><span class=\"line\">\tlocalSize uintptr        </span><br><span class=\"line\">\tNew func() interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>local可以理解为指向一个poolLocal数组,大小由localSize指定(localSize由cpu cores决定).<br>New指定一个函数,用来创建Pool中的对象</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type poolLocal struct &#123;</span><br><span class=\"line\">\tpoolLocalInternal</span><br><span class=\"line\">\tpad [128 - unsafe.Sizeof(poolLocalInternal&#123;&#125;)%128]byte</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">type poolLocalInternal struct &#123;</span><br><span class=\"line\">\tprivate interface&#123;&#125;   // Can be used only by the respective P.</span><br><span class=\"line\">\tshared  []interface&#123;&#125; // Can be used by any P.</span><br><span class=\"line\">\tMutex                 // Protects shared.</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>poolLocal中关键的字段为private和shared,private保存只能由相应的P(go调度器中概念,P/M/G)使用的对象.shared中保存可以由所有的P共同使用的对象</p>\n<p>我们看一下Put的代码<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) Put(x interface&#123;&#125;) &#123;</span><br><span class=\"line\">\tif x == nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tl := p.pin()</span><br><span class=\"line\">\tif l.private == nil &#123;</span><br><span class=\"line\">\t\tl.private = x</span><br><span class=\"line\">\t\tx = nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tif x != nil &#123;</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tl.shared = append(l.shared, x)</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>关键路径为首先将要放回的对象放入poolLocal中的private,否则放入共享的shared结构.</p>\n<p>看一下Get()的代码路径<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) Get() interface&#123;&#125; &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tl := p.pin()</span><br><span class=\"line\">\tx := l.private</span><br><span class=\"line\">\tl.private = nil</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tif x == nil &#123;</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tlast := len(l.shared) - 1</span><br><span class=\"line\">\t\tif last &gt;= 0 &#123;</span><br><span class=\"line\">\t\t\tx = l.shared[last]</span><br><span class=\"line\">\t\t\tl.shared = l.shared[:last]</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t\tif x == nil &#123;</span><br><span class=\"line\">\t\t\tx = p.getSlow()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tif x == nil &amp;&amp; p.New != nil &#123;</span><br><span class=\"line\">\t\tx = p.New()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn x</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>首先从poolLocal的private中获取,如果未获取到则获取shared的最后一个元素,否则调用getSlow函数.<br>依然获取不到的话调用pool结构中的New函数生成.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *Pool) getSlow() (x interface&#123;&#125;) &#123;</span><br><span class=\"line\">\tsize := atomic.LoadUintptr(&amp;p.localSize) // load-acquire</span><br><span class=\"line\">\tlocal := p.local                         // load-consume</span><br><span class=\"line\">\tpid := runtime_procPin()</span><br><span class=\"line\">\truntime_procUnpin()</span><br><span class=\"line\">\tfor i := 0; i &lt; int(size); i++ &#123;</span><br><span class=\"line\">\t\tl := indexLocal(local, (pid+i+1)%int(size))</span><br><span class=\"line\">\t\tl.Lock()</span><br><span class=\"line\">\t\tlast := len(l.shared) - 1</span><br><span class=\"line\">\t\tif last &gt;= 0 &#123;</span><br><span class=\"line\">\t\t\tx = l.shared[last]</span><br><span class=\"line\">\t\t\tl.shared = l.shared[:last]</span><br><span class=\"line\">\t\t\tl.Unlock()</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tl.Unlock()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn x</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>getSlow函数会从当前P的下一个P开始依次遍历其他poolLocal中的shared结构去获取对象.</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li>runtime_procPin()会返回当前P的pid,需要了解go scheduler相关知识加深理解</li>\n<li>pool中会注册一个runtime_registerPoolCleanup(poolCleanup),与Go GC相关,需了解go GC相关知识</li>\n</ul>\n<h2 id=\"sync-Cond包\"><a href=\"#sync-Cond包\" class=\"headerlink\" title=\"sync.Cond包\"></a>sync.Cond包</h2><p>条件变量,控制goroutine间的同步位点<br>通过NewCond生成一个Cond,调用cond.Wait()之后阻塞,其他goroutine调用cond.Signal()或者cond.Broadcast()唤醒wait的一个或者全部goroutine</p>\n<h3 id=\"一个示例-1\"><a href=\"#一个示例-1\" class=\"headerlink\" title=\"一个示例\"></a>一个示例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c.L.Lock()</span><br><span class=\"line\">for !condition() &#123;</span><br><span class=\"line\">    c.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">... make use of condition ...</span><br><span class=\"line\">c.L.Unlock()</span><br></pre></td></tr></table></figure>\n<p>一个goroutine中要执行Wait之前,首先将cond中的c.L.Lock()</p>\n<h3 id=\"关键结构体和方法\"><a href=\"#关键结构体和方法\" class=\"headerlink\" title=\"关键结构体和方法\"></a>关键结构体和方法</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Cond struct &#123;</span><br><span class=\"line\">\tnoCopy noCopy</span><br><span class=\"line\">\t// L is held while observing or changing the condition</span><br><span class=\"line\">\tL Locker</span><br><span class=\"line\">\tnotify  notifyList</span><br><span class=\"line\">\tchecker copyChecker</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewCond(l Locker) *Cond &#123;</span><br><span class=\"line\">\treturn &amp;Cond&#123;L: l&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>调用NewCond需要传入一个实现了Locker接口的结构</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *Cond) Wait() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\tt := runtime_notifyListAdd(&amp;c.notify)</span><br><span class=\"line\">\tc.L.Unlock()</span><br><span class=\"line\">\truntime_notifyListWait(&amp;c.notify, t)</span><br><span class=\"line\">\tc.L.Lock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Wait函数首先调用runtime将c.notify加入notifyList,然后解锁,然后等待.当条件变量满足后首先获取锁后Wait才会返回</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">func (c *Cond) Signal() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\truntime_notifyListNotifyOne(&amp;c.notify)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Signal()函数唤醒一个在等待的goroutine</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *Cond) Broadcast() &#123;</span><br><span class=\"line\">\tc.checker.check()</span><br><span class=\"line\">\truntime_notifyListNotifyAll(&amp;c.notify)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Broadcast唤醒全部等待的goroutine</p>\n<h3 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题\"></a>问题</h3><ul>\n<li>进一步的实现依赖于runtime,需要熟悉runtime</li>\n</ul>\n"},{"title":"go context包源码分析","date":"2019-05-18T16:00:00.000Z","_content":">go的context包可以用来实现goroutine间的数据同步或控制goroutine的生命周期\n\n## 最佳实践\n* Context最好显式的作为函数的第一个参数进行传递,而非保存在一个结构体中\n* 不要传递一个nil的context,如果不知道需要使用哪种context,传递context.TODO\n* 使用context Values保存请求级别的数据而不是用来传递函数的参数\n* WithCancel,WithDeadline,WithTimeout接收一个parent context并且返回一个衍生出的child context和一个CancelFunc.调用CancelFunc之后会取消child context和child context对应的children,并且删除掉parent context对child context的引用,停止相关连的timers.\n\n## 代码分析\n\n### WithCancel\n\n关键结构体:\n```\ntype Context interface {\n\tDeadline() (deadline time.Time, ok bool)\n\tDone() <-chan struct{}\n\tErr() error\n\tValue(key interface{}) interface{}\n}\n\ntype canceler interface {\n\tcancel(removeFromParent bool, err error)\n\tDone() <-chan struct{}\n}\n\ntype cancelCtx struct { \n\tContext\n\n\tmu       sync.Mutex            // protects following fields\n\tdone     chan struct{}         // created lazily, closed by first cancel call\n\tchildren map[canceler]struct{} // set to nil by the first cancel call\n\terr      error                 // set to non-nil by the first cancel call\n}\n```\ncancelCtx中children字段保存context的父子关系.WithCancel函数创建子context以及cancel函数.当创建子context或者取消一个context的时候会相应的建立和使用children字段.下文对应的函数中详述.\n                 \n首先看一下WithCancel()函数:\n```\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) {\n\tc := newCancelCtx(parent)\n\tpropagateCancel(parent, &c)\n\treturn &c, func() { c.cancel(true, Canceled) }\n}\n```\n首先将cancelCtx中的Context匿名字段赋值为parent,然后在cancelCtx的children字段中建立父子关系.最后返回cancelCtx,以及一个CancelFunc,CancelFunc可以看到调用时会执行cancelCtx的cancel函数.我们看看cancel函数\n\n```\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) {\n\t...\n\tc.err = err\n\tif c.done == nil {\n\t\tc.done = closedchan\n\t} else {\n\t\tclose(c.done)\n\t}\n\tfor child := range c.children {\n\t\t// NOTE: acquiring the child's lock while holding parent's lock.\n\t\tchild.cancel(false, err)\n\t}\n\t...\n}\n```\ncancel函数中比较关键的有三个部分:\n* 将c.err字段赋值为err\n* close(c.done),即将cancelCtx中的done channel关闭\n* 遍历c.children,依次执行cancel函数,即父context cancel之后,所有的子context也会依次cancel.\n\n而Context接口中的Done和Err函数在cancelCtx中实现如下:\n```\nfunc (c *cancelCtx) Done() <-chan struct{} {\n\tc.mu.Lock()\n\tif c.done == nil {\n\t\tc.done = make(chan struct{})\n\t}\n\td := c.done\n\tc.mu.Unlock()\n\treturn d\n}\n\nfunc (c *cancelCtx) Err() error {\n\tc.mu.Lock()\n\terr := c.err\n\tc.mu.Unlock()\n\treturn err\n}\n```\n很简单,Done函数获取cancelCtx结构中的done字段,Err()函数获取cancelCtx中的err字段.二者都是在cancel()函数调用时进行的关闭与赋值.\n\n通过WithCancel建立cancelCtx之后通过在goroutine中检测ctx.Done()函数,当上层cancel之后该会关闭该管道,此时goroutine可以退出\n\n### WithDeadline\n\n```\n\ntype timerCtx struct {\n\tcancelCtx\n\ttimer *time.Timer // Under cancelCtx.mu.\n\n\tdeadline time.Time\n}\n```\nWithDeadline函数返回一个timerCtx和timerCtx定义的cancel()函数\n\n```\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {\n\tif cur, ok := parent.Deadline(); ok && cur.Before(d) {\n\t\treturn WithCancel(parent)\n\t}\n\tc := &timerCtx{\n\t\tcancelCtx: newCancelCtx(parent),\n\t\tdeadline:  d,\n\t}\n\tpropagateCancel(parent, c)\n\tdur := time.Until(d)\n\tif dur <= 0 {\n\t\tc.cancel(true, DeadlineExceeded) // deadline has already passed\n\t\treturn c, func() { c.cancel(true, Canceled) }\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif c.err == nil {\n\t\tc.timer = time.AfterFunc(dur, func() {\n\t\t\tc.cancel(true, DeadlineExceeded)\n\t\t})\n\t}\n\treturn c, func() { c.cancel(true, Canceled) }\n}\n```\nWithDeadline()做了如下几个判断:\n* 如果parent context已经是一个timerCtx,并且deadline早于现在要设置的deadline,则不再设置定时器,直接调用WithCancel()并返回\n* 如果deadline小于当前时间,直接取消后返回\n* 否则设置一个定时器然后返回\n\n```\nfunc (c *timerCtx) cancel(removeFromParent bool, err error) {\n\tc.cancelCtx.cancel(false, err)\n\tif removeFromParent {\n\t\t// Remove this timerCtx from its parent cancelCtx's children.\n\t\tremoveChild(c.cancelCtx.Context, c)\n\t}\n\tc.mu.Lock()\n\tif c.timer != nil {\n\t\tc.timer.Stop()\n\t\tc.timer = nil\n\t}\n\tc.mu.Unlock()\n}\n```\ntimerCtx的cancel()函数多了一个停止定时器的步骤\n\n### WithTimeout\nWithTimeout函数很简单,将当前时间加timeout即可转换为WithDeadline函数\n```\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {\n\treturn WithDeadline(parent, time.Now().Add(timeout))\n}\n```\n\n### WithValue\n\n```\ntype valueCtx struct {\n\tContext\n\tkey, val interface{}\n}\n```\nWithValue返回的是一个valueCtx结构体,除了Context匿名字段之外,包括了一个key和val字段,二者都是接口类型\n\n```\nfunc WithValue(parent Context, key, val interface{}) Context {\n\tif key == nil {\n\t\tpanic(\"nil key\")\n\t}\n\tif !reflect.TypeOf(key).Comparable() {\n\t\tpanic(\"key is not comparable\")\n\t}\n\treturn &valueCtx{parent, key, val}\n}\n```\nWithValue函数返回一个valueCtx\n```\nfunc (c *valueCtx) Value(key interface{}) interface{} {\n\tif c.key == key {\n\t\treturn c.val\n\t}\n\treturn c.Context.Value(key)\n}\n\n```\nValue函数通过key获取相应的值,会逐层依次寻找","source":"_posts/go-context.md","raw":"---\ntitle: go context包源码分析\ndate: 2019-05-19\ntags: go\n---\n>go的context包可以用来实现goroutine间的数据同步或控制goroutine的生命周期\n\n## 最佳实践\n* Context最好显式的作为函数的第一个参数进行传递,而非保存在一个结构体中\n* 不要传递一个nil的context,如果不知道需要使用哪种context,传递context.TODO\n* 使用context Values保存请求级别的数据而不是用来传递函数的参数\n* WithCancel,WithDeadline,WithTimeout接收一个parent context并且返回一个衍生出的child context和一个CancelFunc.调用CancelFunc之后会取消child context和child context对应的children,并且删除掉parent context对child context的引用,停止相关连的timers.\n\n## 代码分析\n\n### WithCancel\n\n关键结构体:\n```\ntype Context interface {\n\tDeadline() (deadline time.Time, ok bool)\n\tDone() <-chan struct{}\n\tErr() error\n\tValue(key interface{}) interface{}\n}\n\ntype canceler interface {\n\tcancel(removeFromParent bool, err error)\n\tDone() <-chan struct{}\n}\n\ntype cancelCtx struct { \n\tContext\n\n\tmu       sync.Mutex            // protects following fields\n\tdone     chan struct{}         // created lazily, closed by first cancel call\n\tchildren map[canceler]struct{} // set to nil by the first cancel call\n\terr      error                 // set to non-nil by the first cancel call\n}\n```\ncancelCtx中children字段保存context的父子关系.WithCancel函数创建子context以及cancel函数.当创建子context或者取消一个context的时候会相应的建立和使用children字段.下文对应的函数中详述.\n                 \n首先看一下WithCancel()函数:\n```\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) {\n\tc := newCancelCtx(parent)\n\tpropagateCancel(parent, &c)\n\treturn &c, func() { c.cancel(true, Canceled) }\n}\n```\n首先将cancelCtx中的Context匿名字段赋值为parent,然后在cancelCtx的children字段中建立父子关系.最后返回cancelCtx,以及一个CancelFunc,CancelFunc可以看到调用时会执行cancelCtx的cancel函数.我们看看cancel函数\n\n```\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) {\n\t...\n\tc.err = err\n\tif c.done == nil {\n\t\tc.done = closedchan\n\t} else {\n\t\tclose(c.done)\n\t}\n\tfor child := range c.children {\n\t\t// NOTE: acquiring the child's lock while holding parent's lock.\n\t\tchild.cancel(false, err)\n\t}\n\t...\n}\n```\ncancel函数中比较关键的有三个部分:\n* 将c.err字段赋值为err\n* close(c.done),即将cancelCtx中的done channel关闭\n* 遍历c.children,依次执行cancel函数,即父context cancel之后,所有的子context也会依次cancel.\n\n而Context接口中的Done和Err函数在cancelCtx中实现如下:\n```\nfunc (c *cancelCtx) Done() <-chan struct{} {\n\tc.mu.Lock()\n\tif c.done == nil {\n\t\tc.done = make(chan struct{})\n\t}\n\td := c.done\n\tc.mu.Unlock()\n\treturn d\n}\n\nfunc (c *cancelCtx) Err() error {\n\tc.mu.Lock()\n\terr := c.err\n\tc.mu.Unlock()\n\treturn err\n}\n```\n很简单,Done函数获取cancelCtx结构中的done字段,Err()函数获取cancelCtx中的err字段.二者都是在cancel()函数调用时进行的关闭与赋值.\n\n通过WithCancel建立cancelCtx之后通过在goroutine中检测ctx.Done()函数,当上层cancel之后该会关闭该管道,此时goroutine可以退出\n\n### WithDeadline\n\n```\n\ntype timerCtx struct {\n\tcancelCtx\n\ttimer *time.Timer // Under cancelCtx.mu.\n\n\tdeadline time.Time\n}\n```\nWithDeadline函数返回一个timerCtx和timerCtx定义的cancel()函数\n\n```\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {\n\tif cur, ok := parent.Deadline(); ok && cur.Before(d) {\n\t\treturn WithCancel(parent)\n\t}\n\tc := &timerCtx{\n\t\tcancelCtx: newCancelCtx(parent),\n\t\tdeadline:  d,\n\t}\n\tpropagateCancel(parent, c)\n\tdur := time.Until(d)\n\tif dur <= 0 {\n\t\tc.cancel(true, DeadlineExceeded) // deadline has already passed\n\t\treturn c, func() { c.cancel(true, Canceled) }\n\t}\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif c.err == nil {\n\t\tc.timer = time.AfterFunc(dur, func() {\n\t\t\tc.cancel(true, DeadlineExceeded)\n\t\t})\n\t}\n\treturn c, func() { c.cancel(true, Canceled) }\n}\n```\nWithDeadline()做了如下几个判断:\n* 如果parent context已经是一个timerCtx,并且deadline早于现在要设置的deadline,则不再设置定时器,直接调用WithCancel()并返回\n* 如果deadline小于当前时间,直接取消后返回\n* 否则设置一个定时器然后返回\n\n```\nfunc (c *timerCtx) cancel(removeFromParent bool, err error) {\n\tc.cancelCtx.cancel(false, err)\n\tif removeFromParent {\n\t\t// Remove this timerCtx from its parent cancelCtx's children.\n\t\tremoveChild(c.cancelCtx.Context, c)\n\t}\n\tc.mu.Lock()\n\tif c.timer != nil {\n\t\tc.timer.Stop()\n\t\tc.timer = nil\n\t}\n\tc.mu.Unlock()\n}\n```\ntimerCtx的cancel()函数多了一个停止定时器的步骤\n\n### WithTimeout\nWithTimeout函数很简单,将当前时间加timeout即可转换为WithDeadline函数\n```\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {\n\treturn WithDeadline(parent, time.Now().Add(timeout))\n}\n```\n\n### WithValue\n\n```\ntype valueCtx struct {\n\tContext\n\tkey, val interface{}\n}\n```\nWithValue返回的是一个valueCtx结构体,除了Context匿名字段之外,包括了一个key和val字段,二者都是接口类型\n\n```\nfunc WithValue(parent Context, key, val interface{}) Context {\n\tif key == nil {\n\t\tpanic(\"nil key\")\n\t}\n\tif !reflect.TypeOf(key).Comparable() {\n\t\tpanic(\"key is not comparable\")\n\t}\n\treturn &valueCtx{parent, key, val}\n}\n```\nWithValue函数返回一个valueCtx\n```\nfunc (c *valueCtx) Value(key interface{}) interface{} {\n\tif c.key == key {\n\t\treturn c.val\n\t}\n\treturn c.Context.Value(key)\n}\n\n```\nValue函数通过key获取相应的值,会逐层依次寻找","slug":"go-context","published":1,"updated":"2019-05-19T03:23:50.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9u000qbms6cvqhjc3c","content":"<blockquote>\n<p>go的context包可以用来实现goroutine间的数据同步或控制goroutine的生命周期</p>\n</blockquote>\n<h2 id=\"最佳实践\"><a href=\"#最佳实践\" class=\"headerlink\" title=\"最佳实践\"></a>最佳实践</h2><ul>\n<li>Context最好显式的作为函数的第一个参数进行传递,而非保存在一个结构体中</li>\n<li>不要传递一个nil的context,如果不知道需要使用哪种context,传递context.TODO</li>\n<li>使用context Values保存请求级别的数据而不是用来传递函数的参数</li>\n<li>WithCancel,WithDeadline,WithTimeout接收一个parent context并且返回一个衍生出的child context和一个CancelFunc.调用CancelFunc之后会取消child context和child context对应的children,并且删除掉parent context对child context的引用,停止相关连的timers.</li>\n</ul>\n<h2 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h2><h3 id=\"WithCancel\"><a href=\"#WithCancel\" class=\"headerlink\" title=\"WithCancel\"></a>WithCancel</h3><p>关键结构体:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Context interface &#123;</span><br><span class=\"line\">\tDeadline() (deadline time.Time, ok bool)</span><br><span class=\"line\">\tDone() &lt;-chan struct&#123;&#125;</span><br><span class=\"line\">\tErr() error</span><br><span class=\"line\">\tValue(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type canceler interface &#123;</span><br><span class=\"line\">\tcancel(removeFromParent bool, err error)</span><br><span class=\"line\">\tDone() &lt;-chan struct&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type cancelCtx struct &#123; </span><br><span class=\"line\">\tContext</span><br><span class=\"line\"></span><br><span class=\"line\">\tmu       sync.Mutex            // protects following fields</span><br><span class=\"line\">\tdone     chan struct&#123;&#125;         // created lazily, closed by first cancel call</span><br><span class=\"line\">\tchildren map[canceler]struct&#123;&#125; // set to nil by the first cancel call</span><br><span class=\"line\">\terr      error                 // set to non-nil by the first cancel call</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>cancelCtx中children字段保存context的父子关系.WithCancel函数创建子context以及cancel函数.当创建子context或者取消一个context的时候会相应的建立和使用children字段.下文对应的函数中详述.</p>\n<p>首先看一下WithCancel()函数:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123;</span><br><span class=\"line\">\tc := newCancelCtx(parent)</span><br><span class=\"line\">\tpropagateCancel(parent, &amp;c)</span><br><span class=\"line\">\treturn &amp;c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>首先将cancelCtx中的Context匿名字段赋值为parent,然后在cancelCtx的children字段中建立父子关系.最后返回cancelCtx,以及一个CancelFunc,CancelFunc可以看到调用时会执行cancelCtx的cancel函数.我们看看cancel函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tc.err = err</span><br><span class=\"line\">\tif c.done == nil &#123;</span><br><span class=\"line\">\t\tc.done = closedchan</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tclose(c.done)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor child := range c.children &#123;</span><br><span class=\"line\">\t\t// NOTE: acquiring the child&apos;s lock while holding parent&apos;s lock.</span><br><span class=\"line\">\t\tchild.cancel(false, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>cancel函数中比较关键的有三个部分:</p>\n<ul>\n<li>将c.err字段赋值为err</li>\n<li>close(c.done),即将cancelCtx中的done channel关闭</li>\n<li>遍历c.children,依次执行cancel函数,即父context cancel之后,所有的子context也会依次cancel.</li>\n</ul>\n<p>而Context接口中的Done和Err函数在cancelCtx中实现如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tif c.done == nil &#123;</span><br><span class=\"line\">\t\tc.done = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\td := c.done</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">\treturn d</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (c *cancelCtx) Err() error &#123;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\terr := c.err</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">\treturn err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>很简单,Done函数获取cancelCtx结构中的done字段,Err()函数获取cancelCtx中的err字段.二者都是在cancel()函数调用时进行的关闭与赋值.</p>\n<p>通过WithCancel建立cancelCtx之后通过在goroutine中检测ctx.Done()函数,当上层cancel之后该会关闭该管道,此时goroutine可以退出</p>\n<h3 id=\"WithDeadline\"><a href=\"#WithDeadline\" class=\"headerlink\" title=\"WithDeadline\"></a>WithDeadline</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">type timerCtx struct &#123;</span><br><span class=\"line\">\tcancelCtx</span><br><span class=\"line\">\ttimer *time.Timer // Under cancelCtx.mu.</span><br><span class=\"line\"></span><br><span class=\"line\">\tdeadline time.Time</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithDeadline函数返回一个timerCtx和timerCtx定义的cancel()函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123;</span><br><span class=\"line\">\tif cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;</span><br><span class=\"line\">\t\treturn WithCancel(parent)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc := &amp;timerCtx&#123;</span><br><span class=\"line\">\t\tcancelCtx: newCancelCtx(parent),</span><br><span class=\"line\">\t\tdeadline:  d,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpropagateCancel(parent, c)</span><br><span class=\"line\">\tdur := time.Until(d)</span><br><span class=\"line\">\tif dur &lt;= 0 &#123;</span><br><span class=\"line\">\t\tc.cancel(true, DeadlineExceeded) // deadline has already passed</span><br><span class=\"line\">\t\treturn c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tdefer c.mu.Unlock()</span><br><span class=\"line\">\tif c.err == nil &#123;</span><br><span class=\"line\">\t\tc.timer = time.AfterFunc(dur, func() &#123;</span><br><span class=\"line\">\t\t\tc.cancel(true, DeadlineExceeded)</span><br><span class=\"line\">\t\t&#125;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithDeadline()做了如下几个判断:</p>\n<ul>\n<li>如果parent context已经是一个timerCtx,并且deadline早于现在要设置的deadline,则不再设置定时器,直接调用WithCancel()并返回</li>\n<li>如果deadline小于当前时间,直接取消后返回</li>\n<li>否则设置一个定时器然后返回</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *timerCtx) cancel(removeFromParent bool, err error) &#123;</span><br><span class=\"line\">\tc.cancelCtx.cancel(false, err)</span><br><span class=\"line\">\tif removeFromParent &#123;</span><br><span class=\"line\">\t\t// Remove this timerCtx from its parent cancelCtx&apos;s children.</span><br><span class=\"line\">\t\tremoveChild(c.cancelCtx.Context, c)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tif c.timer != nil &#123;</span><br><span class=\"line\">\t\tc.timer.Stop()</span><br><span class=\"line\">\t\tc.timer = nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>timerCtx的cancel()函数多了一个停止定时器的步骤</p>\n<h3 id=\"WithTimeout\"><a href=\"#WithTimeout\" class=\"headerlink\" title=\"WithTimeout\"></a>WithTimeout</h3><p>WithTimeout函数很简单,将当前时间加timeout即可转换为WithDeadline函数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123;</span><br><span class=\"line\">\treturn WithDeadline(parent, time.Now().Add(timeout))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"WithValue\"><a href=\"#WithValue\" class=\"headerlink\" title=\"WithValue\"></a>WithValue</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type valueCtx struct &#123;</span><br><span class=\"line\">\tContext</span><br><span class=\"line\">\tkey, val interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithValue返回的是一个valueCtx结构体,除了Context匿名字段之外,包括了一个key和val字段,二者都是接口类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123;</span><br><span class=\"line\">\tif key == nil &#123;</span><br><span class=\"line\">\t\tpanic(&quot;nil key&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif !reflect.TypeOf(key).Comparable() &#123;</span><br><span class=\"line\">\t\tpanic(&quot;key is not comparable&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithValue函数返回一个valueCtx<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;</span><br><span class=\"line\">\tif c.key == key &#123;</span><br><span class=\"line\">\t\treturn c.val</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn c.Context.Value(key)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Value函数通过key获取相应的值,会逐层依次寻找</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>go的context包可以用来实现goroutine间的数据同步或控制goroutine的生命周期</p>\n</blockquote>\n<h2 id=\"最佳实践\"><a href=\"#最佳实践\" class=\"headerlink\" title=\"最佳实践\"></a>最佳实践</h2><ul>\n<li>Context最好显式的作为函数的第一个参数进行传递,而非保存在一个结构体中</li>\n<li>不要传递一个nil的context,如果不知道需要使用哪种context,传递context.TODO</li>\n<li>使用context Values保存请求级别的数据而不是用来传递函数的参数</li>\n<li>WithCancel,WithDeadline,WithTimeout接收一个parent context并且返回一个衍生出的child context和一个CancelFunc.调用CancelFunc之后会取消child context和child context对应的children,并且删除掉parent context对child context的引用,停止相关连的timers.</li>\n</ul>\n<h2 id=\"代码分析\"><a href=\"#代码分析\" class=\"headerlink\" title=\"代码分析\"></a>代码分析</h2><h3 id=\"WithCancel\"><a href=\"#WithCancel\" class=\"headerlink\" title=\"WithCancel\"></a>WithCancel</h3><p>关键结构体:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Context interface &#123;</span><br><span class=\"line\">\tDeadline() (deadline time.Time, ok bool)</span><br><span class=\"line\">\tDone() &lt;-chan struct&#123;&#125;</span><br><span class=\"line\">\tErr() error</span><br><span class=\"line\">\tValue(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type canceler interface &#123;</span><br><span class=\"line\">\tcancel(removeFromParent bool, err error)</span><br><span class=\"line\">\tDone() &lt;-chan struct&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type cancelCtx struct &#123; </span><br><span class=\"line\">\tContext</span><br><span class=\"line\"></span><br><span class=\"line\">\tmu       sync.Mutex            // protects following fields</span><br><span class=\"line\">\tdone     chan struct&#123;&#125;         // created lazily, closed by first cancel call</span><br><span class=\"line\">\tchildren map[canceler]struct&#123;&#125; // set to nil by the first cancel call</span><br><span class=\"line\">\terr      error                 // set to non-nil by the first cancel call</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>cancelCtx中children字段保存context的父子关系.WithCancel函数创建子context以及cancel函数.当创建子context或者取消一个context的时候会相应的建立和使用children字段.下文对应的函数中详述.</p>\n<p>首先看一下WithCancel()函数:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123;</span><br><span class=\"line\">\tc := newCancelCtx(parent)</span><br><span class=\"line\">\tpropagateCancel(parent, &amp;c)</span><br><span class=\"line\">\treturn &amp;c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>首先将cancelCtx中的Context匿名字段赋值为parent,然后在cancelCtx的children字段中建立父子关系.最后返回cancelCtx,以及一个CancelFunc,CancelFunc可以看到调用时会执行cancelCtx的cancel函数.我们看看cancel函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tc.err = err</span><br><span class=\"line\">\tif c.done == nil &#123;</span><br><span class=\"line\">\t\tc.done = closedchan</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tclose(c.done)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor child := range c.children &#123;</span><br><span class=\"line\">\t\t// NOTE: acquiring the child&apos;s lock while holding parent&apos;s lock.</span><br><span class=\"line\">\t\tchild.cancel(false, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>cancel函数中比较关键的有三个部分:</p>\n<ul>\n<li>将c.err字段赋值为err</li>\n<li>close(c.done),即将cancelCtx中的done channel关闭</li>\n<li>遍历c.children,依次执行cancel函数,即父context cancel之后,所有的子context也会依次cancel.</li>\n</ul>\n<p>而Context接口中的Done和Err函数在cancelCtx中实现如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tif c.done == nil &#123;</span><br><span class=\"line\">\t\tc.done = make(chan struct&#123;&#125;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\td := c.done</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">\treturn d</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (c *cancelCtx) Err() error &#123;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\terr := c.err</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">\treturn err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>很简单,Done函数获取cancelCtx结构中的done字段,Err()函数获取cancelCtx中的err字段.二者都是在cancel()函数调用时进行的关闭与赋值.</p>\n<p>通过WithCancel建立cancelCtx之后通过在goroutine中检测ctx.Done()函数,当上层cancel之后该会关闭该管道,此时goroutine可以退出</p>\n<h3 id=\"WithDeadline\"><a href=\"#WithDeadline\" class=\"headerlink\" title=\"WithDeadline\"></a>WithDeadline</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">type timerCtx struct &#123;</span><br><span class=\"line\">\tcancelCtx</span><br><span class=\"line\">\ttimer *time.Timer // Under cancelCtx.mu.</span><br><span class=\"line\"></span><br><span class=\"line\">\tdeadline time.Time</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithDeadline函数返回一个timerCtx和timerCtx定义的cancel()函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123;</span><br><span class=\"line\">\tif cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;</span><br><span class=\"line\">\t\treturn WithCancel(parent)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc := &amp;timerCtx&#123;</span><br><span class=\"line\">\t\tcancelCtx: newCancelCtx(parent),</span><br><span class=\"line\">\t\tdeadline:  d,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpropagateCancel(parent, c)</span><br><span class=\"line\">\tdur := time.Until(d)</span><br><span class=\"line\">\tif dur &lt;= 0 &#123;</span><br><span class=\"line\">\t\tc.cancel(true, DeadlineExceeded) // deadline has already passed</span><br><span class=\"line\">\t\treturn c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tdefer c.mu.Unlock()</span><br><span class=\"line\">\tif c.err == nil &#123;</span><br><span class=\"line\">\t\tc.timer = time.AfterFunc(dur, func() &#123;</span><br><span class=\"line\">\t\t\tc.cancel(true, DeadlineExceeded)</span><br><span class=\"line\">\t\t&#125;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn c, func() &#123; c.cancel(true, Canceled) &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithDeadline()做了如下几个判断:</p>\n<ul>\n<li>如果parent context已经是一个timerCtx,并且deadline早于现在要设置的deadline,则不再设置定时器,直接调用WithCancel()并返回</li>\n<li>如果deadline小于当前时间,直接取消后返回</li>\n<li>否则设置一个定时器然后返回</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *timerCtx) cancel(removeFromParent bool, err error) &#123;</span><br><span class=\"line\">\tc.cancelCtx.cancel(false, err)</span><br><span class=\"line\">\tif removeFromParent &#123;</span><br><span class=\"line\">\t\t// Remove this timerCtx from its parent cancelCtx&apos;s children.</span><br><span class=\"line\">\t\tremoveChild(c.cancelCtx.Context, c)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Lock()</span><br><span class=\"line\">\tif c.timer != nil &#123;</span><br><span class=\"line\">\t\tc.timer.Stop()</span><br><span class=\"line\">\t\tc.timer = nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tc.mu.Unlock()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>timerCtx的cancel()函数多了一个停止定时器的步骤</p>\n<h3 id=\"WithTimeout\"><a href=\"#WithTimeout\" class=\"headerlink\" title=\"WithTimeout\"></a>WithTimeout</h3><p>WithTimeout函数很简单,将当前时间加timeout即可转换为WithDeadline函数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123;</span><br><span class=\"line\">\treturn WithDeadline(parent, time.Now().Add(timeout))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"WithValue\"><a href=\"#WithValue\" class=\"headerlink\" title=\"WithValue\"></a>WithValue</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type valueCtx struct &#123;</span><br><span class=\"line\">\tContext</span><br><span class=\"line\">\tkey, val interface&#123;&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithValue返回的是一个valueCtx结构体,除了Context匿名字段之外,包括了一个key和val字段,二者都是接口类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123;</span><br><span class=\"line\">\tif key == nil &#123;</span><br><span class=\"line\">\t\tpanic(&quot;nil key&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif !reflect.TypeOf(key).Comparable() &#123;</span><br><span class=\"line\">\t\tpanic(&quot;key is not comparable&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>WithValue函数返回一个valueCtx<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;</span><br><span class=\"line\">\tif c.key == key &#123;</span><br><span class=\"line\">\t\treturn c.val</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn c.Context.Value(key)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Value函数通过key获取相应的值,会逐层依次寻找</p>\n"},{"title":"如何设计一个高效的rpc监控系统","date":"2019-05-16T16:00:00.000Z","_content":"\n>本文主要关注两点,一为分布式追踪系统的监控设计,一为分布式调用指标的采集.主要思路来源于google dapper与statsd.\n\n## dapper:大规模分布式追踪系统基础架构\n* traceId:一次请求的唯一标识,通过traceid可以将该请求所有的调用串联起来\n* spanId:我们需要知道调用方与被调用方,因此需要spanId来区分.每个调用方生成自己的spanId,传递给被调用方,被调用方将该spanId作为自己的parentId.\n* 通过traceId与spanId(parentId)可以将调用关系生成一颗树,其中根节点的parentId为null.\n\n实际生产中需要考虑如下问题:\n* traceId与spanId的生成.需要高效并且唯一\n* 对应用透明\n* 开销要小\n\n采集和汇总工具:\ndapper会将traceId,spanId(parentId)打印到日志中,通过一个采集器采集上报,放到一个bigtable中汇总分析.\n\n## statsd:简单但强大的指标聚合工具\n\n在<<如何设计一个高并发的日志系统>>一文中,我们提到可以通过udp将日志输出.这种方式还有一个好处是,udp server可以实现一些逻辑,做一些汇总统计的工作.\n\nstatsd就是通过这种方式进行数据采集.statsd主要是进行应用层面的数据采集,应用层每次进行rpc调用时可以通过一个简单的协议将调用结果或者调用延时通过udp发送到statsd,statsd统计汇总之后上报展示.\n\nstatsd在一个周期范围内(10-60s,可配置)统计两类指标,每次周期结束后将统计清零然后重新开始下一个周期\n\n* 计数:例如20s内该rpc调用共执行了多少次,失败多少次\n* 计时:例如20s内该rpc调用每次耗时的99分位,50分位,最低最高值\n\n\n## 参考链接\n* http://code.flickr.net/2008/10/27/counting-timing/\n* https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf","source":"_posts/how-to-design-a-effective-rpc-monitor-system.md","raw":"---\ntitle: 如何设计一个高效的rpc监控系统\ndate: 2019-05-17\ntags: architecture\n---\n\n>本文主要关注两点,一为分布式追踪系统的监控设计,一为分布式调用指标的采集.主要思路来源于google dapper与statsd.\n\n## dapper:大规模分布式追踪系统基础架构\n* traceId:一次请求的唯一标识,通过traceid可以将该请求所有的调用串联起来\n* spanId:我们需要知道调用方与被调用方,因此需要spanId来区分.每个调用方生成自己的spanId,传递给被调用方,被调用方将该spanId作为自己的parentId.\n* 通过traceId与spanId(parentId)可以将调用关系生成一颗树,其中根节点的parentId为null.\n\n实际生产中需要考虑如下问题:\n* traceId与spanId的生成.需要高效并且唯一\n* 对应用透明\n* 开销要小\n\n采集和汇总工具:\ndapper会将traceId,spanId(parentId)打印到日志中,通过一个采集器采集上报,放到一个bigtable中汇总分析.\n\n## statsd:简单但强大的指标聚合工具\n\n在<<如何设计一个高并发的日志系统>>一文中,我们提到可以通过udp将日志输出.这种方式还有一个好处是,udp server可以实现一些逻辑,做一些汇总统计的工作.\n\nstatsd就是通过这种方式进行数据采集.statsd主要是进行应用层面的数据采集,应用层每次进行rpc调用时可以通过一个简单的协议将调用结果或者调用延时通过udp发送到statsd,statsd统计汇总之后上报展示.\n\nstatsd在一个周期范围内(10-60s,可配置)统计两类指标,每次周期结束后将统计清零然后重新开始下一个周期\n\n* 计数:例如20s内该rpc调用共执行了多少次,失败多少次\n* 计时:例如20s内该rpc调用每次耗时的99分位,50分位,最低最高值\n\n\n## 参考链接\n* http://code.flickr.net/2008/10/27/counting-timing/\n* https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf","slug":"how-to-design-a-effective-rpc-monitor-system","published":1,"updated":"2019-05-17T09:04:40.541Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9v000sbms694zro3ah","content":"<blockquote>\n<p>本文主要关注两点,一为分布式追踪系统的监控设计,一为分布式调用指标的采集.主要思路来源于google dapper与statsd.</p>\n</blockquote>\n<h2 id=\"dapper-大规模分布式追踪系统基础架构\"><a href=\"#dapper-大规模分布式追踪系统基础架构\" class=\"headerlink\" title=\"dapper:大规模分布式追踪系统基础架构\"></a>dapper:大规模分布式追踪系统基础架构</h2><ul>\n<li>traceId:一次请求的唯一标识,通过traceid可以将该请求所有的调用串联起来</li>\n<li>spanId:我们需要知道调用方与被调用方,因此需要spanId来区分.每个调用方生成自己的spanId,传递给被调用方,被调用方将该spanId作为自己的parentId.</li>\n<li>通过traceId与spanId(parentId)可以将调用关系生成一颗树,其中根节点的parentId为null.</li>\n</ul>\n<p>实际生产中需要考虑如下问题:</p>\n<ul>\n<li>traceId与spanId的生成.需要高效并且唯一</li>\n<li>对应用透明</li>\n<li>开销要小</li>\n</ul>\n<p>采集和汇总工具:<br>dapper会将traceId,spanId(parentId)打印到日志中,通过一个采集器采集上报,放到一个bigtable中汇总分析.</p>\n<h2 id=\"statsd-简单但强大的指标聚合工具\"><a href=\"#statsd-简单但强大的指标聚合工具\" class=\"headerlink\" title=\"statsd:简单但强大的指标聚合工具\"></a>statsd:简单但强大的指标聚合工具</h2><p>在&lt;&lt;如何设计一个高并发的日志系统&gt;&gt;一文中,我们提到可以通过udp将日志输出.这种方式还有一个好处是,udp server可以实现一些逻辑,做一些汇总统计的工作.</p>\n<p>statsd就是通过这种方式进行数据采集.statsd主要是进行应用层面的数据采集,应用层每次进行rpc调用时可以通过一个简单的协议将调用结果或者调用延时通过udp发送到statsd,statsd统计汇总之后上报展示.</p>\n<p>statsd在一个周期范围内(10-60s,可配置)统计两类指标,每次周期结束后将统计清零然后重新开始下一个周期</p>\n<ul>\n<li>计数:例如20s内该rpc调用共执行了多少次,失败多少次</li>\n<li>计时:例如20s内该rpc调用每次耗时的99分位,50分位,最低最高值</li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"http://code.flickr.net/2008/10/27/counting-timing/\" target=\"_blank\" rel=\"noopener\">http://code.flickr.net/2008/10/27/counting-timing/</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf\" target=\"_blank\" rel=\"noopener\">https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文主要关注两点,一为分布式追踪系统的监控设计,一为分布式调用指标的采集.主要思路来源于google dapper与statsd.</p>\n</blockquote>\n<h2 id=\"dapper-大规模分布式追踪系统基础架构\"><a href=\"#dapper-大规模分布式追踪系统基础架构\" class=\"headerlink\" title=\"dapper:大规模分布式追踪系统基础架构\"></a>dapper:大规模分布式追踪系统基础架构</h2><ul>\n<li>traceId:一次请求的唯一标识,通过traceid可以将该请求所有的调用串联起来</li>\n<li>spanId:我们需要知道调用方与被调用方,因此需要spanId来区分.每个调用方生成自己的spanId,传递给被调用方,被调用方将该spanId作为自己的parentId.</li>\n<li>通过traceId与spanId(parentId)可以将调用关系生成一颗树,其中根节点的parentId为null.</li>\n</ul>\n<p>实际生产中需要考虑如下问题:</p>\n<ul>\n<li>traceId与spanId的生成.需要高效并且唯一</li>\n<li>对应用透明</li>\n<li>开销要小</li>\n</ul>\n<p>采集和汇总工具:<br>dapper会将traceId,spanId(parentId)打印到日志中,通过一个采集器采集上报,放到一个bigtable中汇总分析.</p>\n<h2 id=\"statsd-简单但强大的指标聚合工具\"><a href=\"#statsd-简单但强大的指标聚合工具\" class=\"headerlink\" title=\"statsd:简单但强大的指标聚合工具\"></a>statsd:简单但强大的指标聚合工具</h2><p>在&lt;&lt;如何设计一个高并发的日志系统&gt;&gt;一文中,我们提到可以通过udp将日志输出.这种方式还有一个好处是,udp server可以实现一些逻辑,做一些汇总统计的工作.</p>\n<p>statsd就是通过这种方式进行数据采集.statsd主要是进行应用层面的数据采集,应用层每次进行rpc调用时可以通过一个简单的协议将调用结果或者调用延时通过udp发送到statsd,statsd统计汇总之后上报展示.</p>\n<p>statsd在一个周期范围内(10-60s,可配置)统计两类指标,每次周期结束后将统计清零然后重新开始下一个周期</p>\n<ul>\n<li>计数:例如20s内该rpc调用共执行了多少次,失败多少次</li>\n<li>计时:例如20s内该rpc调用每次耗时的99分位,50分位,最低最高值</li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"http://code.flickr.net/2008/10/27/counting-timing/\" target=\"_blank\" rel=\"noopener\">http://code.flickr.net/2008/10/27/counting-timing/</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf\" target=\"_blank\" rel=\"noopener\">https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/papers/dapper-2010-1.pdf</a></li>\n</ul>\n"},{"title":"如何设计一个并行、高可用、高并发的A/B实验系统","date":"2019-05-13T16:00:00.000Z","_content":"\n### A/B实验系统设计\n* 圈定人群或者流量\n圈定人群或者流量功能可以独立出来做灰度发布.人群可以根据白名单、号码包、uid、城市、时间或者自定义等维度做区分\n* 分组\n分组之后可以写两套代码分别部署于不同的IDC或者服务器,也可以在一套代码中根据分组走不同的逻辑.人群划分之后为了避免多因素影响A/B测试的准确性,一般分组根据流量划分,不可根据城市或者时间段等划分\n\n* 指标统计\n根据实验目的统计指标变化\n\n* 置信区间、显著度\n实验是否可信\n\n###  并行A/B系统设计要点\n\n假设线上同时运行成千上万组A/B实验,并且实验之间是各自独立的.为避免实验之间互相影响,有两种做法\n\n* 人群按实验组数划分,但会随着实验组数增加导致人群变少\n* 流量划分时在每个实验之间都随机划分, 例如A/B/C三个实验,每个实验分三组,例如A1/A2/A3,B1/B2/B3,C1/C2/C3,UID1-UID999 共999个用户,不能使UID1-UID333同时进入A1/B1/C1,此时B1的效果可能受A1影响,C1的效果也可能受A1/B1影响\n\n流量划分常见策略是根据uid进行hash后对bucket大小取余,因此为了避免并行实验互相影响,每一个实验hash时需要hash(uid,salt).其中每一个实验的salt需要不相同\n\n\n### 如何设计高可用\n\n需要配置两地三机房或者异地双活.当一个机房故障时可以切流到其他机房\n\n### 如何应对大并发\n\n以常见的zookeeper为例,如果每次请求配置都需要执行一次rpc调用,大并发情况下耗费时间是相当可观的.所以最好的策略是将配置下发到本地,通过本地读取.可以通过在机器上边部署client,定期或者触发式去拉取配置.此时client的高可用和监控也需要保证.例如通过supervised保活,监控系统进行监控.\n\n### sdk开发\n为了方便android/ios/服务端不同语言接入,需要开发sdk,增加接入的便捷度\n\n### 配置平台\n为了方便运营或者开发同学配置灰度发布或者A/B实验,需要增加一个配置平台,配置完毕后可以同步到配置系统","source":"_posts/how-to-design-ab-system.md","raw":"---\ntitle: 如何设计一个并行、高可用、高并发的A/B实验系统\ndate: 2019-05-14\ntags: architecture\n---\n\n### A/B实验系统设计\n* 圈定人群或者流量\n圈定人群或者流量功能可以独立出来做灰度发布.人群可以根据白名单、号码包、uid、城市、时间或者自定义等维度做区分\n* 分组\n分组之后可以写两套代码分别部署于不同的IDC或者服务器,也可以在一套代码中根据分组走不同的逻辑.人群划分之后为了避免多因素影响A/B测试的准确性,一般分组根据流量划分,不可根据城市或者时间段等划分\n\n* 指标统计\n根据实验目的统计指标变化\n\n* 置信区间、显著度\n实验是否可信\n\n###  并行A/B系统设计要点\n\n假设线上同时运行成千上万组A/B实验,并且实验之间是各自独立的.为避免实验之间互相影响,有两种做法\n\n* 人群按实验组数划分,但会随着实验组数增加导致人群变少\n* 流量划分时在每个实验之间都随机划分, 例如A/B/C三个实验,每个实验分三组,例如A1/A2/A3,B1/B2/B3,C1/C2/C3,UID1-UID999 共999个用户,不能使UID1-UID333同时进入A1/B1/C1,此时B1的效果可能受A1影响,C1的效果也可能受A1/B1影响\n\n流量划分常见策略是根据uid进行hash后对bucket大小取余,因此为了避免并行实验互相影响,每一个实验hash时需要hash(uid,salt).其中每一个实验的salt需要不相同\n\n\n### 如何设计高可用\n\n需要配置两地三机房或者异地双活.当一个机房故障时可以切流到其他机房\n\n### 如何应对大并发\n\n以常见的zookeeper为例,如果每次请求配置都需要执行一次rpc调用,大并发情况下耗费时间是相当可观的.所以最好的策略是将配置下发到本地,通过本地读取.可以通过在机器上边部署client,定期或者触发式去拉取配置.此时client的高可用和监控也需要保证.例如通过supervised保活,监控系统进行监控.\n\n### sdk开发\n为了方便android/ios/服务端不同语言接入,需要开发sdk,增加接入的便捷度\n\n### 配置平台\n为了方便运营或者开发同学配置灰度发布或者A/B实验,需要增加一个配置平台,配置完毕后可以同步到配置系统","slug":"how-to-design-ab-system","published":1,"updated":"2019-05-14T10:24:53.453Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9x000ubms6yz3elos1","content":"<h3 id=\"A-B实验系统设计\"><a href=\"#A-B实验系统设计\" class=\"headerlink\" title=\"A/B实验系统设计\"></a>A/B实验系统设计</h3><ul>\n<li>圈定人群或者流量<br>圈定人群或者流量功能可以独立出来做灰度发布.人群可以根据白名单、号码包、uid、城市、时间或者自定义等维度做区分</li>\n<li><p>分组<br>分组之后可以写两套代码分别部署于不同的IDC或者服务器,也可以在一套代码中根据分组走不同的逻辑.人群划分之后为了避免多因素影响A/B测试的准确性,一般分组根据流量划分,不可根据城市或者时间段等划分</p>\n</li>\n<li><p>指标统计<br>根据实验目的统计指标变化</p>\n</li>\n<li><p>置信区间、显著度<br>实验是否可信</p>\n</li>\n</ul>\n<h3 id=\"并行A-B系统设计要点\"><a href=\"#并行A-B系统设计要点\" class=\"headerlink\" title=\"并行A/B系统设计要点\"></a>并行A/B系统设计要点</h3><p>假设线上同时运行成千上万组A/B实验,并且实验之间是各自独立的.为避免实验之间互相影响,有两种做法</p>\n<ul>\n<li>人群按实验组数划分,但会随着实验组数增加导致人群变少</li>\n<li>流量划分时在每个实验之间都随机划分, 例如A/B/C三个实验,每个实验分三组,例如A1/A2/A3,B1/B2/B3,C1/C2/C3,UID1-UID999 共999个用户,不能使UID1-UID333同时进入A1/B1/C1,此时B1的效果可能受A1影响,C1的效果也可能受A1/B1影响</li>\n</ul>\n<p>流量划分常见策略是根据uid进行hash后对bucket大小取余,因此为了避免并行实验互相影响,每一个实验hash时需要hash(uid,salt).其中每一个实验的salt需要不相同</p>\n<h3 id=\"如何设计高可用\"><a href=\"#如何设计高可用\" class=\"headerlink\" title=\"如何设计高可用\"></a>如何设计高可用</h3><p>需要配置两地三机房或者异地双活.当一个机房故障时可以切流到其他机房</p>\n<h3 id=\"如何应对大并发\"><a href=\"#如何应对大并发\" class=\"headerlink\" title=\"如何应对大并发\"></a>如何应对大并发</h3><p>以常见的zookeeper为例,如果每次请求配置都需要执行一次rpc调用,大并发情况下耗费时间是相当可观的.所以最好的策略是将配置下发到本地,通过本地读取.可以通过在机器上边部署client,定期或者触发式去拉取配置.此时client的高可用和监控也需要保证.例如通过supervised保活,监控系统进行监控.</p>\n<h3 id=\"sdk开发\"><a href=\"#sdk开发\" class=\"headerlink\" title=\"sdk开发\"></a>sdk开发</h3><p>为了方便android/ios/服务端不同语言接入,需要开发sdk,增加接入的便捷度</p>\n<h3 id=\"配置平台\"><a href=\"#配置平台\" class=\"headerlink\" title=\"配置平台\"></a>配置平台</h3><p>为了方便运营或者开发同学配置灰度发布或者A/B实验,需要增加一个配置平台,配置完毕后可以同步到配置系统</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"A-B实验系统设计\"><a href=\"#A-B实验系统设计\" class=\"headerlink\" title=\"A/B实验系统设计\"></a>A/B实验系统设计</h3><ul>\n<li>圈定人群或者流量<br>圈定人群或者流量功能可以独立出来做灰度发布.人群可以根据白名单、号码包、uid、城市、时间或者自定义等维度做区分</li>\n<li><p>分组<br>分组之后可以写两套代码分别部署于不同的IDC或者服务器,也可以在一套代码中根据分组走不同的逻辑.人群划分之后为了避免多因素影响A/B测试的准确性,一般分组根据流量划分,不可根据城市或者时间段等划分</p>\n</li>\n<li><p>指标统计<br>根据实验目的统计指标变化</p>\n</li>\n<li><p>置信区间、显著度<br>实验是否可信</p>\n</li>\n</ul>\n<h3 id=\"并行A-B系统设计要点\"><a href=\"#并行A-B系统设计要点\" class=\"headerlink\" title=\"并行A/B系统设计要点\"></a>并行A/B系统设计要点</h3><p>假设线上同时运行成千上万组A/B实验,并且实验之间是各自独立的.为避免实验之间互相影响,有两种做法</p>\n<ul>\n<li>人群按实验组数划分,但会随着实验组数增加导致人群变少</li>\n<li>流量划分时在每个实验之间都随机划分, 例如A/B/C三个实验,每个实验分三组,例如A1/A2/A3,B1/B2/B3,C1/C2/C3,UID1-UID999 共999个用户,不能使UID1-UID333同时进入A1/B1/C1,此时B1的效果可能受A1影响,C1的效果也可能受A1/B1影响</li>\n</ul>\n<p>流量划分常见策略是根据uid进行hash后对bucket大小取余,因此为了避免并行实验互相影响,每一个实验hash时需要hash(uid,salt).其中每一个实验的salt需要不相同</p>\n<h3 id=\"如何设计高可用\"><a href=\"#如何设计高可用\" class=\"headerlink\" title=\"如何设计高可用\"></a>如何设计高可用</h3><p>需要配置两地三机房或者异地双活.当一个机房故障时可以切流到其他机房</p>\n<h3 id=\"如何应对大并发\"><a href=\"#如何应对大并发\" class=\"headerlink\" title=\"如何应对大并发\"></a>如何应对大并发</h3><p>以常见的zookeeper为例,如果每次请求配置都需要执行一次rpc调用,大并发情况下耗费时间是相当可观的.所以最好的策略是将配置下发到本地,通过本地读取.可以通过在机器上边部署client,定期或者触发式去拉取配置.此时client的高可用和监控也需要保证.例如通过supervised保活,监控系统进行监控.</p>\n<h3 id=\"sdk开发\"><a href=\"#sdk开发\" class=\"headerlink\" title=\"sdk开发\"></a>sdk开发</h3><p>为了方便android/ios/服务端不同语言接入,需要开发sdk,增加接入的便捷度</p>\n<h3 id=\"配置平台\"><a href=\"#配置平台\" class=\"headerlink\" title=\"配置平台\"></a>配置平台</h3><p>为了方便运营或者开发同学配置灰度发布或者A/B实验,需要增加一个配置平台,配置完毕后可以同步到配置系统</p>\n"},{"title":"如何设计一个高并发的日志系统","date":"2019-05-12T16:00:00.000Z","_content":"\n## 日志系统基本概念\n\n### 日志系统必要的因素\n* 日志级别:FATAL,WARNING,NOTICE,DEBUG,ALL ...\n* 调用栈:文件,函数,行数,日期\n  php可以通过debug_backtrace()获取,go通过runtime.Caller()获取\n* 日志信息:自定义\n\n### 日志系统性能考量\n\n我们知道日志系统是需要写入磁盘的,在大并发量下,写磁盘是一个昂贵的操作.那么如何避免写入磁盘呢\n\n* 缓冲然后写入\n* 通过本机起一个udp服务收集日志.每次写入时通过往127.0.0.1:udpport发送日志\n\n## 各种不同的写入日志方式\n\n* 正常写入\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"sync\"\n)\n\nvar fileName string\nvar fileHandle *os.File\nvar err error\nvar mu sync.Mutex\n\nfunc init() {\n\tfileName = \"/tmp/logger.log\"\n\tfileHandle, err = os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\n//Logger direct logger\nfunc Logger(log string) {\n\t//fmt.Fprint(fileHandle, log)\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tfileHandle.WriteString(log)\n}\n\n//Close close logger filehandle\nfunc Close() {\n\tfileHandle.Close()\n}\n\n```\n\n* 缓冲写入\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"bufio\"\n\t\"log\"\n\t\"os\"\n)\n\nvar maxBufferSize int\nvar fileNameBuffer string\nvar fileHandleBuffer *os.File\nvar writer *bufio.Writer\n\nfunc init() {\n\tmaxBufferSize = 1 * 1024 * 1024\n\tfileNameBuffer = \"/tmp/loggerbuffer.log\"\n\tvar err error\n\tfileHandleBuffer, err = os.OpenFile(fileNameBuffer, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\twriter = bufio.NewWriterSize(fileHandleBuffer, maxBufferSize)\n}\n\n//BufferLogger buffer logger\nfunc BufferLogger(log string) {\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tif writer.Available() < len(log) {\n\t\twriter.Flush()\n\t}\n\t//fmt.Fprint(writer, log)\n\twriter.WriteString(log)\n}\n\n//BufferFlush destruct buffer logger\nfunc BufferFlush() {\n\twriter.Flush()\n}\n\n//BufferClose close buffer logger filehandle\nfunc BufferClose() {\n\tfileHandleBuffer.Close()\n}\n\n\n```\n\n* 起一个udp服务,然后发送日志到udp服务\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"log\"\n\t\"net\"\n)\n\nvar conn *net.UDPConn\n\nfunc init() {\n\tsip := net.ParseIP(\"127.0.0.1\")\n\tsrcAddr := &net.UDPAddr{IP: net.IPv4zero, Port: 0}\n\tdstAddr := &net.UDPAddr{IP: sip, Port: 9981}\n\tvar err error\n\tconn, err = net.DialUDP(\"udp\", srcAddr, dstAddr)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\n//UDPLogger buffer logger\nfunc UDPLogger(log string) {\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tconn.Write([]byte(log))\n}\n\n```\n\nudp server的代码如下:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n)\n\nfunc main() {\n\tvar fileNameUDP = \"/tmp/loggerUdp.log\"\n\tfileHandleUDP, err := os.OpenFile(fileNameUDP, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlistener, err := net.ListenUDP(\"udp\", &net.UDPAddr{IP: net.ParseIP(\"127.0.0.1\"), Port: 9981})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdata := make([]byte, 1024)\n\tfor {\n\t\tn, err := listener.Read(data)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"error during read: %s\", err)\n\t\t}\n\t\tfmt.Fprint(fileHandleUDP, string(data[:n]))\n\n\t}\n}\n```\n\n三种方法的压测函数如下:\n\n```\npackage logger\n\nimport (\n\t\"testing\"\n)\n\nfunc BenchmarkLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tLogger(\"this is a long long test\")\n\t}\n}\n\nfunc BenchmarkBufferLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tBufferLogger(\"this is a long long test\")\n\n\t}\n}\n\nfunc BenchmarkUDPLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tUDPLogger(\"this is a long long test\")\n\t}\n}\n\n```\n\n压测结果如下:\n```\n go test -bench=.\ngoos: darwin\ngoarch: amd64\npkg: copywriter.io/logger\nBenchmarkLogger-4                 300000              4348 ns/op\nBenchmarkBufferLogger-4         20000000                98.7 ns/op\nBenchmarkUDPLogger-4              500000              3314 ns/op\nPASS\nok      copywriter.io/logger    5.216s\n```\n\n再次执行,如下:\n```\ngo test -bench=.\ngoos: darwin\ngoarch: amd64\npkg: copywriter.io/logger\nBenchmarkLogger-4                 300000              5528 ns/op\nBenchmarkBufferLogger-4         10000000               127 ns/op\nBenchmarkUDPLogger-4              500000              3216 ns/op\nPASS\nok      copywriter.io/logger    4.868s\n```\n\n## 结论\n\n缓冲写入>udp写入>直接写入\n观察测试结果可以看到,随着写入数据的增加,直接写入会有一个寻址时间导致逐步变慢.而缓冲写入和udp写入不受影响.并且缓冲写入几乎等价于内存操作,但缺点是系统崩溃时可能会丢失部分日志数据","source":"_posts/how-to-design-a-log-system.md","raw":"---\ntitle: 如何设计一个高并发的日志系统\ndate: 2019-05-13 \ntags: architecture\n---\n\n## 日志系统基本概念\n\n### 日志系统必要的因素\n* 日志级别:FATAL,WARNING,NOTICE,DEBUG,ALL ...\n* 调用栈:文件,函数,行数,日期\n  php可以通过debug_backtrace()获取,go通过runtime.Caller()获取\n* 日志信息:自定义\n\n### 日志系统性能考量\n\n我们知道日志系统是需要写入磁盘的,在大并发量下,写磁盘是一个昂贵的操作.那么如何避免写入磁盘呢\n\n* 缓冲然后写入\n* 通过本机起一个udp服务收集日志.每次写入时通过往127.0.0.1:udpport发送日志\n\n## 各种不同的写入日志方式\n\n* 正常写入\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"log\"\n\t\"os\"\n\t\"sync\"\n)\n\nvar fileName string\nvar fileHandle *os.File\nvar err error\nvar mu sync.Mutex\n\nfunc init() {\n\tfileName = \"/tmp/logger.log\"\n\tfileHandle, err = os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\n//Logger direct logger\nfunc Logger(log string) {\n\t//fmt.Fprint(fileHandle, log)\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tfileHandle.WriteString(log)\n}\n\n//Close close logger filehandle\nfunc Close() {\n\tfileHandle.Close()\n}\n\n```\n\n* 缓冲写入\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"bufio\"\n\t\"log\"\n\t\"os\"\n)\n\nvar maxBufferSize int\nvar fileNameBuffer string\nvar fileHandleBuffer *os.File\nvar writer *bufio.Writer\n\nfunc init() {\n\tmaxBufferSize = 1 * 1024 * 1024\n\tfileNameBuffer = \"/tmp/loggerbuffer.log\"\n\tvar err error\n\tfileHandleBuffer, err = os.OpenFile(fileNameBuffer, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\twriter = bufio.NewWriterSize(fileHandleBuffer, maxBufferSize)\n}\n\n//BufferLogger buffer logger\nfunc BufferLogger(log string) {\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tif writer.Available() < len(log) {\n\t\twriter.Flush()\n\t}\n\t//fmt.Fprint(writer, log)\n\twriter.WriteString(log)\n}\n\n//BufferFlush destruct buffer logger\nfunc BufferFlush() {\n\twriter.Flush()\n}\n\n//BufferClose close buffer logger filehandle\nfunc BufferClose() {\n\tfileHandleBuffer.Close()\n}\n\n\n```\n\n* 起一个udp服务,然后发送日志到udp服务\n如下为代码示例\n```\npackage logger\n\nimport (\n\t\"log\"\n\t\"net\"\n)\n\nvar conn *net.UDPConn\n\nfunc init() {\n\tsip := net.ParseIP(\"127.0.0.1\")\n\tsrcAddr := &net.UDPAddr{IP: net.IPv4zero, Port: 0}\n\tdstAddr := &net.UDPAddr{IP: sip, Port: 9981}\n\tvar err error\n\tconn, err = net.DialUDP(\"udp\", srcAddr, dstAddr)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\n//UDPLogger buffer logger\nfunc UDPLogger(log string) {\n\tdefer mu.Unlock()\n\tmu.Lock()\n\tconn.Write([]byte(log))\n}\n\n```\n\nudp server的代码如下:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n)\n\nfunc main() {\n\tvar fileNameUDP = \"/tmp/loggerUdp.log\"\n\tfileHandleUDP, err := os.OpenFile(fileNameUDP, os.O_RDWR|os.O_CREATE, 0755)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlistener, err := net.ListenUDP(\"udp\", &net.UDPAddr{IP: net.ParseIP(\"127.0.0.1\"), Port: 9981})\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdata := make([]byte, 1024)\n\tfor {\n\t\tn, err := listener.Read(data)\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"error during read: %s\", err)\n\t\t}\n\t\tfmt.Fprint(fileHandleUDP, string(data[:n]))\n\n\t}\n}\n```\n\n三种方法的压测函数如下:\n\n```\npackage logger\n\nimport (\n\t\"testing\"\n)\n\nfunc BenchmarkLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tLogger(\"this is a long long test\")\n\t}\n}\n\nfunc BenchmarkBufferLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tBufferLogger(\"this is a long long test\")\n\n\t}\n}\n\nfunc BenchmarkUDPLogger(b *testing.B) {\n\tb.ResetTimer()\n\n\tfor i := 0; i < b.N; i++ {\n\t\tUDPLogger(\"this is a long long test\")\n\t}\n}\n\n```\n\n压测结果如下:\n```\n go test -bench=.\ngoos: darwin\ngoarch: amd64\npkg: copywriter.io/logger\nBenchmarkLogger-4                 300000              4348 ns/op\nBenchmarkBufferLogger-4         20000000                98.7 ns/op\nBenchmarkUDPLogger-4              500000              3314 ns/op\nPASS\nok      copywriter.io/logger    5.216s\n```\n\n再次执行,如下:\n```\ngo test -bench=.\ngoos: darwin\ngoarch: amd64\npkg: copywriter.io/logger\nBenchmarkLogger-4                 300000              5528 ns/op\nBenchmarkBufferLogger-4         10000000               127 ns/op\nBenchmarkUDPLogger-4              500000              3216 ns/op\nPASS\nok      copywriter.io/logger    4.868s\n```\n\n## 结论\n\n缓冲写入>udp写入>直接写入\n观察测试结果可以看到,随着写入数据的增加,直接写入会有一个寻址时间导致逐步变慢.而缓冲写入和udp写入不受影响.并且缓冲写入几乎等价于内存操作,但缺点是系统崩溃时可能会丢失部分日志数据","slug":"how-to-design-a-log-system","published":1,"updated":"2019-05-15T02:50:57.672Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65z9y000wbms6klaor2tw","content":"<h2 id=\"日志系统基本概念\"><a href=\"#日志系统基本概念\" class=\"headerlink\" title=\"日志系统基本概念\"></a>日志系统基本概念</h2><h3 id=\"日志系统必要的因素\"><a href=\"#日志系统必要的因素\" class=\"headerlink\" title=\"日志系统必要的因素\"></a>日志系统必要的因素</h3><ul>\n<li>日志级别:FATAL,WARNING,NOTICE,DEBUG,ALL …</li>\n<li>调用栈:文件,函数,行数,日期<br>php可以通过debug_backtrace()获取,go通过runtime.Caller()获取</li>\n<li>日志信息:自定义</li>\n</ul>\n<h3 id=\"日志系统性能考量\"><a href=\"#日志系统性能考量\" class=\"headerlink\" title=\"日志系统性能考量\"></a>日志系统性能考量</h3><p>我们知道日志系统是需要写入磁盘的,在大并发量下,写磁盘是一个昂贵的操作.那么如何避免写入磁盘呢</p>\n<ul>\n<li>缓冲然后写入</li>\n<li>通过本机起一个udp服务收集日志.每次写入时通过往127.0.0.1:udpport发送日志</li>\n</ul>\n<h2 id=\"各种不同的写入日志方式\"><a href=\"#各种不同的写入日志方式\" class=\"headerlink\" title=\"各种不同的写入日志方式\"></a>各种不同的写入日志方式</h2><ul>\n<li><p>正常写入<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var fileName string</span><br><span class=\"line\">var fileHandle *os.File</span><br><span class=\"line\">var err error</span><br><span class=\"line\">var mu sync.Mutex</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tfileName = &quot;/tmp/logger.log&quot;</span><br><span class=\"line\">\tfileHandle, err = os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//Logger direct logger</span><br><span class=\"line\">func Logger(log string) &#123;</span><br><span class=\"line\">\t//fmt.Fprint(fileHandle, log)</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tfileHandle.WriteString(log)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//Close close logger filehandle</span><br><span class=\"line\">func Close() &#123;</span><br><span class=\"line\">\tfileHandle.Close()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缓冲写入<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;bufio&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var maxBufferSize int</span><br><span class=\"line\">var fileNameBuffer string</span><br><span class=\"line\">var fileHandleBuffer *os.File</span><br><span class=\"line\">var writer *bufio.Writer</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tmaxBufferSize = 1 * 1024 * 1024</span><br><span class=\"line\">\tfileNameBuffer = &quot;/tmp/loggerbuffer.log&quot;</span><br><span class=\"line\">\tvar err error</span><br><span class=\"line\">\tfileHandleBuffer, err = os.OpenFile(fileNameBuffer, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\twriter = bufio.NewWriterSize(fileHandleBuffer, maxBufferSize)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferLogger buffer logger</span><br><span class=\"line\">func BufferLogger(log string) &#123;</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tif writer.Available() &lt; len(log) &#123;</span><br><span class=\"line\">\t\twriter.Flush()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//fmt.Fprint(writer, log)</span><br><span class=\"line\">\twriter.WriteString(log)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferFlush destruct buffer logger</span><br><span class=\"line\">func BufferFlush() &#123;</span><br><span class=\"line\">\twriter.Flush()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferClose close buffer logger filehandle</span><br><span class=\"line\">func BufferClose() &#123;</span><br><span class=\"line\">\tfileHandleBuffer.Close()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>起一个udp服务,然后发送日志到udp服务<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var conn *net.UDPConn</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tsip := net.ParseIP(&quot;127.0.0.1&quot;)</span><br><span class=\"line\">\tsrcAddr := &amp;net.UDPAddr&#123;IP: net.IPv4zero, Port: 0&#125;</span><br><span class=\"line\">\tdstAddr := &amp;net.UDPAddr&#123;IP: sip, Port: 9981&#125;</span><br><span class=\"line\">\tvar err error</span><br><span class=\"line\">\tconn, err = net.DialUDP(&quot;udp&quot;, srcAddr, dstAddr)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//UDPLogger buffer logger</span><br><span class=\"line\">func UDPLogger(log string) &#123;</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tconn.Write([]byte(log))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>udp server的代码如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar fileNameUDP = &quot;/tmp/loggerUdp.log&quot;</span><br><span class=\"line\">\tfileHandleUDP, err := os.OpenFile(fileNameUDP, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tlistener, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123;IP: net.ParseIP(&quot;127.0.0.1&quot;), Port: 9981&#125;)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdata := make([]byte, 1024)</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tn, err := listener.Read(data)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tfmt.Printf(&quot;error during read: %s&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfmt.Fprint(fileHandleUDP, string(data[:n]))</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>三种方法的压测函数如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;testing&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkBufferLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tBufferLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkUDPLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tUDPLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>压测结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> go test -bench=.</span><br><span class=\"line\">goos: darwin</span><br><span class=\"line\">goarch: amd64</span><br><span class=\"line\">pkg: copywriter.io/logger</span><br><span class=\"line\">BenchmarkLogger-4                 300000              4348 ns/op</span><br><span class=\"line\">BenchmarkBufferLogger-4         20000000                98.7 ns/op</span><br><span class=\"line\">BenchmarkUDPLogger-4              500000              3314 ns/op</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok      copywriter.io/logger    5.216s</span><br></pre></td></tr></table></figure></p>\n<p>再次执行,如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go test -bench=.</span><br><span class=\"line\">goos: darwin</span><br><span class=\"line\">goarch: amd64</span><br><span class=\"line\">pkg: copywriter.io/logger</span><br><span class=\"line\">BenchmarkLogger-4                 300000              5528 ns/op</span><br><span class=\"line\">BenchmarkBufferLogger-4         10000000               127 ns/op</span><br><span class=\"line\">BenchmarkUDPLogger-4              500000              3216 ns/op</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok      copywriter.io/logger    4.868s</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>缓冲写入&gt;udp写入&gt;直接写入<br>观察测试结果可以看到,随着写入数据的增加,直接写入会有一个寻址时间导致逐步变慢.而缓冲写入和udp写入不受影响.并且缓冲写入几乎等价于内存操作,但缺点是系统崩溃时可能会丢失部分日志数据</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"日志系统基本概念\"><a href=\"#日志系统基本概念\" class=\"headerlink\" title=\"日志系统基本概念\"></a>日志系统基本概念</h2><h3 id=\"日志系统必要的因素\"><a href=\"#日志系统必要的因素\" class=\"headerlink\" title=\"日志系统必要的因素\"></a>日志系统必要的因素</h3><ul>\n<li>日志级别:FATAL,WARNING,NOTICE,DEBUG,ALL …</li>\n<li>调用栈:文件,函数,行数,日期<br>php可以通过debug_backtrace()获取,go通过runtime.Caller()获取</li>\n<li>日志信息:自定义</li>\n</ul>\n<h3 id=\"日志系统性能考量\"><a href=\"#日志系统性能考量\" class=\"headerlink\" title=\"日志系统性能考量\"></a>日志系统性能考量</h3><p>我们知道日志系统是需要写入磁盘的,在大并发量下,写磁盘是一个昂贵的操作.那么如何避免写入磁盘呢</p>\n<ul>\n<li>缓冲然后写入</li>\n<li>通过本机起一个udp服务收集日志.每次写入时通过往127.0.0.1:udpport发送日志</li>\n</ul>\n<h2 id=\"各种不同的写入日志方式\"><a href=\"#各种不同的写入日志方式\" class=\"headerlink\" title=\"各种不同的写入日志方式\"></a>各种不同的写入日志方式</h2><ul>\n<li><p>正常写入<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var fileName string</span><br><span class=\"line\">var fileHandle *os.File</span><br><span class=\"line\">var err error</span><br><span class=\"line\">var mu sync.Mutex</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tfileName = &quot;/tmp/logger.log&quot;</span><br><span class=\"line\">\tfileHandle, err = os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//Logger direct logger</span><br><span class=\"line\">func Logger(log string) &#123;</span><br><span class=\"line\">\t//fmt.Fprint(fileHandle, log)</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tfileHandle.WriteString(log)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//Close close logger filehandle</span><br><span class=\"line\">func Close() &#123;</span><br><span class=\"line\">\tfileHandle.Close()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缓冲写入<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;bufio&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var maxBufferSize int</span><br><span class=\"line\">var fileNameBuffer string</span><br><span class=\"line\">var fileHandleBuffer *os.File</span><br><span class=\"line\">var writer *bufio.Writer</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tmaxBufferSize = 1 * 1024 * 1024</span><br><span class=\"line\">\tfileNameBuffer = &quot;/tmp/loggerbuffer.log&quot;</span><br><span class=\"line\">\tvar err error</span><br><span class=\"line\">\tfileHandleBuffer, err = os.OpenFile(fileNameBuffer, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\twriter = bufio.NewWriterSize(fileHandleBuffer, maxBufferSize)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferLogger buffer logger</span><br><span class=\"line\">func BufferLogger(log string) &#123;</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tif writer.Available() &lt; len(log) &#123;</span><br><span class=\"line\">\t\twriter.Flush()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//fmt.Fprint(writer, log)</span><br><span class=\"line\">\twriter.WriteString(log)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferFlush destruct buffer logger</span><br><span class=\"line\">func BufferFlush() &#123;</span><br><span class=\"line\">\twriter.Flush()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//BufferClose close buffer logger filehandle</span><br><span class=\"line\">func BufferClose() &#123;</span><br><span class=\"line\">\tfileHandleBuffer.Close()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>起一个udp服务,然后发送日志到udp服务<br>如下为代码示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var conn *net.UDPConn</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tsip := net.ParseIP(&quot;127.0.0.1&quot;)</span><br><span class=\"line\">\tsrcAddr := &amp;net.UDPAddr&#123;IP: net.IPv4zero, Port: 0&#125;</span><br><span class=\"line\">\tdstAddr := &amp;net.UDPAddr&#123;IP: sip, Port: 9981&#125;</span><br><span class=\"line\">\tvar err error</span><br><span class=\"line\">\tconn, err = net.DialUDP(&quot;udp&quot;, srcAddr, dstAddr)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//UDPLogger buffer logger</span><br><span class=\"line\">func UDPLogger(log string) &#123;</span><br><span class=\"line\">\tdefer mu.Unlock()</span><br><span class=\"line\">\tmu.Lock()</span><br><span class=\"line\">\tconn.Write([]byte(log))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>udp server的代码如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar fileNameUDP = &quot;/tmp/loggerUdp.log&quot;</span><br><span class=\"line\">\tfileHandleUDP, err := os.OpenFile(fileNameUDP, os.O_RDWR|os.O_CREATE, 0755)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tlistener, err := net.ListenUDP(&quot;udp&quot;, &amp;net.UDPAddr&#123;IP: net.ParseIP(&quot;127.0.0.1&quot;), Port: 9981&#125;)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdata := make([]byte, 1024)</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tn, err := listener.Read(data)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tfmt.Printf(&quot;error during read: %s&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfmt.Fprint(fileHandleUDP, string(data[:n]))</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>三种方法的压测函数如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package logger</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;testing&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkBufferLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tBufferLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func BenchmarkUDPLogger(b *testing.B) &#123;</span><br><span class=\"line\">\tb.ResetTimer()</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor i := 0; i &lt; b.N; i++ &#123;</span><br><span class=\"line\">\t\tUDPLogger(&quot;this is a long long test&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>压测结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> go test -bench=.</span><br><span class=\"line\">goos: darwin</span><br><span class=\"line\">goarch: amd64</span><br><span class=\"line\">pkg: copywriter.io/logger</span><br><span class=\"line\">BenchmarkLogger-4                 300000              4348 ns/op</span><br><span class=\"line\">BenchmarkBufferLogger-4         20000000                98.7 ns/op</span><br><span class=\"line\">BenchmarkUDPLogger-4              500000              3314 ns/op</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok      copywriter.io/logger    5.216s</span><br></pre></td></tr></table></figure></p>\n<p>再次执行,如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">go test -bench=.</span><br><span class=\"line\">goos: darwin</span><br><span class=\"line\">goarch: amd64</span><br><span class=\"line\">pkg: copywriter.io/logger</span><br><span class=\"line\">BenchmarkLogger-4                 300000              5528 ns/op</span><br><span class=\"line\">BenchmarkBufferLogger-4         10000000               127 ns/op</span><br><span class=\"line\">BenchmarkUDPLogger-4              500000              3216 ns/op</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok      copywriter.io/logger    4.868s</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>缓冲写入&gt;udp写入&gt;直接写入<br>观察测试结果可以看到,随着写入数据的增加,直接写入会有一个寻址时间导致逐步变慢.而缓冲写入和udp写入不受影响.并且缓冲写入几乎等价于内存操作,但缺点是系统崩溃时可能会丢失部分日志数据</p>\n"},{"title":"NGINX HTTP2 处理流程","date":"2018-12-11T06:55:36.000Z","_content":"\n本文通过一个小例子串一遍nginx处理http2的流程。主要涉及到http2的协议以及nginx的处理流程。\n\n## http2简介\n\nhttp2比较http1.1主要有如下五个方面的不同：\n\n* 二进制协议 http1.1请求行和请求头部都是纯文本编码,即可以直接按ascii字符解释，而http2是有自己的编码格式。并且nginx中http2必须建立在ssl协议之上。\n* 头部压缩 举个例子,HTTP1.1传一个header  <method: GET>,需要11个字符.http2中有一个静态索引表，客户端传索引键，例如1，nginx通过查表能知道1代表method: GET.nginx中除了该静态表，还会有一个动态表，保存例如host这种变化的头部\n* 多路复用 http1.1一个连接上只能传输一个请求，当一个请求结束之后才能传输下一个请求。所以对http1.1协议的服务发起请求时，一般浏览器会建立6条连接，并行的去请求不同的资源。而http2的二进制协议中有一个frame的概念，每个frame有自己的id,所以一个连接上可以同时多路复用传输多个不同id的frame\n* 主动push http1.1是请求-响应模型，而http2可以主动给客户端推送资源\n* 优先级 既然多路复用，所有数据跑在了一条通道上，必然会有优先级的需求\n\n\n\n本文的例子主要通过解析报文说明头三个特性\n\n## 配置环境\nNGINX配置如下：\n```\n    server {\n        listen 8443 ssl http2;\n        access_log  logs/host_server2.access.log  main;\n        ssl_certificate /home/xiaoju/nginx-2/nginx-selfsigned.crt;\n        ssl_certificate_key /home/xiaoju/nginx-2/nginx-selfsigned.key;\n        ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;\n\n        location / {\n            root   html;\n            index  index.html index.htm /abc.html;\n            access_log  logs/host_location3.access.log  main;\n            http2_push /favicon.ico;\n            http2_push /nginx.png;\n        }\n    }\n```\n客户端按如下方式发起请求:\n```\ncurl  -k  -I   -L https://IP:8443\nHTTP/2 200  //可以看到，返回是http/2\nserver: nginx/1.14.0\ndate: Tue, 11 Dec 2018 09:20:33 GMT\ncontent-type: text/html\ncontent-length: 664\nlast-modified: Tue, 11 Dec 2018 04:19:32 GMT\netag: \"5c0f3ad4-298\"\naccept-ranges: bytes\n```\n\n## 请求解析\n### 客户端请求问题\n先思考一个问题，上文配置中使用curl发送请求时,为何直接返回的是http/2,而不是http/1.1(虽然服务端配置了使用http2,但万一客户端未支持http2协议，直接返回http2客户端会解析不了)\n\n因为nginx中http2必须在ssl之上，所以我们首先通过在nginx代码中的ssl握手部分打断点gdb跟一下.\n\n```\n(gdb) b ngx_ssl_handshake_handler  //ssl握手函数\nBreakpoint 1 at 0x47ddb5: file src/event/ngx_event_openssl.c, line 1373.\n(gdb) c\nContinuing.\nBreakpoint 1, ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1373\n1373\t{\n\n1390\t    c->ssl->handler(c); //实际处理逻辑位于ngx_http_ssl_handshake_handler\n(gdb) s\nngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:782\n782\t{\n\n(gdb) n\n805\t        if (hc->addr_conf->http2) { //配置http2后hc->addr_conf->http2标志位为1\n\n(gdb) n\n808\t            SSL_get0_alpn_selected(c->ssl->connection, &data, &len);//从ssl协议中取出alpn\n\n\n(gdb) n\n820\t            if (len == 2 && data[0] == 'h' && data[1] == '2') { //如果为h2,说明客户端支持升级到http2协议\n\n(gdb) n\n821\t                ngx_http_v2_init(c->read);//开始进入http2的初始化阶段\n```\n\n简单说就是通过ssl协议握手阶段获取一个alpn相关的配置，如果是h2，就进入http2的处理流程。我们通过wireshark抓包可以更直观的看出这个流程\n\n![nginx](/img/n21.png)\n\n如上图，在ssl握手中的Client Hello 阶段有一个协议扩展alpn\n\n### http2报文格式\nhttp2 以一个preface开头，接着是一个个的frame,其中每个frame都有一个header,如下：\n\n![frame header](/img/n22.png)\n\n其中length代表frame内容的长度,type表明frame的类型,flag给frame做一些特殊的标记,sid代表的就是frame的id.\n\n其中 frame有如下10种类型\n\n```\n#define NGX_HTTP_V2_DATA_FRAME           0x0 //body数据\n#define NGX_HTTP_V2_HEADERS_FRAME        0x1 //header数据\n#define NGX_HTTP_V2_PRIORITY_FRAME       0x2 //优先级设置\n#define NGX_HTTP_V2_RST_STREAM_FRAME     0x3 //重置一个stream\n#define NGX_HTTP_V2_SETTINGS_FRAME       0x4 //其他设置项，例如是否开启push,同时能够处理的stream数量等\n#define NGX_HTTP_V2_PUSH_PROMISE_FRAME   0x5 //push\n#define NGX_HTTP_V2_PING_FRAME           0x6 //ping\n#define NGX_HTTP_V2_GOAWAY_FRAME         0x7 //goaway.发送此frame后会重新建立连接\n#define NGX_HTTP_V2_WINDOW_UPDATE_FRAME  0x8 //窗口更新 流控使用\n#define NGX_HTTP_V2_CONTINUATION_FRAME   0x9 //当一个frame发送不完数据时，可以按continuation格式继续发送\n```\n\nframe ID在客户端按奇数递增，例如1，3，5，偶数型id留给服务端推送push时使用，设置连接属性相关的frame id都为0\n\nflags有如下定义：\n\n```\n#define NGX_HTTP_V2_NO_FLAG              0x00 //未设置\n#define NGX_HTTP_V2_ACK_FLAG             0x01 //ack flag\n#define NGX_HTTP_V2_END_STREAM_FLAG      0x01 //结束stream\n#define NGX_HTTP_V2_END_HEADERS_FLAG     0x04 //结束headers\n#define NGX_HTTP_V2_PADDED_FLAG          0x08 //填充flag\n#define NGX_HTTP_V2_PRIORITY_FLAG        0x20 //优先级设置flag\n```\n\n如下是一个http头类型frame具体的内容格式：\n\n![header](/img/n23.png)\n\npadded和priority由上文头部的flag决定是否有这两字段。接下来占8bit的flag决定header是否需要索引，如果需要，索引号是多少。\n\nhuff(1)表明该字段是否使用了huffman编码。header_value_len(7)和header_value是具体头字段的value值\n\n如下是一个设置相关的frame\n\n![setting](/img/n24.png)\n\n如下是一个窗口更新的frame\n\n![update](/img/n25.png)\n\n下边我们看一个具体的例子\n\n### http2报文解析\n新版本的curl有一个–http2参数，可以直接指明使用http2进行通讯。我们将客户端命令修改如下：\n```\ncurl --http2 -k  -I   -L https://10.96.79.14:8443\n```\n通过上边的gdb跟踪，我们看到http2初始化入口函数为ngx_http_v2_init，直接在此处打断点，继续跟踪代码.跟踪过程不再详细描述，当把报文读取进缓存之后，我们直接在gdb中bt查看调用路径，如下：\n```\n#0  ngx_http_v2_state_preface (h2c=0x15a9310, pos=0x164b0b0 \"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\", end=0x164b11e \"\")\n    at src/http/v2/ngx_http_v2.c:713\n#1  0x00000000004bca20 in ngx_http_v2_read_handler (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:415\n#2  0x00000000004bcf8a in ngx_http_v2_init (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:328\n#3  0x0000000000490a13 in ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:821\n#4  0x000000000047de24 in ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1390\n#5  0x0000000000479637 in ngx_epoll_process_events (cycle=0x1597e30, timer=<optimized out>, flags=<optimized out>)\n    at src/event/modules/ngx_epoll_module.c:902\n#6  0x000000000046f9db in ngx_process_events_and_timers (cycle=0x1597e30) at src/event/ngx_event.c:242\n#7  0x000000000047761c in ngx_worker_process_cycle (cycle=0x1597e30, data=<optimized out>) at src/os/unix/ngx_process_cycle.c:750\n#8  0x0000000000475c50 in ngx_spawn_process (cycle=0x1597e30, proc=0x477589 <ngx_worker_process_cycle>, data=0x0,\n    name=0x684922 \"worker process\", respawn=-3) at src/os/unix/ngx_process.c:199\n#9  0x00000000004769aa in ngx_start_worker_processes (cycle=0x1597e30, n=1, type=-3) at src/os/unix/ngx_process_cycle.c:359\n#10 0x0000000000477cb0 in ngx_master_process_cycle (cycle=0x1597e30) at src/os/unix/ngx_process_cycle.c:131\n#11 0x0000000000450ea4 in main (argc=<optimized out>, argv=<optimized out>) at src/core/nginx.c:382\n```\n\n调用到ngx_http_v2_state_preface这个函数之后，开始处理http2请求，我们将请求内容打印出来看一下：\n\n\n```\n(gdb) p end-pos\n$1 = 110\n(gdb) p *pos@110\n$2 = \"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\\000\\000\\022\\004\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000d\\000\\004@\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\004\\b\\000\\000\\000\\000\\000?\\377\\000\\001\\000\\000%\\001\\005\\000\\000\\000\\001B\\004HEAD\\204\\207A\\214\\b\\027}\\305\\335}p\\265q\\346\\232gz\\210%\\266Pë\\266\\322\\340S\\003*/*\"\n```\nnginx接下来开始处理http2请求，处理方法可以按上述方法继续跟踪，我们直接按http2协议将上述报文解析一下，如下所示：\n\n注意gdb打印出来的是八进制格式\n\n![detail](/img/n26.png)\n\n![detail](/img/n27.png)\n\n### http push抓包\n注意上文nginx配置中配置了两条http2_push指令，即服务端会在请求index.html时主动将favicon.ico和nginx.png两个图片push下去。\n\nwireshark中抓包如下：\n\n![detail](/img/n28.png)\n\n服务端首先发送一个push_promise报文，报文中会包括push的文件路径和frame id.第二个和第三个红框即开始push具体的信息,frame id分别为2和4\n\n我们从浏览器端看一下push的请求：\n\n![push](/img/n29.png)\n\n不主动push请求如下：\n![push](/img/n210.png)\n\n浏览器必须首先将index.html加载之后才会知道接着去请求哪些资源，于是favicon.ico和nginx.png就会延迟加载。\n\n### Q&A\n* HTTP2如果在服务端动态索引header，会使http变成有状态的服务，集群之间如何解决header头缓存的问题？\n* 静态资源文件首次请求后会在浏览器端缓存，push如何保证只推送一次(即只有首次请求时才push)?\n\n## 参考资料\n1.https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/\n\n2.https://httpwg.org/specs/rfc7540","source":"_posts/NGINX-HTTP2-处理流程.md","raw":"---\ntitle: NGINX HTTP2 处理流程\ndate: 2018-12-11 14:55:36\ntags: NGINX\n---\n\n本文通过一个小例子串一遍nginx处理http2的流程。主要涉及到http2的协议以及nginx的处理流程。\n\n## http2简介\n\nhttp2比较http1.1主要有如下五个方面的不同：\n\n* 二进制协议 http1.1请求行和请求头部都是纯文本编码,即可以直接按ascii字符解释，而http2是有自己的编码格式。并且nginx中http2必须建立在ssl协议之上。\n* 头部压缩 举个例子,HTTP1.1传一个header  <method: GET>,需要11个字符.http2中有一个静态索引表，客户端传索引键，例如1，nginx通过查表能知道1代表method: GET.nginx中除了该静态表，还会有一个动态表，保存例如host这种变化的头部\n* 多路复用 http1.1一个连接上只能传输一个请求，当一个请求结束之后才能传输下一个请求。所以对http1.1协议的服务发起请求时，一般浏览器会建立6条连接，并行的去请求不同的资源。而http2的二进制协议中有一个frame的概念，每个frame有自己的id,所以一个连接上可以同时多路复用传输多个不同id的frame\n* 主动push http1.1是请求-响应模型，而http2可以主动给客户端推送资源\n* 优先级 既然多路复用，所有数据跑在了一条通道上，必然会有优先级的需求\n\n\n\n本文的例子主要通过解析报文说明头三个特性\n\n## 配置环境\nNGINX配置如下：\n```\n    server {\n        listen 8443 ssl http2;\n        access_log  logs/host_server2.access.log  main;\n        ssl_certificate /home/xiaoju/nginx-2/nginx-selfsigned.crt;\n        ssl_certificate_key /home/xiaoju/nginx-2/nginx-selfsigned.key;\n        ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;\n\n        location / {\n            root   html;\n            index  index.html index.htm /abc.html;\n            access_log  logs/host_location3.access.log  main;\n            http2_push /favicon.ico;\n            http2_push /nginx.png;\n        }\n    }\n```\n客户端按如下方式发起请求:\n```\ncurl  -k  -I   -L https://IP:8443\nHTTP/2 200  //可以看到，返回是http/2\nserver: nginx/1.14.0\ndate: Tue, 11 Dec 2018 09:20:33 GMT\ncontent-type: text/html\ncontent-length: 664\nlast-modified: Tue, 11 Dec 2018 04:19:32 GMT\netag: \"5c0f3ad4-298\"\naccept-ranges: bytes\n```\n\n## 请求解析\n### 客户端请求问题\n先思考一个问题，上文配置中使用curl发送请求时,为何直接返回的是http/2,而不是http/1.1(虽然服务端配置了使用http2,但万一客户端未支持http2协议，直接返回http2客户端会解析不了)\n\n因为nginx中http2必须在ssl之上，所以我们首先通过在nginx代码中的ssl握手部分打断点gdb跟一下.\n\n```\n(gdb) b ngx_ssl_handshake_handler  //ssl握手函数\nBreakpoint 1 at 0x47ddb5: file src/event/ngx_event_openssl.c, line 1373.\n(gdb) c\nContinuing.\nBreakpoint 1, ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1373\n1373\t{\n\n1390\t    c->ssl->handler(c); //实际处理逻辑位于ngx_http_ssl_handshake_handler\n(gdb) s\nngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:782\n782\t{\n\n(gdb) n\n805\t        if (hc->addr_conf->http2) { //配置http2后hc->addr_conf->http2标志位为1\n\n(gdb) n\n808\t            SSL_get0_alpn_selected(c->ssl->connection, &data, &len);//从ssl协议中取出alpn\n\n\n(gdb) n\n820\t            if (len == 2 && data[0] == 'h' && data[1] == '2') { //如果为h2,说明客户端支持升级到http2协议\n\n(gdb) n\n821\t                ngx_http_v2_init(c->read);//开始进入http2的初始化阶段\n```\n\n简单说就是通过ssl协议握手阶段获取一个alpn相关的配置，如果是h2，就进入http2的处理流程。我们通过wireshark抓包可以更直观的看出这个流程\n\n![nginx](/img/n21.png)\n\n如上图，在ssl握手中的Client Hello 阶段有一个协议扩展alpn\n\n### http2报文格式\nhttp2 以一个preface开头，接着是一个个的frame,其中每个frame都有一个header,如下：\n\n![frame header](/img/n22.png)\n\n其中length代表frame内容的长度,type表明frame的类型,flag给frame做一些特殊的标记,sid代表的就是frame的id.\n\n其中 frame有如下10种类型\n\n```\n#define NGX_HTTP_V2_DATA_FRAME           0x0 //body数据\n#define NGX_HTTP_V2_HEADERS_FRAME        0x1 //header数据\n#define NGX_HTTP_V2_PRIORITY_FRAME       0x2 //优先级设置\n#define NGX_HTTP_V2_RST_STREAM_FRAME     0x3 //重置一个stream\n#define NGX_HTTP_V2_SETTINGS_FRAME       0x4 //其他设置项，例如是否开启push,同时能够处理的stream数量等\n#define NGX_HTTP_V2_PUSH_PROMISE_FRAME   0x5 //push\n#define NGX_HTTP_V2_PING_FRAME           0x6 //ping\n#define NGX_HTTP_V2_GOAWAY_FRAME         0x7 //goaway.发送此frame后会重新建立连接\n#define NGX_HTTP_V2_WINDOW_UPDATE_FRAME  0x8 //窗口更新 流控使用\n#define NGX_HTTP_V2_CONTINUATION_FRAME   0x9 //当一个frame发送不完数据时，可以按continuation格式继续发送\n```\n\nframe ID在客户端按奇数递增，例如1，3，5，偶数型id留给服务端推送push时使用，设置连接属性相关的frame id都为0\n\nflags有如下定义：\n\n```\n#define NGX_HTTP_V2_NO_FLAG              0x00 //未设置\n#define NGX_HTTP_V2_ACK_FLAG             0x01 //ack flag\n#define NGX_HTTP_V2_END_STREAM_FLAG      0x01 //结束stream\n#define NGX_HTTP_V2_END_HEADERS_FLAG     0x04 //结束headers\n#define NGX_HTTP_V2_PADDED_FLAG          0x08 //填充flag\n#define NGX_HTTP_V2_PRIORITY_FLAG        0x20 //优先级设置flag\n```\n\n如下是一个http头类型frame具体的内容格式：\n\n![header](/img/n23.png)\n\npadded和priority由上文头部的flag决定是否有这两字段。接下来占8bit的flag决定header是否需要索引，如果需要，索引号是多少。\n\nhuff(1)表明该字段是否使用了huffman编码。header_value_len(7)和header_value是具体头字段的value值\n\n如下是一个设置相关的frame\n\n![setting](/img/n24.png)\n\n如下是一个窗口更新的frame\n\n![update](/img/n25.png)\n\n下边我们看一个具体的例子\n\n### http2报文解析\n新版本的curl有一个–http2参数，可以直接指明使用http2进行通讯。我们将客户端命令修改如下：\n```\ncurl --http2 -k  -I   -L https://10.96.79.14:8443\n```\n通过上边的gdb跟踪，我们看到http2初始化入口函数为ngx_http_v2_init，直接在此处打断点，继续跟踪代码.跟踪过程不再详细描述，当把报文读取进缓存之后，我们直接在gdb中bt查看调用路径，如下：\n```\n#0  ngx_http_v2_state_preface (h2c=0x15a9310, pos=0x164b0b0 \"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\", end=0x164b11e \"\")\n    at src/http/v2/ngx_http_v2.c:713\n#1  0x00000000004bca20 in ngx_http_v2_read_handler (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:415\n#2  0x00000000004bcf8a in ngx_http_v2_init (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:328\n#3  0x0000000000490a13 in ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:821\n#4  0x000000000047de24 in ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1390\n#5  0x0000000000479637 in ngx_epoll_process_events (cycle=0x1597e30, timer=<optimized out>, flags=<optimized out>)\n    at src/event/modules/ngx_epoll_module.c:902\n#6  0x000000000046f9db in ngx_process_events_and_timers (cycle=0x1597e30) at src/event/ngx_event.c:242\n#7  0x000000000047761c in ngx_worker_process_cycle (cycle=0x1597e30, data=<optimized out>) at src/os/unix/ngx_process_cycle.c:750\n#8  0x0000000000475c50 in ngx_spawn_process (cycle=0x1597e30, proc=0x477589 <ngx_worker_process_cycle>, data=0x0,\n    name=0x684922 \"worker process\", respawn=-3) at src/os/unix/ngx_process.c:199\n#9  0x00000000004769aa in ngx_start_worker_processes (cycle=0x1597e30, n=1, type=-3) at src/os/unix/ngx_process_cycle.c:359\n#10 0x0000000000477cb0 in ngx_master_process_cycle (cycle=0x1597e30) at src/os/unix/ngx_process_cycle.c:131\n#11 0x0000000000450ea4 in main (argc=<optimized out>, argv=<optimized out>) at src/core/nginx.c:382\n```\n\n调用到ngx_http_v2_state_preface这个函数之后，开始处理http2请求，我们将请求内容打印出来看一下：\n\n\n```\n(gdb) p end-pos\n$1 = 110\n(gdb) p *pos@110\n$2 = \"PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\\000\\000\\022\\004\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000d\\000\\004@\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\004\\b\\000\\000\\000\\000\\000?\\377\\000\\001\\000\\000%\\001\\005\\000\\000\\000\\001B\\004HEAD\\204\\207A\\214\\b\\027}\\305\\335}p\\265q\\346\\232gz\\210%\\266Pë\\266\\322\\340S\\003*/*\"\n```\nnginx接下来开始处理http2请求，处理方法可以按上述方法继续跟踪，我们直接按http2协议将上述报文解析一下，如下所示：\n\n注意gdb打印出来的是八进制格式\n\n![detail](/img/n26.png)\n\n![detail](/img/n27.png)\n\n### http push抓包\n注意上文nginx配置中配置了两条http2_push指令，即服务端会在请求index.html时主动将favicon.ico和nginx.png两个图片push下去。\n\nwireshark中抓包如下：\n\n![detail](/img/n28.png)\n\n服务端首先发送一个push_promise报文，报文中会包括push的文件路径和frame id.第二个和第三个红框即开始push具体的信息,frame id分别为2和4\n\n我们从浏览器端看一下push的请求：\n\n![push](/img/n29.png)\n\n不主动push请求如下：\n![push](/img/n210.png)\n\n浏览器必须首先将index.html加载之后才会知道接着去请求哪些资源，于是favicon.ico和nginx.png就会延迟加载。\n\n### Q&A\n* HTTP2如果在服务端动态索引header，会使http变成有状态的服务，集群之间如何解决header头缓存的问题？\n* 静态资源文件首次请求后会在浏览器端缓存，push如何保证只推送一次(即只有首次请求时才push)?\n\n## 参考资料\n1.https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/\n\n2.https://httpwg.org/specs/rfc7540","slug":"NGINX-HTTP2-处理流程","published":1,"updated":"2019-02-19T07:11:21.579Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbb001ebms6v0uu2kkr","content":"<p>本文通过一个小例子串一遍nginx处理http2的流程。主要涉及到http2的协议以及nginx的处理流程。</p>\n<h2 id=\"http2简介\"><a href=\"#http2简介\" class=\"headerlink\" title=\"http2简介\"></a>http2简介</h2><p>http2比较http1.1主要有如下五个方面的不同：</p>\n<ul>\n<li>二进制协议 http1.1请求行和请求头部都是纯文本编码,即可以直接按ascii字符解释，而http2是有自己的编码格式。并且nginx中http2必须建立在ssl协议之上。</li>\n<li>头部压缩 举个例子,HTTP1.1传一个header  &lt;method: GET&gt;,需要11个字符.http2中有一个静态索引表，客户端传索引键，例如1，nginx通过查表能知道1代表method: GET.nginx中除了该静态表，还会有一个动态表，保存例如host这种变化的头部</li>\n<li>多路复用 http1.1一个连接上只能传输一个请求，当一个请求结束之后才能传输下一个请求。所以对http1.1协议的服务发起请求时，一般浏览器会建立6条连接，并行的去请求不同的资源。而http2的二进制协议中有一个frame的概念，每个frame有自己的id,所以一个连接上可以同时多路复用传输多个不同id的frame</li>\n<li>主动push http1.1是请求-响应模型，而http2可以主动给客户端推送资源</li>\n<li>优先级 既然多路复用，所有数据跑在了一条通道上，必然会有优先级的需求</li>\n</ul>\n<p>本文的例子主要通过解析报文说明头三个特性</p>\n<h2 id=\"配置环境\"><a href=\"#配置环境\" class=\"headerlink\" title=\"配置环境\"></a>配置环境</h2><p>NGINX配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    listen 8443 ssl http2;</span><br><span class=\"line\">    access_log  logs/host_server2.access.log  main;</span><br><span class=\"line\">    ssl_certificate /home/xiaoju/nginx-2/nginx-selfsigned.crt;</span><br><span class=\"line\">    ssl_certificate_key /home/xiaoju/nginx-2/nginx-selfsigned.key;</span><br><span class=\"line\">    ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;</span><br><span class=\"line\"></span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        root   html;</span><br><span class=\"line\">        index  index.html index.htm /abc.html;</span><br><span class=\"line\">        access_log  logs/host_location3.access.log  main;</span><br><span class=\"line\">        http2_push /favicon.ico;</span><br><span class=\"line\">        http2_push /nginx.png;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>客户端按如下方式发起请求:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl  -k  -I   -L https://IP:8443</span><br><span class=\"line\">HTTP/2 200  //可以看到，返回是http/2</span><br><span class=\"line\">server: nginx/1.14.0</span><br><span class=\"line\">date: Tue, 11 Dec 2018 09:20:33 GMT</span><br><span class=\"line\">content-type: text/html</span><br><span class=\"line\">content-length: 664</span><br><span class=\"line\">last-modified: Tue, 11 Dec 2018 04:19:32 GMT</span><br><span class=\"line\">etag: &quot;5c0f3ad4-298&quot;</span><br><span class=\"line\">accept-ranges: bytes</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"请求解析\"><a href=\"#请求解析\" class=\"headerlink\" title=\"请求解析\"></a>请求解析</h2><h3 id=\"客户端请求问题\"><a href=\"#客户端请求问题\" class=\"headerlink\" title=\"客户端请求问题\"></a>客户端请求问题</h3><p>先思考一个问题，上文配置中使用curl发送请求时,为何直接返回的是http/2,而不是http/1.1(虽然服务端配置了使用http2,但万一客户端未支持http2协议，直接返回http2客户端会解析不了)</p>\n<p>因为nginx中http2必须在ssl之上，所以我们首先通过在nginx代码中的ssl握手部分打断点gdb跟一下.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(gdb) b ngx_ssl_handshake_handler  //ssl握手函数</span><br><span class=\"line\">Breakpoint 1 at 0x47ddb5: file src/event/ngx_event_openssl.c, line 1373.</span><br><span class=\"line\">(gdb) c</span><br><span class=\"line\">Continuing.</span><br><span class=\"line\">Breakpoint 1, ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1373</span><br><span class=\"line\">1373\t&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">1390\t    c-&gt;ssl-&gt;handler(c); //实际处理逻辑位于ngx_http_ssl_handshake_handler</span><br><span class=\"line\">(gdb) s</span><br><span class=\"line\">ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:782</span><br><span class=\"line\">782\t&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">805\t        if (hc-&gt;addr_conf-&gt;http2) &#123; //配置http2后hc-&gt;addr_conf-&gt;http2标志位为1</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">808\t            SSL_get0_alpn_selected(c-&gt;ssl-&gt;connection, &amp;data, &amp;len);//从ssl协议中取出alpn</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">820\t            if (len == 2 &amp;&amp; data[0] == &apos;h&apos; &amp;&amp; data[1] == &apos;2&apos;) &#123; //如果为h2,说明客户端支持升级到http2协议</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">821\t                ngx_http_v2_init(c-&gt;read);//开始进入http2的初始化阶段</span><br></pre></td></tr></table></figure>\n<p>简单说就是通过ssl协议握手阶段获取一个alpn相关的配置，如果是h2，就进入http2的处理流程。我们通过wireshark抓包可以更直观的看出这个流程</p>\n<p><img src=\"/img/n21.png\" alt=\"nginx\"></p>\n<p>如上图，在ssl握手中的Client Hello 阶段有一个协议扩展alpn</p>\n<h3 id=\"http2报文格式\"><a href=\"#http2报文格式\" class=\"headerlink\" title=\"http2报文格式\"></a>http2报文格式</h3><p>http2 以一个preface开头，接着是一个个的frame,其中每个frame都有一个header,如下：</p>\n<p><img src=\"/img/n22.png\" alt=\"frame header\"></p>\n<p>其中length代表frame内容的长度,type表明frame的类型,flag给frame做一些特殊的标记,sid代表的就是frame的id.</p>\n<p>其中 frame有如下10种类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NGX_HTTP_V2_DATA_FRAME           0x0 //body数据</span><br><span class=\"line\">#define NGX_HTTP_V2_HEADERS_FRAME        0x1 //header数据</span><br><span class=\"line\">#define NGX_HTTP_V2_PRIORITY_FRAME       0x2 //优先级设置</span><br><span class=\"line\">#define NGX_HTTP_V2_RST_STREAM_FRAME     0x3 //重置一个stream</span><br><span class=\"line\">#define NGX_HTTP_V2_SETTINGS_FRAME       0x4 //其他设置项，例如是否开启push,同时能够处理的stream数量等</span><br><span class=\"line\">#define NGX_HTTP_V2_PUSH_PROMISE_FRAME   0x5 //push</span><br><span class=\"line\">#define NGX_HTTP_V2_PING_FRAME           0x6 //ping</span><br><span class=\"line\">#define NGX_HTTP_V2_GOAWAY_FRAME         0x7 //goaway.发送此frame后会重新建立连接</span><br><span class=\"line\">#define NGX_HTTP_V2_WINDOW_UPDATE_FRAME  0x8 //窗口更新 流控使用</span><br><span class=\"line\">#define NGX_HTTP_V2_CONTINUATION_FRAME   0x9 //当一个frame发送不完数据时，可以按continuation格式继续发送</span><br></pre></td></tr></table></figure>\n<p>frame ID在客户端按奇数递增，例如1，3，5，偶数型id留给服务端推送push时使用，设置连接属性相关的frame id都为0</p>\n<p>flags有如下定义：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NGX_HTTP_V2_NO_FLAG              0x00 //未设置</span><br><span class=\"line\">#define NGX_HTTP_V2_ACK_FLAG             0x01 //ack flag</span><br><span class=\"line\">#define NGX_HTTP_V2_END_STREAM_FLAG      0x01 //结束stream</span><br><span class=\"line\">#define NGX_HTTP_V2_END_HEADERS_FLAG     0x04 //结束headers</span><br><span class=\"line\">#define NGX_HTTP_V2_PADDED_FLAG          0x08 //填充flag</span><br><span class=\"line\">#define NGX_HTTP_V2_PRIORITY_FLAG        0x20 //优先级设置flag</span><br></pre></td></tr></table></figure>\n<p>如下是一个http头类型frame具体的内容格式：</p>\n<p><img src=\"/img/n23.png\" alt=\"header\"></p>\n<p>padded和priority由上文头部的flag决定是否有这两字段。接下来占8bit的flag决定header是否需要索引，如果需要，索引号是多少。</p>\n<p>huff(1)表明该字段是否使用了huffman编码。header_value_len(7)和header_value是具体头字段的value值</p>\n<p>如下是一个设置相关的frame</p>\n<p><img src=\"/img/n24.png\" alt=\"setting\"></p>\n<p>如下是一个窗口更新的frame</p>\n<p><img src=\"/img/n25.png\" alt=\"update\"></p>\n<p>下边我们看一个具体的例子</p>\n<h3 id=\"http2报文解析\"><a href=\"#http2报文解析\" class=\"headerlink\" title=\"http2报文解析\"></a>http2报文解析</h3><p>新版本的curl有一个–http2参数，可以直接指明使用http2进行通讯。我们将客户端命令修改如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl --http2 -k  -I   -L https://10.96.79.14:8443</span><br></pre></td></tr></table></figure></p>\n<p>通过上边的gdb跟踪，我们看到http2初始化入口函数为ngx_http_v2_init，直接在此处打断点，继续跟踪代码.跟踪过程不再详细描述，当把报文读取进缓存之后，我们直接在gdb中bt查看调用路径，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#0  ngx_http_v2_state_preface (h2c=0x15a9310, pos=0x164b0b0 &quot;PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n&quot;, end=0x164b11e &quot;&quot;)</span><br><span class=\"line\">    at src/http/v2/ngx_http_v2.c:713</span><br><span class=\"line\">#1  0x00000000004bca20 in ngx_http_v2_read_handler (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:415</span><br><span class=\"line\">#2  0x00000000004bcf8a in ngx_http_v2_init (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:328</span><br><span class=\"line\">#3  0x0000000000490a13 in ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:821</span><br><span class=\"line\">#4  0x000000000047de24 in ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1390</span><br><span class=\"line\">#5  0x0000000000479637 in ngx_epoll_process_events (cycle=0x1597e30, timer=&lt;optimized out&gt;, flags=&lt;optimized out&gt;)</span><br><span class=\"line\">    at src/event/modules/ngx_epoll_module.c:902</span><br><span class=\"line\">#6  0x000000000046f9db in ngx_process_events_and_timers (cycle=0x1597e30) at src/event/ngx_event.c:242</span><br><span class=\"line\">#7  0x000000000047761c in ngx_worker_process_cycle (cycle=0x1597e30, data=&lt;optimized out&gt;) at src/os/unix/ngx_process_cycle.c:750</span><br><span class=\"line\">#8  0x0000000000475c50 in ngx_spawn_process (cycle=0x1597e30, proc=0x477589 &lt;ngx_worker_process_cycle&gt;, data=0x0,</span><br><span class=\"line\">    name=0x684922 &quot;worker process&quot;, respawn=-3) at src/os/unix/ngx_process.c:199</span><br><span class=\"line\">#9  0x00000000004769aa in ngx_start_worker_processes (cycle=0x1597e30, n=1, type=-3) at src/os/unix/ngx_process_cycle.c:359</span><br><span class=\"line\">#10 0x0000000000477cb0 in ngx_master_process_cycle (cycle=0x1597e30) at src/os/unix/ngx_process_cycle.c:131</span><br><span class=\"line\">#11 0x0000000000450ea4 in main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at src/core/nginx.c:382</span><br></pre></td></tr></table></figure></p>\n<p>调用到ngx_http_v2_state_preface这个函数之后，开始处理http2请求，我们将请求内容打印出来看一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(gdb) p end-pos</span><br><span class=\"line\">$1 = 110</span><br><span class=\"line\">(gdb) p *pos@110</span><br><span class=\"line\">$2 = &quot;PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\\000\\000\\022\\004\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000d\\000\\004@\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\004\\b\\000\\000\\000\\000\\000?\\377\\000\\001\\000\\000%\\001\\005\\000\\000\\000\\001B\\004HEAD\\204\\207A\\214\\b\\027&#125;\\305\\335&#125;p\\265q\\346\\232gz\\210%\\266Pë\\266\\322\\340S\\003*/*&quot;</span><br></pre></td></tr></table></figure>\n<p>nginx接下来开始处理http2请求，处理方法可以按上述方法继续跟踪，我们直接按http2协议将上述报文解析一下，如下所示：</p>\n<p>注意gdb打印出来的是八进制格式</p>\n<p><img src=\"/img/n26.png\" alt=\"detail\"></p>\n<p><img src=\"/img/n27.png\" alt=\"detail\"></p>\n<h3 id=\"http-push抓包\"><a href=\"#http-push抓包\" class=\"headerlink\" title=\"http push抓包\"></a>http push抓包</h3><p>注意上文nginx配置中配置了两条http2_push指令，即服务端会在请求index.html时主动将favicon.ico和nginx.png两个图片push下去。</p>\n<p>wireshark中抓包如下：</p>\n<p><img src=\"/img/n28.png\" alt=\"detail\"></p>\n<p>服务端首先发送一个push_promise报文，报文中会包括push的文件路径和frame id.第二个和第三个红框即开始push具体的信息,frame id分别为2和4</p>\n<p>我们从浏览器端看一下push的请求：</p>\n<p><img src=\"/img/n29.png\" alt=\"push\"></p>\n<p>不主动push请求如下：<br><img src=\"/img/n210.png\" alt=\"push\"></p>\n<p>浏览器必须首先将index.html加载之后才会知道接着去请求哪些资源，于是favicon.ico和nginx.png就会延迟加载。</p>\n<h3 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h3><ul>\n<li>HTTP2如果在服务端动态索引header，会使http变成有状态的服务，集群之间如何解决header头缓存的问题？</li>\n<li>静态资源文件首次请求后会在浏览器端缓存，push如何保证只推送一次(即只有首次请求时才push)?</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>1.<a href=\"https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/\" target=\"_blank\" rel=\"noopener\">https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/</a></p>\n<p>2.<a href=\"https://httpwg.org/specs/rfc7540\" target=\"_blank\" rel=\"noopener\">https://httpwg.org/specs/rfc7540</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文通过一个小例子串一遍nginx处理http2的流程。主要涉及到http2的协议以及nginx的处理流程。</p>\n<h2 id=\"http2简介\"><a href=\"#http2简介\" class=\"headerlink\" title=\"http2简介\"></a>http2简介</h2><p>http2比较http1.1主要有如下五个方面的不同：</p>\n<ul>\n<li>二进制协议 http1.1请求行和请求头部都是纯文本编码,即可以直接按ascii字符解释，而http2是有自己的编码格式。并且nginx中http2必须建立在ssl协议之上。</li>\n<li>头部压缩 举个例子,HTTP1.1传一个header  &lt;method: GET&gt;,需要11个字符.http2中有一个静态索引表，客户端传索引键，例如1，nginx通过查表能知道1代表method: GET.nginx中除了该静态表，还会有一个动态表，保存例如host这种变化的头部</li>\n<li>多路复用 http1.1一个连接上只能传输一个请求，当一个请求结束之后才能传输下一个请求。所以对http1.1协议的服务发起请求时，一般浏览器会建立6条连接，并行的去请求不同的资源。而http2的二进制协议中有一个frame的概念，每个frame有自己的id,所以一个连接上可以同时多路复用传输多个不同id的frame</li>\n<li>主动push http1.1是请求-响应模型，而http2可以主动给客户端推送资源</li>\n<li>优先级 既然多路复用，所有数据跑在了一条通道上，必然会有优先级的需求</li>\n</ul>\n<p>本文的例子主要通过解析报文说明头三个特性</p>\n<h2 id=\"配置环境\"><a href=\"#配置环境\" class=\"headerlink\" title=\"配置环境\"></a>配置环境</h2><p>NGINX配置如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">server &#123;</span><br><span class=\"line\">    listen 8443 ssl http2;</span><br><span class=\"line\">    access_log  logs/host_server2.access.log  main;</span><br><span class=\"line\">    ssl_certificate /home/xiaoju/nginx-2/nginx-selfsigned.crt;</span><br><span class=\"line\">    ssl_certificate_key /home/xiaoju/nginx-2/nginx-selfsigned.key;</span><br><span class=\"line\">    ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;</span><br><span class=\"line\"></span><br><span class=\"line\">    location / &#123;</span><br><span class=\"line\">        root   html;</span><br><span class=\"line\">        index  index.html index.htm /abc.html;</span><br><span class=\"line\">        access_log  logs/host_location3.access.log  main;</span><br><span class=\"line\">        http2_push /favicon.ico;</span><br><span class=\"line\">        http2_push /nginx.png;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>客户端按如下方式发起请求:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl  -k  -I   -L https://IP:8443</span><br><span class=\"line\">HTTP/2 200  //可以看到，返回是http/2</span><br><span class=\"line\">server: nginx/1.14.0</span><br><span class=\"line\">date: Tue, 11 Dec 2018 09:20:33 GMT</span><br><span class=\"line\">content-type: text/html</span><br><span class=\"line\">content-length: 664</span><br><span class=\"line\">last-modified: Tue, 11 Dec 2018 04:19:32 GMT</span><br><span class=\"line\">etag: &quot;5c0f3ad4-298&quot;</span><br><span class=\"line\">accept-ranges: bytes</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"请求解析\"><a href=\"#请求解析\" class=\"headerlink\" title=\"请求解析\"></a>请求解析</h2><h3 id=\"客户端请求问题\"><a href=\"#客户端请求问题\" class=\"headerlink\" title=\"客户端请求问题\"></a>客户端请求问题</h3><p>先思考一个问题，上文配置中使用curl发送请求时,为何直接返回的是http/2,而不是http/1.1(虽然服务端配置了使用http2,但万一客户端未支持http2协议，直接返回http2客户端会解析不了)</p>\n<p>因为nginx中http2必须在ssl之上，所以我们首先通过在nginx代码中的ssl握手部分打断点gdb跟一下.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(gdb) b ngx_ssl_handshake_handler  //ssl握手函数</span><br><span class=\"line\">Breakpoint 1 at 0x47ddb5: file src/event/ngx_event_openssl.c, line 1373.</span><br><span class=\"line\">(gdb) c</span><br><span class=\"line\">Continuing.</span><br><span class=\"line\">Breakpoint 1, ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1373</span><br><span class=\"line\">1373\t&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">1390\t    c-&gt;ssl-&gt;handler(c); //实际处理逻辑位于ngx_http_ssl_handshake_handler</span><br><span class=\"line\">(gdb) s</span><br><span class=\"line\">ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:782</span><br><span class=\"line\">782\t&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">805\t        if (hc-&gt;addr_conf-&gt;http2) &#123; //配置http2后hc-&gt;addr_conf-&gt;http2标志位为1</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">808\t            SSL_get0_alpn_selected(c-&gt;ssl-&gt;connection, &amp;data, &amp;len);//从ssl协议中取出alpn</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">820\t            if (len == 2 &amp;&amp; data[0] == &apos;h&apos; &amp;&amp; data[1] == &apos;2&apos;) &#123; //如果为h2,说明客户端支持升级到http2协议</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">821\t                ngx_http_v2_init(c-&gt;read);//开始进入http2的初始化阶段</span><br></pre></td></tr></table></figure>\n<p>简单说就是通过ssl协议握手阶段获取一个alpn相关的配置，如果是h2，就进入http2的处理流程。我们通过wireshark抓包可以更直观的看出这个流程</p>\n<p><img src=\"/img/n21.png\" alt=\"nginx\"></p>\n<p>如上图，在ssl握手中的Client Hello 阶段有一个协议扩展alpn</p>\n<h3 id=\"http2报文格式\"><a href=\"#http2报文格式\" class=\"headerlink\" title=\"http2报文格式\"></a>http2报文格式</h3><p>http2 以一个preface开头，接着是一个个的frame,其中每个frame都有一个header,如下：</p>\n<p><img src=\"/img/n22.png\" alt=\"frame header\"></p>\n<p>其中length代表frame内容的长度,type表明frame的类型,flag给frame做一些特殊的标记,sid代表的就是frame的id.</p>\n<p>其中 frame有如下10种类型</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NGX_HTTP_V2_DATA_FRAME           0x0 //body数据</span><br><span class=\"line\">#define NGX_HTTP_V2_HEADERS_FRAME        0x1 //header数据</span><br><span class=\"line\">#define NGX_HTTP_V2_PRIORITY_FRAME       0x2 //优先级设置</span><br><span class=\"line\">#define NGX_HTTP_V2_RST_STREAM_FRAME     0x3 //重置一个stream</span><br><span class=\"line\">#define NGX_HTTP_V2_SETTINGS_FRAME       0x4 //其他设置项，例如是否开启push,同时能够处理的stream数量等</span><br><span class=\"line\">#define NGX_HTTP_V2_PUSH_PROMISE_FRAME   0x5 //push</span><br><span class=\"line\">#define NGX_HTTP_V2_PING_FRAME           0x6 //ping</span><br><span class=\"line\">#define NGX_HTTP_V2_GOAWAY_FRAME         0x7 //goaway.发送此frame后会重新建立连接</span><br><span class=\"line\">#define NGX_HTTP_V2_WINDOW_UPDATE_FRAME  0x8 //窗口更新 流控使用</span><br><span class=\"line\">#define NGX_HTTP_V2_CONTINUATION_FRAME   0x9 //当一个frame发送不完数据时，可以按continuation格式继续发送</span><br></pre></td></tr></table></figure>\n<p>frame ID在客户端按奇数递增，例如1，3，5，偶数型id留给服务端推送push时使用，设置连接属性相关的frame id都为0</p>\n<p>flags有如下定义：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#define NGX_HTTP_V2_NO_FLAG              0x00 //未设置</span><br><span class=\"line\">#define NGX_HTTP_V2_ACK_FLAG             0x01 //ack flag</span><br><span class=\"line\">#define NGX_HTTP_V2_END_STREAM_FLAG      0x01 //结束stream</span><br><span class=\"line\">#define NGX_HTTP_V2_END_HEADERS_FLAG     0x04 //结束headers</span><br><span class=\"line\">#define NGX_HTTP_V2_PADDED_FLAG          0x08 //填充flag</span><br><span class=\"line\">#define NGX_HTTP_V2_PRIORITY_FLAG        0x20 //优先级设置flag</span><br></pre></td></tr></table></figure>\n<p>如下是一个http头类型frame具体的内容格式：</p>\n<p><img src=\"/img/n23.png\" alt=\"header\"></p>\n<p>padded和priority由上文头部的flag决定是否有这两字段。接下来占8bit的flag决定header是否需要索引，如果需要，索引号是多少。</p>\n<p>huff(1)表明该字段是否使用了huffman编码。header_value_len(7)和header_value是具体头字段的value值</p>\n<p>如下是一个设置相关的frame</p>\n<p><img src=\"/img/n24.png\" alt=\"setting\"></p>\n<p>如下是一个窗口更新的frame</p>\n<p><img src=\"/img/n25.png\" alt=\"update\"></p>\n<p>下边我们看一个具体的例子</p>\n<h3 id=\"http2报文解析\"><a href=\"#http2报文解析\" class=\"headerlink\" title=\"http2报文解析\"></a>http2报文解析</h3><p>新版本的curl有一个–http2参数，可以直接指明使用http2进行通讯。我们将客户端命令修改如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl --http2 -k  -I   -L https://10.96.79.14:8443</span><br></pre></td></tr></table></figure></p>\n<p>通过上边的gdb跟踪，我们看到http2初始化入口函数为ngx_http_v2_init，直接在此处打断点，继续跟踪代码.跟踪过程不再详细描述，当把报文读取进缓存之后，我们直接在gdb中bt查看调用路径，如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#0  ngx_http_v2_state_preface (h2c=0x15a9310, pos=0x164b0b0 &quot;PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n&quot;, end=0x164b11e &quot;&quot;)</span><br><span class=\"line\">    at src/http/v2/ngx_http_v2.c:713</span><br><span class=\"line\">#1  0x00000000004bca20 in ngx_http_v2_read_handler (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:415</span><br><span class=\"line\">#2  0x00000000004bcf8a in ngx_http_v2_init (rev=0x16141f0) at src/http/v2/ngx_http_v2.c:328</span><br><span class=\"line\">#3  0x0000000000490a13 in ngx_http_ssl_handshake_handler (c=0x15da400) at src/http/ngx_http_request.c:821</span><br><span class=\"line\">#4  0x000000000047de24 in ngx_ssl_handshake_handler (ev=0x16141f0) at src/event/ngx_event_openssl.c:1390</span><br><span class=\"line\">#5  0x0000000000479637 in ngx_epoll_process_events (cycle=0x1597e30, timer=&lt;optimized out&gt;, flags=&lt;optimized out&gt;)</span><br><span class=\"line\">    at src/event/modules/ngx_epoll_module.c:902</span><br><span class=\"line\">#6  0x000000000046f9db in ngx_process_events_and_timers (cycle=0x1597e30) at src/event/ngx_event.c:242</span><br><span class=\"line\">#7  0x000000000047761c in ngx_worker_process_cycle (cycle=0x1597e30, data=&lt;optimized out&gt;) at src/os/unix/ngx_process_cycle.c:750</span><br><span class=\"line\">#8  0x0000000000475c50 in ngx_spawn_process (cycle=0x1597e30, proc=0x477589 &lt;ngx_worker_process_cycle&gt;, data=0x0,</span><br><span class=\"line\">    name=0x684922 &quot;worker process&quot;, respawn=-3) at src/os/unix/ngx_process.c:199</span><br><span class=\"line\">#9  0x00000000004769aa in ngx_start_worker_processes (cycle=0x1597e30, n=1, type=-3) at src/os/unix/ngx_process_cycle.c:359</span><br><span class=\"line\">#10 0x0000000000477cb0 in ngx_master_process_cycle (cycle=0x1597e30) at src/os/unix/ngx_process_cycle.c:131</span><br><span class=\"line\">#11 0x0000000000450ea4 in main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at src/core/nginx.c:382</span><br></pre></td></tr></table></figure></p>\n<p>调用到ngx_http_v2_state_preface这个函数之后，开始处理http2请求，我们将请求内容打印出来看一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(gdb) p end-pos</span><br><span class=\"line\">$1 = 110</span><br><span class=\"line\">(gdb) p *pos@110</span><br><span class=\"line\">$2 = &quot;PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n\\000\\000\\022\\004\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000d\\000\\004@\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\004\\b\\000\\000\\000\\000\\000?\\377\\000\\001\\000\\000%\\001\\005\\000\\000\\000\\001B\\004HEAD\\204\\207A\\214\\b\\027&#125;\\305\\335&#125;p\\265q\\346\\232gz\\210%\\266Pë\\266\\322\\340S\\003*/*&quot;</span><br></pre></td></tr></table></figure>\n<p>nginx接下来开始处理http2请求，处理方法可以按上述方法继续跟踪，我们直接按http2协议将上述报文解析一下，如下所示：</p>\n<p>注意gdb打印出来的是八进制格式</p>\n<p><img src=\"/img/n26.png\" alt=\"detail\"></p>\n<p><img src=\"/img/n27.png\" alt=\"detail\"></p>\n<h3 id=\"http-push抓包\"><a href=\"#http-push抓包\" class=\"headerlink\" title=\"http push抓包\"></a>http push抓包</h3><p>注意上文nginx配置中配置了两条http2_push指令，即服务端会在请求index.html时主动将favicon.ico和nginx.png两个图片push下去。</p>\n<p>wireshark中抓包如下：</p>\n<p><img src=\"/img/n28.png\" alt=\"detail\"></p>\n<p>服务端首先发送一个push_promise报文，报文中会包括push的文件路径和frame id.第二个和第三个红框即开始push具体的信息,frame id分别为2和4</p>\n<p>我们从浏览器端看一下push的请求：</p>\n<p><img src=\"/img/n29.png\" alt=\"push\"></p>\n<p>不主动push请求如下：<br><img src=\"/img/n210.png\" alt=\"push\"></p>\n<p>浏览器必须首先将index.html加载之后才会知道接着去请求哪些资源，于是favicon.ico和nginx.png就会延迟加载。</p>\n<h3 id=\"Q-amp-A\"><a href=\"#Q-amp-A\" class=\"headerlink\" title=\"Q&amp;A\"></a>Q&amp;A</h3><ul>\n<li>HTTP2如果在服务端动态索引header，会使http变成有状态的服务，集群之间如何解决header头缓存的问题？</li>\n<li>静态资源文件首次请求后会在浏览器端缓存，push如何保证只推送一次(即只有首次请求时才push)?</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>1.<a href=\"https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/\" target=\"_blank\" rel=\"noopener\">https://www.nginx.com/blog/http2-theory-and-practice-in-nginx-stable-13/</a></p>\n<p>2.<a href=\"https://httpwg.org/specs/rfc7540\" target=\"_blank\" rel=\"noopener\">https://httpwg.org/specs/rfc7540</a></p>\n"},{"title":"Redis 懒删除(lazy free)简史","date":"2018-12-15T05:29:12.000Z","_content":"## Redis是单进程单线程模式吗\n\n下图为Redis5.0启动之后的效果。LWP为线程ID，NLWP为线程数量。可以看到，5.0的redis server共有四个线程，一个主线程48684，三个bio(background IO,后台io任务)线程，三个后台线程分别执行不同的io任务，我们重点考察删除一个key时的io线程执行。\n\n![process](/img/rl1.png)\n\nRedis增加了异步删除命令unlink,防止删除大key时阻塞主线程。其原理为执行unlink时会将需要删除的数据挂到一个链表中，由专门的线程负责将其删除。而原来的del命令还是阻塞的。我们通过对一个有1000万条数据的集合分别执行del和unlink来观察其效果。\n\n## 看一个大集合的删除\n首先通过脚本生成一个有1000万个元素的集合testset，然后通过del命令删除，如下：\n\n```\n127.0.0.1:8888>info//首先调用info命令查看内存消耗：\n \n# Memory\nused_memory:857536\nused_memory_human:837.44K\n \n127.0.0.1:8888> eval \"local i = tonumber(ARGV[1]);local res;math.randomseed(tonumber(ARGV[2]));while (i > 0) do res = redis.call('sadd',KEYS[1],math.random());i = i-1;end\" 1  testset 10000000 2\n(nil)\n(18.51s)//创建耗时18.51s \n \n127.0.0.1:8888>info//再次查看内存消耗\n# Memory\nused_memory:681063080\nused_memory_human:649.51M\n\n127.0.0.1:8888> scard testset//查看集合中元素数量\n(integer) 9976638 //通过math.random()生成，由于集合中不能有重复数据，可以看到，最终只有9976638条数据不重复。\n127.0.0.1:8888> sscan testset 0 //查看集合中的元素内容\n1) \"3670016\"\n2)  1) \"0.94438312106969913\"\n    2) \"0.55726669754705704\"\n    3) \"0.3246220281927949\"\n    4) \"0.51470726752407259\"\n    5) \"0.33469647464095453\"\n    6) \"0.48387842554779648\"\n    7) \"0.3680923377946449\"\n    8) \"0.34466382877187052\"\n    9) \"0.019202849370987551\"\n   10) \"0.71412580307299545\"\n   11) \"0.12846412375963484\"\n   12) \"0.10548432828182557\"\n\n127.0.0.1:8888> del testset //调用del命令删除，耗时2.76s \n(integer) 1\n(2.76s) \n \n127.0.0.1:8888>info//再次查看内存消耗\n# Memory\nused_memory:858568\nused_memory_human:838.45K\n```\n\n重新做上边的实验,这次试用unlink来删除。\n\n```\n\n127.0.0.1:8888> unlink testset//unlink瞬间返回\n(integer) 1\n127.0.0.1:8888>info//再次查看内存消耗。可以看到，返回之后testset并没有清理干净。内存仍然占用了大约一半，再经过1-2s,会清理干净\n# Memory\nused_memory:326898224\nused_memory_human:311.75M\n```\n\n## 尝试渐进式删除\n参见:http://antirez.com/news/93\n\n为了解决这个问题，Redis作者Antirez首先考虑的是通过渐进式删除来解决。Redis也在很多地方用到了渐进式的策略，例如 lru eviction,key 过期以及渐进式rehash.原文如下：\n\n```\nSo this was the first thing I tried: create a new timer function, and perform the eviction there. Objects were just queued into a linked list, to be reclaimed slowly and incrementally each time the timer function was called. This requires some trick to work well. For example objects implemented with hash tables were also reclaimed incrementally using the same mechanism used inside Redis SCAN command: taking a cursor inside the dictionary and iterating it to free element after element. This way, in each timer call, we don’t have to free a whole hash table. The cursor will tell us where we left when we re-enter the timer function.\n```\n\n大意就是把要删除的对象放到一个链表中，起一个定期任务，每次只删除其中一部分。\n\n这会有什么问题呢，仍然看原文中说的一种案例:\n\n```\n    WHILE 1\n        SADD myset element1 element2 … many many many elements\n        DEL myset\n    END\n```\n\n如果删除没有增加快，上边这种案例会导致内存暴涨.(虽然不知道什么情况下会有这种案例发生)。于是作者开始设计一种自适应性的删除,即通过判断内存是增加还是减少，来动态调整删除任务执行的频率，代码示例如下：\n\n\n```\n /* Compute the memory trend, biased towards thinking memory is raising\n     * for a few calls every time previous and current memory raise. */\n\t\n\t//只要内存有一次显示是增加的趋势，则接下来即使内存不再增加，还是会有连续六次mem_is_raising都是1，即判断为增加。\n\t//注意mem_is_raising的值是根据mem_trend和0.1来比较。 即第一次0.9,第二次为0.9*0.9,第三次为0.81*0.81.第六次之后才会小于0.1  (勘误:应该为0.9^22 之后小于0.1)\n\t//这也就是上边注释描述的会偏向于认为只要有一次内存是增加的，就会连续几次加快执行调用删除任务的频率\n    if (prev_mem < mem) mem_trend = 1; \n    mem_trend *= 0.9; /* Make it slowly forget. */\n    int mem_is_raising = mem_trend > .1;\n\n\t//删除一些数据\n    /* Free a few items. */\n    size_t workdone = lazyfreeStep(LAZYFREE_STEP_SLOW);\n\n\t//动态调整执行频率\n    /* Adjust this timer call frequency according to the current state. */\n    if (workdone) {\n        if (timer_period == 1000) timer_period = 20;\n        if (mem_is_raising && timer_period > 3)//如果内存在增加，就加大执行频率\n            timer_period--; /* Raise call frequency. */\n        else if (!mem_is_raising && timer_period < 20)\n            timer_period++; /* Lower call frequency. *///否则减小频率\n    } else {\n        timer_period = 1000;    /* 1 HZ */\n    }\n```\n\n这种方法有个缺陷，因为毕竟是在一个线程中，当回收的特别频繁时，会降低redis的qps,qps只能达到正常情况下的65%.\n\n\n```\nwhen the lazy free cycle was very busy, operations per second were reduced to around 65% of the norm\n```\n\n于是redis作者antirez开始考虑异步线程回收。\n\n## 异步线程\n### 共享对象\n#### 异步线程为何不能有共享数据\n共享数据越多，多线程之间发生争用的可能性越大。所以为了性能，必须首先将共享数据消灭掉。\n\n那么redis在什么地方会用到共享数据呢\n\n#### 如何共享\n如下代码示例为Redis2.8.24.\n\n先看执行sadd时底层数据是如何保存的\n\n```\nsadd testset val1\n```\n底层保存如下(gdb过程如下，比较晦涩,参考下文解释)：\n\n```\n254\t    set = lookupKeyWrite(c->db,c->argv[1]);\n(gdb) n\n255\t    if (set == NULL) {\n(gdb) p c->argv[1]\n$1 = (robj *) 0x7f58e3ccfcc0\n(gdb) p *c->argv[1]\n$2 = {type = 0, encoding = 0, lru = 1367521, refcount = 1, ptr = 0x7f58e3ccfcd8}\n\n(gdb) p (char *)c->argv[1].ptr //client中的argv是一个个robj,argv[1]的ptr中存储着key值'testset'\n$4 = 0x7f58e3ccfcd8 \"testset\"\n(gdb) n\n254\t    set = lookupKeyWrite(c->db,c->argv[1]);\n(gdb) n\n255\t    if (set == NULL) {\n...\n(gdb) p (char *)((robj *)((dict *)set.ptr).ht[0].table[3].key).ptr\n$37 = 0x7f58e3ccfcb8 \"val1\" //值val1保存在一个dict中，dict保存着一个个dictEntry,dictEntry的key是一个指针，指向一个robj,robj中是具体的值\n```\n\n通过下文结构体讲解，可以看下sadd testset val1,testset和val1保存在什么地方\n\n\n```\ntypedef struct dict {\n    dictType *type;\n    void *privdata;\n    dictht ht[2];\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n    int iterators; /* number of iterators currently running */\n} dict;\n\n\n \ntypedef struct dictht {\n    dictEntry **table;\n    unsigned long size;\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;\n\ntypedef struct dictEntry {\n    void *key;\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } v;\n    struct dictEntry *next;\n} dictEntry;\n \ntypedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */\n    int refcount;\n    void *ptr;\n} robj;\n\n```\n\n* 首先所有的key保存在一个dict.ht[0]的dictht结构体中。通过上边的结构体看到，dictht中的table是一个dictEntry二级指针。\n\n* 执行sadd testset val1时，testset是其中一个dictEntry中的key,key是一个void*指针，实际存储情况为testset保存为一个char *类型\n\n* 假设testset经过哈希之后index为3，则dict.ht[0].table[3].key为testset,dict.ht[0].table[3].v.val为一个void*指针，实际存储一个robj *类型\n\n* 第三步中的robj中有个ptr指针，指向一个dict类型。dict中的其中一个entry的key指向另一个robj指针，该指针的ptr指向val\n\n即获取一个值的流程为：\n\n    key -> value_obj -> hash table -> robj -> sds_string\n然后看两个共享对象的典型场景：\n\n1.sunionstore命令\n\n看下代码实现：\n\n```\n\nint setTypeAdd(robj *subject, robj *value) {\n\t...\n    if (subject->encoding == REDIS_ENCODING_HT) {\n        if (dictAdd(subject->ptr,value,NULL) == DICT_OK) {\n            incrRefCount(value);//此处的value值由于是从已存在的集合中直接取出，refcount已经是1，此处并没有新建robj,而是直接将引用计数加1\n            return 1;\n        }\n    } \n\t...\n}\n```\n\n执行以下命令：\n\nsadd testset1 value2\n\nsunionstore set testset1 testset2 //即将testset1和testset2的元素取并集并保存到set中\n\n然后我们可以通过查看testset的元素，看看其引用计数是否变为了2\n\nsmembers testset\n\n```\n\n(gdb) p *(robj *)(((dict *)setobj.ptr).ht[0].table[3].key)\n$88 = {type = 0, encoding = 0, lru = 1457112, refcount = 2, ptr = 0x7f58e3ccfb68} //refcount为2\n \n(gdb) p (char *)(((robj *)(((dict *)setobj.ptr).ht[0].table[3].key)).ptr)\n$89 = 0x7f58e3ccfb68 \"val\"                                  //值为val\n```\n\n2.smembers命令\n\n返回元素的时候，重点看返回时的代码\n\n```\n\n/* Add a Redis Object as a bulk reply */\nvoid addReplyBulk(redisClient *c, robj *obj) {\n    addReplyBulkLen(c,obj);\n    addReply(c,obj);\n    addReply(c,shared.crlf);\n}\n```\n\n会直接将robj对象作为返回参数\n\n并且客户端传入参数也是一个个robj对象，会直接作为值保存到对象中\n\n\n#### 共享时如何删除\n那么，共享对象在单线程情况下是如何删除的呢？\n\n看看del命令的实现\n\ndel调用dictDelete，最终调用每个数据类型自己的析构函数\n\n```\ndictFreeKey(d, he);\ndictFreeVal(d, he);\n```\n集合类型调用如下函数\n\n```\nvoid dictRedisObjectDestructor(void *privdata, void *val)\n{\n    DICT_NOTUSED(privdata);\n\n    if (val == NULL) return; /* Values of swapped out keys as set to NULL */\n    decrRefCount(val);\n}\n```\n\n可以看到，只是将值的refcount减1\n如何解决共享数据\n新版本如何解决了共享数据\n\n还是通过sunionstore和smembers命令看下这两处如何解决共享：\n\n以下代码使用redis 5.0.3版本介绍：\n\n```\nvoid saddCommand(client *c) {\n    ...\n    for (j = 2; j < c->argc; j++) {\n        if (setTypeAdd(set,c->argv[j]->ptr)) added++; //sadd的时候元素也变为了c->argv[j]->ptr,一个字符串\n    }\n\t...\n}\n \nint setTypeAdd(robj *subject, sds value) {//value是一个sds\n    long long llval;\n    if (subject->encoding == OBJ_ENCODING_HT) {\n        dict *ht = subject->ptr;\n        dictEntry *de = dictAddRaw(ht,value,NULL);\n        if (de) {\n            dictSetKey(ht,de,sdsdup(value));\n            dictSetVal(ht,de,NULL);\n            return 1;\n        }\n    }\n    return 0;\n}\n```\n增加值的时候已经变为了一个sds.\n\n现在的保存结构为：\n\n    key -> value_obj -> hash table -> sds_string\n而返回到客户端的时候也变为了一个sds,如下：\n\n```\n\naddReplyBulkCBuffer(c,elesds,sdslen(elesds));\n\nvoid addReplyBulkCBuffer(client *c, const void *p, size_t len) {\n    addReplyLongLongWithPrefix(c,len,'$');\n    addReplyString(c,p,len);\n    addReply(c,shared.crlf);\n}\n```\n\n#### 效果如何\n效果如何呢？\n\n首先取值的时候从robj的间接引用变为了一个sds的直接引用。\n\n其次减少了共享会增加内存的消耗，而使用了sds之后，每个sds的内存占用会比一个robj要小。我们看下antirez如何评价这个修改：\n\n```\n\nThe result is that Redis is now more memory efficient since there are no robj structures around in the implementation of the data structures (but they are used in the code paths where there is a lot of sharing going on, for example during the command dispatch and replication). \n...\nBut, the most interesting thing is, Redis is now faster in all the operations I tested so far. Less indirection was a real winner here. It is faster even in unrelated benchmarks just because the client output buffers are now simpler and faster.\n```\n\n说了两层意思，一是内存使用更加高效了\n\n二是更少的间接引用导致redis比以前更加快，而且客户端输出更加简洁和快速。\n\n### 异步线程\n异步线程的实现以后在详细描述\n\n问题\n\n1.多线程之间在堆上分配内存时会有争用。但是antirez说因为redis在内存分配上使用的时间极少，可以忽略这种情况。\n\n如何考虑这个问题？\n\n参考：https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads","source":"_posts/Redis-懒删除-lazy-free-简史.md","raw":"---\ntitle: Redis 懒删除(lazy free)简史\ndate: 2018-12-15 13:29:12\ntags: Redis\n---\n## Redis是单进程单线程模式吗\n\n下图为Redis5.0启动之后的效果。LWP为线程ID，NLWP为线程数量。可以看到，5.0的redis server共有四个线程，一个主线程48684，三个bio(background IO,后台io任务)线程，三个后台线程分别执行不同的io任务，我们重点考察删除一个key时的io线程执行。\n\n![process](/img/rl1.png)\n\nRedis增加了异步删除命令unlink,防止删除大key时阻塞主线程。其原理为执行unlink时会将需要删除的数据挂到一个链表中，由专门的线程负责将其删除。而原来的del命令还是阻塞的。我们通过对一个有1000万条数据的集合分别执行del和unlink来观察其效果。\n\n## 看一个大集合的删除\n首先通过脚本生成一个有1000万个元素的集合testset，然后通过del命令删除，如下：\n\n```\n127.0.0.1:8888>info//首先调用info命令查看内存消耗：\n \n# Memory\nused_memory:857536\nused_memory_human:837.44K\n \n127.0.0.1:8888> eval \"local i = tonumber(ARGV[1]);local res;math.randomseed(tonumber(ARGV[2]));while (i > 0) do res = redis.call('sadd',KEYS[1],math.random());i = i-1;end\" 1  testset 10000000 2\n(nil)\n(18.51s)//创建耗时18.51s \n \n127.0.0.1:8888>info//再次查看内存消耗\n# Memory\nused_memory:681063080\nused_memory_human:649.51M\n\n127.0.0.1:8888> scard testset//查看集合中元素数量\n(integer) 9976638 //通过math.random()生成，由于集合中不能有重复数据，可以看到，最终只有9976638条数据不重复。\n127.0.0.1:8888> sscan testset 0 //查看集合中的元素内容\n1) \"3670016\"\n2)  1) \"0.94438312106969913\"\n    2) \"0.55726669754705704\"\n    3) \"0.3246220281927949\"\n    4) \"0.51470726752407259\"\n    5) \"0.33469647464095453\"\n    6) \"0.48387842554779648\"\n    7) \"0.3680923377946449\"\n    8) \"0.34466382877187052\"\n    9) \"0.019202849370987551\"\n   10) \"0.71412580307299545\"\n   11) \"0.12846412375963484\"\n   12) \"0.10548432828182557\"\n\n127.0.0.1:8888> del testset //调用del命令删除，耗时2.76s \n(integer) 1\n(2.76s) \n \n127.0.0.1:8888>info//再次查看内存消耗\n# Memory\nused_memory:858568\nused_memory_human:838.45K\n```\n\n重新做上边的实验,这次试用unlink来删除。\n\n```\n\n127.0.0.1:8888> unlink testset//unlink瞬间返回\n(integer) 1\n127.0.0.1:8888>info//再次查看内存消耗。可以看到，返回之后testset并没有清理干净。内存仍然占用了大约一半，再经过1-2s,会清理干净\n# Memory\nused_memory:326898224\nused_memory_human:311.75M\n```\n\n## 尝试渐进式删除\n参见:http://antirez.com/news/93\n\n为了解决这个问题，Redis作者Antirez首先考虑的是通过渐进式删除来解决。Redis也在很多地方用到了渐进式的策略，例如 lru eviction,key 过期以及渐进式rehash.原文如下：\n\n```\nSo this was the first thing I tried: create a new timer function, and perform the eviction there. Objects were just queued into a linked list, to be reclaimed slowly and incrementally each time the timer function was called. This requires some trick to work well. For example objects implemented with hash tables were also reclaimed incrementally using the same mechanism used inside Redis SCAN command: taking a cursor inside the dictionary and iterating it to free element after element. This way, in each timer call, we don’t have to free a whole hash table. The cursor will tell us where we left when we re-enter the timer function.\n```\n\n大意就是把要删除的对象放到一个链表中，起一个定期任务，每次只删除其中一部分。\n\n这会有什么问题呢，仍然看原文中说的一种案例:\n\n```\n    WHILE 1\n        SADD myset element1 element2 … many many many elements\n        DEL myset\n    END\n```\n\n如果删除没有增加快，上边这种案例会导致内存暴涨.(虽然不知道什么情况下会有这种案例发生)。于是作者开始设计一种自适应性的删除,即通过判断内存是增加还是减少，来动态调整删除任务执行的频率，代码示例如下：\n\n\n```\n /* Compute the memory trend, biased towards thinking memory is raising\n     * for a few calls every time previous and current memory raise. */\n\t\n\t//只要内存有一次显示是增加的趋势，则接下来即使内存不再增加，还是会有连续六次mem_is_raising都是1，即判断为增加。\n\t//注意mem_is_raising的值是根据mem_trend和0.1来比较。 即第一次0.9,第二次为0.9*0.9,第三次为0.81*0.81.第六次之后才会小于0.1  (勘误:应该为0.9^22 之后小于0.1)\n\t//这也就是上边注释描述的会偏向于认为只要有一次内存是增加的，就会连续几次加快执行调用删除任务的频率\n    if (prev_mem < mem) mem_trend = 1; \n    mem_trend *= 0.9; /* Make it slowly forget. */\n    int mem_is_raising = mem_trend > .1;\n\n\t//删除一些数据\n    /* Free a few items. */\n    size_t workdone = lazyfreeStep(LAZYFREE_STEP_SLOW);\n\n\t//动态调整执行频率\n    /* Adjust this timer call frequency according to the current state. */\n    if (workdone) {\n        if (timer_period == 1000) timer_period = 20;\n        if (mem_is_raising && timer_period > 3)//如果内存在增加，就加大执行频率\n            timer_period--; /* Raise call frequency. */\n        else if (!mem_is_raising && timer_period < 20)\n            timer_period++; /* Lower call frequency. *///否则减小频率\n    } else {\n        timer_period = 1000;    /* 1 HZ */\n    }\n```\n\n这种方法有个缺陷，因为毕竟是在一个线程中，当回收的特别频繁时，会降低redis的qps,qps只能达到正常情况下的65%.\n\n\n```\nwhen the lazy free cycle was very busy, operations per second were reduced to around 65% of the norm\n```\n\n于是redis作者antirez开始考虑异步线程回收。\n\n## 异步线程\n### 共享对象\n#### 异步线程为何不能有共享数据\n共享数据越多，多线程之间发生争用的可能性越大。所以为了性能，必须首先将共享数据消灭掉。\n\n那么redis在什么地方会用到共享数据呢\n\n#### 如何共享\n如下代码示例为Redis2.8.24.\n\n先看执行sadd时底层数据是如何保存的\n\n```\nsadd testset val1\n```\n底层保存如下(gdb过程如下，比较晦涩,参考下文解释)：\n\n```\n254\t    set = lookupKeyWrite(c->db,c->argv[1]);\n(gdb) n\n255\t    if (set == NULL) {\n(gdb) p c->argv[1]\n$1 = (robj *) 0x7f58e3ccfcc0\n(gdb) p *c->argv[1]\n$2 = {type = 0, encoding = 0, lru = 1367521, refcount = 1, ptr = 0x7f58e3ccfcd8}\n\n(gdb) p (char *)c->argv[1].ptr //client中的argv是一个个robj,argv[1]的ptr中存储着key值'testset'\n$4 = 0x7f58e3ccfcd8 \"testset\"\n(gdb) n\n254\t    set = lookupKeyWrite(c->db,c->argv[1]);\n(gdb) n\n255\t    if (set == NULL) {\n...\n(gdb) p (char *)((robj *)((dict *)set.ptr).ht[0].table[3].key).ptr\n$37 = 0x7f58e3ccfcb8 \"val1\" //值val1保存在一个dict中，dict保存着一个个dictEntry,dictEntry的key是一个指针，指向一个robj,robj中是具体的值\n```\n\n通过下文结构体讲解，可以看下sadd testset val1,testset和val1保存在什么地方\n\n\n```\ntypedef struct dict {\n    dictType *type;\n    void *privdata;\n    dictht ht[2];\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n    int iterators; /* number of iterators currently running */\n} dict;\n\n\n \ntypedef struct dictht {\n    dictEntry **table;\n    unsigned long size;\n    unsigned long sizemask;\n    unsigned long used;\n} dictht;\n\ntypedef struct dictEntry {\n    void *key;\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n        double d;\n    } v;\n    struct dictEntry *next;\n} dictEntry;\n \ntypedef struct redisObject {\n    unsigned type:4;\n    unsigned encoding:4;\n    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */\n    int refcount;\n    void *ptr;\n} robj;\n\n```\n\n* 首先所有的key保存在一个dict.ht[0]的dictht结构体中。通过上边的结构体看到，dictht中的table是一个dictEntry二级指针。\n\n* 执行sadd testset val1时，testset是其中一个dictEntry中的key,key是一个void*指针，实际存储情况为testset保存为一个char *类型\n\n* 假设testset经过哈希之后index为3，则dict.ht[0].table[3].key为testset,dict.ht[0].table[3].v.val为一个void*指针，实际存储一个robj *类型\n\n* 第三步中的robj中有个ptr指针，指向一个dict类型。dict中的其中一个entry的key指向另一个robj指针，该指针的ptr指向val\n\n即获取一个值的流程为：\n\n    key -> value_obj -> hash table -> robj -> sds_string\n然后看两个共享对象的典型场景：\n\n1.sunionstore命令\n\n看下代码实现：\n\n```\n\nint setTypeAdd(robj *subject, robj *value) {\n\t...\n    if (subject->encoding == REDIS_ENCODING_HT) {\n        if (dictAdd(subject->ptr,value,NULL) == DICT_OK) {\n            incrRefCount(value);//此处的value值由于是从已存在的集合中直接取出，refcount已经是1，此处并没有新建robj,而是直接将引用计数加1\n            return 1;\n        }\n    } \n\t...\n}\n```\n\n执行以下命令：\n\nsadd testset1 value2\n\nsunionstore set testset1 testset2 //即将testset1和testset2的元素取并集并保存到set中\n\n然后我们可以通过查看testset的元素，看看其引用计数是否变为了2\n\nsmembers testset\n\n```\n\n(gdb) p *(robj *)(((dict *)setobj.ptr).ht[0].table[3].key)\n$88 = {type = 0, encoding = 0, lru = 1457112, refcount = 2, ptr = 0x7f58e3ccfb68} //refcount为2\n \n(gdb) p (char *)(((robj *)(((dict *)setobj.ptr).ht[0].table[3].key)).ptr)\n$89 = 0x7f58e3ccfb68 \"val\"                                  //值为val\n```\n\n2.smembers命令\n\n返回元素的时候，重点看返回时的代码\n\n```\n\n/* Add a Redis Object as a bulk reply */\nvoid addReplyBulk(redisClient *c, robj *obj) {\n    addReplyBulkLen(c,obj);\n    addReply(c,obj);\n    addReply(c,shared.crlf);\n}\n```\n\n会直接将robj对象作为返回参数\n\n并且客户端传入参数也是一个个robj对象，会直接作为值保存到对象中\n\n\n#### 共享时如何删除\n那么，共享对象在单线程情况下是如何删除的呢？\n\n看看del命令的实现\n\ndel调用dictDelete，最终调用每个数据类型自己的析构函数\n\n```\ndictFreeKey(d, he);\ndictFreeVal(d, he);\n```\n集合类型调用如下函数\n\n```\nvoid dictRedisObjectDestructor(void *privdata, void *val)\n{\n    DICT_NOTUSED(privdata);\n\n    if (val == NULL) return; /* Values of swapped out keys as set to NULL */\n    decrRefCount(val);\n}\n```\n\n可以看到，只是将值的refcount减1\n如何解决共享数据\n新版本如何解决了共享数据\n\n还是通过sunionstore和smembers命令看下这两处如何解决共享：\n\n以下代码使用redis 5.0.3版本介绍：\n\n```\nvoid saddCommand(client *c) {\n    ...\n    for (j = 2; j < c->argc; j++) {\n        if (setTypeAdd(set,c->argv[j]->ptr)) added++; //sadd的时候元素也变为了c->argv[j]->ptr,一个字符串\n    }\n\t...\n}\n \nint setTypeAdd(robj *subject, sds value) {//value是一个sds\n    long long llval;\n    if (subject->encoding == OBJ_ENCODING_HT) {\n        dict *ht = subject->ptr;\n        dictEntry *de = dictAddRaw(ht,value,NULL);\n        if (de) {\n            dictSetKey(ht,de,sdsdup(value));\n            dictSetVal(ht,de,NULL);\n            return 1;\n        }\n    }\n    return 0;\n}\n```\n增加值的时候已经变为了一个sds.\n\n现在的保存结构为：\n\n    key -> value_obj -> hash table -> sds_string\n而返回到客户端的时候也变为了一个sds,如下：\n\n```\n\naddReplyBulkCBuffer(c,elesds,sdslen(elesds));\n\nvoid addReplyBulkCBuffer(client *c, const void *p, size_t len) {\n    addReplyLongLongWithPrefix(c,len,'$');\n    addReplyString(c,p,len);\n    addReply(c,shared.crlf);\n}\n```\n\n#### 效果如何\n效果如何呢？\n\n首先取值的时候从robj的间接引用变为了一个sds的直接引用。\n\n其次减少了共享会增加内存的消耗，而使用了sds之后，每个sds的内存占用会比一个robj要小。我们看下antirez如何评价这个修改：\n\n```\n\nThe result is that Redis is now more memory efficient since there are no robj structures around in the implementation of the data structures (but they are used in the code paths where there is a lot of sharing going on, for example during the command dispatch and replication). \n...\nBut, the most interesting thing is, Redis is now faster in all the operations I tested so far. Less indirection was a real winner here. It is faster even in unrelated benchmarks just because the client output buffers are now simpler and faster.\n```\n\n说了两层意思，一是内存使用更加高效了\n\n二是更少的间接引用导致redis比以前更加快，而且客户端输出更加简洁和快速。\n\n### 异步线程\n异步线程的实现以后在详细描述\n\n问题\n\n1.多线程之间在堆上分配内存时会有争用。但是antirez说因为redis在内存分配上使用的时间极少，可以忽略这种情况。\n\n如何考虑这个问题？\n\n参考：https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads","slug":"Redis-懒删除-lazy-free-简史","published":1,"updated":"2019-02-19T06:33:28.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbb001fbms6e2p1dwdq","content":"<h2 id=\"Redis是单进程单线程模式吗\"><a href=\"#Redis是单进程单线程模式吗\" class=\"headerlink\" title=\"Redis是单进程单线程模式吗\"></a>Redis是单进程单线程模式吗</h2><p>下图为Redis5.0启动之后的效果。LWP为线程ID，NLWP为线程数量。可以看到，5.0的redis server共有四个线程，一个主线程48684，三个bio(background IO,后台io任务)线程，三个后台线程分别执行不同的io任务，我们重点考察删除一个key时的io线程执行。</p>\n<p><img src=\"/img/rl1.png\" alt=\"process\"></p>\n<p>Redis增加了异步删除命令unlink,防止删除大key时阻塞主线程。其原理为执行unlink时会将需要删除的数据挂到一个链表中，由专门的线程负责将其删除。而原来的del命令还是阻塞的。我们通过对一个有1000万条数据的集合分别执行del和unlink来观察其效果。</p>\n<h2 id=\"看一个大集合的删除\"><a href=\"#看一个大集合的删除\" class=\"headerlink\" title=\"看一个大集合的删除\"></a>看一个大集合的删除</h2><p>首先通过脚本生成一个有1000万个元素的集合testset，然后通过del命令删除，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:8888&gt;info//首先调用info命令查看内存消耗：</span><br><span class=\"line\"> </span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:857536</span><br><span class=\"line\">used_memory_human:837.44K</span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt; eval &quot;local i = tonumber(ARGV[1]);local res;math.randomseed(tonumber(ARGV[2]));while (i &gt; 0) do res = redis.call(&apos;sadd&apos;,KEYS[1],math.random());i = i-1;end&quot; 1  testset 10000000 2</span><br><span class=\"line\">(nil)</span><br><span class=\"line\">(18.51s)//创建耗时18.51s </span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:681063080</span><br><span class=\"line\">used_memory_human:649.51M</span><br><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; scard testset//查看集合中元素数量</span><br><span class=\"line\">(integer) 9976638 //通过math.random()生成，由于集合中不能有重复数据，可以看到，最终只有9976638条数据不重复。</span><br><span class=\"line\">127.0.0.1:8888&gt; sscan testset 0 //查看集合中的元素内容</span><br><span class=\"line\">1) &quot;3670016&quot;</span><br><span class=\"line\">2)  1) &quot;0.94438312106969913&quot;</span><br><span class=\"line\">    2) &quot;0.55726669754705704&quot;</span><br><span class=\"line\">    3) &quot;0.3246220281927949&quot;</span><br><span class=\"line\">    4) &quot;0.51470726752407259&quot;</span><br><span class=\"line\">    5) &quot;0.33469647464095453&quot;</span><br><span class=\"line\">    6) &quot;0.48387842554779648&quot;</span><br><span class=\"line\">    7) &quot;0.3680923377946449&quot;</span><br><span class=\"line\">    8) &quot;0.34466382877187052&quot;</span><br><span class=\"line\">    9) &quot;0.019202849370987551&quot;</span><br><span class=\"line\">   10) &quot;0.71412580307299545&quot;</span><br><span class=\"line\">   11) &quot;0.12846412375963484&quot;</span><br><span class=\"line\">   12) &quot;0.10548432828182557&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; del testset //调用del命令删除，耗时2.76s </span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">(2.76s) </span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:858568</span><br><span class=\"line\">used_memory_human:838.45K</span><br></pre></td></tr></table></figure>\n<p>重新做上边的实验,这次试用unlink来删除。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; unlink testset//unlink瞬间返回</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗。可以看到，返回之后testset并没有清理干净。内存仍然占用了大约一半，再经过1-2s,会清理干净</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:326898224</span><br><span class=\"line\">used_memory_human:311.75M</span><br></pre></td></tr></table></figure>\n<h2 id=\"尝试渐进式删除\"><a href=\"#尝试渐进式删除\" class=\"headerlink\" title=\"尝试渐进式删除\"></a>尝试渐进式删除</h2><p>参见:<a href=\"http://antirez.com/news/93\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/93</a></p>\n<p>为了解决这个问题，Redis作者Antirez首先考虑的是通过渐进式删除来解决。Redis也在很多地方用到了渐进式的策略，例如 lru eviction,key 过期以及渐进式rehash.原文如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">So this was the first thing I tried: create a new timer function, and perform the eviction there. Objects were just queued into a linked list, to be reclaimed slowly and incrementally each time the timer function was called. This requires some trick to work well. For example objects implemented with hash tables were also reclaimed incrementally using the same mechanism used inside Redis SCAN command: taking a cursor inside the dictionary and iterating it to free element after element. This way, in each timer call, we don’t have to free a whole hash table. The cursor will tell us where we left when we re-enter the timer function.</span><br></pre></td></tr></table></figure>\n<p>大意就是把要删除的对象放到一个链表中，起一个定期任务，每次只删除其中一部分。</p>\n<p>这会有什么问题呢，仍然看原文中说的一种案例:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WHILE 1</span><br><span class=\"line\">    SADD myset element1 element2 … many many many elements</span><br><span class=\"line\">    DEL myset</span><br><span class=\"line\">END</span><br></pre></td></tr></table></figure>\n<p>如果删除没有增加快，上边这种案例会导致内存暴涨.(虽然不知道什么情况下会有这种案例发生)。于是作者开始设计一种自适应性的删除,即通过判断内存是增加还是减少，来动态调整删除任务执行的频率，代码示例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/* Compute the memory trend, biased towards thinking memory is raising</span><br><span class=\"line\">    * for a few calls every time previous and current memory raise. */</span><br><span class=\"line\"></span><br><span class=\"line\">//只要内存有一次显示是增加的趋势，则接下来即使内存不再增加，还是会有连续六次mem_is_raising都是1，即判断为增加。</span><br><span class=\"line\">//注意mem_is_raising的值是根据mem_trend和0.1来比较。 即第一次0.9,第二次为0.9*0.9,第三次为0.81*0.81.第六次之后才会小于0.1  (勘误:应该为0.9^22 之后小于0.1)</span><br><span class=\"line\">//这也就是上边注释描述的会偏向于认为只要有一次内存是增加的，就会连续几次加快执行调用删除任务的频率</span><br><span class=\"line\">   if (prev_mem &lt; mem) mem_trend = 1; </span><br><span class=\"line\">   mem_trend *= 0.9; /* Make it slowly forget. */</span><br><span class=\"line\">   int mem_is_raising = mem_trend &gt; .1;</span><br><span class=\"line\"></span><br><span class=\"line\">//删除一些数据</span><br><span class=\"line\">   /* Free a few items. */</span><br><span class=\"line\">   size_t workdone = lazyfreeStep(LAZYFREE_STEP_SLOW);</span><br><span class=\"line\"></span><br><span class=\"line\">//动态调整执行频率</span><br><span class=\"line\">   /* Adjust this timer call frequency according to the current state. */</span><br><span class=\"line\">   if (workdone) &#123;</span><br><span class=\"line\">       if (timer_period == 1000) timer_period = 20;</span><br><span class=\"line\">       if (mem_is_raising &amp;&amp; timer_period &gt; 3)//如果内存在增加，就加大执行频率</span><br><span class=\"line\">           timer_period--; /* Raise call frequency. */</span><br><span class=\"line\">       else if (!mem_is_raising &amp;&amp; timer_period &lt; 20)</span><br><span class=\"line\">           timer_period++; /* Lower call frequency. *///否则减小频率</span><br><span class=\"line\">   &#125; else &#123;</span><br><span class=\"line\">       timer_period = 1000;    /* 1 HZ */</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>这种方法有个缺陷，因为毕竟是在一个线程中，当回收的特别频繁时，会降低redis的qps,qps只能达到正常情况下的65%.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">when the lazy free cycle was very busy, operations per second were reduced to around 65% of the norm</span><br></pre></td></tr></table></figure>\n<p>于是redis作者antirez开始考虑异步线程回收。</p>\n<h2 id=\"异步线程\"><a href=\"#异步线程\" class=\"headerlink\" title=\"异步线程\"></a>异步线程</h2><h3 id=\"共享对象\"><a href=\"#共享对象\" class=\"headerlink\" title=\"共享对象\"></a>共享对象</h3><h4 id=\"异步线程为何不能有共享数据\"><a href=\"#异步线程为何不能有共享数据\" class=\"headerlink\" title=\"异步线程为何不能有共享数据\"></a>异步线程为何不能有共享数据</h4><p>共享数据越多，多线程之间发生争用的可能性越大。所以为了性能，必须首先将共享数据消灭掉。</p>\n<p>那么redis在什么地方会用到共享数据呢</p>\n<h4 id=\"如何共享\"><a href=\"#如何共享\" class=\"headerlink\" title=\"如何共享\"></a>如何共享</h4><p>如下代码示例为Redis2.8.24.</p>\n<p>先看执行sadd时底层数据是如何保存的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sadd testset val1</span><br></pre></td></tr></table></figure>\n<p>底层保存如下(gdb过程如下，比较晦涩,参考下文解释)：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">254\t    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">255\t    if (set == NULL) &#123;</span><br><span class=\"line\">(gdb) p c-&gt;argv[1]</span><br><span class=\"line\">$1 = (robj *) 0x7f58e3ccfcc0</span><br><span class=\"line\">(gdb) p *c-&gt;argv[1]</span><br><span class=\"line\">$2 = &#123;type = 0, encoding = 0, lru = 1367521, refcount = 1, ptr = 0x7f58e3ccfcd8&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) p (char *)c-&gt;argv[1].ptr //client中的argv是一个个robj,argv[1]的ptr中存储着key值&apos;testset&apos;</span><br><span class=\"line\">$4 = 0x7f58e3ccfcd8 &quot;testset&quot;</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">254\t    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">255\t    if (set == NULL) &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">(gdb) p (char *)((robj *)((dict *)set.ptr).ht[0].table[3].key).ptr</span><br><span class=\"line\">$37 = 0x7f58e3ccfcb8 &quot;val1&quot; //值val1保存在一个dict中，dict保存着一个个dictEntry,dictEntry的key是一个指针，指向一个robj,robj中是具体的值</span><br></pre></td></tr></table></figure>\n<p>通过下文结构体讲解，可以看下sadd testset val1,testset和val1保存在什么地方</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef struct dict &#123;</span><br><span class=\"line\">    dictType *type;</span><br><span class=\"line\">    void *privdata;</span><br><span class=\"line\">    dictht ht[2];</span><br><span class=\"line\">    long rehashidx; /* rehashing not in progress if rehashidx == -1 */</span><br><span class=\"line\">    int iterators; /* number of iterators currently running */</span><br><span class=\"line\">&#125; dict;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"> </span><br><span class=\"line\">typedef struct dictht &#123;</span><br><span class=\"line\">    dictEntry **table;</span><br><span class=\"line\">    unsigned long size;</span><br><span class=\"line\">    unsigned long sizemask;</span><br><span class=\"line\">    unsigned long used;</span><br><span class=\"line\">&#125; dictht;</span><br><span class=\"line\"></span><br><span class=\"line\">typedef struct dictEntry &#123;</span><br><span class=\"line\">    void *key;</span><br><span class=\"line\">    union &#123;</span><br><span class=\"line\">        void *val;</span><br><span class=\"line\">        uint64_t u64;</span><br><span class=\"line\">        int64_t s64;</span><br><span class=\"line\">        double d;</span><br><span class=\"line\">    &#125; v;</span><br><span class=\"line\">    struct dictEntry *next;</span><br><span class=\"line\">&#125; dictEntry;</span><br><span class=\"line\"> </span><br><span class=\"line\">typedef struct redisObject &#123;</span><br><span class=\"line\">    unsigned type:4;</span><br><span class=\"line\">    unsigned encoding:4;</span><br><span class=\"line\">    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */</span><br><span class=\"line\">    int refcount;</span><br><span class=\"line\">    void *ptr;</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>首先所有的key保存在一个dict.ht[0]的dictht结构体中。通过上边的结构体看到，dictht中的table是一个dictEntry二级指针。</p>\n</li>\n<li><p>执行sadd testset val1时，testset是其中一个dictEntry中的key,key是一个void<em>指针，实际存储情况为testset保存为一个char </em>类型</p>\n</li>\n<li><p>假设testset经过哈希之后index为3，则dict.ht[0].table[3].key为testset,dict.ht[0].table[3].v.val为一个void<em>指针，实际存储一个robj </em>类型</p>\n</li>\n<li><p>第三步中的robj中有个ptr指针，指向一个dict类型。dict中的其中一个entry的key指向另一个robj指针，该指针的ptr指向val</p>\n</li>\n</ul>\n<p>即获取一个值的流程为：</p>\n<pre><code>key -&gt; value_obj -&gt; hash table -&gt; robj -&gt; sds_string\n</code></pre><p>然后看两个共享对象的典型场景：</p>\n<p>1.sunionstore命令</p>\n<p>看下代码实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">int setTypeAdd(robj *subject, robj *value) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    if (subject-&gt;encoding == REDIS_ENCODING_HT) &#123;</span><br><span class=\"line\">        if (dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK) &#123;</span><br><span class=\"line\">            incrRefCount(value);//此处的value值由于是从已存在的集合中直接取出，refcount已经是1，此处并没有新建robj,而是直接将引用计数加1</span><br><span class=\"line\">            return 1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行以下命令：</p>\n<p>sadd testset1 value2</p>\n<p>sunionstore set testset1 testset2 //即将testset1和testset2的元素取并集并保存到set中</p>\n<p>然后我们可以通过查看testset的元素，看看其引用计数是否变为了2</p>\n<p>smembers testset</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">(gdb) p *(robj *)(((dict *)setobj.ptr).ht[0].table[3].key)</span><br><span class=\"line\">$88 = &#123;type = 0, encoding = 0, lru = 1457112, refcount = 2, ptr = 0x7f58e3ccfb68&#125; //refcount为2</span><br><span class=\"line\"> </span><br><span class=\"line\">(gdb) p (char *)(((robj *)(((dict *)setobj.ptr).ht[0].table[3].key)).ptr)</span><br><span class=\"line\">$89 = 0x7f58e3ccfb68 &quot;val&quot;                                  //值为val</span><br></pre></td></tr></table></figure>\n<p>2.smembers命令</p>\n<p>返回元素的时候，重点看返回时的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">/* Add a Redis Object as a bulk reply */</span><br><span class=\"line\">void addReplyBulk(redisClient *c, robj *obj) &#123;</span><br><span class=\"line\">    addReplyBulkLen(c,obj);</span><br><span class=\"line\">    addReply(c,obj);</span><br><span class=\"line\">    addReply(c,shared.crlf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>会直接将robj对象作为返回参数</p>\n<p>并且客户端传入参数也是一个个robj对象，会直接作为值保存到对象中</p>\n<h4 id=\"共享时如何删除\"><a href=\"#共享时如何删除\" class=\"headerlink\" title=\"共享时如何删除\"></a>共享时如何删除</h4><p>那么，共享对象在单线程情况下是如何删除的呢？</p>\n<p>看看del命令的实现</p>\n<p>del调用dictDelete，最终调用每个数据类型自己的析构函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dictFreeKey(d, he);</span><br><span class=\"line\">dictFreeVal(d, he);</span><br></pre></td></tr></table></figure>\n<p>集合类型调用如下函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void dictRedisObjectDestructor(void *privdata, void *val)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    DICT_NOTUSED(privdata);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (val == NULL) return; /* Values of swapped out keys as set to NULL */</span><br><span class=\"line\">    decrRefCount(val);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，只是将值的refcount减1<br>如何解决共享数据<br>新版本如何解决了共享数据</p>\n<p>还是通过sunionstore和smembers命令看下这两处如何解决共享：</p>\n<p>以下代码使用redis 5.0.3版本介绍：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void saddCommand(client *c) &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    for (j = 2; j &lt; c-&gt;argc; j++) &#123;</span><br><span class=\"line\">        if (setTypeAdd(set,c-&gt;argv[j]-&gt;ptr)) added++; //sadd的时候元素也变为了c-&gt;argv[j]-&gt;ptr,一个字符串</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">int setTypeAdd(robj *subject, sds value) &#123;//value是一个sds</span><br><span class=\"line\">    long long llval;</span><br><span class=\"line\">    if (subject-&gt;encoding == OBJ_ENCODING_HT) &#123;</span><br><span class=\"line\">        dict *ht = subject-&gt;ptr;</span><br><span class=\"line\">        dictEntry *de = dictAddRaw(ht,value,NULL);</span><br><span class=\"line\">        if (de) &#123;</span><br><span class=\"line\">            dictSetKey(ht,de,sdsdup(value));</span><br><span class=\"line\">            dictSetVal(ht,de,NULL);</span><br><span class=\"line\">            return 1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>增加值的时候已经变为了一个sds.</p>\n<p>现在的保存结构为：</p>\n<pre><code>key -&gt; value_obj -&gt; hash table -&gt; sds_string\n</code></pre><p>而返回到客户端的时候也变为了一个sds,如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">addReplyBulkCBuffer(c,elesds,sdslen(elesds));</span><br><span class=\"line\"></span><br><span class=\"line\">void addReplyBulkCBuffer(client *c, const void *p, size_t len) &#123;</span><br><span class=\"line\">    addReplyLongLongWithPrefix(c,len,&apos;$&apos;);</span><br><span class=\"line\">    addReplyString(c,p,len);</span><br><span class=\"line\">    addReply(c,shared.crlf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"效果如何\"><a href=\"#效果如何\" class=\"headerlink\" title=\"效果如何\"></a>效果如何</h4><p>效果如何呢？</p>\n<p>首先取值的时候从robj的间接引用变为了一个sds的直接引用。</p>\n<p>其次减少了共享会增加内存的消耗，而使用了sds之后，每个sds的内存占用会比一个robj要小。我们看下antirez如何评价这个修改：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">The result is that Redis is now more memory efficient since there are no robj structures around in the implementation of the data structures (but they are used in the code paths where there is a lot of sharing going on, for example during the command dispatch and replication). </span><br><span class=\"line\">...</span><br><span class=\"line\">But, the most interesting thing is, Redis is now faster in all the operations I tested so far. Less indirection was a real winner here. It is faster even in unrelated benchmarks just because the client output buffers are now simpler and faster.</span><br></pre></td></tr></table></figure>\n<p>说了两层意思，一是内存使用更加高效了</p>\n<p>二是更少的间接引用导致redis比以前更加快，而且客户端输出更加简洁和快速。</p>\n<h3 id=\"异步线程-1\"><a href=\"#异步线程-1\" class=\"headerlink\" title=\"异步线程\"></a>异步线程</h3><p>异步线程的实现以后在详细描述</p>\n<p>问题</p>\n<p>1.多线程之间在堆上分配内存时会有争用。但是antirez说因为redis在内存分配上使用的时间极少，可以忽略这种情况。</p>\n<p>如何考虑这个问题？</p>\n<p>参考：<a href=\"https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads\" target=\"_blank\" rel=\"noopener\">https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Redis是单进程单线程模式吗\"><a href=\"#Redis是单进程单线程模式吗\" class=\"headerlink\" title=\"Redis是单进程单线程模式吗\"></a>Redis是单进程单线程模式吗</h2><p>下图为Redis5.0启动之后的效果。LWP为线程ID，NLWP为线程数量。可以看到，5.0的redis server共有四个线程，一个主线程48684，三个bio(background IO,后台io任务)线程，三个后台线程分别执行不同的io任务，我们重点考察删除一个key时的io线程执行。</p>\n<p><img src=\"/img/rl1.png\" alt=\"process\"></p>\n<p>Redis增加了异步删除命令unlink,防止删除大key时阻塞主线程。其原理为执行unlink时会将需要删除的数据挂到一个链表中，由专门的线程负责将其删除。而原来的del命令还是阻塞的。我们通过对一个有1000万条数据的集合分别执行del和unlink来观察其效果。</p>\n<h2 id=\"看一个大集合的删除\"><a href=\"#看一个大集合的删除\" class=\"headerlink\" title=\"看一个大集合的删除\"></a>看一个大集合的删除</h2><p>首先通过脚本生成一个有1000万个元素的集合testset，然后通过del命令删除，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:8888&gt;info//首先调用info命令查看内存消耗：</span><br><span class=\"line\"> </span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:857536</span><br><span class=\"line\">used_memory_human:837.44K</span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt; eval &quot;local i = tonumber(ARGV[1]);local res;math.randomseed(tonumber(ARGV[2]));while (i &gt; 0) do res = redis.call(&apos;sadd&apos;,KEYS[1],math.random());i = i-1;end&quot; 1  testset 10000000 2</span><br><span class=\"line\">(nil)</span><br><span class=\"line\">(18.51s)//创建耗时18.51s </span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:681063080</span><br><span class=\"line\">used_memory_human:649.51M</span><br><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; scard testset//查看集合中元素数量</span><br><span class=\"line\">(integer) 9976638 //通过math.random()生成，由于集合中不能有重复数据，可以看到，最终只有9976638条数据不重复。</span><br><span class=\"line\">127.0.0.1:8888&gt; sscan testset 0 //查看集合中的元素内容</span><br><span class=\"line\">1) &quot;3670016&quot;</span><br><span class=\"line\">2)  1) &quot;0.94438312106969913&quot;</span><br><span class=\"line\">    2) &quot;0.55726669754705704&quot;</span><br><span class=\"line\">    3) &quot;0.3246220281927949&quot;</span><br><span class=\"line\">    4) &quot;0.51470726752407259&quot;</span><br><span class=\"line\">    5) &quot;0.33469647464095453&quot;</span><br><span class=\"line\">    6) &quot;0.48387842554779648&quot;</span><br><span class=\"line\">    7) &quot;0.3680923377946449&quot;</span><br><span class=\"line\">    8) &quot;0.34466382877187052&quot;</span><br><span class=\"line\">    9) &quot;0.019202849370987551&quot;</span><br><span class=\"line\">   10) &quot;0.71412580307299545&quot;</span><br><span class=\"line\">   11) &quot;0.12846412375963484&quot;</span><br><span class=\"line\">   12) &quot;0.10548432828182557&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; del testset //调用del命令删除，耗时2.76s </span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">(2.76s) </span><br><span class=\"line\"> </span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:858568</span><br><span class=\"line\">used_memory_human:838.45K</span><br></pre></td></tr></table></figure>\n<p>重新做上边的实验,这次试用unlink来删除。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">127.0.0.1:8888&gt; unlink testset//unlink瞬间返回</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:8888&gt;info//再次查看内存消耗。可以看到，返回之后testset并没有清理干净。内存仍然占用了大约一半，再经过1-2s,会清理干净</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:326898224</span><br><span class=\"line\">used_memory_human:311.75M</span><br></pre></td></tr></table></figure>\n<h2 id=\"尝试渐进式删除\"><a href=\"#尝试渐进式删除\" class=\"headerlink\" title=\"尝试渐进式删除\"></a>尝试渐进式删除</h2><p>参见:<a href=\"http://antirez.com/news/93\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/93</a></p>\n<p>为了解决这个问题，Redis作者Antirez首先考虑的是通过渐进式删除来解决。Redis也在很多地方用到了渐进式的策略，例如 lru eviction,key 过期以及渐进式rehash.原文如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">So this was the first thing I tried: create a new timer function, and perform the eviction there. Objects were just queued into a linked list, to be reclaimed slowly and incrementally each time the timer function was called. This requires some trick to work well. For example objects implemented with hash tables were also reclaimed incrementally using the same mechanism used inside Redis SCAN command: taking a cursor inside the dictionary and iterating it to free element after element. This way, in each timer call, we don’t have to free a whole hash table. The cursor will tell us where we left when we re-enter the timer function.</span><br></pre></td></tr></table></figure>\n<p>大意就是把要删除的对象放到一个链表中，起一个定期任务，每次只删除其中一部分。</p>\n<p>这会有什么问题呢，仍然看原文中说的一种案例:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WHILE 1</span><br><span class=\"line\">    SADD myset element1 element2 … many many many elements</span><br><span class=\"line\">    DEL myset</span><br><span class=\"line\">END</span><br></pre></td></tr></table></figure>\n<p>如果删除没有增加快，上边这种案例会导致内存暴涨.(虽然不知道什么情况下会有这种案例发生)。于是作者开始设计一种自适应性的删除,即通过判断内存是增加还是减少，来动态调整删除任务执行的频率，代码示例如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/* Compute the memory trend, biased towards thinking memory is raising</span><br><span class=\"line\">    * for a few calls every time previous and current memory raise. */</span><br><span class=\"line\"></span><br><span class=\"line\">//只要内存有一次显示是增加的趋势，则接下来即使内存不再增加，还是会有连续六次mem_is_raising都是1，即判断为增加。</span><br><span class=\"line\">//注意mem_is_raising的值是根据mem_trend和0.1来比较。 即第一次0.9,第二次为0.9*0.9,第三次为0.81*0.81.第六次之后才会小于0.1  (勘误:应该为0.9^22 之后小于0.1)</span><br><span class=\"line\">//这也就是上边注释描述的会偏向于认为只要有一次内存是增加的，就会连续几次加快执行调用删除任务的频率</span><br><span class=\"line\">   if (prev_mem &lt; mem) mem_trend = 1; </span><br><span class=\"line\">   mem_trend *= 0.9; /* Make it slowly forget. */</span><br><span class=\"line\">   int mem_is_raising = mem_trend &gt; .1;</span><br><span class=\"line\"></span><br><span class=\"line\">//删除一些数据</span><br><span class=\"line\">   /* Free a few items. */</span><br><span class=\"line\">   size_t workdone = lazyfreeStep(LAZYFREE_STEP_SLOW);</span><br><span class=\"line\"></span><br><span class=\"line\">//动态调整执行频率</span><br><span class=\"line\">   /* Adjust this timer call frequency according to the current state. */</span><br><span class=\"line\">   if (workdone) &#123;</span><br><span class=\"line\">       if (timer_period == 1000) timer_period = 20;</span><br><span class=\"line\">       if (mem_is_raising &amp;&amp; timer_period &gt; 3)//如果内存在增加，就加大执行频率</span><br><span class=\"line\">           timer_period--; /* Raise call frequency. */</span><br><span class=\"line\">       else if (!mem_is_raising &amp;&amp; timer_period &lt; 20)</span><br><span class=\"line\">           timer_period++; /* Lower call frequency. *///否则减小频率</span><br><span class=\"line\">   &#125; else &#123;</span><br><span class=\"line\">       timer_period = 1000;    /* 1 HZ */</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>这种方法有个缺陷，因为毕竟是在一个线程中，当回收的特别频繁时，会降低redis的qps,qps只能达到正常情况下的65%.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">when the lazy free cycle was very busy, operations per second were reduced to around 65% of the norm</span><br></pre></td></tr></table></figure>\n<p>于是redis作者antirez开始考虑异步线程回收。</p>\n<h2 id=\"异步线程\"><a href=\"#异步线程\" class=\"headerlink\" title=\"异步线程\"></a>异步线程</h2><h3 id=\"共享对象\"><a href=\"#共享对象\" class=\"headerlink\" title=\"共享对象\"></a>共享对象</h3><h4 id=\"异步线程为何不能有共享数据\"><a href=\"#异步线程为何不能有共享数据\" class=\"headerlink\" title=\"异步线程为何不能有共享数据\"></a>异步线程为何不能有共享数据</h4><p>共享数据越多，多线程之间发生争用的可能性越大。所以为了性能，必须首先将共享数据消灭掉。</p>\n<p>那么redis在什么地方会用到共享数据呢</p>\n<h4 id=\"如何共享\"><a href=\"#如何共享\" class=\"headerlink\" title=\"如何共享\"></a>如何共享</h4><p>如下代码示例为Redis2.8.24.</p>\n<p>先看执行sadd时底层数据是如何保存的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sadd testset val1</span><br></pre></td></tr></table></figure>\n<p>底层保存如下(gdb过程如下，比较晦涩,参考下文解释)：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">254\t    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">255\t    if (set == NULL) &#123;</span><br><span class=\"line\">(gdb) p c-&gt;argv[1]</span><br><span class=\"line\">$1 = (robj *) 0x7f58e3ccfcc0</span><br><span class=\"line\">(gdb) p *c-&gt;argv[1]</span><br><span class=\"line\">$2 = &#123;type = 0, encoding = 0, lru = 1367521, refcount = 1, ptr = 0x7f58e3ccfcd8&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">(gdb) p (char *)c-&gt;argv[1].ptr //client中的argv是一个个robj,argv[1]的ptr中存储着key值&apos;testset&apos;</span><br><span class=\"line\">$4 = 0x7f58e3ccfcd8 &quot;testset&quot;</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">254\t    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);</span><br><span class=\"line\">(gdb) n</span><br><span class=\"line\">255\t    if (set == NULL) &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">(gdb) p (char *)((robj *)((dict *)set.ptr).ht[0].table[3].key).ptr</span><br><span class=\"line\">$37 = 0x7f58e3ccfcb8 &quot;val1&quot; //值val1保存在一个dict中，dict保存着一个个dictEntry,dictEntry的key是一个指针，指向一个robj,robj中是具体的值</span><br></pre></td></tr></table></figure>\n<p>通过下文结构体讲解，可以看下sadd testset val1,testset和val1保存在什么地方</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef struct dict &#123;</span><br><span class=\"line\">    dictType *type;</span><br><span class=\"line\">    void *privdata;</span><br><span class=\"line\">    dictht ht[2];</span><br><span class=\"line\">    long rehashidx; /* rehashing not in progress if rehashidx == -1 */</span><br><span class=\"line\">    int iterators; /* number of iterators currently running */</span><br><span class=\"line\">&#125; dict;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"> </span><br><span class=\"line\">typedef struct dictht &#123;</span><br><span class=\"line\">    dictEntry **table;</span><br><span class=\"line\">    unsigned long size;</span><br><span class=\"line\">    unsigned long sizemask;</span><br><span class=\"line\">    unsigned long used;</span><br><span class=\"line\">&#125; dictht;</span><br><span class=\"line\"></span><br><span class=\"line\">typedef struct dictEntry &#123;</span><br><span class=\"line\">    void *key;</span><br><span class=\"line\">    union &#123;</span><br><span class=\"line\">        void *val;</span><br><span class=\"line\">        uint64_t u64;</span><br><span class=\"line\">        int64_t s64;</span><br><span class=\"line\">        double d;</span><br><span class=\"line\">    &#125; v;</span><br><span class=\"line\">    struct dictEntry *next;</span><br><span class=\"line\">&#125; dictEntry;</span><br><span class=\"line\"> </span><br><span class=\"line\">typedef struct redisObject &#123;</span><br><span class=\"line\">    unsigned type:4;</span><br><span class=\"line\">    unsigned encoding:4;</span><br><span class=\"line\">    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */</span><br><span class=\"line\">    int refcount;</span><br><span class=\"line\">    void *ptr;</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>首先所有的key保存在一个dict.ht[0]的dictht结构体中。通过上边的结构体看到，dictht中的table是一个dictEntry二级指针。</p>\n</li>\n<li><p>执行sadd testset val1时，testset是其中一个dictEntry中的key,key是一个void<em>指针，实际存储情况为testset保存为一个char </em>类型</p>\n</li>\n<li><p>假设testset经过哈希之后index为3，则dict.ht[0].table[3].key为testset,dict.ht[0].table[3].v.val为一个void<em>指针，实际存储一个robj </em>类型</p>\n</li>\n<li><p>第三步中的robj中有个ptr指针，指向一个dict类型。dict中的其中一个entry的key指向另一个robj指针，该指针的ptr指向val</p>\n</li>\n</ul>\n<p>即获取一个值的流程为：</p>\n<pre><code>key -&gt; value_obj -&gt; hash table -&gt; robj -&gt; sds_string\n</code></pre><p>然后看两个共享对象的典型场景：</p>\n<p>1.sunionstore命令</p>\n<p>看下代码实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">int setTypeAdd(robj *subject, robj *value) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    if (subject-&gt;encoding == REDIS_ENCODING_HT) &#123;</span><br><span class=\"line\">        if (dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK) &#123;</span><br><span class=\"line\">            incrRefCount(value);//此处的value值由于是从已存在的集合中直接取出，refcount已经是1，此处并没有新建robj,而是直接将引用计数加1</span><br><span class=\"line\">            return 1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行以下命令：</p>\n<p>sadd testset1 value2</p>\n<p>sunionstore set testset1 testset2 //即将testset1和testset2的元素取并集并保存到set中</p>\n<p>然后我们可以通过查看testset的元素，看看其引用计数是否变为了2</p>\n<p>smembers testset</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">(gdb) p *(robj *)(((dict *)setobj.ptr).ht[0].table[3].key)</span><br><span class=\"line\">$88 = &#123;type = 0, encoding = 0, lru = 1457112, refcount = 2, ptr = 0x7f58e3ccfb68&#125; //refcount为2</span><br><span class=\"line\"> </span><br><span class=\"line\">(gdb) p (char *)(((robj *)(((dict *)setobj.ptr).ht[0].table[3].key)).ptr)</span><br><span class=\"line\">$89 = 0x7f58e3ccfb68 &quot;val&quot;                                  //值为val</span><br></pre></td></tr></table></figure>\n<p>2.smembers命令</p>\n<p>返回元素的时候，重点看返回时的代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">/* Add a Redis Object as a bulk reply */</span><br><span class=\"line\">void addReplyBulk(redisClient *c, robj *obj) &#123;</span><br><span class=\"line\">    addReplyBulkLen(c,obj);</span><br><span class=\"line\">    addReply(c,obj);</span><br><span class=\"line\">    addReply(c,shared.crlf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>会直接将robj对象作为返回参数</p>\n<p>并且客户端传入参数也是一个个robj对象，会直接作为值保存到对象中</p>\n<h4 id=\"共享时如何删除\"><a href=\"#共享时如何删除\" class=\"headerlink\" title=\"共享时如何删除\"></a>共享时如何删除</h4><p>那么，共享对象在单线程情况下是如何删除的呢？</p>\n<p>看看del命令的实现</p>\n<p>del调用dictDelete，最终调用每个数据类型自己的析构函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dictFreeKey(d, he);</span><br><span class=\"line\">dictFreeVal(d, he);</span><br></pre></td></tr></table></figure>\n<p>集合类型调用如下函数</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void dictRedisObjectDestructor(void *privdata, void *val)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    DICT_NOTUSED(privdata);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (val == NULL) return; /* Values of swapped out keys as set to NULL */</span><br><span class=\"line\">    decrRefCount(val);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，只是将值的refcount减1<br>如何解决共享数据<br>新版本如何解决了共享数据</p>\n<p>还是通过sunionstore和smembers命令看下这两处如何解决共享：</p>\n<p>以下代码使用redis 5.0.3版本介绍：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void saddCommand(client *c) &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    for (j = 2; j &lt; c-&gt;argc; j++) &#123;</span><br><span class=\"line\">        if (setTypeAdd(set,c-&gt;argv[j]-&gt;ptr)) added++; //sadd的时候元素也变为了c-&gt;argv[j]-&gt;ptr,一个字符串</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">int setTypeAdd(robj *subject, sds value) &#123;//value是一个sds</span><br><span class=\"line\">    long long llval;</span><br><span class=\"line\">    if (subject-&gt;encoding == OBJ_ENCODING_HT) &#123;</span><br><span class=\"line\">        dict *ht = subject-&gt;ptr;</span><br><span class=\"line\">        dictEntry *de = dictAddRaw(ht,value,NULL);</span><br><span class=\"line\">        if (de) &#123;</span><br><span class=\"line\">            dictSetKey(ht,de,sdsdup(value));</span><br><span class=\"line\">            dictSetVal(ht,de,NULL);</span><br><span class=\"line\">            return 1;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return 0;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>增加值的时候已经变为了一个sds.</p>\n<p>现在的保存结构为：</p>\n<pre><code>key -&gt; value_obj -&gt; hash table -&gt; sds_string\n</code></pre><p>而返回到客户端的时候也变为了一个sds,如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">addReplyBulkCBuffer(c,elesds,sdslen(elesds));</span><br><span class=\"line\"></span><br><span class=\"line\">void addReplyBulkCBuffer(client *c, const void *p, size_t len) &#123;</span><br><span class=\"line\">    addReplyLongLongWithPrefix(c,len,&apos;$&apos;);</span><br><span class=\"line\">    addReplyString(c,p,len);</span><br><span class=\"line\">    addReply(c,shared.crlf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"效果如何\"><a href=\"#效果如何\" class=\"headerlink\" title=\"效果如何\"></a>效果如何</h4><p>效果如何呢？</p>\n<p>首先取值的时候从robj的间接引用变为了一个sds的直接引用。</p>\n<p>其次减少了共享会增加内存的消耗，而使用了sds之后，每个sds的内存占用会比一个robj要小。我们看下antirez如何评价这个修改：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">The result is that Redis is now more memory efficient since there are no robj structures around in the implementation of the data structures (but they are used in the code paths where there is a lot of sharing going on, for example during the command dispatch and replication). </span><br><span class=\"line\">...</span><br><span class=\"line\">But, the most interesting thing is, Redis is now faster in all the operations I tested so far. Less indirection was a real winner here. It is faster even in unrelated benchmarks just because the client output buffers are now simpler and faster.</span><br></pre></td></tr></table></figure>\n<p>说了两层意思，一是内存使用更加高效了</p>\n<p>二是更少的间接引用导致redis比以前更加快，而且客户端输出更加简洁和快速。</p>\n<h3 id=\"异步线程-1\"><a href=\"#异步线程-1\" class=\"headerlink\" title=\"异步线程\"></a>异步线程</h3><p>异步线程的实现以后在详细描述</p>\n<p>问题</p>\n<p>1.多线程之间在堆上分配内存时会有争用。但是antirez说因为redis在内存分配上使用的时间极少，可以忽略这种情况。</p>\n<p>如何考虑这个问题？</p>\n<p>参考：<a href=\"https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads\" target=\"_blank\" rel=\"noopener\">https://software.intel.com/zh-cn/articles/avoiding-heap-contention-among-threads</a></p>\n"},{"title":"Redis中的lru算法实现","date":"2018-12-21T05:54:13.000Z","_content":"## lru是什么\nlru(least recently used)是一种缓存置换算法。即在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。因为缓存是否可能被访问到没法做预测，所以基于如下假设实现该算法:\n\n**如果一个key经常被访问，那么该key的idle time应该是最小的**。\n\n(但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)\n\n这也就是lru的实现思路。首先实现一个双向链表,每次有一个key被访问之后，就把被访问的key放到链表的头部。当缓存不够时,直接从尾部逐个摘除。\n\n在这种假设下的实现方法很明显会有一个问题，例如mysql中执行如下一条语句:\n\n```sql\nselect * from table_a;\n```\n\n如果table_a中有大量数据并且读取之后不会继续使用,则lru头部会被大量的table_a中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io\n\nmysql innodb的buffer pool使用了一种改进的lru算法，大意是将lru链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，再次访问时才会移动到newlist.具体参考如下文章:\n\nhttps://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html\n\n而Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。他认为既然lru本来就是基于假设做出的算法，为什么不能模拟实现一个lru呢。\n\n## Redis中的实现\n首先Redis并没有使用双向链表实现一个lru算法。具体实现方法接下来逐步介绍\n\n首先看一下robj结构体(Redis整体上是一个大的dict,key是一个string,而value都会保存为一个robj)\n\n```c\n\ntypedef struct redisObject {\n\t...\n    unsigned lru:LRU_BITS; //LRU_BITS为24bit\n\t...\n} robj;\n\n```\n\n我们看到每个robj中都有一个24bit长度的lru字段，lru字段里边保存的是一个时间戳。看下边的代码\n\n```c\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n\t...\n\t        if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) { //如果配置的是lfu方式，则更新lfu\n                updateLFU(val);\n            } else {\n                val->lru = LRU_CLOCK();//否则按lru方式更新\n            }\n\t...\n}\n```\n在Redis的dict中每次按key获取一个值的时候，都会调用lookupKey函数,如果配置使用了lru模式,该函数会更新value中的lru字段为当前秒级别的时间戳(lfu方式后文再描述)。\n\n那么，虽然记录了每个value的时间戳，但是淘汰时总不能挨个遍历dict中的所有槽，逐个比较lru大小吧。\n\nRedis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。(随机选取的key是个可配置的参数maxmemory-samples,默认值为5).\n\n在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。\n\n淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。\n\n我们知道Redis执行命令时首先会调用processCommand函数，在processCommand中会进行key的淘汰，代码如下:\n\n```c\n\nint processCommmand(){\n\t...\n    if (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = freeMemoryIfNeeded() == C_ERR;//如果开启了maxmemory的限制,则会调用freeMemoryIfNeeded()函数，该函数中进行缓存的淘汰\n\t...\n    }\n}\n\n```\n\n可以看到，lru本身是基于概率的猜测，这个算法也是基于概率的猜测，也就是作者说的模拟lru.那么效果如何呢？作者做了个实验，如下图所示\n\n![lru](/img/lru1.png)\n\n首先加入n个key并顺序访问这n个key,之后加入n/2个key（假设redis中只能保存n个key,于是会有n/2个key被逐出）.上图中浅灰色为被逐出的key,淡蓝色是新增加的key,灰色的为最近被访问的key(即不会被lru逐出的key)\n\n左上图为理想中的lru算法,新增加的key和最近被访问的key都不应该被逐出。\n\n可以看到,Redis2.8当每次随机采样5个key时，新增加的key和最近访问的key都有一定概率被逐出\n\nRedis3.0增加了pool后效果好一些(右下角的图)。当Redis3.0增加了pool并且将采样key增加到10个后，基本等同于理想中的lru(虽然还是有一点差距)\n\n如果继续增加采样的key或者pool的大小，作者发现很能进一步优化lru算法,于是作者开始转换思路。\n\n上文介绍了实现lru的一种思路,即**如果一个key经常被访问，那么该key的idle time应该是最小的**\n\n那么能不能换一种思路呢。**如果能够记录一个key被访问的次数,那么经常被访问的key最有可能再次被访问到。这也就是lfu(least frequently used),访问次数最少的最应该被逐出**\n\nlfu的代码如下:\n\n```c\nvoid updateLFU(robj *val) {\n    unsigned long counter = LFUDecrAndReturn(val);//首先计算是否需要将counter衰减\n    counter = LFULogIncr(counter);//根据上述返回的counter计算新的counter\n    val->lru = (LFUGetTimeInMinutes()<<8) | counter; //robj中的lru字段只有24bits,lfu复用该字段。高16位存储一个分钟数级别的时间戳，低8位存储访问计数\n}\n \nunsigned long LFUDecrAndReturn(robj *o) {\n    unsigned long ldt = o->lru >> 8;//原来保存的时间戳\n    unsigned long counter = o->lru & 255; //原来保存的counter\n    unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;\n    //server.lfu_decay_time默认为1,每经过一分钟counter衰减1\n    if (num_periods)\n        counter = (num_periods > counter) ? 0 : counter - num_periods;//如果需要衰减,则计算衰减后的值\n    return counter;\n}\n \nuint8_t LFULogIncr(uint8_t counter) {\n    if (counter == 255) return 255;//counter最大只能存储到255,到达后不再增加\n    double r = (double)rand()/RAND_MAX;//算一个随机的小数值\n    double baseval = counter - LFU_INIT_VAL;//新加入的key初始counter设置为LFU_INIT_VAL,为5.不设置为0的原因是防止直接被逐出\n    if (baseval < 0) baseval = 0;\n    double p = 1.0/(baseval*server.lfu_log_factor+1);//server.lfu_log_facotr默认为10\n    if (r < p) counter++;//可以看到,counter越大,则p越小，随机值r小于p的概率就越小。换言之,counter增加起来会越来越缓慢\n    return counter;\n}\n \nunsigned long LFUGetTimeInMinutes(void) {\n    return (server.unixtime/60) & 65535;//获取分钟级别的时间戳\n}\n \n```\n\nlfu本质上是一个概率计数器，称为morris counter.随着访问次数的增加,counter的增加会越来越缓慢。如下是访问次数与counter值之间的关系\n\n![lru2](/img/lru2.png)\n\nfactor即server.lfu_log_facotr配置值，默认为10.可以看到,一个key访问一千万次以后counter值才会到达255.factor值越小, counter越灵敏\n\nlfu随着分钟数对counter做衰减是基于一个原理:过去被大量访问的key不一定现在仍然会被访问。相当于除了计数，给时间也增加了一定的权重。\n\n淘汰时就很简单了，仍然是一个pool,随机选取10个key,counter最小的被淘汰\n\n## 算法验证\nredis-cli提供了一个参数,可以验证lru算法的效率。主要是通过验证hits/miss的比率，来判断淘汰算法是否有效。命中比率高说明确实淘汰了不会被经常访问的key.具体做法如下:\n\n配置redis lru算法为 allkeys-lru\n\n```\ntest ~/redis-5.0.0$./src/redis-cli -p 6380\n127.0.0.1:6380> config set maxmemory 50m //设置redis最大使用50M内存\nOK\n127.0.0.1:6380> config get  maxmemory-policy\n1) \"maxmemory-policy\"\n2) \"noeviction\"\n127.0.0.1:6380> config set maxmemory-policy allkeys-lru//设置lru算法为allkeys-lru\nOK\n```\n执行redis-cli --lru-test验证命中率\n\n```\n./src/redis-cli -p 6380 --lru-test 1000000//模拟100万个key\n```\n\n通过info查看使用的内存和被逐出的keys\n```\n...\n# Memory\nused_memory:50001216\n...\nevicted_keys:115092\n...\n```\n查看lru-test的输出\n```\n131250 Gets/sec | Hits: 124113 (94.56%) | Misses: 7137 (5.44%)\n132250 Gets/sec | Hits: 125091 (94.59%) | Misses: 7159 (5.41%)\n131250 Gets/sec | Hits: 124027 (94.50%) | Misses: 7223 (5.50%)\n133000 Gets/sec | Hits: 125855 (94.63%) | Misses: 7145 (5.37%)\n136250 Gets/sec | Hits: 128882 (94.59%) | Misses: 7368 (5.41%)\n139750 Gets/sec | Hits: 132231 (94.62%) | Misses: 7519 (5.38%)\n136000 Gets/sec | Hits: 128702 (94.63%) | Misses: 7298 (5.37%)\n134500 Gets/sec | Hits: 127374 (94.70%) | Misses: 7126 (5.30%)\n134750 Gets/sec | Hits: 127427 (94.57%) | Misses: 7323 (5.43%)\n134250 Gets/sec | Hits: 127004 (94.60%) | Misses: 7246 (5.40%)\n138500 Gets/sec | Hits: 131019 (94.60%) | Misses: 7481 (5.40%)\n130000 Gets/sec | Hits: 122918 (94.55%) | Misses: 7082 (5.45%)\n126500 Gets/sec | Hits: 119646 (94.58%) | Misses: 6854 (5.42%)\n132750 Gets/sec | Hits: 125672 (94.67%) | Misses: 7078 (5.33%)\n136000 Gets/sec | Hits: 128563 (94.53%) | Misses: 7437 (5.47%)\n132500 Gets/sec | Hits: 125450 (94.68%) | Misses: 7050 (5.32%)\n132250 Gets/sec | Hits: 125234 (94.69%) | Misses: 7016 (5.31%)\n133000 Gets/sec | Hits: 125761 (94.56%) | Misses: 7239 (5.44%)\n134750 Gets/sec | Hits: 127431 (94.57%) | Misses: 7319 (5.43%)\n130750 Gets/sec | Hits: 123707 (94.61%) | Misses: 7043 (5.39%)\n133500 Gets/sec | Hits: 126195 (94.53%) | Misses: 7305 (5.47%)\n```\n大概有5%-5.5%之间的miss概率。我们将lru策略切换为allkeys-lfu，再次实验\n\n结果如下:\n```\n131250 Gets/sec | Hits: 124480 (94.84%) | Misses: 6770 (5.16%)\n134750 Gets/sec | Hits: 127926 (94.94%) | Misses: 6824 (5.06%)\n130000 Gets/sec | Hits: 123458 (94.97%) | Misses: 6542 (5.03%)\n127750 Gets/sec | Hits: 121231 (94.90%) | Misses: 6519 (5.10%)\n130500 Gets/sec | Hits: 123958 (94.99%) | Misses: 6542 (5.01%)\n130500 Gets/sec | Hits: 123935 (94.97%) | Misses: 6565 (5.03%)\n131250 Gets/sec | Hits: 124622 (94.95%) | Misses: 6628 (5.05%)\n131250 Gets/sec | Hits: 124618 (94.95%) | Misses: 6632 (5.05%)\n128000 Gets/sec | Hits: 121315 (94.78%) | Misses: 6685 (5.22%)\n129000 Gets/sec | Hits: 122585 (95.03%) | Misses: 6415 (4.97%)\n132000 Gets/sec | Hits: 125277 (94.91%) | Misses: 6723 (5.09%)\n134000 Gets/sec | Hits: 127329 (95.02%) | Misses: 6671 (4.98%)\n131750 Gets/sec | Hits: 125258 (95.07%) | Misses: 6492 (4.93%)\n136000 Gets/sec | Hits: 129207 (95.01%) | Misses: 6793 (4.99%)\n135500 Gets/sec | Hits: 128659 (94.95%) | Misses: 6841 (5.05%)\n133750 Gets/sec | Hits: 126995 (94.95%) | Misses: 6755 (5.05%)\n131250 Gets/sec | Hits: 124680 (94.99%) | Misses: 6570 (5.01%)\n129750 Gets/sec | Hits: 123408 (95.11%) | Misses: 6342 (4.89%)\n130500 Gets/sec | Hits: 124043 (95.05%) | Misses: 6457 (4.95%)\n```\n%5左右的miss率，在这个测试下,lfu比lru的预测准确率略微高一些。\n\n在实际生产环境中,不同的redis访问模式需要配置不同的lru策略， 然后可以通过lru test工具验证效果。\n\n## 参考链接\n1.http://antirez.com/news/109\n\n2.https://redis.io/topics/lru-cache","source":"_posts/Redis中的lru算法实现.md","raw":"---\ntitle: Redis中的lru算法实现\ndate: 2018-12-21 13:54:13\ntags: Redis\n---\n## lru是什么\nlru(least recently used)是一种缓存置换算法。即在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。因为缓存是否可能被访问到没法做预测，所以基于如下假设实现该算法:\n\n**如果一个key经常被访问，那么该key的idle time应该是最小的**。\n\n(但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)\n\n这也就是lru的实现思路。首先实现一个双向链表,每次有一个key被访问之后，就把被访问的key放到链表的头部。当缓存不够时,直接从尾部逐个摘除。\n\n在这种假设下的实现方法很明显会有一个问题，例如mysql中执行如下一条语句:\n\n```sql\nselect * from table_a;\n```\n\n如果table_a中有大量数据并且读取之后不会继续使用,则lru头部会被大量的table_a中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io\n\nmysql innodb的buffer pool使用了一种改进的lru算法，大意是将lru链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，再次访问时才会移动到newlist.具体参考如下文章:\n\nhttps://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html\n\n而Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。他认为既然lru本来就是基于假设做出的算法，为什么不能模拟实现一个lru呢。\n\n## Redis中的实现\n首先Redis并没有使用双向链表实现一个lru算法。具体实现方法接下来逐步介绍\n\n首先看一下robj结构体(Redis整体上是一个大的dict,key是一个string,而value都会保存为一个robj)\n\n```c\n\ntypedef struct redisObject {\n\t...\n    unsigned lru:LRU_BITS; //LRU_BITS为24bit\n\t...\n} robj;\n\n```\n\n我们看到每个robj中都有一个24bit长度的lru字段，lru字段里边保存的是一个时间戳。看下边的代码\n\n```c\nrobj *lookupKey(redisDb *db, robj *key, int flags) {\n\t...\n\t        if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) { //如果配置的是lfu方式，则更新lfu\n                updateLFU(val);\n            } else {\n                val->lru = LRU_CLOCK();//否则按lru方式更新\n            }\n\t...\n}\n```\n在Redis的dict中每次按key获取一个值的时候，都会调用lookupKey函数,如果配置使用了lru模式,该函数会更新value中的lru字段为当前秒级别的时间戳(lfu方式后文再描述)。\n\n那么，虽然记录了每个value的时间戳，但是淘汰时总不能挨个遍历dict中的所有槽，逐个比较lru大小吧。\n\nRedis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。(随机选取的key是个可配置的参数maxmemory-samples,默认值为5).\n\n在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。\n\n淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。\n\n我们知道Redis执行命令时首先会调用processCommand函数，在processCommand中会进行key的淘汰，代码如下:\n\n```c\n\nint processCommmand(){\n\t...\n    if (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = freeMemoryIfNeeded() == C_ERR;//如果开启了maxmemory的限制,则会调用freeMemoryIfNeeded()函数，该函数中进行缓存的淘汰\n\t...\n    }\n}\n\n```\n\n可以看到，lru本身是基于概率的猜测，这个算法也是基于概率的猜测，也就是作者说的模拟lru.那么效果如何呢？作者做了个实验，如下图所示\n\n![lru](/img/lru1.png)\n\n首先加入n个key并顺序访问这n个key,之后加入n/2个key（假设redis中只能保存n个key,于是会有n/2个key被逐出）.上图中浅灰色为被逐出的key,淡蓝色是新增加的key,灰色的为最近被访问的key(即不会被lru逐出的key)\n\n左上图为理想中的lru算法,新增加的key和最近被访问的key都不应该被逐出。\n\n可以看到,Redis2.8当每次随机采样5个key时，新增加的key和最近访问的key都有一定概率被逐出\n\nRedis3.0增加了pool后效果好一些(右下角的图)。当Redis3.0增加了pool并且将采样key增加到10个后，基本等同于理想中的lru(虽然还是有一点差距)\n\n如果继续增加采样的key或者pool的大小，作者发现很能进一步优化lru算法,于是作者开始转换思路。\n\n上文介绍了实现lru的一种思路,即**如果一个key经常被访问，那么该key的idle time应该是最小的**\n\n那么能不能换一种思路呢。**如果能够记录一个key被访问的次数,那么经常被访问的key最有可能再次被访问到。这也就是lfu(least frequently used),访问次数最少的最应该被逐出**\n\nlfu的代码如下:\n\n```c\nvoid updateLFU(robj *val) {\n    unsigned long counter = LFUDecrAndReturn(val);//首先计算是否需要将counter衰减\n    counter = LFULogIncr(counter);//根据上述返回的counter计算新的counter\n    val->lru = (LFUGetTimeInMinutes()<<8) | counter; //robj中的lru字段只有24bits,lfu复用该字段。高16位存储一个分钟数级别的时间戳，低8位存储访问计数\n}\n \nunsigned long LFUDecrAndReturn(robj *o) {\n    unsigned long ldt = o->lru >> 8;//原来保存的时间戳\n    unsigned long counter = o->lru & 255; //原来保存的counter\n    unsigned long num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : 0;\n    //server.lfu_decay_time默认为1,每经过一分钟counter衰减1\n    if (num_periods)\n        counter = (num_periods > counter) ? 0 : counter - num_periods;//如果需要衰减,则计算衰减后的值\n    return counter;\n}\n \nuint8_t LFULogIncr(uint8_t counter) {\n    if (counter == 255) return 255;//counter最大只能存储到255,到达后不再增加\n    double r = (double)rand()/RAND_MAX;//算一个随机的小数值\n    double baseval = counter - LFU_INIT_VAL;//新加入的key初始counter设置为LFU_INIT_VAL,为5.不设置为0的原因是防止直接被逐出\n    if (baseval < 0) baseval = 0;\n    double p = 1.0/(baseval*server.lfu_log_factor+1);//server.lfu_log_facotr默认为10\n    if (r < p) counter++;//可以看到,counter越大,则p越小，随机值r小于p的概率就越小。换言之,counter增加起来会越来越缓慢\n    return counter;\n}\n \nunsigned long LFUGetTimeInMinutes(void) {\n    return (server.unixtime/60) & 65535;//获取分钟级别的时间戳\n}\n \n```\n\nlfu本质上是一个概率计数器，称为morris counter.随着访问次数的增加,counter的增加会越来越缓慢。如下是访问次数与counter值之间的关系\n\n![lru2](/img/lru2.png)\n\nfactor即server.lfu_log_facotr配置值，默认为10.可以看到,一个key访问一千万次以后counter值才会到达255.factor值越小, counter越灵敏\n\nlfu随着分钟数对counter做衰减是基于一个原理:过去被大量访问的key不一定现在仍然会被访问。相当于除了计数，给时间也增加了一定的权重。\n\n淘汰时就很简单了，仍然是一个pool,随机选取10个key,counter最小的被淘汰\n\n## 算法验证\nredis-cli提供了一个参数,可以验证lru算法的效率。主要是通过验证hits/miss的比率，来判断淘汰算法是否有效。命中比率高说明确实淘汰了不会被经常访问的key.具体做法如下:\n\n配置redis lru算法为 allkeys-lru\n\n```\ntest ~/redis-5.0.0$./src/redis-cli -p 6380\n127.0.0.1:6380> config set maxmemory 50m //设置redis最大使用50M内存\nOK\n127.0.0.1:6380> config get  maxmemory-policy\n1) \"maxmemory-policy\"\n2) \"noeviction\"\n127.0.0.1:6380> config set maxmemory-policy allkeys-lru//设置lru算法为allkeys-lru\nOK\n```\n执行redis-cli --lru-test验证命中率\n\n```\n./src/redis-cli -p 6380 --lru-test 1000000//模拟100万个key\n```\n\n通过info查看使用的内存和被逐出的keys\n```\n...\n# Memory\nused_memory:50001216\n...\nevicted_keys:115092\n...\n```\n查看lru-test的输出\n```\n131250 Gets/sec | Hits: 124113 (94.56%) | Misses: 7137 (5.44%)\n132250 Gets/sec | Hits: 125091 (94.59%) | Misses: 7159 (5.41%)\n131250 Gets/sec | Hits: 124027 (94.50%) | Misses: 7223 (5.50%)\n133000 Gets/sec | Hits: 125855 (94.63%) | Misses: 7145 (5.37%)\n136250 Gets/sec | Hits: 128882 (94.59%) | Misses: 7368 (5.41%)\n139750 Gets/sec | Hits: 132231 (94.62%) | Misses: 7519 (5.38%)\n136000 Gets/sec | Hits: 128702 (94.63%) | Misses: 7298 (5.37%)\n134500 Gets/sec | Hits: 127374 (94.70%) | Misses: 7126 (5.30%)\n134750 Gets/sec | Hits: 127427 (94.57%) | Misses: 7323 (5.43%)\n134250 Gets/sec | Hits: 127004 (94.60%) | Misses: 7246 (5.40%)\n138500 Gets/sec | Hits: 131019 (94.60%) | Misses: 7481 (5.40%)\n130000 Gets/sec | Hits: 122918 (94.55%) | Misses: 7082 (5.45%)\n126500 Gets/sec | Hits: 119646 (94.58%) | Misses: 6854 (5.42%)\n132750 Gets/sec | Hits: 125672 (94.67%) | Misses: 7078 (5.33%)\n136000 Gets/sec | Hits: 128563 (94.53%) | Misses: 7437 (5.47%)\n132500 Gets/sec | Hits: 125450 (94.68%) | Misses: 7050 (5.32%)\n132250 Gets/sec | Hits: 125234 (94.69%) | Misses: 7016 (5.31%)\n133000 Gets/sec | Hits: 125761 (94.56%) | Misses: 7239 (5.44%)\n134750 Gets/sec | Hits: 127431 (94.57%) | Misses: 7319 (5.43%)\n130750 Gets/sec | Hits: 123707 (94.61%) | Misses: 7043 (5.39%)\n133500 Gets/sec | Hits: 126195 (94.53%) | Misses: 7305 (5.47%)\n```\n大概有5%-5.5%之间的miss概率。我们将lru策略切换为allkeys-lfu，再次实验\n\n结果如下:\n```\n131250 Gets/sec | Hits: 124480 (94.84%) | Misses: 6770 (5.16%)\n134750 Gets/sec | Hits: 127926 (94.94%) | Misses: 6824 (5.06%)\n130000 Gets/sec | Hits: 123458 (94.97%) | Misses: 6542 (5.03%)\n127750 Gets/sec | Hits: 121231 (94.90%) | Misses: 6519 (5.10%)\n130500 Gets/sec | Hits: 123958 (94.99%) | Misses: 6542 (5.01%)\n130500 Gets/sec | Hits: 123935 (94.97%) | Misses: 6565 (5.03%)\n131250 Gets/sec | Hits: 124622 (94.95%) | Misses: 6628 (5.05%)\n131250 Gets/sec | Hits: 124618 (94.95%) | Misses: 6632 (5.05%)\n128000 Gets/sec | Hits: 121315 (94.78%) | Misses: 6685 (5.22%)\n129000 Gets/sec | Hits: 122585 (95.03%) | Misses: 6415 (4.97%)\n132000 Gets/sec | Hits: 125277 (94.91%) | Misses: 6723 (5.09%)\n134000 Gets/sec | Hits: 127329 (95.02%) | Misses: 6671 (4.98%)\n131750 Gets/sec | Hits: 125258 (95.07%) | Misses: 6492 (4.93%)\n136000 Gets/sec | Hits: 129207 (95.01%) | Misses: 6793 (4.99%)\n135500 Gets/sec | Hits: 128659 (94.95%) | Misses: 6841 (5.05%)\n133750 Gets/sec | Hits: 126995 (94.95%) | Misses: 6755 (5.05%)\n131250 Gets/sec | Hits: 124680 (94.99%) | Misses: 6570 (5.01%)\n129750 Gets/sec | Hits: 123408 (95.11%) | Misses: 6342 (4.89%)\n130500 Gets/sec | Hits: 124043 (95.05%) | Misses: 6457 (4.95%)\n```\n%5左右的miss率，在这个测试下,lfu比lru的预测准确率略微高一些。\n\n在实际生产环境中,不同的redis访问模式需要配置不同的lru策略， 然后可以通过lru test工具验证效果。\n\n## 参考链接\n1.http://antirez.com/news/109\n\n2.https://redis.io/topics/lru-cache","slug":"Redis中的lru算法实现","published":1,"updated":"2019-02-19T06:33:28.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbc001hbms6yaolhos2","content":"<h2 id=\"lru是什么\"><a href=\"#lru是什么\" class=\"headerlink\" title=\"lru是什么\"></a>lru是什么</h2><p>lru(least recently used)是一种缓存置换算法。即在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。因为缓存是否可能被访问到没法做预测，所以基于如下假设实现该算法:</p>\n<p><strong>如果一个key经常被访问，那么该key的idle time应该是最小的</strong>。</p>\n<p>(但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)</p>\n<p>这也就是lru的实现思路。首先实现一个双向链表,每次有一个key被访问之后，就把被访问的key放到链表的头部。当缓存不够时,直接从尾部逐个摘除。</p>\n<p>在这种假设下的实现方法很明显会有一个问题，例如mysql中执行如下一条语句:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> table_a;</span><br></pre></td></tr></table></figure>\n<p>如果table_a中有大量数据并且读取之后不会继续使用,则lru头部会被大量的table_a中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io</p>\n<p>mysql innodb的buffer pool使用了一种改进的lru算法，大意是将lru链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，再次访问时才会移动到newlist.具体参考如下文章:</p>\n<p><a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html</a></p>\n<p>而Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。他认为既然lru本来就是基于假设做出的算法，为什么不能模拟实现一个lru呢。</p>\n<h2 id=\"Redis中的实现\"><a href=\"#Redis中的实现\" class=\"headerlink\" title=\"Redis中的实现\"></a>Redis中的实现</h2><p>首先Redis并没有使用双向链表实现一个lru算法。具体实现方法接下来逐步介绍</p>\n<p>首先看一下robj结构体(Redis整体上是一个大的dict,key是一个string,而value都会保存为一个robj)</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">redisObject</span> &#123;</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> lru:LRU_BITS; <span class=\"comment\">//LRU_BITS为24bit</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<p>我们看到每个robj中都有一个24bit长度的lru字段，lru字段里边保存的是一个时间戳。看下边的代码</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">robj *<span class=\"title\">lookupKey</span><span class=\"params\">(redisDb *db, robj *key, <span class=\"keyword\">int</span> flags)</span> </span>&#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t        <span class=\"keyword\">if</span> (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; <span class=\"comment\">//如果配置的是lfu方式，则更新lfu</span></span><br><span class=\"line\">                updateLFU(val);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                val-&gt;lru = LRU_CLOCK();<span class=\"comment\">//否则按lru方式更新</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在Redis的dict中每次按key获取一个值的时候，都会调用lookupKey函数,如果配置使用了lru模式,该函数会更新value中的lru字段为当前秒级别的时间戳(lfu方式后文再描述)。</p>\n<p>那么，虽然记录了每个value的时间戳，但是淘汰时总不能挨个遍历dict中的所有槽，逐个比较lru大小吧。</p>\n<p>Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。(随机选取的key是个可配置的参数maxmemory-samples,默认值为5).</p>\n<p>在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。</p>\n<p>淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。</p>\n<p>我们知道Redis执行命令时首先会调用processCommand函数，在processCommand中会进行key的淘汰，代码如下:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">processCommmand</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (server.maxmemory &amp;&amp; !server.lua_timedout) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> out_of_memory = freeMemoryIfNeeded() == C_ERR;<span class=\"comment\">//如果开启了maxmemory的限制,则会调用freeMemoryIfNeeded()函数，该函数中进行缓存的淘汰</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，lru本身是基于概率的猜测，这个算法也是基于概率的猜测，也就是作者说的模拟lru.那么效果如何呢？作者做了个实验，如下图所示</p>\n<p><img src=\"/img/lru1.png\" alt=\"lru\"></p>\n<p>首先加入n个key并顺序访问这n个key,之后加入n/2个key（假设redis中只能保存n个key,于是会有n/2个key被逐出）.上图中浅灰色为被逐出的key,淡蓝色是新增加的key,灰色的为最近被访问的key(即不会被lru逐出的key)</p>\n<p>左上图为理想中的lru算法,新增加的key和最近被访问的key都不应该被逐出。</p>\n<p>可以看到,Redis2.8当每次随机采样5个key时，新增加的key和最近访问的key都有一定概率被逐出</p>\n<p>Redis3.0增加了pool后效果好一些(右下角的图)。当Redis3.0增加了pool并且将采样key增加到10个后，基本等同于理想中的lru(虽然还是有一点差距)</p>\n<p>如果继续增加采样的key或者pool的大小，作者发现很能进一步优化lru算法,于是作者开始转换思路。</p>\n<p>上文介绍了实现lru的一种思路,即<strong>如果一个key经常被访问，那么该key的idle time应该是最小的</strong></p>\n<p>那么能不能换一种思路呢。<strong>如果能够记录一个key被访问的次数,那么经常被访问的key最有可能再次被访问到。这也就是lfu(least frequently used),访问次数最少的最应该被逐出</strong></p>\n<p>lfu的代码如下:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">updateLFU</span><span class=\"params\">(robj *val)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> counter = LFUDecrAndReturn(val);<span class=\"comment\">//首先计算是否需要将counter衰减</span></span><br><span class=\"line\">    counter = LFULogIncr(counter);<span class=\"comment\">//根据上述返回的counter计算新的counter</span></span><br><span class=\"line\">    val-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;<span class=\"number\">8</span>) | counter; <span class=\"comment\">//robj中的lru字段只有24bits,lfu复用该字段。高16位存储一个分钟数级别的时间戳，低8位存储访问计数</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> <span class=\"title\">LFUDecrAndReturn</span><span class=\"params\">(robj *o)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> ldt = o-&gt;lru &gt;&gt; <span class=\"number\">8</span>;<span class=\"comment\">//原来保存的时间戳</span></span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> counter = o-&gt;lru &amp; <span class=\"number\">255</span>; <span class=\"comment\">//原来保存的counter</span></span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">//server.lfu_decay_time默认为1,每经过一分钟counter衰减1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (num_periods)</span><br><span class=\"line\">        counter = (num_periods &gt; counter) ? <span class=\"number\">0</span> : counter - num_periods;<span class=\"comment\">//如果需要衰减,则计算衰减后的值</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> counter;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">uint8_t</span> LFULogIncr(<span class=\"keyword\">uint8_t</span> counter) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (counter == <span class=\"number\">255</span>) <span class=\"keyword\">return</span> <span class=\"number\">255</span>;<span class=\"comment\">//counter最大只能存储到255,到达后不再增加</span></span><br><span class=\"line\">    <span class=\"keyword\">double</span> r = (<span class=\"keyword\">double</span>)rand()/RAND_MAX;<span class=\"comment\">//算一个随机的小数值</span></span><br><span class=\"line\">    <span class=\"keyword\">double</span> baseval = counter - LFU_INIT_VAL;<span class=\"comment\">//新加入的key初始counter设置为LFU_INIT_VAL,为5.不设置为0的原因是防止直接被逐出</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (baseval &lt; <span class=\"number\">0</span>) baseval = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">double</span> p = <span class=\"number\">1.0</span>/(baseval*server.lfu_log_factor+<span class=\"number\">1</span>);<span class=\"comment\">//server.lfu_log_facotr默认为10</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (r &lt; p) counter++;<span class=\"comment\">//可以看到,counter越大,则p越小，随机值r小于p的概率就越小。换言之,counter增加起来会越来越缓慢</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> counter;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> <span class=\"title\">LFUGetTimeInMinutes</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (server.unixtime/<span class=\"number\">60</span>) &amp; <span class=\"number\">65535</span>;<span class=\"comment\">//获取分钟级别的时间戳</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>lfu本质上是一个概率计数器，称为morris counter.随着访问次数的增加,counter的增加会越来越缓慢。如下是访问次数与counter值之间的关系</p>\n<p><img src=\"/img/lru2.png\" alt=\"lru2\"></p>\n<p>factor即server.lfu_log_facotr配置值，默认为10.可以看到,一个key访问一千万次以后counter值才会到达255.factor值越小, counter越灵敏</p>\n<p>lfu随着分钟数对counter做衰减是基于一个原理:过去被大量访问的key不一定现在仍然会被访问。相当于除了计数，给时间也增加了一定的权重。</p>\n<p>淘汰时就很简单了，仍然是一个pool,随机选取10个key,counter最小的被淘汰</p>\n<h2 id=\"算法验证\"><a href=\"#算法验证\" class=\"headerlink\" title=\"算法验证\"></a>算法验证</h2><p>redis-cli提供了一个参数,可以验证lru算法的效率。主要是通过验证hits/miss的比率，来判断淘汰算法是否有效。命中比率高说明确实淘汰了不会被经常访问的key.具体做法如下:</p>\n<p>配置redis lru算法为 allkeys-lru</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test ~/redis-5.0.0$./src/redis-cli -p 6380</span><br><span class=\"line\">127.0.0.1:6380&gt; config set maxmemory 50m //设置redis最大使用50M内存</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6380&gt; config get  maxmemory-policy</span><br><span class=\"line\">1) &quot;maxmemory-policy&quot;</span><br><span class=\"line\">2) &quot;noeviction&quot;</span><br><span class=\"line\">127.0.0.1:6380&gt; config set maxmemory-policy allkeys-lru//设置lru算法为allkeys-lru</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>执行redis-cli –lru-test验证命中率</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./src/redis-cli -p 6380 --lru-test 1000000//模拟100万个key</span><br></pre></td></tr></table></figure>\n<p>通过info查看使用的内存和被逐出的keys<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:50001216</span><br><span class=\"line\">...</span><br><span class=\"line\">evicted_keys:115092</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>查看lru-test的输出<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">131250 Gets/sec | Hits: 124113 (94.56%) | Misses: 7137 (5.44%)</span><br><span class=\"line\">132250 Gets/sec | Hits: 125091 (94.59%) | Misses: 7159 (5.41%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124027 (94.50%) | Misses: 7223 (5.50%)</span><br><span class=\"line\">133000 Gets/sec | Hits: 125855 (94.63%) | Misses: 7145 (5.37%)</span><br><span class=\"line\">136250 Gets/sec | Hits: 128882 (94.59%) | Misses: 7368 (5.41%)</span><br><span class=\"line\">139750 Gets/sec | Hits: 132231 (94.62%) | Misses: 7519 (5.38%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 128702 (94.63%) | Misses: 7298 (5.37%)</span><br><span class=\"line\">134500 Gets/sec | Hits: 127374 (94.70%) | Misses: 7126 (5.30%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127427 (94.57%) | Misses: 7323 (5.43%)</span><br><span class=\"line\">134250 Gets/sec | Hits: 127004 (94.60%) | Misses: 7246 (5.40%)</span><br><span class=\"line\">138500 Gets/sec | Hits: 131019 (94.60%) | Misses: 7481 (5.40%)</span><br><span class=\"line\">130000 Gets/sec | Hits: 122918 (94.55%) | Misses: 7082 (5.45%)</span><br><span class=\"line\">126500 Gets/sec | Hits: 119646 (94.58%) | Misses: 6854 (5.42%)</span><br><span class=\"line\">132750 Gets/sec | Hits: 125672 (94.67%) | Misses: 7078 (5.33%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 128563 (94.53%) | Misses: 7437 (5.47%)</span><br><span class=\"line\">132500 Gets/sec | Hits: 125450 (94.68%) | Misses: 7050 (5.32%)</span><br><span class=\"line\">132250 Gets/sec | Hits: 125234 (94.69%) | Misses: 7016 (5.31%)</span><br><span class=\"line\">133000 Gets/sec | Hits: 125761 (94.56%) | Misses: 7239 (5.44%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127431 (94.57%) | Misses: 7319 (5.43%)</span><br><span class=\"line\">130750 Gets/sec | Hits: 123707 (94.61%) | Misses: 7043 (5.39%)</span><br><span class=\"line\">133500 Gets/sec | Hits: 126195 (94.53%) | Misses: 7305 (5.47%)</span><br></pre></td></tr></table></figure></p>\n<p>大概有5%-5.5%之间的miss概率。我们将lru策略切换为allkeys-lfu，再次实验</p>\n<p>结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">131250 Gets/sec | Hits: 124480 (94.84%) | Misses: 6770 (5.16%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127926 (94.94%) | Misses: 6824 (5.06%)</span><br><span class=\"line\">130000 Gets/sec | Hits: 123458 (94.97%) | Misses: 6542 (5.03%)</span><br><span class=\"line\">127750 Gets/sec | Hits: 121231 (94.90%) | Misses: 6519 (5.10%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 123958 (94.99%) | Misses: 6542 (5.01%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 123935 (94.97%) | Misses: 6565 (5.03%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124622 (94.95%) | Misses: 6628 (5.05%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124618 (94.95%) | Misses: 6632 (5.05%)</span><br><span class=\"line\">128000 Gets/sec | Hits: 121315 (94.78%) | Misses: 6685 (5.22%)</span><br><span class=\"line\">129000 Gets/sec | Hits: 122585 (95.03%) | Misses: 6415 (4.97%)</span><br><span class=\"line\">132000 Gets/sec | Hits: 125277 (94.91%) | Misses: 6723 (5.09%)</span><br><span class=\"line\">134000 Gets/sec | Hits: 127329 (95.02%) | Misses: 6671 (4.98%)</span><br><span class=\"line\">131750 Gets/sec | Hits: 125258 (95.07%) | Misses: 6492 (4.93%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 129207 (95.01%) | Misses: 6793 (4.99%)</span><br><span class=\"line\">135500 Gets/sec | Hits: 128659 (94.95%) | Misses: 6841 (5.05%)</span><br><span class=\"line\">133750 Gets/sec | Hits: 126995 (94.95%) | Misses: 6755 (5.05%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124680 (94.99%) | Misses: 6570 (5.01%)</span><br><span class=\"line\">129750 Gets/sec | Hits: 123408 (95.11%) | Misses: 6342 (4.89%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 124043 (95.05%) | Misses: 6457 (4.95%)</span><br></pre></td></tr></table></figure></p>\n<p>%5左右的miss率，在这个测试下,lfu比lru的预测准确率略微高一些。</p>\n<p>在实际生产环境中,不同的redis访问模式需要配置不同的lru策略， 然后可以通过lru test工具验证效果。</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p>1.<a href=\"http://antirez.com/news/109\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/109</a></p>\n<p>2.<a href=\"https://redis.io/topics/lru-cache\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/lru-cache</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"lru是什么\"><a href=\"#lru是什么\" class=\"headerlink\" title=\"lru是什么\"></a>lru是什么</h2><p>lru(least recently used)是一种缓存置换算法。即在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。因为缓存是否可能被访问到没法做预测，所以基于如下假设实现该算法:</p>\n<p><strong>如果一个key经常被访问，那么该key的idle time应该是最小的</strong>。</p>\n<p>(但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)</p>\n<p>这也就是lru的实现思路。首先实现一个双向链表,每次有一个key被访问之后，就把被访问的key放到链表的头部。当缓存不够时,直接从尾部逐个摘除。</p>\n<p>在这种假设下的实现方法很明显会有一个问题，例如mysql中执行如下一条语句:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> table_a;</span><br></pre></td></tr></table></figure>\n<p>如果table_a中有大量数据并且读取之后不会继续使用,则lru头部会被大量的table_a中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io</p>\n<p>mysql innodb的buffer pool使用了一种改进的lru算法，大意是将lru链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，再次访问时才会移动到newlist.具体参考如下文章:</p>\n<p><a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html</a></p>\n<p>而Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。他认为既然lru本来就是基于假设做出的算法，为什么不能模拟实现一个lru呢。</p>\n<h2 id=\"Redis中的实现\"><a href=\"#Redis中的实现\" class=\"headerlink\" title=\"Redis中的实现\"></a>Redis中的实现</h2><p>首先Redis并没有使用双向链表实现一个lru算法。具体实现方法接下来逐步介绍</p>\n<p>首先看一下robj结构体(Redis整体上是一个大的dict,key是一个string,而value都会保存为一个robj)</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">redisObject</span> &#123;</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> lru:LRU_BITS; <span class=\"comment\">//LRU_BITS为24bit</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<p>我们看到每个robj中都有一个24bit长度的lru字段，lru字段里边保存的是一个时间戳。看下边的代码</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">robj *<span class=\"title\">lookupKey</span><span class=\"params\">(redisDb *db, robj *key, <span class=\"keyword\">int</span> flags)</span> </span>&#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t        <span class=\"keyword\">if</span> (server.maxmemory_policy &amp; MAXMEMORY_FLAG_LFU) &#123; <span class=\"comment\">//如果配置的是lfu方式，则更新lfu</span></span><br><span class=\"line\">                updateLFU(val);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                val-&gt;lru = LRU_CLOCK();<span class=\"comment\">//否则按lru方式更新</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>在Redis的dict中每次按key获取一个值的时候，都会调用lookupKey函数,如果配置使用了lru模式,该函数会更新value中的lru字段为当前秒级别的时间戳(lfu方式后文再描述)。</p>\n<p>那么，虽然记录了每个value的时间戳，但是淘汰时总不能挨个遍历dict中的所有槽，逐个比较lru大小吧。</p>\n<p>Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。(随机选取的key是个可配置的参数maxmemory-samples,默认值为5).</p>\n<p>在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。</p>\n<p>淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。</p>\n<p>我们知道Redis执行命令时首先会调用processCommand函数，在processCommand中会进行key的淘汰，代码如下:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">processCommmand</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (server.maxmemory &amp;&amp; !server.lua_timedout) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> out_of_memory = freeMemoryIfNeeded() == C_ERR;<span class=\"comment\">//如果开启了maxmemory的限制,则会调用freeMemoryIfNeeded()函数，该函数中进行缓存的淘汰</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，lru本身是基于概率的猜测，这个算法也是基于概率的猜测，也就是作者说的模拟lru.那么效果如何呢？作者做了个实验，如下图所示</p>\n<p><img src=\"/img/lru1.png\" alt=\"lru\"></p>\n<p>首先加入n个key并顺序访问这n个key,之后加入n/2个key（假设redis中只能保存n个key,于是会有n/2个key被逐出）.上图中浅灰色为被逐出的key,淡蓝色是新增加的key,灰色的为最近被访问的key(即不会被lru逐出的key)</p>\n<p>左上图为理想中的lru算法,新增加的key和最近被访问的key都不应该被逐出。</p>\n<p>可以看到,Redis2.8当每次随机采样5个key时，新增加的key和最近访问的key都有一定概率被逐出</p>\n<p>Redis3.0增加了pool后效果好一些(右下角的图)。当Redis3.0增加了pool并且将采样key增加到10个后，基本等同于理想中的lru(虽然还是有一点差距)</p>\n<p>如果继续增加采样的key或者pool的大小，作者发现很能进一步优化lru算法,于是作者开始转换思路。</p>\n<p>上文介绍了实现lru的一种思路,即<strong>如果一个key经常被访问，那么该key的idle time应该是最小的</strong></p>\n<p>那么能不能换一种思路呢。<strong>如果能够记录一个key被访问的次数,那么经常被访问的key最有可能再次被访问到。这也就是lfu(least frequently used),访问次数最少的最应该被逐出</strong></p>\n<p>lfu的代码如下:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">updateLFU</span><span class=\"params\">(robj *val)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> counter = LFUDecrAndReturn(val);<span class=\"comment\">//首先计算是否需要将counter衰减</span></span><br><span class=\"line\">    counter = LFULogIncr(counter);<span class=\"comment\">//根据上述返回的counter计算新的counter</span></span><br><span class=\"line\">    val-&gt;lru = (LFUGetTimeInMinutes()&lt;&lt;<span class=\"number\">8</span>) | counter; <span class=\"comment\">//robj中的lru字段只有24bits,lfu复用该字段。高16位存储一个分钟数级别的时间戳，低8位存储访问计数</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> <span class=\"title\">LFUDecrAndReturn</span><span class=\"params\">(robj *o)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> ldt = o-&gt;lru &gt;&gt; <span class=\"number\">8</span>;<span class=\"comment\">//原来保存的时间戳</span></span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> counter = o-&gt;lru &amp; <span class=\"number\">255</span>; <span class=\"comment\">//原来保存的counter</span></span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">//server.lfu_decay_time默认为1,每经过一分钟counter衰减1</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (num_periods)</span><br><span class=\"line\">        counter = (num_periods &gt; counter) ? <span class=\"number\">0</span> : counter - num_periods;<span class=\"comment\">//如果需要衰减,则计算衰减后的值</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> counter;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">uint8_t</span> LFULogIncr(<span class=\"keyword\">uint8_t</span> counter) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (counter == <span class=\"number\">255</span>) <span class=\"keyword\">return</span> <span class=\"number\">255</span>;<span class=\"comment\">//counter最大只能存储到255,到达后不再增加</span></span><br><span class=\"line\">    <span class=\"keyword\">double</span> r = (<span class=\"keyword\">double</span>)rand()/RAND_MAX;<span class=\"comment\">//算一个随机的小数值</span></span><br><span class=\"line\">    <span class=\"keyword\">double</span> baseval = counter - LFU_INIT_VAL;<span class=\"comment\">//新加入的key初始counter设置为LFU_INIT_VAL,为5.不设置为0的原因是防止直接被逐出</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (baseval &lt; <span class=\"number\">0</span>) baseval = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">double</span> p = <span class=\"number\">1.0</span>/(baseval*server.lfu_log_factor+<span class=\"number\">1</span>);<span class=\"comment\">//server.lfu_log_facotr默认为10</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (r &lt; p) counter++;<span class=\"comment\">//可以看到,counter越大,则p越小，随机值r小于p的概率就越小。换言之,counter增加起来会越来越缓慢</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> counter;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> <span class=\"title\">LFUGetTimeInMinutes</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (server.unixtime/<span class=\"number\">60</span>) &amp; <span class=\"number\">65535</span>;<span class=\"comment\">//获取分钟级别的时间戳</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>lfu本质上是一个概率计数器，称为morris counter.随着访问次数的增加,counter的增加会越来越缓慢。如下是访问次数与counter值之间的关系</p>\n<p><img src=\"/img/lru2.png\" alt=\"lru2\"></p>\n<p>factor即server.lfu_log_facotr配置值，默认为10.可以看到,一个key访问一千万次以后counter值才会到达255.factor值越小, counter越灵敏</p>\n<p>lfu随着分钟数对counter做衰减是基于一个原理:过去被大量访问的key不一定现在仍然会被访问。相当于除了计数，给时间也增加了一定的权重。</p>\n<p>淘汰时就很简单了，仍然是一个pool,随机选取10个key,counter最小的被淘汰</p>\n<h2 id=\"算法验证\"><a href=\"#算法验证\" class=\"headerlink\" title=\"算法验证\"></a>算法验证</h2><p>redis-cli提供了一个参数,可以验证lru算法的效率。主要是通过验证hits/miss的比率，来判断淘汰算法是否有效。命中比率高说明确实淘汰了不会被经常访问的key.具体做法如下:</p>\n<p>配置redis lru算法为 allkeys-lru</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test ~/redis-5.0.0$./src/redis-cli -p 6380</span><br><span class=\"line\">127.0.0.1:6380&gt; config set maxmemory 50m //设置redis最大使用50M内存</span><br><span class=\"line\">OK</span><br><span class=\"line\">127.0.0.1:6380&gt; config get  maxmemory-policy</span><br><span class=\"line\">1) &quot;maxmemory-policy&quot;</span><br><span class=\"line\">2) &quot;noeviction&quot;</span><br><span class=\"line\">127.0.0.1:6380&gt; config set maxmemory-policy allkeys-lru//设置lru算法为allkeys-lru</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n<p>执行redis-cli –lru-test验证命中率</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./src/redis-cli -p 6380 --lru-test 1000000//模拟100万个key</span><br></pre></td></tr></table></figure>\n<p>通过info查看使用的内存和被逐出的keys<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\"># Memory</span><br><span class=\"line\">used_memory:50001216</span><br><span class=\"line\">...</span><br><span class=\"line\">evicted_keys:115092</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>查看lru-test的输出<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">131250 Gets/sec | Hits: 124113 (94.56%) | Misses: 7137 (5.44%)</span><br><span class=\"line\">132250 Gets/sec | Hits: 125091 (94.59%) | Misses: 7159 (5.41%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124027 (94.50%) | Misses: 7223 (5.50%)</span><br><span class=\"line\">133000 Gets/sec | Hits: 125855 (94.63%) | Misses: 7145 (5.37%)</span><br><span class=\"line\">136250 Gets/sec | Hits: 128882 (94.59%) | Misses: 7368 (5.41%)</span><br><span class=\"line\">139750 Gets/sec | Hits: 132231 (94.62%) | Misses: 7519 (5.38%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 128702 (94.63%) | Misses: 7298 (5.37%)</span><br><span class=\"line\">134500 Gets/sec | Hits: 127374 (94.70%) | Misses: 7126 (5.30%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127427 (94.57%) | Misses: 7323 (5.43%)</span><br><span class=\"line\">134250 Gets/sec | Hits: 127004 (94.60%) | Misses: 7246 (5.40%)</span><br><span class=\"line\">138500 Gets/sec | Hits: 131019 (94.60%) | Misses: 7481 (5.40%)</span><br><span class=\"line\">130000 Gets/sec | Hits: 122918 (94.55%) | Misses: 7082 (5.45%)</span><br><span class=\"line\">126500 Gets/sec | Hits: 119646 (94.58%) | Misses: 6854 (5.42%)</span><br><span class=\"line\">132750 Gets/sec | Hits: 125672 (94.67%) | Misses: 7078 (5.33%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 128563 (94.53%) | Misses: 7437 (5.47%)</span><br><span class=\"line\">132500 Gets/sec | Hits: 125450 (94.68%) | Misses: 7050 (5.32%)</span><br><span class=\"line\">132250 Gets/sec | Hits: 125234 (94.69%) | Misses: 7016 (5.31%)</span><br><span class=\"line\">133000 Gets/sec | Hits: 125761 (94.56%) | Misses: 7239 (5.44%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127431 (94.57%) | Misses: 7319 (5.43%)</span><br><span class=\"line\">130750 Gets/sec | Hits: 123707 (94.61%) | Misses: 7043 (5.39%)</span><br><span class=\"line\">133500 Gets/sec | Hits: 126195 (94.53%) | Misses: 7305 (5.47%)</span><br></pre></td></tr></table></figure></p>\n<p>大概有5%-5.5%之间的miss概率。我们将lru策略切换为allkeys-lfu，再次实验</p>\n<p>结果如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">131250 Gets/sec | Hits: 124480 (94.84%) | Misses: 6770 (5.16%)</span><br><span class=\"line\">134750 Gets/sec | Hits: 127926 (94.94%) | Misses: 6824 (5.06%)</span><br><span class=\"line\">130000 Gets/sec | Hits: 123458 (94.97%) | Misses: 6542 (5.03%)</span><br><span class=\"line\">127750 Gets/sec | Hits: 121231 (94.90%) | Misses: 6519 (5.10%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 123958 (94.99%) | Misses: 6542 (5.01%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 123935 (94.97%) | Misses: 6565 (5.03%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124622 (94.95%) | Misses: 6628 (5.05%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124618 (94.95%) | Misses: 6632 (5.05%)</span><br><span class=\"line\">128000 Gets/sec | Hits: 121315 (94.78%) | Misses: 6685 (5.22%)</span><br><span class=\"line\">129000 Gets/sec | Hits: 122585 (95.03%) | Misses: 6415 (4.97%)</span><br><span class=\"line\">132000 Gets/sec | Hits: 125277 (94.91%) | Misses: 6723 (5.09%)</span><br><span class=\"line\">134000 Gets/sec | Hits: 127329 (95.02%) | Misses: 6671 (4.98%)</span><br><span class=\"line\">131750 Gets/sec | Hits: 125258 (95.07%) | Misses: 6492 (4.93%)</span><br><span class=\"line\">136000 Gets/sec | Hits: 129207 (95.01%) | Misses: 6793 (4.99%)</span><br><span class=\"line\">135500 Gets/sec | Hits: 128659 (94.95%) | Misses: 6841 (5.05%)</span><br><span class=\"line\">133750 Gets/sec | Hits: 126995 (94.95%) | Misses: 6755 (5.05%)</span><br><span class=\"line\">131250 Gets/sec | Hits: 124680 (94.99%) | Misses: 6570 (5.01%)</span><br><span class=\"line\">129750 Gets/sec | Hits: 123408 (95.11%) | Misses: 6342 (4.89%)</span><br><span class=\"line\">130500 Gets/sec | Hits: 124043 (95.05%) | Misses: 6457 (4.95%)</span><br></pre></td></tr></table></figure></p>\n<p>%5左右的miss率，在这个测试下,lfu比lru的预测准确率略微高一些。</p>\n<p>在实际生产环境中,不同的redis访问模式需要配置不同的lru策略， 然后可以通过lru test工具验证效果。</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p>1.<a href=\"http://antirez.com/news/109\" target=\"_blank\" rel=\"noopener\">http://antirez.com/news/109</a></p>\n<p>2.<a href=\"https://redis.io/topics/lru-cache\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/lru-cache</a></p>\n"},{"title":"Redis的一个历史bug及其后续改进","date":"2019-04-15T11:24:00.000Z","_content":"\n## ziplist简介\n\nRedis使用ziplist是为了节省内存.以zset为例,当zset元素个数少并且每个元素也比较小的时候,如果直接使用skiplist(可以理解为多层的双向链表),每个节点的前后指针这些元数据占用空间的比例可能达到50%以上.而ziplist是分配在堆上的一块连续内存,通过一定的编码格式,使数据保存更加紧凑.如下是一个编码为ziplist的zset.\n```\n127.0.0.1:6666> zadd zs 100 'a'\n(integer) 1\n127.0.0.1:6666> zadd zs 200 'b'\n(integer) 1\n127.0.0.1:6666> object encoding zs\n\"ziplist\"\n```\n## ziplist格式\nziplist的格式如下图所示:\n![ziplist](/img/zl1.png)\nziplist各字段解释如下:\n* zlbytes:ziplist占用的内存空间大小\n* zltail:ziplist最后一个entry的偏移量\n* zllen:ziplist中entry的个数.\n* entry:每个元素\n* 0xFF:ziplist的结束标志\n\n每个entry的字段解释如下:\n* prev_entry_len:前一个entry占用的字节大小,占用1个或者5个字节.**当小于254时,占用1字节,当大于等于254时,占用5字节**\n* encoding:当前entry内容的编码格式及其长度\n* content:当前entry保存的内容\n\n注意ziplist中有一个zltail字段是最后一个entry的偏移量,通过该字段定位到最后一个entry后,读取prev_entry_len可以继续向前定位上一个entry的起始地址.也就是说**ziplist适合于从后往前遍历**.\n\n## bug原因及其复现\n首先看下代码中是如何修复该bug的,然后通过把代码反向修改回来,可以构造示例复现该bug.通过复现过程详细描述该bug的产生过程\n```\n@@ -778,7 +778,12 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha\n     /* When the insert position is not equal to the tail, we need to\n      * make sure that the next entry can hold this entry's length in\n      * its prevlen field. */\n+    int forcelarge = 0;\n     nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;\n+    if (nextdiff == -4 && reqlen < 4) {\n+        nextdiff = 0;\n+        forcelarge = 1;\n+    }\n\n     /* Store offset because a realloc may change the address of zl. */\n     offset = p-zl;\n@@ -791,7 +796,10 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha\n         memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);\n\n         /* Encode this entry's raw length in the next entry. */\n-        zipStorePrevEntryLength(p+reqlen,reqlen);\n+        if (forcelarge)\n+            zipStorePrevEntryLength(p+reqlen,reqlen);\n+        else\n+            zipStorePrevEntryLengthLarge(p+reqlen,reqlen);\n\n         /* Update offset for tail */\n         ZIPLIST_TAIL_OFFSET(zl) =\n```\n可以看到代码中增加了一个判断\n```\nif (nextdiff == -4 && reqlen < 4) \n```\n我们看看nextdiff是如何计算的\n```\nint zipPrevLenByteDiff(unsigned char *p, unsigned int len) {\n    unsigned int prevlensize;\n    //宏,展开之后根据p[0]处的值计算出prevlensize,如果p[0]<254,prevlensize为1,否则为5\n    ZIP_DECODE_PREVLENSIZE(p, prevlensize);\n    //zipStorePrevEntryLength函数如果第一个参数为NULL,则根据len字段计算需要的字节数,同理,len<254为1个字节,否则为5个字节\n    return zipStorePrevEntryLength(NULL, len) - prevlensize;\n}\n```\n如上函数计算nextdiff,可以看出,根据插入位置p当前保存prev_entry_len字段的字节数和即将插入的entry需要的字节数相减得出nextdiff.值有三种类型\n* 0: 空间相等\n* 4：需要更多空间\n* -4：空间富余\n\nbug修复过程首先判断nextdiff等于-4,即p位置的prev_entry_len为5个字节,而当前要插入的entry的长度只需要1个字节去保存.然后判断reqlen < 4.看到此处可能读者会有疑惑,既然prev_entry_len长度已经为5个字节了,那么新插入的值prev_entry_len+encoding+content字段肯定会大于5字节,为什么会出现小于4的情况呢?\n这种情况确实比较费解,通过下文的构造示例我们能够看出,在连锁更新的时候,为了防止大量的重新分配空间的动作,如果一个entry的长度只需要1个字节就能够保存,但是连锁更新时如果原先已经为prev_entry_len分配了5个字节,则不会进行缩容操作.\n把bug修复代码反向修改回来,编译之后执行如下命令可以导致Redis crash(注意前边是命令编号,下文通过该编号解释Redis中ziplist内存的变化情况):\n```\n     \t  0.redis-cli del list\n        1.redis-cli rpush list one\n        2.redis-cli rpush list two\n        3.redis-cli rpush list\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        4.redis-cli rpush list\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        5.redis-cli rpush list three\n        6.redis-cli rpush list a\n        7.redis-cli lrem list 1\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        8.redis-cli linsert list after\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA 10\n        9.redis-cli lrange list 0 -1\n```\n前6条命令会往一个list中分别插入'one','two',252个'A',250个'A','three','a'六个元素.此时内存占用情况如下:\n![orig](/img/zl3.png)\n\n**每个小矩形框表示占用内存字节数,大矩形框表示一个个entry,每个entry有三项,分别为prev_entry_len,encoding和content字段**\n\n\n接着执行第7条命令,内存占用情况如图,表示如下:\n![cascade update](/img/zl2.png)\n\n删除了第3个entry,此时第4个entry的前一个entry长度由255字节变为5字节(第2个entry此时为第4个entry的前一个entry),所以prev_entry_len字段由占用5个字节变为占用1个字节.**参见图中黄框部分**.\n\n\n注意此时会发生连锁更新,因为蓝框部分的prev_entry_len由257字节变为253,也可以更新为1个字节.但Redis中在连锁更新的情况下为了避免频繁的realloc操作,这种情况下不进行缩容.\n\n接着执行第8条命令,插入绿框中的数据(见图第3列所示),此时蓝筐中的prev_entry_len是5个字节,绿框中的数据只占用2字节,当将prev_entry_len更新为1字节后,prev_entry_len多余的4字节可以完整的容纳绿框中的数据.\n**即虽然插入了数据,但realloc之后反而缩小了占用的内存,从而导致ziplist中的数据损坏.**\n\n修复这个bug的代码也就很容易理解了,即图中第3列蓝框的prev_entry_len仍然保留为5个字节.\n\n**可以进一步构造另一种情况,即第6步构造为rpush list 10,则此时不会造成redis crash,而是会丢失10这个元素.读者可以画出内存占用图自行分析**\n\n## redis作者对该bug的思考\n\n通过上边的分析,是不是觉着很难理解？Redis作者也意识到由于连锁更新的存在导致ziplist并不是简单易懂.于是提出了一个优化后的替代结构listpack.\n\nlistpack主要做了如下两点改进:\n* 头部省去了4个字节的zltail字段\n* entry中不再保存prev_entry_len这个字段,而是改为保存本entry自己的长度\n\n整体结构如下:\n```\n<tot-bytes> <num-elements> <element-1> ... <element-N> <listpack-end-byte>\n```\n每个entry的结构如下:\n```\n<encoding-type><element-data><element-tot-len>\n```\n\n我们知道ziplist设计为适合从尾部到头部逐个遍历,那么listpack如何实现该功能呢？\n首先通过tot-bytes偏移到结尾,然后**从右到左**读取element-tot-len(**注意该字段设计为从右往左读取**),这样既实现了尾部到头部的遍历,又没有连锁更新的情况.是不是很巧妙.\n\n## 参考文档\n* https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175\n* https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES\n* https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\n* https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3","source":"_posts/Redis的一个历史bug及其后续改进.md","raw":"---\ntitle: Redis的一个历史bug及其后续改进\ndate: 2019-04-15 19:24:00\ntags: Redis\n---\n\n## ziplist简介\n\nRedis使用ziplist是为了节省内存.以zset为例,当zset元素个数少并且每个元素也比较小的时候,如果直接使用skiplist(可以理解为多层的双向链表),每个节点的前后指针这些元数据占用空间的比例可能达到50%以上.而ziplist是分配在堆上的一块连续内存,通过一定的编码格式,使数据保存更加紧凑.如下是一个编码为ziplist的zset.\n```\n127.0.0.1:6666> zadd zs 100 'a'\n(integer) 1\n127.0.0.1:6666> zadd zs 200 'b'\n(integer) 1\n127.0.0.1:6666> object encoding zs\n\"ziplist\"\n```\n## ziplist格式\nziplist的格式如下图所示:\n![ziplist](/img/zl1.png)\nziplist各字段解释如下:\n* zlbytes:ziplist占用的内存空间大小\n* zltail:ziplist最后一个entry的偏移量\n* zllen:ziplist中entry的个数.\n* entry:每个元素\n* 0xFF:ziplist的结束标志\n\n每个entry的字段解释如下:\n* prev_entry_len:前一个entry占用的字节大小,占用1个或者5个字节.**当小于254时,占用1字节,当大于等于254时,占用5字节**\n* encoding:当前entry内容的编码格式及其长度\n* content:当前entry保存的内容\n\n注意ziplist中有一个zltail字段是最后一个entry的偏移量,通过该字段定位到最后一个entry后,读取prev_entry_len可以继续向前定位上一个entry的起始地址.也就是说**ziplist适合于从后往前遍历**.\n\n## bug原因及其复现\n首先看下代码中是如何修复该bug的,然后通过把代码反向修改回来,可以构造示例复现该bug.通过复现过程详细描述该bug的产生过程\n```\n@@ -778,7 +778,12 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha\n     /* When the insert position is not equal to the tail, we need to\n      * make sure that the next entry can hold this entry's length in\n      * its prevlen field. */\n+    int forcelarge = 0;\n     nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;\n+    if (nextdiff == -4 && reqlen < 4) {\n+        nextdiff = 0;\n+        forcelarge = 1;\n+    }\n\n     /* Store offset because a realloc may change the address of zl. */\n     offset = p-zl;\n@@ -791,7 +796,10 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha\n         memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);\n\n         /* Encode this entry's raw length in the next entry. */\n-        zipStorePrevEntryLength(p+reqlen,reqlen);\n+        if (forcelarge)\n+            zipStorePrevEntryLength(p+reqlen,reqlen);\n+        else\n+            zipStorePrevEntryLengthLarge(p+reqlen,reqlen);\n\n         /* Update offset for tail */\n         ZIPLIST_TAIL_OFFSET(zl) =\n```\n可以看到代码中增加了一个判断\n```\nif (nextdiff == -4 && reqlen < 4) \n```\n我们看看nextdiff是如何计算的\n```\nint zipPrevLenByteDiff(unsigned char *p, unsigned int len) {\n    unsigned int prevlensize;\n    //宏,展开之后根据p[0]处的值计算出prevlensize,如果p[0]<254,prevlensize为1,否则为5\n    ZIP_DECODE_PREVLENSIZE(p, prevlensize);\n    //zipStorePrevEntryLength函数如果第一个参数为NULL,则根据len字段计算需要的字节数,同理,len<254为1个字节,否则为5个字节\n    return zipStorePrevEntryLength(NULL, len) - prevlensize;\n}\n```\n如上函数计算nextdiff,可以看出,根据插入位置p当前保存prev_entry_len字段的字节数和即将插入的entry需要的字节数相减得出nextdiff.值有三种类型\n* 0: 空间相等\n* 4：需要更多空间\n* -4：空间富余\n\nbug修复过程首先判断nextdiff等于-4,即p位置的prev_entry_len为5个字节,而当前要插入的entry的长度只需要1个字节去保存.然后判断reqlen < 4.看到此处可能读者会有疑惑,既然prev_entry_len长度已经为5个字节了,那么新插入的值prev_entry_len+encoding+content字段肯定会大于5字节,为什么会出现小于4的情况呢?\n这种情况确实比较费解,通过下文的构造示例我们能够看出,在连锁更新的时候,为了防止大量的重新分配空间的动作,如果一个entry的长度只需要1个字节就能够保存,但是连锁更新时如果原先已经为prev_entry_len分配了5个字节,则不会进行缩容操作.\n把bug修复代码反向修改回来,编译之后执行如下命令可以导致Redis crash(注意前边是命令编号,下文通过该编号解释Redis中ziplist内存的变化情况):\n```\n     \t  0.redis-cli del list\n        1.redis-cli rpush list one\n        2.redis-cli rpush list two\n        3.redis-cli rpush list\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        4.redis-cli rpush list\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        5.redis-cli rpush list three\n        6.redis-cli rpush list a\n        7.redis-cli lrem list 1\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n        8.redis-cli linsert list after\n        AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA 10\n        9.redis-cli lrange list 0 -1\n```\n前6条命令会往一个list中分别插入'one','two',252个'A',250个'A','three','a'六个元素.此时内存占用情况如下:\n![orig](/img/zl3.png)\n\n**每个小矩形框表示占用内存字节数,大矩形框表示一个个entry,每个entry有三项,分别为prev_entry_len,encoding和content字段**\n\n\n接着执行第7条命令,内存占用情况如图,表示如下:\n![cascade update](/img/zl2.png)\n\n删除了第3个entry,此时第4个entry的前一个entry长度由255字节变为5字节(第2个entry此时为第4个entry的前一个entry),所以prev_entry_len字段由占用5个字节变为占用1个字节.**参见图中黄框部分**.\n\n\n注意此时会发生连锁更新,因为蓝框部分的prev_entry_len由257字节变为253,也可以更新为1个字节.但Redis中在连锁更新的情况下为了避免频繁的realloc操作,这种情况下不进行缩容.\n\n接着执行第8条命令,插入绿框中的数据(见图第3列所示),此时蓝筐中的prev_entry_len是5个字节,绿框中的数据只占用2字节,当将prev_entry_len更新为1字节后,prev_entry_len多余的4字节可以完整的容纳绿框中的数据.\n**即虽然插入了数据,但realloc之后反而缩小了占用的内存,从而导致ziplist中的数据损坏.**\n\n修复这个bug的代码也就很容易理解了,即图中第3列蓝框的prev_entry_len仍然保留为5个字节.\n\n**可以进一步构造另一种情况,即第6步构造为rpush list 10,则此时不会造成redis crash,而是会丢失10这个元素.读者可以画出内存占用图自行分析**\n\n## redis作者对该bug的思考\n\n通过上边的分析,是不是觉着很难理解？Redis作者也意识到由于连锁更新的存在导致ziplist并不是简单易懂.于是提出了一个优化后的替代结构listpack.\n\nlistpack主要做了如下两点改进:\n* 头部省去了4个字节的zltail字段\n* entry中不再保存prev_entry_len这个字段,而是改为保存本entry自己的长度\n\n整体结构如下:\n```\n<tot-bytes> <num-elements> <element-1> ... <element-N> <listpack-end-byte>\n```\n每个entry的结构如下:\n```\n<encoding-type><element-data><element-tot-len>\n```\n\n我们知道ziplist设计为适合从尾部到头部逐个遍历,那么listpack如何实现该功能呢？\n首先通过tot-bytes偏移到结尾,然后**从右到左**读取element-tot-len(**注意该字段设计为从右往左读取**),这样既实现了尾部到头部的遍历,又没有连锁更新的情况.是不是很巧妙.\n\n## 参考文档\n* https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175\n* https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES\n* https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\n* https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3","slug":"Redis的一个历史bug及其后续改进","published":1,"updated":"2019-05-04T15:11:57.311Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbd001jbms6ezc8t4pt","content":"<h2 id=\"ziplist简介\"><a href=\"#ziplist简介\" class=\"headerlink\" title=\"ziplist简介\"></a>ziplist简介</h2><p>Redis使用ziplist是为了节省内存.以zset为例,当zset元素个数少并且每个元素也比较小的时候,如果直接使用skiplist(可以理解为多层的双向链表),每个节点的前后指针这些元数据占用空间的比例可能达到50%以上.而ziplist是分配在堆上的一块连续内存,通过一定的编码格式,使数据保存更加紧凑.如下是一个编码为ziplist的zset.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6666&gt; zadd zs 100 &apos;a&apos;</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6666&gt; zadd zs 200 &apos;b&apos;</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6666&gt; object encoding zs</span><br><span class=\"line\">&quot;ziplist&quot;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ziplist格式\"><a href=\"#ziplist格式\" class=\"headerlink\" title=\"ziplist格式\"></a>ziplist格式</h2><p>ziplist的格式如下图所示:<br><img src=\"/img/zl1.png\" alt=\"ziplist\"><br>ziplist各字段解释如下:</p>\n<ul>\n<li>zlbytes:ziplist占用的内存空间大小</li>\n<li>zltail:ziplist最后一个entry的偏移量</li>\n<li>zllen:ziplist中entry的个数.</li>\n<li>entry:每个元素</li>\n<li>0xFF:ziplist的结束标志</li>\n</ul>\n<p>每个entry的字段解释如下:</p>\n<ul>\n<li>prev_entry_len:前一个entry占用的字节大小,占用1个或者5个字节.<strong>当小于254时,占用1字节,当大于等于254时,占用5字节</strong></li>\n<li>encoding:当前entry内容的编码格式及其长度</li>\n<li>content:当前entry保存的内容</li>\n</ul>\n<p>注意ziplist中有一个zltail字段是最后一个entry的偏移量,通过该字段定位到最后一个entry后,读取prev_entry_len可以继续向前定位上一个entry的起始地址.也就是说<strong>ziplist适合于从后往前遍历</strong>.</p>\n<h2 id=\"bug原因及其复现\"><a href=\"#bug原因及其复现\" class=\"headerlink\" title=\"bug原因及其复现\"></a>bug原因及其复现</h2><p>首先看下代码中是如何修复该bug的,然后通过把代码反向修改回来,可以构造示例复现该bug.通过复现过程详细描述该bug的产生过程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@@ -778,7 +778,12 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha</span><br><span class=\"line\">     /* When the insert position is not equal to the tail, we need to</span><br><span class=\"line\">      * make sure that the next entry can hold this entry&apos;s length in</span><br><span class=\"line\">      * its prevlen field. */</span><br><span class=\"line\">+    int forcelarge = 0;</span><br><span class=\"line\">     nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;</span><br><span class=\"line\">+    if (nextdiff == -4 &amp;&amp; reqlen &lt; 4) &#123;</span><br><span class=\"line\">+        nextdiff = 0;</span><br><span class=\"line\">+        forcelarge = 1;</span><br><span class=\"line\">+    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     /* Store offset because a realloc may change the address of zl. */</span><br><span class=\"line\">     offset = p-zl;</span><br><span class=\"line\">@@ -791,7 +796,10 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha</span><br><span class=\"line\">         memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);</span><br><span class=\"line\"></span><br><span class=\"line\">         /* Encode this entry&apos;s raw length in the next entry. */</span><br><span class=\"line\">-        zipStorePrevEntryLength(p+reqlen,reqlen);</span><br><span class=\"line\">+        if (forcelarge)</span><br><span class=\"line\">+            zipStorePrevEntryLength(p+reqlen,reqlen);</span><br><span class=\"line\">+        else</span><br><span class=\"line\">+            zipStorePrevEntryLengthLarge(p+reqlen,reqlen);</span><br><span class=\"line\"></span><br><span class=\"line\">         /* Update offset for tail */</span><br><span class=\"line\">         ZIPLIST_TAIL_OFFSET(zl) =</span><br></pre></td></tr></table></figure></p>\n<p>可以看到代码中增加了一个判断<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (nextdiff == -4 &amp;&amp; reqlen &lt; 4)</span><br></pre></td></tr></table></figure></p>\n<p>我们看看nextdiff是如何计算的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int zipPrevLenByteDiff(unsigned char *p, unsigned int len) &#123;</span><br><span class=\"line\">    unsigned int prevlensize;</span><br><span class=\"line\">    //宏,展开之后根据p[0]处的值计算出prevlensize,如果p[0]&lt;254,prevlensize为1,否则为5</span><br><span class=\"line\">    ZIP_DECODE_PREVLENSIZE(p, prevlensize);</span><br><span class=\"line\">    //zipStorePrevEntryLength函数如果第一个参数为NULL,则根据len字段计算需要的字节数,同理,len&lt;254为1个字节,否则为5个字节</span><br><span class=\"line\">    return zipStorePrevEntryLength(NULL, len) - prevlensize;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>如上函数计算nextdiff,可以看出,根据插入位置p当前保存prev_entry_len字段的字节数和即将插入的entry需要的字节数相减得出nextdiff.值有三种类型</p>\n<ul>\n<li>0: 空间相等</li>\n<li>4：需要更多空间</li>\n<li>-4：空间富余</li>\n</ul>\n<p>bug修复过程首先判断nextdiff等于-4,即p位置的prev_entry_len为5个字节,而当前要插入的entry的长度只需要1个字节去保存.然后判断reqlen &lt; 4.看到此处可能读者会有疑惑,既然prev_entry_len长度已经为5个字节了,那么新插入的值prev_entry_len+encoding+content字段肯定会大于5字节,为什么会出现小于4的情况呢?<br>这种情况确实比较费解,通过下文的构造示例我们能够看出,在连锁更新的时候,为了防止大量的重新分配空间的动作,如果一个entry的长度只需要1个字节就能够保存,但是连锁更新时如果原先已经为prev_entry_len分配了5个字节,则不会进行缩容操作.<br>把bug修复代码反向修改回来,编译之后执行如下命令可以导致Redis crash(注意前边是命令编号,下文通过该编号解释Redis中ziplist内存的变化情况):<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.redis-cli del list</span><br><span class=\"line\">1.redis-cli rpush list one</span><br><span class=\"line\">2.redis-cli rpush list two</span><br><span class=\"line\">3.redis-cli rpush list</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">4.redis-cli rpush list</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">5.redis-cli rpush list three</span><br><span class=\"line\">6.redis-cli rpush list a</span><br><span class=\"line\">7.redis-cli lrem list 1</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">8.redis-cli linsert list after</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA 10</span><br><span class=\"line\">9.redis-cli lrange list 0 -1</span><br></pre></td></tr></table></figure></p>\n<p>前6条命令会往一个list中分别插入’one’,’two’,252个’A’,250个’A’,’three’,’a’六个元素.此时内存占用情况如下:<br><img src=\"/img/zl3.png\" alt=\"orig\"></p>\n<p><strong>每个小矩形框表示占用内存字节数,大矩形框表示一个个entry,每个entry有三项,分别为prev_entry_len,encoding和content字段</strong></p>\n<p>接着执行第7条命令,内存占用情况如图,表示如下:<br><img src=\"/img/zl2.png\" alt=\"cascade update\"></p>\n<p>删除了第3个entry,此时第4个entry的前一个entry长度由255字节变为5字节(第2个entry此时为第4个entry的前一个entry),所以prev_entry_len字段由占用5个字节变为占用1个字节.<strong>参见图中黄框部分</strong>.</p>\n<p>注意此时会发生连锁更新,因为蓝框部分的prev_entry_len由257字节变为253,也可以更新为1个字节.但Redis中在连锁更新的情况下为了避免频繁的realloc操作,这种情况下不进行缩容.</p>\n<p>接着执行第8条命令,插入绿框中的数据(见图第3列所示),此时蓝筐中的prev_entry_len是5个字节,绿框中的数据只占用2字节,当将prev_entry_len更新为1字节后,prev_entry_len多余的4字节可以完整的容纳绿框中的数据.<br><strong>即虽然插入了数据,但realloc之后反而缩小了占用的内存,从而导致ziplist中的数据损坏.</strong></p>\n<p>修复这个bug的代码也就很容易理解了,即图中第3列蓝框的prev_entry_len仍然保留为5个字节.</p>\n<p><strong>可以进一步构造另一种情况,即第6步构造为rpush list 10,则此时不会造成redis crash,而是会丢失10这个元素.读者可以画出内存占用图自行分析</strong></p>\n<h2 id=\"redis作者对该bug的思考\"><a href=\"#redis作者对该bug的思考\" class=\"headerlink\" title=\"redis作者对该bug的思考\"></a>redis作者对该bug的思考</h2><p>通过上边的分析,是不是觉着很难理解？Redis作者也意识到由于连锁更新的存在导致ziplist并不是简单易懂.于是提出了一个优化后的替代结构listpack.</p>\n<p>listpack主要做了如下两点改进:</p>\n<ul>\n<li>头部省去了4个字节的zltail字段</li>\n<li>entry中不再保存prev_entry_len这个字段,而是改为保存本entry自己的长度</li>\n</ul>\n<p>整体结构如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;tot-bytes&gt; &lt;num-elements&gt; &lt;element-1&gt; ... &lt;element-N&gt; &lt;listpack-end-byte&gt;</span><br></pre></td></tr></table></figure></p>\n<p>每个entry的结构如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;encoding-type&gt;&lt;element-data&gt;&lt;element-tot-len&gt;</span><br></pre></td></tr></table></figure></p>\n<p>我们知道ziplist设计为适合从尾部到头部逐个遍历,那么listpack如何实现该功能呢？<br>首先通过tot-bytes偏移到结尾,然后<strong>从右到左</strong>读取element-tot-len(<strong>注意该字段设计为从右往左读取</strong>),这样既实现了尾部到头部的遍历,又没有连锁更新的情况.是不是很巧妙.</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><a href=\"https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175\" target=\"_blank\" rel=\"noopener\">https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175</a></li>\n<li><a href=\"https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES</a></li>\n<li><a href=\"https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\" target=\"_blank\" rel=\"noopener\">https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3</a></li>\n<li><a href=\"https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\" target=\"_blank\" rel=\"noopener\">https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"ziplist简介\"><a href=\"#ziplist简介\" class=\"headerlink\" title=\"ziplist简介\"></a>ziplist简介</h2><p>Redis使用ziplist是为了节省内存.以zset为例,当zset元素个数少并且每个元素也比较小的时候,如果直接使用skiplist(可以理解为多层的双向链表),每个节点的前后指针这些元数据占用空间的比例可能达到50%以上.而ziplist是分配在堆上的一块连续内存,通过一定的编码格式,使数据保存更加紧凑.如下是一个编码为ziplist的zset.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6666&gt; zadd zs 100 &apos;a&apos;</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6666&gt; zadd zs 200 &apos;b&apos;</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6666&gt; object encoding zs</span><br><span class=\"line\">&quot;ziplist&quot;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"ziplist格式\"><a href=\"#ziplist格式\" class=\"headerlink\" title=\"ziplist格式\"></a>ziplist格式</h2><p>ziplist的格式如下图所示:<br><img src=\"/img/zl1.png\" alt=\"ziplist\"><br>ziplist各字段解释如下:</p>\n<ul>\n<li>zlbytes:ziplist占用的内存空间大小</li>\n<li>zltail:ziplist最后一个entry的偏移量</li>\n<li>zllen:ziplist中entry的个数.</li>\n<li>entry:每个元素</li>\n<li>0xFF:ziplist的结束标志</li>\n</ul>\n<p>每个entry的字段解释如下:</p>\n<ul>\n<li>prev_entry_len:前一个entry占用的字节大小,占用1个或者5个字节.<strong>当小于254时,占用1字节,当大于等于254时,占用5字节</strong></li>\n<li>encoding:当前entry内容的编码格式及其长度</li>\n<li>content:当前entry保存的内容</li>\n</ul>\n<p>注意ziplist中有一个zltail字段是最后一个entry的偏移量,通过该字段定位到最后一个entry后,读取prev_entry_len可以继续向前定位上一个entry的起始地址.也就是说<strong>ziplist适合于从后往前遍历</strong>.</p>\n<h2 id=\"bug原因及其复现\"><a href=\"#bug原因及其复现\" class=\"headerlink\" title=\"bug原因及其复现\"></a>bug原因及其复现</h2><p>首先看下代码中是如何修复该bug的,然后通过把代码反向修改回来,可以构造示例复现该bug.通过复现过程详细描述该bug的产生过程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@@ -778,7 +778,12 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha</span><br><span class=\"line\">     /* When the insert position is not equal to the tail, we need to</span><br><span class=\"line\">      * make sure that the next entry can hold this entry&apos;s length in</span><br><span class=\"line\">      * its prevlen field. */</span><br><span class=\"line\">+    int forcelarge = 0;</span><br><span class=\"line\">     nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;</span><br><span class=\"line\">+    if (nextdiff == -4 &amp;&amp; reqlen &lt; 4) &#123;</span><br><span class=\"line\">+        nextdiff = 0;</span><br><span class=\"line\">+        forcelarge = 1;</span><br><span class=\"line\">+    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">     /* Store offset because a realloc may change the address of zl. */</span><br><span class=\"line\">     offset = p-zl;</span><br><span class=\"line\">@@ -791,7 +796,10 @@ unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned cha</span><br><span class=\"line\">         memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);</span><br><span class=\"line\"></span><br><span class=\"line\">         /* Encode this entry&apos;s raw length in the next entry. */</span><br><span class=\"line\">-        zipStorePrevEntryLength(p+reqlen,reqlen);</span><br><span class=\"line\">+        if (forcelarge)</span><br><span class=\"line\">+            zipStorePrevEntryLength(p+reqlen,reqlen);</span><br><span class=\"line\">+        else</span><br><span class=\"line\">+            zipStorePrevEntryLengthLarge(p+reqlen,reqlen);</span><br><span class=\"line\"></span><br><span class=\"line\">         /* Update offset for tail */</span><br><span class=\"line\">         ZIPLIST_TAIL_OFFSET(zl) =</span><br></pre></td></tr></table></figure></p>\n<p>可以看到代码中增加了一个判断<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (nextdiff == -4 &amp;&amp; reqlen &lt; 4)</span><br></pre></td></tr></table></figure></p>\n<p>我们看看nextdiff是如何计算的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int zipPrevLenByteDiff(unsigned char *p, unsigned int len) &#123;</span><br><span class=\"line\">    unsigned int prevlensize;</span><br><span class=\"line\">    //宏,展开之后根据p[0]处的值计算出prevlensize,如果p[0]&lt;254,prevlensize为1,否则为5</span><br><span class=\"line\">    ZIP_DECODE_PREVLENSIZE(p, prevlensize);</span><br><span class=\"line\">    //zipStorePrevEntryLength函数如果第一个参数为NULL,则根据len字段计算需要的字节数,同理,len&lt;254为1个字节,否则为5个字节</span><br><span class=\"line\">    return zipStorePrevEntryLength(NULL, len) - prevlensize;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>如上函数计算nextdiff,可以看出,根据插入位置p当前保存prev_entry_len字段的字节数和即将插入的entry需要的字节数相减得出nextdiff.值有三种类型</p>\n<ul>\n<li>0: 空间相等</li>\n<li>4：需要更多空间</li>\n<li>-4：空间富余</li>\n</ul>\n<p>bug修复过程首先判断nextdiff等于-4,即p位置的prev_entry_len为5个字节,而当前要插入的entry的长度只需要1个字节去保存.然后判断reqlen &lt; 4.看到此处可能读者会有疑惑,既然prev_entry_len长度已经为5个字节了,那么新插入的值prev_entry_len+encoding+content字段肯定会大于5字节,为什么会出现小于4的情况呢?<br>这种情况确实比较费解,通过下文的构造示例我们能够看出,在连锁更新的时候,为了防止大量的重新分配空间的动作,如果一个entry的长度只需要1个字节就能够保存,但是连锁更新时如果原先已经为prev_entry_len分配了5个字节,则不会进行缩容操作.<br>把bug修复代码反向修改回来,编译之后执行如下命令可以导致Redis crash(注意前边是命令编号,下文通过该编号解释Redis中ziplist内存的变化情况):<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.redis-cli del list</span><br><span class=\"line\">1.redis-cli rpush list one</span><br><span class=\"line\">2.redis-cli rpush list two</span><br><span class=\"line\">3.redis-cli rpush list</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">4.redis-cli rpush list</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">5.redis-cli rpush list three</span><br><span class=\"line\">6.redis-cli rpush list a</span><br><span class=\"line\">7.redis-cli lrem list 1</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</span><br><span class=\"line\">8.redis-cli linsert list after</span><br><span class=\"line\">AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA 10</span><br><span class=\"line\">9.redis-cli lrange list 0 -1</span><br></pre></td></tr></table></figure></p>\n<p>前6条命令会往一个list中分别插入’one’,’two’,252个’A’,250个’A’,’three’,’a’六个元素.此时内存占用情况如下:<br><img src=\"/img/zl3.png\" alt=\"orig\"></p>\n<p><strong>每个小矩形框表示占用内存字节数,大矩形框表示一个个entry,每个entry有三项,分别为prev_entry_len,encoding和content字段</strong></p>\n<p>接着执行第7条命令,内存占用情况如图,表示如下:<br><img src=\"/img/zl2.png\" alt=\"cascade update\"></p>\n<p>删除了第3个entry,此时第4个entry的前一个entry长度由255字节变为5字节(第2个entry此时为第4个entry的前一个entry),所以prev_entry_len字段由占用5个字节变为占用1个字节.<strong>参见图中黄框部分</strong>.</p>\n<p>注意此时会发生连锁更新,因为蓝框部分的prev_entry_len由257字节变为253,也可以更新为1个字节.但Redis中在连锁更新的情况下为了避免频繁的realloc操作,这种情况下不进行缩容.</p>\n<p>接着执行第8条命令,插入绿框中的数据(见图第3列所示),此时蓝筐中的prev_entry_len是5个字节,绿框中的数据只占用2字节,当将prev_entry_len更新为1字节后,prev_entry_len多余的4字节可以完整的容纳绿框中的数据.<br><strong>即虽然插入了数据,但realloc之后反而缩小了占用的内存,从而导致ziplist中的数据损坏.</strong></p>\n<p>修复这个bug的代码也就很容易理解了,即图中第3列蓝框的prev_entry_len仍然保留为5个字节.</p>\n<p><strong>可以进一步构造另一种情况,即第6步构造为rpush list 10,则此时不会造成redis crash,而是会丢失10这个元素.读者可以画出内存占用图自行分析</strong></p>\n<h2 id=\"redis作者对该bug的思考\"><a href=\"#redis作者对该bug的思考\" class=\"headerlink\" title=\"redis作者对该bug的思考\"></a>redis作者对该bug的思考</h2><p>通过上边的分析,是不是觉着很难理解？Redis作者也意识到由于连锁更新的存在导致ziplist并不是简单易懂.于是提出了一个优化后的替代结构listpack.</p>\n<p>listpack主要做了如下两点改进:</p>\n<ul>\n<li>头部省去了4个字节的zltail字段</li>\n<li>entry中不再保存prev_entry_len这个字段,而是改为保存本entry自己的长度</li>\n</ul>\n<p>整体结构如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;tot-bytes&gt; &lt;num-elements&gt; &lt;element-1&gt; ... &lt;element-N&gt; &lt;listpack-end-byte&gt;</span><br></pre></td></tr></table></figure></p>\n<p>每个entry的结构如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;encoding-type&gt;&lt;element-data&gt;&lt;element-tot-len&gt;</span><br></pre></td></tr></table></figure></p>\n<p>我们知道ziplist设计为适合从尾部到头部逐个遍历,那么listpack如何实现该功能呢？<br>首先通过tot-bytes偏移到结尾,然后<strong>从右到左</strong>读取element-tot-len(<strong>注意该字段设计为从右往左读取</strong>),这样既实现了尾部到头部的遍历,又没有连锁更新的情况.是不是很巧妙.</p>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><ul>\n<li><a href=\"https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175\" target=\"_blank\" rel=\"noopener\">https://gist.github.com/antirez/66ffab20190ece8a7485bd9accfbc175</a></li>\n<li><a href=\"https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES</a></li>\n<li><a href=\"https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\" target=\"_blank\" rel=\"noopener\">https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3</a></li>\n<li><a href=\"https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3\" target=\"_blank\" rel=\"noopener\">https://github.com/antirez/redis/commit/8327b813#diff-b109b27001207a835769c556a54ff1b3</a></li>\n</ul>\n"},{"title":"Sqlite Write-Ahead Logging","date":"2019-04-15T16:00:00.000Z","_content":"\n>这篇文章译自Sqlite官方文档,介绍另一种保证Sqlite原子性的机制,Write-Ahead logging\n\n\n## Sqlite WAL\n原文链接:https://www.sqlite.org/wal.html\n\n### 1.概览\n\nSqlite中默认保证原子性的机制是rollback journal,从3.7.0(2010-07-21)开始,Sqlite引入了另一种机制,Write-Ahead logging,简称为'WAL'.\n\nWAL和rollback journal相比有如下四方面的优点:\n* 在大多数场景下WAL要比rollback journal快\n* WAL模式下,读不阻塞写,写也不阻塞读,读写可以并行执行,所以并发性能更好\n* WAL模式倾向于顺序I/O\n* WAL模式下fsync()的刷盘操作会更少\n\nWAL相比rollback journal也有如下的9方面缺点:\n* WAL需要VFS层面支持共享内存原语,有些操作系统可能并不支持\n* 所有使用数据库的进程必须处于同一台机器,WAL在网络文件系统上不能工作(例如NFS)\n* 如果一个事务中包括多个数据库文件(通过attch命令),WAL模式下只能保证每个数据库的执行是原子性的,但不保证全局的原子性\n* 即使是在一个空数据库或者通过使用vacuum或者通过backup api恢复一个数据库的情况下,要想修改page size必须在rollback journal模式下\n* 从3.22.0(2018-01-22)开始,如果-shm和-wal文件已经存在或者这两文件能够被创建或者数据库是immutable的情况下,能够打开一个read-only的wal模式下的数据库文件\n* WAL模式在大部分读只有极少数写的情况下,会比rollback-journal模式慢1%-2%\n* 因为有一个准持久化的-wal文件和一个-shm共享内存文件,导致Sqlite作为一个 applicate file-format增加了一些复杂度\n* WAL模式下有一个checkpointing机制(自动执行),需要应用开发者引起注意\n* 从3.11.0(2016-02-15)开始,WAL模式在大事务情形下和rollback-journal模式同样有效.但在之前的版本,大事务情行下WAL会慢一些\n\n### 2.实现机制\n\n传统的rollback journal在修改前先将历史数据保存在rollback journal中,然后修改数据库文件.在回滚时,直接将rollback journal中的历史数据覆盖掉被修改的数据库文件,从而恢复到数据修改之前的状态.当删除rollback journal后一个事务就结束了.\n\nWAL和rollback journal是反过来的,数据库文件并不会直接修改,而是将修改append到一个WAL文件中,当事务的记录都已经append到WAL文件之后,事务就可以结束了.因此读操作可以继续读原来的数据库文件,多个写操作也可以同时往一个WAL文件进行append操作.(**回滚操作只要将append到WAL的内容清除即可**)\n\n#### 2.1 checkpointing\n\n把WAL文件中的事务逐步写回数据库文件的过程称为'checkpoint'(**为什么需要写回呢?考虑读取的情况,读取时除了需要读取数据库文件,也得读取WAL中已经提交完成的事务所做的修改,当WAL很大时会影响读取效率**)\n\ncheckpoint可以通过配置SQLITE_DEFAULT_WAL_AUTOCHECKPOINT该选项决定WAL多大时执行自动的checkpoint.默认为1000 pages.当然也可以关掉该功能,通过另外的线程在空闲时去执行checkpoint.\n\n#### 2.2 并行性\n当开启一个读取操作后,首先需要记录一下当前最后一个在WAL提交的有效记录,记为'end mark'.因为WAL日志在不停增长,因此不同的读取操作会有自己的'end mark'.但在整个事务中,每个读取操作的 'end mark'不会改变.\n\n读取一个page时,首先从WAL中(本读取操作的'end mark'之前)获取一份最新的page,如果没有找到则从数据库文件中获取.为了防止读取操作每次都遍历WAL获取一个page(WAL可能会很大),在共享内存中提供了一个'wal index'的结构,能够快速定位WAL中的一个page.这也是为何WAL机制的所有连接必须处于同一台机器,并且不能通过网络文件系统使用的原因.\n\n写入操作只是往WAL文件append记录,可以看出读写互不影响\n\ncheckpoint从WAL的开头往后顺序执行,直到到达任意一个正在执行的读取操作的'end mark',此时停止checkpoint(**如果读取超出end mark的数据并且回写到数据库文件,会使读取操作读取到不该看到的内容**).注意该停止点也保存在共享内存的wal-index中,下次启动时从此处继续执行.可以看出,一个运行很长时间的read transaction会阻止checkpoint的运行.\n\n当一个写操作执行的时候,如果发现整个WAL文件都被checkpoint完成并且进行了刷盘并且当前没有任何读取操作的话,会重新开始从WAL的头部开始写入事务.从而避免WAL文件一直增长\n\n#### 2.3 性能考虑 \n写入时由于只需要写一次(rollback journal需要写两次)并且是顺序写,因此性能会高一些\n读取时需要遍历WAL文件,虽然有共享内存中的WAL-index,随着文件增大,读取性能还是会受影响.因此为了获得好的读取性能,建议定期执行checkpoint.\ncheckpoint时需要进行数据库文件的刷盘和寻道操作,虽然checkpoint尽量做到顺序写入page(**如何做到**),但是仍然需要花费很多寻道的时间,因此checkpoint会比写入要慢.\n \n默认情况下,当WAL达到1000pages时会将WAL进行checkpoint,并且该动作由执行写操作的进程自己负责,这可能会导致大部分情况下写操作很快,但有个别事务因为执行checkpoint导致变慢.如果不希望受此影响,可以关闭自动checkpoint,由另外的线程或进程定期去执行.\n\n读写性能可以通过配置checkpoint的页数达到一个折衷.如果频繁checkpoint,读性能会高一些,但如果尽量减少checkpoint,写性能会高一些.可以根据实际需求来配置\n\n### 配置WAL模式\n```\n\tPRAGMA journal_mode=WAL;\n```\n该配置会设置为WAL模式.如果VFS不支持共享内存原语,则会继续使用 'journal_mode = delete'即rollback journal模式\n\n#### 3.1 自动checkpoint\n当WAL文件中发生一个commit之后会调用通过sqlite3_wal_hook()注册的回调函数.例如可以使用sqlite3_wal_checkpoint()或者sqlite3_wal_checkpoint_v2()来执行checkpoint.自动checkpoint也是在sqlite3_wal_hook()之上简单的进行了包装.\n\n```\npragma wal_autocheckpoint\n```\n该配置用来修改自动执行checkpoint的配置\n\n#### 3.2 应用启动的checkpoint\n\n通过调用sqlite3_wal_checkpoint可以启动一个passive类型的checkpoint,该类型的checkpoint不会影响其他连接的读写操作.\n通过调用sqlite3_wal_checkpoint_v2可以启动一个full或者restart类型的checkpoint,这两种类型会将checkpoint执行直到完成\n\n#### 3.3 WAL配置的持久性\n当配置如下时\n```\nPRAGMA journal_mode=WAL\n```\n即使关闭后重启database,仍然是WAL模式.\n但如果PRAGMA journal_mode=truncate,关闭重启后就会返回为delete.(**不知为何**)\n\n### WAL文件\n\n当在WAL模式下打开一个数据库连接后,会生成一个WAL文件,命名方式为数据库文件名称加'-wal'后缀.\n\n只要有数据库连接打开数据库,WAL文件就会存在.通常来说,当数据库上最后一个连接关闭之后,WAL文件会被自动删除.如果最后一个连接没有显示关闭连接或者SQLITE_FCNTL_PERSIST_WAL被使用,WAL文件将会在磁盘上一直存在.WAL文件需要合数据库文件保存到一块,否则可能会发生数据丢失或者数据库文件损坏.删除一个wal文件最安全的方法是首先调用sqlite3_open()打开一个数据库文件然后调用sqlite3_close()关闭该文件.\n\nWAL文件格式是严格定义的并且跨平台.\n\n### read-only数据库\n\n从3.22.0(2018-01-22)开始允许一个wal模式的数据在只读媒介上打开.只需要满足如下三个条件:\n* -shm和-wal文件已经存在并且可读\n* 包括-shm和-wal文件的目录可写,以便创建这两文件\n* 数据库连接 以'immutable query parameter'打开\n\n虽然允许打开一个wal模式下的只读数据库,最好是在将sqlite部署到只读媒介时将pragma journal_mode修改为delete\n\n### 如何避免生成过大的wal file\n* 关闭自动checkpoint后可能会造成 wal file过大\n* 当有大量的读操作时会造成checkpoint不能执行完成,可能导致wal file过大.此时应该考虑手动checkpoint（使用SQLITE_CHECKPOINT_RESTART或者SQLITE_CHECKPOINT_TRUNCATE选项）.\n但注意这样会造成读操作在执行checkpoint时阻塞\n* 当有一个非常大的写事务时会导致chedkpoint没法执行完成.导致wal file 过大.从sqlite 3.11.0(2016-02-15)开始,被一个事务修改的pages只会往wal文件写一次.旧版本中,如果一个事务使用数据大小超过page cache的话,会导致同一个page可能被多次写入wal file.\n\n### wal-index在共享内存中的实现\n\nwal-index通过将一个普通文件mmap到内存中实现.之前是将wal-index通过在/dev/shm(linux)或者/tmp(unix)中创建一个文件来实现.但这种方法会导致有不同根目录(通过chroot)的进程看到不同的文件从而使用了不同的共享内存,导致数据库损坏.其他的创建匿名共享内存的方法又不够通用.因此现在直接通过在数据库文件所在目录创建一个普通文件然后映射到内存中实现共享.\n\n这种方法也有缺点,从共享内存刷新到磁盘可能会导致不必要的磁盘I/O.但Sqlite开发者不认为这是个问题,因为wal-index很少会超过32KB并且从不会被刷盘.进一步,wal-index 文件在最后一个数据库连接断开之后会被删除,因此不会有任何实质性的disk I/O会发生.\n\n如果有些应用觉着这种方法不可接受,也可以自己定制.例如:如果应用只会通过在一个进程中的不同线程访问,那么wal-index可以实现到堆内存中而不是使用共享内存.\n\n### 不适用共享内存的wal模式\n\nSQLite3.7.4 (2010-12-07)之后,如果locking_mode在第一个请求到来之前设置为exclusive,则wal模式可以在没有共享内存的情况下使用.换句话说即保证只有一个进程会访问数据库.\n\n### 请求返回SQLITE_BUSY的情形\n\n大部分情况下读写请求互不阻塞,但有些情况下可能会返回SQLITE_BUSY.\n\n例如:\n\n* 如果一个连接以exclusive mode模式打开数据库,其他请求都会返回SQLITE_BUSY.CHROME和FIREFOX都是以exclusive mode打开的数据库,所以如果其他视图打开读取chrome和firefox数据库的请求都会返回SQLITE_BUSY.\n\n* 当最后一个连接关闭的时候,该连接会短暂的获取一个exclusive lock以便清理WAL和shared-memory文件,如果第二个请求在此时想要打开该数据库文件,也会返回一个SQLITE_BUSY错误.\n\n* 如果最后一个连接crash,则新的连接会首先执行一个恢复流程.该流程中也会持有一个exclusive lock,此时如果另一个连接试图读取也会返回一个SQLITE_BUSY错误.\n\n\n### 后向兼容性\n\n为了防止旧版本的Sqlite(3.7.0之前,2010-07-22,旧版本的Sqlite并不能识别wal文件和共享内存中的wal-index)试图恢复一个wal模式的数据库,数据库文件头中的file format版本号(18-19字节)从1更新为了2(WAL模式下).因此如果一个旧版本的Sqlite尝试连接一个Sqlite数据库文件时,会报一个\"file is encrypted or is not a database\"的错误.\n```\nPRAGMA journal_mode=DELETE;\n```\n使用该配置可以更改WAL模式为roll-back journal模式\n此时版本号会从2改回1,因此旧版本Sqlite可以继续使用该数据库.\n\n\n\n\n\n\n\n\n\n","source":"_posts/Sqlite Write-Ahead Logging .md","raw":"---\ntitle: Sqlite Write-Ahead Logging\ndate: 2019-04-16\ntags: Sqlite\n---\n\n>这篇文章译自Sqlite官方文档,介绍另一种保证Sqlite原子性的机制,Write-Ahead logging\n\n\n## Sqlite WAL\n原文链接:https://www.sqlite.org/wal.html\n\n### 1.概览\n\nSqlite中默认保证原子性的机制是rollback journal,从3.7.0(2010-07-21)开始,Sqlite引入了另一种机制,Write-Ahead logging,简称为'WAL'.\n\nWAL和rollback journal相比有如下四方面的优点:\n* 在大多数场景下WAL要比rollback journal快\n* WAL模式下,读不阻塞写,写也不阻塞读,读写可以并行执行,所以并发性能更好\n* WAL模式倾向于顺序I/O\n* WAL模式下fsync()的刷盘操作会更少\n\nWAL相比rollback journal也有如下的9方面缺点:\n* WAL需要VFS层面支持共享内存原语,有些操作系统可能并不支持\n* 所有使用数据库的进程必须处于同一台机器,WAL在网络文件系统上不能工作(例如NFS)\n* 如果一个事务中包括多个数据库文件(通过attch命令),WAL模式下只能保证每个数据库的执行是原子性的,但不保证全局的原子性\n* 即使是在一个空数据库或者通过使用vacuum或者通过backup api恢复一个数据库的情况下,要想修改page size必须在rollback journal模式下\n* 从3.22.0(2018-01-22)开始,如果-shm和-wal文件已经存在或者这两文件能够被创建或者数据库是immutable的情况下,能够打开一个read-only的wal模式下的数据库文件\n* WAL模式在大部分读只有极少数写的情况下,会比rollback-journal模式慢1%-2%\n* 因为有一个准持久化的-wal文件和一个-shm共享内存文件,导致Sqlite作为一个 applicate file-format增加了一些复杂度\n* WAL模式下有一个checkpointing机制(自动执行),需要应用开发者引起注意\n* 从3.11.0(2016-02-15)开始,WAL模式在大事务情形下和rollback-journal模式同样有效.但在之前的版本,大事务情行下WAL会慢一些\n\n### 2.实现机制\n\n传统的rollback journal在修改前先将历史数据保存在rollback journal中,然后修改数据库文件.在回滚时,直接将rollback journal中的历史数据覆盖掉被修改的数据库文件,从而恢复到数据修改之前的状态.当删除rollback journal后一个事务就结束了.\n\nWAL和rollback journal是反过来的,数据库文件并不会直接修改,而是将修改append到一个WAL文件中,当事务的记录都已经append到WAL文件之后,事务就可以结束了.因此读操作可以继续读原来的数据库文件,多个写操作也可以同时往一个WAL文件进行append操作.(**回滚操作只要将append到WAL的内容清除即可**)\n\n#### 2.1 checkpointing\n\n把WAL文件中的事务逐步写回数据库文件的过程称为'checkpoint'(**为什么需要写回呢?考虑读取的情况,读取时除了需要读取数据库文件,也得读取WAL中已经提交完成的事务所做的修改,当WAL很大时会影响读取效率**)\n\ncheckpoint可以通过配置SQLITE_DEFAULT_WAL_AUTOCHECKPOINT该选项决定WAL多大时执行自动的checkpoint.默认为1000 pages.当然也可以关掉该功能,通过另外的线程在空闲时去执行checkpoint.\n\n#### 2.2 并行性\n当开启一个读取操作后,首先需要记录一下当前最后一个在WAL提交的有效记录,记为'end mark'.因为WAL日志在不停增长,因此不同的读取操作会有自己的'end mark'.但在整个事务中,每个读取操作的 'end mark'不会改变.\n\n读取一个page时,首先从WAL中(本读取操作的'end mark'之前)获取一份最新的page,如果没有找到则从数据库文件中获取.为了防止读取操作每次都遍历WAL获取一个page(WAL可能会很大),在共享内存中提供了一个'wal index'的结构,能够快速定位WAL中的一个page.这也是为何WAL机制的所有连接必须处于同一台机器,并且不能通过网络文件系统使用的原因.\n\n写入操作只是往WAL文件append记录,可以看出读写互不影响\n\ncheckpoint从WAL的开头往后顺序执行,直到到达任意一个正在执行的读取操作的'end mark',此时停止checkpoint(**如果读取超出end mark的数据并且回写到数据库文件,会使读取操作读取到不该看到的内容**).注意该停止点也保存在共享内存的wal-index中,下次启动时从此处继续执行.可以看出,一个运行很长时间的read transaction会阻止checkpoint的运行.\n\n当一个写操作执行的时候,如果发现整个WAL文件都被checkpoint完成并且进行了刷盘并且当前没有任何读取操作的话,会重新开始从WAL的头部开始写入事务.从而避免WAL文件一直增长\n\n#### 2.3 性能考虑 \n写入时由于只需要写一次(rollback journal需要写两次)并且是顺序写,因此性能会高一些\n读取时需要遍历WAL文件,虽然有共享内存中的WAL-index,随着文件增大,读取性能还是会受影响.因此为了获得好的读取性能,建议定期执行checkpoint.\ncheckpoint时需要进行数据库文件的刷盘和寻道操作,虽然checkpoint尽量做到顺序写入page(**如何做到**),但是仍然需要花费很多寻道的时间,因此checkpoint会比写入要慢.\n \n默认情况下,当WAL达到1000pages时会将WAL进行checkpoint,并且该动作由执行写操作的进程自己负责,这可能会导致大部分情况下写操作很快,但有个别事务因为执行checkpoint导致变慢.如果不希望受此影响,可以关闭自动checkpoint,由另外的线程或进程定期去执行.\n\n读写性能可以通过配置checkpoint的页数达到一个折衷.如果频繁checkpoint,读性能会高一些,但如果尽量减少checkpoint,写性能会高一些.可以根据实际需求来配置\n\n### 配置WAL模式\n```\n\tPRAGMA journal_mode=WAL;\n```\n该配置会设置为WAL模式.如果VFS不支持共享内存原语,则会继续使用 'journal_mode = delete'即rollback journal模式\n\n#### 3.1 自动checkpoint\n当WAL文件中发生一个commit之后会调用通过sqlite3_wal_hook()注册的回调函数.例如可以使用sqlite3_wal_checkpoint()或者sqlite3_wal_checkpoint_v2()来执行checkpoint.自动checkpoint也是在sqlite3_wal_hook()之上简单的进行了包装.\n\n```\npragma wal_autocheckpoint\n```\n该配置用来修改自动执行checkpoint的配置\n\n#### 3.2 应用启动的checkpoint\n\n通过调用sqlite3_wal_checkpoint可以启动一个passive类型的checkpoint,该类型的checkpoint不会影响其他连接的读写操作.\n通过调用sqlite3_wal_checkpoint_v2可以启动一个full或者restart类型的checkpoint,这两种类型会将checkpoint执行直到完成\n\n#### 3.3 WAL配置的持久性\n当配置如下时\n```\nPRAGMA journal_mode=WAL\n```\n即使关闭后重启database,仍然是WAL模式.\n但如果PRAGMA journal_mode=truncate,关闭重启后就会返回为delete.(**不知为何**)\n\n### WAL文件\n\n当在WAL模式下打开一个数据库连接后,会生成一个WAL文件,命名方式为数据库文件名称加'-wal'后缀.\n\n只要有数据库连接打开数据库,WAL文件就会存在.通常来说,当数据库上最后一个连接关闭之后,WAL文件会被自动删除.如果最后一个连接没有显示关闭连接或者SQLITE_FCNTL_PERSIST_WAL被使用,WAL文件将会在磁盘上一直存在.WAL文件需要合数据库文件保存到一块,否则可能会发生数据丢失或者数据库文件损坏.删除一个wal文件最安全的方法是首先调用sqlite3_open()打开一个数据库文件然后调用sqlite3_close()关闭该文件.\n\nWAL文件格式是严格定义的并且跨平台.\n\n### read-only数据库\n\n从3.22.0(2018-01-22)开始允许一个wal模式的数据在只读媒介上打开.只需要满足如下三个条件:\n* -shm和-wal文件已经存在并且可读\n* 包括-shm和-wal文件的目录可写,以便创建这两文件\n* 数据库连接 以'immutable query parameter'打开\n\n虽然允许打开一个wal模式下的只读数据库,最好是在将sqlite部署到只读媒介时将pragma journal_mode修改为delete\n\n### 如何避免生成过大的wal file\n* 关闭自动checkpoint后可能会造成 wal file过大\n* 当有大量的读操作时会造成checkpoint不能执行完成,可能导致wal file过大.此时应该考虑手动checkpoint（使用SQLITE_CHECKPOINT_RESTART或者SQLITE_CHECKPOINT_TRUNCATE选项）.\n但注意这样会造成读操作在执行checkpoint时阻塞\n* 当有一个非常大的写事务时会导致chedkpoint没法执行完成.导致wal file 过大.从sqlite 3.11.0(2016-02-15)开始,被一个事务修改的pages只会往wal文件写一次.旧版本中,如果一个事务使用数据大小超过page cache的话,会导致同一个page可能被多次写入wal file.\n\n### wal-index在共享内存中的实现\n\nwal-index通过将一个普通文件mmap到内存中实现.之前是将wal-index通过在/dev/shm(linux)或者/tmp(unix)中创建一个文件来实现.但这种方法会导致有不同根目录(通过chroot)的进程看到不同的文件从而使用了不同的共享内存,导致数据库损坏.其他的创建匿名共享内存的方法又不够通用.因此现在直接通过在数据库文件所在目录创建一个普通文件然后映射到内存中实现共享.\n\n这种方法也有缺点,从共享内存刷新到磁盘可能会导致不必要的磁盘I/O.但Sqlite开发者不认为这是个问题,因为wal-index很少会超过32KB并且从不会被刷盘.进一步,wal-index 文件在最后一个数据库连接断开之后会被删除,因此不会有任何实质性的disk I/O会发生.\n\n如果有些应用觉着这种方法不可接受,也可以自己定制.例如:如果应用只会通过在一个进程中的不同线程访问,那么wal-index可以实现到堆内存中而不是使用共享内存.\n\n### 不适用共享内存的wal模式\n\nSQLite3.7.4 (2010-12-07)之后,如果locking_mode在第一个请求到来之前设置为exclusive,则wal模式可以在没有共享内存的情况下使用.换句话说即保证只有一个进程会访问数据库.\n\n### 请求返回SQLITE_BUSY的情形\n\n大部分情况下读写请求互不阻塞,但有些情况下可能会返回SQLITE_BUSY.\n\n例如:\n\n* 如果一个连接以exclusive mode模式打开数据库,其他请求都会返回SQLITE_BUSY.CHROME和FIREFOX都是以exclusive mode打开的数据库,所以如果其他视图打开读取chrome和firefox数据库的请求都会返回SQLITE_BUSY.\n\n* 当最后一个连接关闭的时候,该连接会短暂的获取一个exclusive lock以便清理WAL和shared-memory文件,如果第二个请求在此时想要打开该数据库文件,也会返回一个SQLITE_BUSY错误.\n\n* 如果最后一个连接crash,则新的连接会首先执行一个恢复流程.该流程中也会持有一个exclusive lock,此时如果另一个连接试图读取也会返回一个SQLITE_BUSY错误.\n\n\n### 后向兼容性\n\n为了防止旧版本的Sqlite(3.7.0之前,2010-07-22,旧版本的Sqlite并不能识别wal文件和共享内存中的wal-index)试图恢复一个wal模式的数据库,数据库文件头中的file format版本号(18-19字节)从1更新为了2(WAL模式下).因此如果一个旧版本的Sqlite尝试连接一个Sqlite数据库文件时,会报一个\"file is encrypted or is not a database\"的错误.\n```\nPRAGMA journal_mode=DELETE;\n```\n使用该配置可以更改WAL模式为roll-back journal模式\n此时版本号会从2改回1,因此旧版本Sqlite可以继续使用该数据库.\n\n\n\n\n\n\n\n\n\n","slug":"Sqlite Write-Ahead Logging ","published":1,"updated":"2019-04-16T11:39:18.159Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbd001lbms66qt1d4hc","content":"<blockquote>\n<p>这篇文章译自Sqlite官方文档,介绍另一种保证Sqlite原子性的机制,Write-Ahead logging</p>\n</blockquote>\n<h2 id=\"Sqlite-WAL\"><a href=\"#Sqlite-WAL\" class=\"headerlink\" title=\"Sqlite WAL\"></a>Sqlite WAL</h2><p>原文链接:<a href=\"https://www.sqlite.org/wal.html\" target=\"_blank\" rel=\"noopener\">https://www.sqlite.org/wal.html</a></p>\n<h3 id=\"1-概览\"><a href=\"#1-概览\" class=\"headerlink\" title=\"1.概览\"></a>1.概览</h3><p>Sqlite中默认保证原子性的机制是rollback journal,从3.7.0(2010-07-21)开始,Sqlite引入了另一种机制,Write-Ahead logging,简称为’WAL’.</p>\n<p>WAL和rollback journal相比有如下四方面的优点:</p>\n<ul>\n<li>在大多数场景下WAL要比rollback journal快</li>\n<li>WAL模式下,读不阻塞写,写也不阻塞读,读写可以并行执行,所以并发性能更好</li>\n<li>WAL模式倾向于顺序I/O</li>\n<li>WAL模式下fsync()的刷盘操作会更少</li>\n</ul>\n<p>WAL相比rollback journal也有如下的9方面缺点:</p>\n<ul>\n<li>WAL需要VFS层面支持共享内存原语,有些操作系统可能并不支持</li>\n<li>所有使用数据库的进程必须处于同一台机器,WAL在网络文件系统上不能工作(例如NFS)</li>\n<li>如果一个事务中包括多个数据库文件(通过attch命令),WAL模式下只能保证每个数据库的执行是原子性的,但不保证全局的原子性</li>\n<li>即使是在一个空数据库或者通过使用vacuum或者通过backup api恢复一个数据库的情况下,要想修改page size必须在rollback journal模式下</li>\n<li>从3.22.0(2018-01-22)开始,如果-shm和-wal文件已经存在或者这两文件能够被创建或者数据库是immutable的情况下,能够打开一个read-only的wal模式下的数据库文件</li>\n<li>WAL模式在大部分读只有极少数写的情况下,会比rollback-journal模式慢1%-2%</li>\n<li>因为有一个准持久化的-wal文件和一个-shm共享内存文件,导致Sqlite作为一个 applicate file-format增加了一些复杂度</li>\n<li>WAL模式下有一个checkpointing机制(自动执行),需要应用开发者引起注意</li>\n<li>从3.11.0(2016-02-15)开始,WAL模式在大事务情形下和rollback-journal模式同样有效.但在之前的版本,大事务情行下WAL会慢一些</li>\n</ul>\n<h3 id=\"2-实现机制\"><a href=\"#2-实现机制\" class=\"headerlink\" title=\"2.实现机制\"></a>2.实现机制</h3><p>传统的rollback journal在修改前先将历史数据保存在rollback journal中,然后修改数据库文件.在回滚时,直接将rollback journal中的历史数据覆盖掉被修改的数据库文件,从而恢复到数据修改之前的状态.当删除rollback journal后一个事务就结束了.</p>\n<p>WAL和rollback journal是反过来的,数据库文件并不会直接修改,而是将修改append到一个WAL文件中,当事务的记录都已经append到WAL文件之后,事务就可以结束了.因此读操作可以继续读原来的数据库文件,多个写操作也可以同时往一个WAL文件进行append操作.(<strong>回滚操作只要将append到WAL的内容清除即可</strong>)</p>\n<h4 id=\"2-1-checkpointing\"><a href=\"#2-1-checkpointing\" class=\"headerlink\" title=\"2.1 checkpointing\"></a>2.1 checkpointing</h4><p>把WAL文件中的事务逐步写回数据库文件的过程称为’checkpoint’(<strong>为什么需要写回呢?考虑读取的情况,读取时除了需要读取数据库文件,也得读取WAL中已经提交完成的事务所做的修改,当WAL很大时会影响读取效率</strong>)</p>\n<p>checkpoint可以通过配置SQLITE_DEFAULT_WAL_AUTOCHECKPOINT该选项决定WAL多大时执行自动的checkpoint.默认为1000 pages.当然也可以关掉该功能,通过另外的线程在空闲时去执行checkpoint.</p>\n<h4 id=\"2-2-并行性\"><a href=\"#2-2-并行性\" class=\"headerlink\" title=\"2.2 并行性\"></a>2.2 并行性</h4><p>当开启一个读取操作后,首先需要记录一下当前最后一个在WAL提交的有效记录,记为’end mark’.因为WAL日志在不停增长,因此不同的读取操作会有自己的’end mark’.但在整个事务中,每个读取操作的 ‘end mark’不会改变.</p>\n<p>读取一个page时,首先从WAL中(本读取操作的’end mark’之前)获取一份最新的page,如果没有找到则从数据库文件中获取.为了防止读取操作每次都遍历WAL获取一个page(WAL可能会很大),在共享内存中提供了一个’wal index’的结构,能够快速定位WAL中的一个page.这也是为何WAL机制的所有连接必须处于同一台机器,并且不能通过网络文件系统使用的原因.</p>\n<p>写入操作只是往WAL文件append记录,可以看出读写互不影响</p>\n<p>checkpoint从WAL的开头往后顺序执行,直到到达任意一个正在执行的读取操作的’end mark’,此时停止checkpoint(<strong>如果读取超出end mark的数据并且回写到数据库文件,会使读取操作读取到不该看到的内容</strong>).注意该停止点也保存在共享内存的wal-index中,下次启动时从此处继续执行.可以看出,一个运行很长时间的read transaction会阻止checkpoint的运行.</p>\n<p>当一个写操作执行的时候,如果发现整个WAL文件都被checkpoint完成并且进行了刷盘并且当前没有任何读取操作的话,会重新开始从WAL的头部开始写入事务.从而避免WAL文件一直增长</p>\n<h4 id=\"2-3-性能考虑\"><a href=\"#2-3-性能考虑\" class=\"headerlink\" title=\"2.3 性能考虑\"></a>2.3 性能考虑</h4><p>写入时由于只需要写一次(rollback journal需要写两次)并且是顺序写,因此性能会高一些<br>读取时需要遍历WAL文件,虽然有共享内存中的WAL-index,随着文件增大,读取性能还是会受影响.因此为了获得好的读取性能,建议定期执行checkpoint.<br>checkpoint时需要进行数据库文件的刷盘和寻道操作,虽然checkpoint尽量做到顺序写入page(<strong>如何做到</strong>),但是仍然需要花费很多寻道的时间,因此checkpoint会比写入要慢.</p>\n<p>默认情况下,当WAL达到1000pages时会将WAL进行checkpoint,并且该动作由执行写操作的进程自己负责,这可能会导致大部分情况下写操作很快,但有个别事务因为执行checkpoint导致变慢.如果不希望受此影响,可以关闭自动checkpoint,由另外的线程或进程定期去执行.</p>\n<p>读写性能可以通过配置checkpoint的页数达到一个折衷.如果频繁checkpoint,读性能会高一些,但如果尽量减少checkpoint,写性能会高一些.可以根据实际需求来配置</p>\n<h3 id=\"配置WAL模式\"><a href=\"#配置WAL模式\" class=\"headerlink\" title=\"配置WAL模式\"></a>配置WAL模式</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=WAL;</span><br></pre></td></tr></table></figure>\n<p>该配置会设置为WAL模式.如果VFS不支持共享内存原语,则会继续使用 ‘journal_mode = delete’即rollback journal模式</p>\n<h4 id=\"3-1-自动checkpoint\"><a href=\"#3-1-自动checkpoint\" class=\"headerlink\" title=\"3.1 自动checkpoint\"></a>3.1 自动checkpoint</h4><p>当WAL文件中发生一个commit之后会调用通过sqlite3_wal_hook()注册的回调函数.例如可以使用sqlite3_wal_checkpoint()或者sqlite3_wal_checkpoint_v2()来执行checkpoint.自动checkpoint也是在sqlite3_wal_hook()之上简单的进行了包装.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma wal_autocheckpoint</span><br></pre></td></tr></table></figure>\n<p>该配置用来修改自动执行checkpoint的配置</p>\n<h4 id=\"3-2-应用启动的checkpoint\"><a href=\"#3-2-应用启动的checkpoint\" class=\"headerlink\" title=\"3.2 应用启动的checkpoint\"></a>3.2 应用启动的checkpoint</h4><p>通过调用sqlite3_wal_checkpoint可以启动一个passive类型的checkpoint,该类型的checkpoint不会影响其他连接的读写操作.<br>通过调用sqlite3_wal_checkpoint_v2可以启动一个full或者restart类型的checkpoint,这两种类型会将checkpoint执行直到完成</p>\n<h4 id=\"3-3-WAL配置的持久性\"><a href=\"#3-3-WAL配置的持久性\" class=\"headerlink\" title=\"3.3 WAL配置的持久性\"></a>3.3 WAL配置的持久性</h4><p>当配置如下时<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=WAL</span><br></pre></td></tr></table></figure></p>\n<p>即使关闭后重启database,仍然是WAL模式.<br>但如果PRAGMA journal_mode=truncate,关闭重启后就会返回为delete.(<strong>不知为何</strong>)</p>\n<h3 id=\"WAL文件\"><a href=\"#WAL文件\" class=\"headerlink\" title=\"WAL文件\"></a>WAL文件</h3><p>当在WAL模式下打开一个数据库连接后,会生成一个WAL文件,命名方式为数据库文件名称加’-wal’后缀.</p>\n<p>只要有数据库连接打开数据库,WAL文件就会存在.通常来说,当数据库上最后一个连接关闭之后,WAL文件会被自动删除.如果最后一个连接没有显示关闭连接或者SQLITE_FCNTL_PERSIST_WAL被使用,WAL文件将会在磁盘上一直存在.WAL文件需要合数据库文件保存到一块,否则可能会发生数据丢失或者数据库文件损坏.删除一个wal文件最安全的方法是首先调用sqlite3_open()打开一个数据库文件然后调用sqlite3_close()关闭该文件.</p>\n<p>WAL文件格式是严格定义的并且跨平台.</p>\n<h3 id=\"read-only数据库\"><a href=\"#read-only数据库\" class=\"headerlink\" title=\"read-only数据库\"></a>read-only数据库</h3><p>从3.22.0(2018-01-22)开始允许一个wal模式的数据在只读媒介上打开.只需要满足如下三个条件:</p>\n<ul>\n<li>-shm和-wal文件已经存在并且可读</li>\n<li>包括-shm和-wal文件的目录可写,以便创建这两文件</li>\n<li>数据库连接 以’immutable query parameter’打开</li>\n</ul>\n<p>虽然允许打开一个wal模式下的只读数据库,最好是在将sqlite部署到只读媒介时将pragma journal_mode修改为delete</p>\n<h3 id=\"如何避免生成过大的wal-file\"><a href=\"#如何避免生成过大的wal-file\" class=\"headerlink\" title=\"如何避免生成过大的wal file\"></a>如何避免生成过大的wal file</h3><ul>\n<li>关闭自动checkpoint后可能会造成 wal file过大</li>\n<li>当有大量的读操作时会造成checkpoint不能执行完成,可能导致wal file过大.此时应该考虑手动checkpoint（使用SQLITE_CHECKPOINT_RESTART或者SQLITE_CHECKPOINT_TRUNCATE选项）.<br>但注意这样会造成读操作在执行checkpoint时阻塞</li>\n<li>当有一个非常大的写事务时会导致chedkpoint没法执行完成.导致wal file 过大.从sqlite 3.11.0(2016-02-15)开始,被一个事务修改的pages只会往wal文件写一次.旧版本中,如果一个事务使用数据大小超过page cache的话,会导致同一个page可能被多次写入wal file.</li>\n</ul>\n<h3 id=\"wal-index在共享内存中的实现\"><a href=\"#wal-index在共享内存中的实现\" class=\"headerlink\" title=\"wal-index在共享内存中的实现\"></a>wal-index在共享内存中的实现</h3><p>wal-index通过将一个普通文件mmap到内存中实现.之前是将wal-index通过在/dev/shm(linux)或者/tmp(unix)中创建一个文件来实现.但这种方法会导致有不同根目录(通过chroot)的进程看到不同的文件从而使用了不同的共享内存,导致数据库损坏.其他的创建匿名共享内存的方法又不够通用.因此现在直接通过在数据库文件所在目录创建一个普通文件然后映射到内存中实现共享.</p>\n<p>这种方法也有缺点,从共享内存刷新到磁盘可能会导致不必要的磁盘I/O.但Sqlite开发者不认为这是个问题,因为wal-index很少会超过32KB并且从不会被刷盘.进一步,wal-index 文件在最后一个数据库连接断开之后会被删除,因此不会有任何实质性的disk I/O会发生.</p>\n<p>如果有些应用觉着这种方法不可接受,也可以自己定制.例如:如果应用只会通过在一个进程中的不同线程访问,那么wal-index可以实现到堆内存中而不是使用共享内存.</p>\n<h3 id=\"不适用共享内存的wal模式\"><a href=\"#不适用共享内存的wal模式\" class=\"headerlink\" title=\"不适用共享内存的wal模式\"></a>不适用共享内存的wal模式</h3><p>SQLite3.7.4 (2010-12-07)之后,如果locking_mode在第一个请求到来之前设置为exclusive,则wal模式可以在没有共享内存的情况下使用.换句话说即保证只有一个进程会访问数据库.</p>\n<h3 id=\"请求返回SQLITE-BUSY的情形\"><a href=\"#请求返回SQLITE-BUSY的情形\" class=\"headerlink\" title=\"请求返回SQLITE_BUSY的情形\"></a>请求返回SQLITE_BUSY的情形</h3><p>大部分情况下读写请求互不阻塞,但有些情况下可能会返回SQLITE_BUSY.</p>\n<p>例如:</p>\n<ul>\n<li><p>如果一个连接以exclusive mode模式打开数据库,其他请求都会返回SQLITE_BUSY.CHROME和FIREFOX都是以exclusive mode打开的数据库,所以如果其他视图打开读取chrome和firefox数据库的请求都会返回SQLITE_BUSY.</p>\n</li>\n<li><p>当最后一个连接关闭的时候,该连接会短暂的获取一个exclusive lock以便清理WAL和shared-memory文件,如果第二个请求在此时想要打开该数据库文件,也会返回一个SQLITE_BUSY错误.</p>\n</li>\n<li><p>如果最后一个连接crash,则新的连接会首先执行一个恢复流程.该流程中也会持有一个exclusive lock,此时如果另一个连接试图读取也会返回一个SQLITE_BUSY错误.</p>\n</li>\n</ul>\n<h3 id=\"后向兼容性\"><a href=\"#后向兼容性\" class=\"headerlink\" title=\"后向兼容性\"></a>后向兼容性</h3><p>为了防止旧版本的Sqlite(3.7.0之前,2010-07-22,旧版本的Sqlite并不能识别wal文件和共享内存中的wal-index)试图恢复一个wal模式的数据库,数据库文件头中的file format版本号(18-19字节)从1更新为了2(WAL模式下).因此如果一个旧版本的Sqlite尝试连接一个Sqlite数据库文件时,会报一个”file is encrypted or is not a database”的错误.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=DELETE;</span><br></pre></td></tr></table></figure></p>\n<p>使用该配置可以更改WAL模式为roll-back journal模式<br>此时版本号会从2改回1,因此旧版本Sqlite可以继续使用该数据库.</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>这篇文章译自Sqlite官方文档,介绍另一种保证Sqlite原子性的机制,Write-Ahead logging</p>\n</blockquote>\n<h2 id=\"Sqlite-WAL\"><a href=\"#Sqlite-WAL\" class=\"headerlink\" title=\"Sqlite WAL\"></a>Sqlite WAL</h2><p>原文链接:<a href=\"https://www.sqlite.org/wal.html\" target=\"_blank\" rel=\"noopener\">https://www.sqlite.org/wal.html</a></p>\n<h3 id=\"1-概览\"><a href=\"#1-概览\" class=\"headerlink\" title=\"1.概览\"></a>1.概览</h3><p>Sqlite中默认保证原子性的机制是rollback journal,从3.7.0(2010-07-21)开始,Sqlite引入了另一种机制,Write-Ahead logging,简称为’WAL’.</p>\n<p>WAL和rollback journal相比有如下四方面的优点:</p>\n<ul>\n<li>在大多数场景下WAL要比rollback journal快</li>\n<li>WAL模式下,读不阻塞写,写也不阻塞读,读写可以并行执行,所以并发性能更好</li>\n<li>WAL模式倾向于顺序I/O</li>\n<li>WAL模式下fsync()的刷盘操作会更少</li>\n</ul>\n<p>WAL相比rollback journal也有如下的9方面缺点:</p>\n<ul>\n<li>WAL需要VFS层面支持共享内存原语,有些操作系统可能并不支持</li>\n<li>所有使用数据库的进程必须处于同一台机器,WAL在网络文件系统上不能工作(例如NFS)</li>\n<li>如果一个事务中包括多个数据库文件(通过attch命令),WAL模式下只能保证每个数据库的执行是原子性的,但不保证全局的原子性</li>\n<li>即使是在一个空数据库或者通过使用vacuum或者通过backup api恢复一个数据库的情况下,要想修改page size必须在rollback journal模式下</li>\n<li>从3.22.0(2018-01-22)开始,如果-shm和-wal文件已经存在或者这两文件能够被创建或者数据库是immutable的情况下,能够打开一个read-only的wal模式下的数据库文件</li>\n<li>WAL模式在大部分读只有极少数写的情况下,会比rollback-journal模式慢1%-2%</li>\n<li>因为有一个准持久化的-wal文件和一个-shm共享内存文件,导致Sqlite作为一个 applicate file-format增加了一些复杂度</li>\n<li>WAL模式下有一个checkpointing机制(自动执行),需要应用开发者引起注意</li>\n<li>从3.11.0(2016-02-15)开始,WAL模式在大事务情形下和rollback-journal模式同样有效.但在之前的版本,大事务情行下WAL会慢一些</li>\n</ul>\n<h3 id=\"2-实现机制\"><a href=\"#2-实现机制\" class=\"headerlink\" title=\"2.实现机制\"></a>2.实现机制</h3><p>传统的rollback journal在修改前先将历史数据保存在rollback journal中,然后修改数据库文件.在回滚时,直接将rollback journal中的历史数据覆盖掉被修改的数据库文件,从而恢复到数据修改之前的状态.当删除rollback journal后一个事务就结束了.</p>\n<p>WAL和rollback journal是反过来的,数据库文件并不会直接修改,而是将修改append到一个WAL文件中,当事务的记录都已经append到WAL文件之后,事务就可以结束了.因此读操作可以继续读原来的数据库文件,多个写操作也可以同时往一个WAL文件进行append操作.(<strong>回滚操作只要将append到WAL的内容清除即可</strong>)</p>\n<h4 id=\"2-1-checkpointing\"><a href=\"#2-1-checkpointing\" class=\"headerlink\" title=\"2.1 checkpointing\"></a>2.1 checkpointing</h4><p>把WAL文件中的事务逐步写回数据库文件的过程称为’checkpoint’(<strong>为什么需要写回呢?考虑读取的情况,读取时除了需要读取数据库文件,也得读取WAL中已经提交完成的事务所做的修改,当WAL很大时会影响读取效率</strong>)</p>\n<p>checkpoint可以通过配置SQLITE_DEFAULT_WAL_AUTOCHECKPOINT该选项决定WAL多大时执行自动的checkpoint.默认为1000 pages.当然也可以关掉该功能,通过另外的线程在空闲时去执行checkpoint.</p>\n<h4 id=\"2-2-并行性\"><a href=\"#2-2-并行性\" class=\"headerlink\" title=\"2.2 并行性\"></a>2.2 并行性</h4><p>当开启一个读取操作后,首先需要记录一下当前最后一个在WAL提交的有效记录,记为’end mark’.因为WAL日志在不停增长,因此不同的读取操作会有自己的’end mark’.但在整个事务中,每个读取操作的 ‘end mark’不会改变.</p>\n<p>读取一个page时,首先从WAL中(本读取操作的’end mark’之前)获取一份最新的page,如果没有找到则从数据库文件中获取.为了防止读取操作每次都遍历WAL获取一个page(WAL可能会很大),在共享内存中提供了一个’wal index’的结构,能够快速定位WAL中的一个page.这也是为何WAL机制的所有连接必须处于同一台机器,并且不能通过网络文件系统使用的原因.</p>\n<p>写入操作只是往WAL文件append记录,可以看出读写互不影响</p>\n<p>checkpoint从WAL的开头往后顺序执行,直到到达任意一个正在执行的读取操作的’end mark’,此时停止checkpoint(<strong>如果读取超出end mark的数据并且回写到数据库文件,会使读取操作读取到不该看到的内容</strong>).注意该停止点也保存在共享内存的wal-index中,下次启动时从此处继续执行.可以看出,一个运行很长时间的read transaction会阻止checkpoint的运行.</p>\n<p>当一个写操作执行的时候,如果发现整个WAL文件都被checkpoint完成并且进行了刷盘并且当前没有任何读取操作的话,会重新开始从WAL的头部开始写入事务.从而避免WAL文件一直增长</p>\n<h4 id=\"2-3-性能考虑\"><a href=\"#2-3-性能考虑\" class=\"headerlink\" title=\"2.3 性能考虑\"></a>2.3 性能考虑</h4><p>写入时由于只需要写一次(rollback journal需要写两次)并且是顺序写,因此性能会高一些<br>读取时需要遍历WAL文件,虽然有共享内存中的WAL-index,随着文件增大,读取性能还是会受影响.因此为了获得好的读取性能,建议定期执行checkpoint.<br>checkpoint时需要进行数据库文件的刷盘和寻道操作,虽然checkpoint尽量做到顺序写入page(<strong>如何做到</strong>),但是仍然需要花费很多寻道的时间,因此checkpoint会比写入要慢.</p>\n<p>默认情况下,当WAL达到1000pages时会将WAL进行checkpoint,并且该动作由执行写操作的进程自己负责,这可能会导致大部分情况下写操作很快,但有个别事务因为执行checkpoint导致变慢.如果不希望受此影响,可以关闭自动checkpoint,由另外的线程或进程定期去执行.</p>\n<p>读写性能可以通过配置checkpoint的页数达到一个折衷.如果频繁checkpoint,读性能会高一些,但如果尽量减少checkpoint,写性能会高一些.可以根据实际需求来配置</p>\n<h3 id=\"配置WAL模式\"><a href=\"#配置WAL模式\" class=\"headerlink\" title=\"配置WAL模式\"></a>配置WAL模式</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=WAL;</span><br></pre></td></tr></table></figure>\n<p>该配置会设置为WAL模式.如果VFS不支持共享内存原语,则会继续使用 ‘journal_mode = delete’即rollback journal模式</p>\n<h4 id=\"3-1-自动checkpoint\"><a href=\"#3-1-自动checkpoint\" class=\"headerlink\" title=\"3.1 自动checkpoint\"></a>3.1 自动checkpoint</h4><p>当WAL文件中发生一个commit之后会调用通过sqlite3_wal_hook()注册的回调函数.例如可以使用sqlite3_wal_checkpoint()或者sqlite3_wal_checkpoint_v2()来执行checkpoint.自动checkpoint也是在sqlite3_wal_hook()之上简单的进行了包装.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pragma wal_autocheckpoint</span><br></pre></td></tr></table></figure>\n<p>该配置用来修改自动执行checkpoint的配置</p>\n<h4 id=\"3-2-应用启动的checkpoint\"><a href=\"#3-2-应用启动的checkpoint\" class=\"headerlink\" title=\"3.2 应用启动的checkpoint\"></a>3.2 应用启动的checkpoint</h4><p>通过调用sqlite3_wal_checkpoint可以启动一个passive类型的checkpoint,该类型的checkpoint不会影响其他连接的读写操作.<br>通过调用sqlite3_wal_checkpoint_v2可以启动一个full或者restart类型的checkpoint,这两种类型会将checkpoint执行直到完成</p>\n<h4 id=\"3-3-WAL配置的持久性\"><a href=\"#3-3-WAL配置的持久性\" class=\"headerlink\" title=\"3.3 WAL配置的持久性\"></a>3.3 WAL配置的持久性</h4><p>当配置如下时<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=WAL</span><br></pre></td></tr></table></figure></p>\n<p>即使关闭后重启database,仍然是WAL模式.<br>但如果PRAGMA journal_mode=truncate,关闭重启后就会返回为delete.(<strong>不知为何</strong>)</p>\n<h3 id=\"WAL文件\"><a href=\"#WAL文件\" class=\"headerlink\" title=\"WAL文件\"></a>WAL文件</h3><p>当在WAL模式下打开一个数据库连接后,会生成一个WAL文件,命名方式为数据库文件名称加’-wal’后缀.</p>\n<p>只要有数据库连接打开数据库,WAL文件就会存在.通常来说,当数据库上最后一个连接关闭之后,WAL文件会被自动删除.如果最后一个连接没有显示关闭连接或者SQLITE_FCNTL_PERSIST_WAL被使用,WAL文件将会在磁盘上一直存在.WAL文件需要合数据库文件保存到一块,否则可能会发生数据丢失或者数据库文件损坏.删除一个wal文件最安全的方法是首先调用sqlite3_open()打开一个数据库文件然后调用sqlite3_close()关闭该文件.</p>\n<p>WAL文件格式是严格定义的并且跨平台.</p>\n<h3 id=\"read-only数据库\"><a href=\"#read-only数据库\" class=\"headerlink\" title=\"read-only数据库\"></a>read-only数据库</h3><p>从3.22.0(2018-01-22)开始允许一个wal模式的数据在只读媒介上打开.只需要满足如下三个条件:</p>\n<ul>\n<li>-shm和-wal文件已经存在并且可读</li>\n<li>包括-shm和-wal文件的目录可写,以便创建这两文件</li>\n<li>数据库连接 以’immutable query parameter’打开</li>\n</ul>\n<p>虽然允许打开一个wal模式下的只读数据库,最好是在将sqlite部署到只读媒介时将pragma journal_mode修改为delete</p>\n<h3 id=\"如何避免生成过大的wal-file\"><a href=\"#如何避免生成过大的wal-file\" class=\"headerlink\" title=\"如何避免生成过大的wal file\"></a>如何避免生成过大的wal file</h3><ul>\n<li>关闭自动checkpoint后可能会造成 wal file过大</li>\n<li>当有大量的读操作时会造成checkpoint不能执行完成,可能导致wal file过大.此时应该考虑手动checkpoint（使用SQLITE_CHECKPOINT_RESTART或者SQLITE_CHECKPOINT_TRUNCATE选项）.<br>但注意这样会造成读操作在执行checkpoint时阻塞</li>\n<li>当有一个非常大的写事务时会导致chedkpoint没法执行完成.导致wal file 过大.从sqlite 3.11.0(2016-02-15)开始,被一个事务修改的pages只会往wal文件写一次.旧版本中,如果一个事务使用数据大小超过page cache的话,会导致同一个page可能被多次写入wal file.</li>\n</ul>\n<h3 id=\"wal-index在共享内存中的实现\"><a href=\"#wal-index在共享内存中的实现\" class=\"headerlink\" title=\"wal-index在共享内存中的实现\"></a>wal-index在共享内存中的实现</h3><p>wal-index通过将一个普通文件mmap到内存中实现.之前是将wal-index通过在/dev/shm(linux)或者/tmp(unix)中创建一个文件来实现.但这种方法会导致有不同根目录(通过chroot)的进程看到不同的文件从而使用了不同的共享内存,导致数据库损坏.其他的创建匿名共享内存的方法又不够通用.因此现在直接通过在数据库文件所在目录创建一个普通文件然后映射到内存中实现共享.</p>\n<p>这种方法也有缺点,从共享内存刷新到磁盘可能会导致不必要的磁盘I/O.但Sqlite开发者不认为这是个问题,因为wal-index很少会超过32KB并且从不会被刷盘.进一步,wal-index 文件在最后一个数据库连接断开之后会被删除,因此不会有任何实质性的disk I/O会发生.</p>\n<p>如果有些应用觉着这种方法不可接受,也可以自己定制.例如:如果应用只会通过在一个进程中的不同线程访问,那么wal-index可以实现到堆内存中而不是使用共享内存.</p>\n<h3 id=\"不适用共享内存的wal模式\"><a href=\"#不适用共享内存的wal模式\" class=\"headerlink\" title=\"不适用共享内存的wal模式\"></a>不适用共享内存的wal模式</h3><p>SQLite3.7.4 (2010-12-07)之后,如果locking_mode在第一个请求到来之前设置为exclusive,则wal模式可以在没有共享内存的情况下使用.换句话说即保证只有一个进程会访问数据库.</p>\n<h3 id=\"请求返回SQLITE-BUSY的情形\"><a href=\"#请求返回SQLITE-BUSY的情形\" class=\"headerlink\" title=\"请求返回SQLITE_BUSY的情形\"></a>请求返回SQLITE_BUSY的情形</h3><p>大部分情况下读写请求互不阻塞,但有些情况下可能会返回SQLITE_BUSY.</p>\n<p>例如:</p>\n<ul>\n<li><p>如果一个连接以exclusive mode模式打开数据库,其他请求都会返回SQLITE_BUSY.CHROME和FIREFOX都是以exclusive mode打开的数据库,所以如果其他视图打开读取chrome和firefox数据库的请求都会返回SQLITE_BUSY.</p>\n</li>\n<li><p>当最后一个连接关闭的时候,该连接会短暂的获取一个exclusive lock以便清理WAL和shared-memory文件,如果第二个请求在此时想要打开该数据库文件,也会返回一个SQLITE_BUSY错误.</p>\n</li>\n<li><p>如果最后一个连接crash,则新的连接会首先执行一个恢复流程.该流程中也会持有一个exclusive lock,此时如果另一个连接试图读取也会返回一个SQLITE_BUSY错误.</p>\n</li>\n</ul>\n<h3 id=\"后向兼容性\"><a href=\"#后向兼容性\" class=\"headerlink\" title=\"后向兼容性\"></a>后向兼容性</h3><p>为了防止旧版本的Sqlite(3.7.0之前,2010-07-22,旧版本的Sqlite并不能识别wal文件和共享内存中的wal-index)试图恢复一个wal模式的数据库,数据库文件头中的file format版本号(18-19字节)从1更新为了2(WAL模式下).因此如果一个旧版本的Sqlite尝试连接一个Sqlite数据库文件时,会报一个”file is encrypted or is not a database”的错误.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=DELETE;</span><br></pre></td></tr></table></figure></p>\n<p>使用该配置可以更改WAL模式为roll-back journal模式<br>此时版本号会从2改回1,因此旧版本Sqlite可以继续使用该数据库.</p>\n"},{"title":"codis proxy处理流程","date":"2019-01-10T07:14:04.000Z","_content":"\n## proxy启动\ncmd/proxy/main.go文件\n\n解析配置文件之后重点是proxy.New(config)函数\n\n该函数中，首先会创建一个Proxy结构体，如下:\n```go\ntype Proxy struct {\n    mu sync.Mutex\n\n\t...\n    config *Config\n    router *Router //Router中比较重要的是连接池和slots\n\t...\n\tlproxy net.Listener //19000端口的Listener\n    ladmin net.Listener //11080端口的Listener\n\t...\n}\n```\n然后起两个协程,分别处理11080和19000端口的请求\n```go\n    go s.serveAdmin()\n    go s.serveProxy()\n```\n我们重点看s.serveProxy()的处理流程，即redis client连接19000端口后proxy如何分发到codis server并且将结果返回到客户端\n\n## Proxy处理\ns.serverProxy也启动了两个协程，一个协程对router中连接池中的连接进行连接可用性检测，另一个协程是一个死循环，accept lproxy端口的连接，并且启动一个新的Session进行处理，代码流程如下:\n```go\n    go func(l net.Listener) (err error) {\n        defer func() {\n            eh <- err\n        }()\n        for {\n            c, err := s.acceptConn(l)//accept连接\n            if err != nil {\n                return err\n            }\n            NewSession(c, s.config).Start(s.router)//启动一个新的session进行处理\n        }\n    }(s.lproxy)//s为proxy,s.lproxy即19000端口的监听\n```\n首先介绍一下Request结构体，该结构体会贯穿整个流程\n```go\ntype Request struct {\n    Multi []*redis.Resp  //保存请求命令,按redis的resp协议类型将请求保存到Multi字段中\n    Batch *sync.WaitGroup //返回响应时,会在Batch处等待,r.Batch.Wait(),所以可以做到当请求执行完成后才会执行返回函数\n\n    Group *sync.WaitGroup\n\n    Broken *atomic2.Bool\n\n    OpStr string\n    OpFlag\n\n    Database int32\n    UnixNano int64\n\n    *redis.Resp //保存响应数据,也是redis的resp协议类型\n    Err error\n\n    Coalesce func() error //聚合函数,适用于mget/mset等需要聚合响应的操作命令\n}\n```\nStart函数处理流程如下:\n```go\n        tasks := NewRequestChanBuffer(1024)//tasks是一个指向RequestChan的指针,RequestChan结构体中有一个data字段,data字段是个数组，保存1024个指向Request的指针\n\n        go func() {\n            s.loopWriter(tasks)//从RequestChan的data中取出请求并且返回给客户端，如果是mget/mset这种需要聚合相应的请求,则会等待所有拆分的子请求执行完毕后执行聚合函数，然后将结果返回给客户端\n            decrSessions()\n        }()\n\n        go func() {\n            s.loopReader(tasks, d)//首先根据key计算该key分配到哪个slot.在此步骤中只会将slot对应的连接取出，然后将请求放到连接的input字段中。\n            tasks.Close()\n        }()\n```\n可以看到,s.loopWriter只是从RequestChan的data字段中取出请求并且返回给客户端，通过上文Request结构体的介绍，可以看到，通过在request的Batch执行wait操作，只有请求处理完成后loopWriter才会执行\n\n下边我们看loopReader的执行流程\n\n```go\n  \t\tr := &Request{}   //新建一个Request结构体，该结构体会贯穿请求的始终，请求字段，响应字段都放在Request中\n        r.Multi = multi\n        r.Batch = &sync.WaitGroup{}\n        r.Database = s.database\n        r.UnixNano = start.UnixNano()\n\n        if err := s.handleRequest(r, d); err != nil {  //执行handleRequest函数，处理请求\n            r.Resp = redis.NewErrorf(\"ERR handle request, %s\", err) \n            tasks.PushBack(r)\n            if breakOnFailure {\n                return err\n            }\n        } else {\n            tasks.PushBack(r) //如果handleRequest执行成功，将请求r放入tasks(即上文的RequestChan)的data字段中。loopWriter会从该字段中获取请求并且返回给客户端\n        }\n\n```\n看handleRequest函数如何处理请求,重点是router的dispatch函数\n```go\nfunc (s *Router) dispatch(r *Request) error {\n    hkey := getHashKey(r.Multi, r.OpStr)//hkey为请求的key\n    var id = Hash(hkey) % MaxSlotNum //hash请求的key之后对1024取模,获取该key分配到哪个slot\n    slot := &s.slots[id] //slot都保存在router的slots数组中,获取对应的slot\n    return slot.forward(r, hkey)//执行slot的forward函数\n}\n```\nforward函数调用process函数，返回一个BackendConn结构,然后调用其PushBack函数将请求放入bc.input中\n```go\nfunc (d *forwardSync) Forward(s *Slot, r *Request, hkey []byte) error {\n    s.lock.RLock()\n    bc, err := d.process(s, r, hkey) //返回一个连接,并且将请求放入BackendConn的input中\n    s.lock.RUnlock()\n    if err != nil {\n        return err\n    }\n    bc.PushBack(r)\n    return nil\n}\nbc.PushBack(r)函数如下:\n\nfunc (bc *BackendConn) PushBack(r *Request) {\n    if r.Batch != nil {\n        r.Batch.Add(1) //将请求的Batch执行add 1的操作，注意前文中的loopWriter会在Batch处等待\n    }\n    bc.input <- r //将请求放入bc.input channel\n}\n```\n至此可以看到,Proxy的处理流程\n```\nloopWriter->RuquestChan的data字段中读取请求并且返回。在Batch处等待\n\nloopReader->将请求放入RequestChan的data字段中，并且将请求放入bc.input channel中。在Batch处加1\n```\n很明显,Proxy并没有真正处理请求,肯定会有goroutine从bc.input中读取请求并且处理完成后在Batch处减1，这样当请求执行完成后,loopWriter就可以返回给客户端端响应了。\n\n## BackendConn的处理流程\n从上文得知,proxy结构体中有一个router字段，类型为Router,结构体类型如下:\n```go\ntype Router struct {\n    mu sync.RWMutex\n    pool struct {\n        primary *sharedBackendConnPool //连接池\n        replica *sharedBackendConnPool\n    }\n    slots [MaxSlotNum]Slot //slot\n\t...\n}\n```\nRouter的pool中管理连接池,执行fillSlot时会真正生成连接，放入Slot结构体的backend字段的bc字段中，Slot结构体如下:\n```go\ntype Slot struct {\n    id   int\n    ...\n    backend, migrate struct {\n        id int\n        bc *sharedBackendConn\n    }\n\t...\n    method forwardMethod\n}\n```\n我们看一下bc字段的结构体sharedBackendConn:\n```go\ntype sharedBackendConn struct {\n    addr string //codis server的地址\n    host []byte //codis server主机名\n    port []byte //codis server的端口\n\n    owner *sharedBackendConnPool //属于哪个连接池\n    conns [][]*BackendConn //二维数组,一般codis server会有16个db,第一个维度为0-15的数组,每个db可以有多个BackendConn连接\n\n    single []*BackendConn //如果每个db只有一个BackendConn连接，则直接放入single中。当每个db有多个连接时会从conns中选一个返回，而每个db只有一个连接时，直接从single中返回\n\n    refcnt int\n}\n```\n每个BackendConn中有一个 input chan *Request字段,是一个channel,channel中的内容为Request指针。也就是第二章节loopReader选取一个BackendConn后，会将请求放入input中。\n\n下边我们看看处理BackendConn input字段中数据的协程是如何启动并处理数据的。代码路径为pkg/proxy/backend.go的newBackendConn函数\n\n```go\n\nfunc NewBackendConn(addr string, database int, config *Config) *BackendConn {\n    bc := &BackendConn{\n        addr: addr, config: config, database: database,\n    }\n    //1024长度的管道,存放1024个*Request\n    bc.input = make(chan *Request, 1024)\n    bc.retry.delay = &DelayExp2{\n        Min: 50, Max: 5000,\n        Unit: time.Millisecond,\n    }\n\n    go bc.run()\n\n    return bc\n}\n```\n可以看到，在此处创建的BackendConn结构，并且初始化bc.input字段。连接池的建立是在proxy初始化启动的时候就会建立好。继续看bc.run()函数的处理流程\n```go\nfunc (bc *BackendConn) run() {\n    log.Warnf(\"backend conn [%p] to %s, db-%d start service\",\n        bc, bc.addr, bc.database)\n    for round := 0; bc.closed.IsFalse(); round++ {\n        log.Warnf(\"backend conn [%p] to %s, db-%d round-[%d]\",\n            bc, bc.addr, bc.database, round)\n        if err := bc.loopWriter(round); err != nil { //执行loopWriter函数，此处的loopWriter和第二章节的loopWriter只是名称相同，是两个不同的处理函数\n            bc.delayBeforeRetry()\n        }\n    }\n    log.Warnf(\"backend conn [%p] to %s, db-%d stop and exit\",\n        bc, bc.addr, bc.database)\n}\n \nfunc (bc *BackendConn) loopWriter(round int) (err error) {\n    ...\n    c, tasks, err := bc.newBackendReader(round, bc.config) //调用newBackendReader函数。注意此处的tasks也是一个存放*Request的channel,用来此处的loopWriter和loopReader交流信息\n    if err != nil {\n        return err\n    }\n    ...\n\n    for r := range bc.input { //可以看到,此处的loopWriter会从bc.input中取出数据并且处理\n\t\t...\n        if err := p.EncodeMultiBulk(r.Multi); err != nil { //将请求编码并且发送到codis server\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        }\n        if err := p.Flush(len(bc.input) == 0); err != nil {\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        } else {\n            tasks <- r  //将请求放入tasks这个channel中\n        }\n    }\n    return nil\n}\n```\n注意此处的loopWriter会从bc.input中取出数据发送到codis server,bc.newBackendReader会起一个loopReader,从codis server中读取数据并且写到request结构体中，此处的loopReader和loopWriter通过tasks这个channel通信。\n```go\nfunc (bc *BackendConn) newBackendReader(round int, config *Config) (*redis.Conn, chan<- *Request, error) {\n    ...\n    tasks := make(chan *Request, config.BackendMaxPipeline)//创建task这个channel并且返回给loopWriter\n    go bc.loopReader(tasks, c, round)//启动loopReader\n\n    return c, tasks, nil\n}\nfunc (bc *BackendConn) loopReader(tasks <-chan *Request, c *redis.Conn, round int) (err error) {\n   \t...\n    for r := range tasks {  //从tasks中取出响应\n        resp, err := c.Decode()\n        if err != nil {\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        }\n        ...\n        bc.setResponse(r, resp, nil)//设置响应数据到request结构体中\n    }\n    return nil\n}\n\nfunc (bc *BackendConn) setResponse(r *Request, resp *redis.Resp, err error) error {\n    r.Resp, r.Err = resp, err //Request的Resp字段设置为响应值\n    if r.Group != nil {\n        r.Group.Done()\n    }\n    if r.Batch != nil {\n        r.Batch.Done() //注意此处会对Batch执行减1操作，这样proxy中的loopWriter可以聚合响应并返回\n    }\n    return err\n}\n```\n总结一下,BackendConn中的函数功能如下\n```\nloopWriter->从bc.input中取出请求并且发给codis server,并且将请求放到tasks channel中\n\nloopReader->从tasks中取出请求，设置codis server的响应字段到Request的Resp字段中，并且将Batch执行减1操作\n```\n\n小结\n一图胜千言，图片版权归李老师，如下\n\n![codis](/img/codis1.png)","source":"_posts/codis-proxy处理流程.md","raw":"---\ntitle: codis proxy处理流程\ndate: 2019-01-10 15:14:04\ntags: codis\n---\n\n## proxy启动\ncmd/proxy/main.go文件\n\n解析配置文件之后重点是proxy.New(config)函数\n\n该函数中，首先会创建一个Proxy结构体，如下:\n```go\ntype Proxy struct {\n    mu sync.Mutex\n\n\t...\n    config *Config\n    router *Router //Router中比较重要的是连接池和slots\n\t...\n\tlproxy net.Listener //19000端口的Listener\n    ladmin net.Listener //11080端口的Listener\n\t...\n}\n```\n然后起两个协程,分别处理11080和19000端口的请求\n```go\n    go s.serveAdmin()\n    go s.serveProxy()\n```\n我们重点看s.serveProxy()的处理流程，即redis client连接19000端口后proxy如何分发到codis server并且将结果返回到客户端\n\n## Proxy处理\ns.serverProxy也启动了两个协程，一个协程对router中连接池中的连接进行连接可用性检测，另一个协程是一个死循环，accept lproxy端口的连接，并且启动一个新的Session进行处理，代码流程如下:\n```go\n    go func(l net.Listener) (err error) {\n        defer func() {\n            eh <- err\n        }()\n        for {\n            c, err := s.acceptConn(l)//accept连接\n            if err != nil {\n                return err\n            }\n            NewSession(c, s.config).Start(s.router)//启动一个新的session进行处理\n        }\n    }(s.lproxy)//s为proxy,s.lproxy即19000端口的监听\n```\n首先介绍一下Request结构体，该结构体会贯穿整个流程\n```go\ntype Request struct {\n    Multi []*redis.Resp  //保存请求命令,按redis的resp协议类型将请求保存到Multi字段中\n    Batch *sync.WaitGroup //返回响应时,会在Batch处等待,r.Batch.Wait(),所以可以做到当请求执行完成后才会执行返回函数\n\n    Group *sync.WaitGroup\n\n    Broken *atomic2.Bool\n\n    OpStr string\n    OpFlag\n\n    Database int32\n    UnixNano int64\n\n    *redis.Resp //保存响应数据,也是redis的resp协议类型\n    Err error\n\n    Coalesce func() error //聚合函数,适用于mget/mset等需要聚合响应的操作命令\n}\n```\nStart函数处理流程如下:\n```go\n        tasks := NewRequestChanBuffer(1024)//tasks是一个指向RequestChan的指针,RequestChan结构体中有一个data字段,data字段是个数组，保存1024个指向Request的指针\n\n        go func() {\n            s.loopWriter(tasks)//从RequestChan的data中取出请求并且返回给客户端，如果是mget/mset这种需要聚合相应的请求,则会等待所有拆分的子请求执行完毕后执行聚合函数，然后将结果返回给客户端\n            decrSessions()\n        }()\n\n        go func() {\n            s.loopReader(tasks, d)//首先根据key计算该key分配到哪个slot.在此步骤中只会将slot对应的连接取出，然后将请求放到连接的input字段中。\n            tasks.Close()\n        }()\n```\n可以看到,s.loopWriter只是从RequestChan的data字段中取出请求并且返回给客户端，通过上文Request结构体的介绍，可以看到，通过在request的Batch执行wait操作，只有请求处理完成后loopWriter才会执行\n\n下边我们看loopReader的执行流程\n\n```go\n  \t\tr := &Request{}   //新建一个Request结构体，该结构体会贯穿请求的始终，请求字段，响应字段都放在Request中\n        r.Multi = multi\n        r.Batch = &sync.WaitGroup{}\n        r.Database = s.database\n        r.UnixNano = start.UnixNano()\n\n        if err := s.handleRequest(r, d); err != nil {  //执行handleRequest函数，处理请求\n            r.Resp = redis.NewErrorf(\"ERR handle request, %s\", err) \n            tasks.PushBack(r)\n            if breakOnFailure {\n                return err\n            }\n        } else {\n            tasks.PushBack(r) //如果handleRequest执行成功，将请求r放入tasks(即上文的RequestChan)的data字段中。loopWriter会从该字段中获取请求并且返回给客户端\n        }\n\n```\n看handleRequest函数如何处理请求,重点是router的dispatch函数\n```go\nfunc (s *Router) dispatch(r *Request) error {\n    hkey := getHashKey(r.Multi, r.OpStr)//hkey为请求的key\n    var id = Hash(hkey) % MaxSlotNum //hash请求的key之后对1024取模,获取该key分配到哪个slot\n    slot := &s.slots[id] //slot都保存在router的slots数组中,获取对应的slot\n    return slot.forward(r, hkey)//执行slot的forward函数\n}\n```\nforward函数调用process函数，返回一个BackendConn结构,然后调用其PushBack函数将请求放入bc.input中\n```go\nfunc (d *forwardSync) Forward(s *Slot, r *Request, hkey []byte) error {\n    s.lock.RLock()\n    bc, err := d.process(s, r, hkey) //返回一个连接,并且将请求放入BackendConn的input中\n    s.lock.RUnlock()\n    if err != nil {\n        return err\n    }\n    bc.PushBack(r)\n    return nil\n}\nbc.PushBack(r)函数如下:\n\nfunc (bc *BackendConn) PushBack(r *Request) {\n    if r.Batch != nil {\n        r.Batch.Add(1) //将请求的Batch执行add 1的操作，注意前文中的loopWriter会在Batch处等待\n    }\n    bc.input <- r //将请求放入bc.input channel\n}\n```\n至此可以看到,Proxy的处理流程\n```\nloopWriter->RuquestChan的data字段中读取请求并且返回。在Batch处等待\n\nloopReader->将请求放入RequestChan的data字段中，并且将请求放入bc.input channel中。在Batch处加1\n```\n很明显,Proxy并没有真正处理请求,肯定会有goroutine从bc.input中读取请求并且处理完成后在Batch处减1，这样当请求执行完成后,loopWriter就可以返回给客户端端响应了。\n\n## BackendConn的处理流程\n从上文得知,proxy结构体中有一个router字段，类型为Router,结构体类型如下:\n```go\ntype Router struct {\n    mu sync.RWMutex\n    pool struct {\n        primary *sharedBackendConnPool //连接池\n        replica *sharedBackendConnPool\n    }\n    slots [MaxSlotNum]Slot //slot\n\t...\n}\n```\nRouter的pool中管理连接池,执行fillSlot时会真正生成连接，放入Slot结构体的backend字段的bc字段中，Slot结构体如下:\n```go\ntype Slot struct {\n    id   int\n    ...\n    backend, migrate struct {\n        id int\n        bc *sharedBackendConn\n    }\n\t...\n    method forwardMethod\n}\n```\n我们看一下bc字段的结构体sharedBackendConn:\n```go\ntype sharedBackendConn struct {\n    addr string //codis server的地址\n    host []byte //codis server主机名\n    port []byte //codis server的端口\n\n    owner *sharedBackendConnPool //属于哪个连接池\n    conns [][]*BackendConn //二维数组,一般codis server会有16个db,第一个维度为0-15的数组,每个db可以有多个BackendConn连接\n\n    single []*BackendConn //如果每个db只有一个BackendConn连接，则直接放入single中。当每个db有多个连接时会从conns中选一个返回，而每个db只有一个连接时，直接从single中返回\n\n    refcnt int\n}\n```\n每个BackendConn中有一个 input chan *Request字段,是一个channel,channel中的内容为Request指针。也就是第二章节loopReader选取一个BackendConn后，会将请求放入input中。\n\n下边我们看看处理BackendConn input字段中数据的协程是如何启动并处理数据的。代码路径为pkg/proxy/backend.go的newBackendConn函数\n\n```go\n\nfunc NewBackendConn(addr string, database int, config *Config) *BackendConn {\n    bc := &BackendConn{\n        addr: addr, config: config, database: database,\n    }\n    //1024长度的管道,存放1024个*Request\n    bc.input = make(chan *Request, 1024)\n    bc.retry.delay = &DelayExp2{\n        Min: 50, Max: 5000,\n        Unit: time.Millisecond,\n    }\n\n    go bc.run()\n\n    return bc\n}\n```\n可以看到，在此处创建的BackendConn结构，并且初始化bc.input字段。连接池的建立是在proxy初始化启动的时候就会建立好。继续看bc.run()函数的处理流程\n```go\nfunc (bc *BackendConn) run() {\n    log.Warnf(\"backend conn [%p] to %s, db-%d start service\",\n        bc, bc.addr, bc.database)\n    for round := 0; bc.closed.IsFalse(); round++ {\n        log.Warnf(\"backend conn [%p] to %s, db-%d round-[%d]\",\n            bc, bc.addr, bc.database, round)\n        if err := bc.loopWriter(round); err != nil { //执行loopWriter函数，此处的loopWriter和第二章节的loopWriter只是名称相同，是两个不同的处理函数\n            bc.delayBeforeRetry()\n        }\n    }\n    log.Warnf(\"backend conn [%p] to %s, db-%d stop and exit\",\n        bc, bc.addr, bc.database)\n}\n \nfunc (bc *BackendConn) loopWriter(round int) (err error) {\n    ...\n    c, tasks, err := bc.newBackendReader(round, bc.config) //调用newBackendReader函数。注意此处的tasks也是一个存放*Request的channel,用来此处的loopWriter和loopReader交流信息\n    if err != nil {\n        return err\n    }\n    ...\n\n    for r := range bc.input { //可以看到,此处的loopWriter会从bc.input中取出数据并且处理\n\t\t...\n        if err := p.EncodeMultiBulk(r.Multi); err != nil { //将请求编码并且发送到codis server\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        }\n        if err := p.Flush(len(bc.input) == 0); err != nil {\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        } else {\n            tasks <- r  //将请求放入tasks这个channel中\n        }\n    }\n    return nil\n}\n```\n注意此处的loopWriter会从bc.input中取出数据发送到codis server,bc.newBackendReader会起一个loopReader,从codis server中读取数据并且写到request结构体中，此处的loopReader和loopWriter通过tasks这个channel通信。\n```go\nfunc (bc *BackendConn) newBackendReader(round int, config *Config) (*redis.Conn, chan<- *Request, error) {\n    ...\n    tasks := make(chan *Request, config.BackendMaxPipeline)//创建task这个channel并且返回给loopWriter\n    go bc.loopReader(tasks, c, round)//启动loopReader\n\n    return c, tasks, nil\n}\nfunc (bc *BackendConn) loopReader(tasks <-chan *Request, c *redis.Conn, round int) (err error) {\n   \t...\n    for r := range tasks {  //从tasks中取出响应\n        resp, err := c.Decode()\n        if err != nil {\n            return bc.setResponse(r, nil, fmt.Errorf(\"backend conn failure, %s\", err))\n        }\n        ...\n        bc.setResponse(r, resp, nil)//设置响应数据到request结构体中\n    }\n    return nil\n}\n\nfunc (bc *BackendConn) setResponse(r *Request, resp *redis.Resp, err error) error {\n    r.Resp, r.Err = resp, err //Request的Resp字段设置为响应值\n    if r.Group != nil {\n        r.Group.Done()\n    }\n    if r.Batch != nil {\n        r.Batch.Done() //注意此处会对Batch执行减1操作，这样proxy中的loopWriter可以聚合响应并返回\n    }\n    return err\n}\n```\n总结一下,BackendConn中的函数功能如下\n```\nloopWriter->从bc.input中取出请求并且发给codis server,并且将请求放到tasks channel中\n\nloopReader->从tasks中取出请求，设置codis server的响应字段到Request的Resp字段中，并且将Batch执行减1操作\n```\n\n小结\n一图胜千言，图片版权归李老师，如下\n\n![codis](/img/codis1.png)","slug":"codis-proxy处理流程","published":1,"updated":"2019-02-19T07:20:08.196Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zbe001nbms672kpndsv","content":"<h2 id=\"proxy启动\"><a href=\"#proxy启动\" class=\"headerlink\" title=\"proxy启动\"></a>proxy启动</h2><p>cmd/proxy/main.go文件</p>\n<p>解析配置文件之后重点是proxy.New(config)函数</p>\n<p>该函数中，首先会创建一个Proxy结构体，如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Proxy <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    mu sync.Mutex</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    config *Config</span><br><span class=\"line\">    router *Router <span class=\"comment\">//Router中比较重要的是连接池和slots</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tlproxy net.Listener <span class=\"comment\">//19000端口的Listener</span></span><br><span class=\"line\">    ladmin net.Listener <span class=\"comment\">//11080端口的Listener</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>然后起两个协程,分别处理11080和19000端口的请求<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">go</span> s.serveAdmin()</span><br><span class=\"line\"><span class=\"keyword\">go</span> s.serveProxy()</span><br></pre></td></tr></table></figure></p>\n<p>我们重点看s.serveProxy()的处理流程，即redis client连接19000端口后proxy如何分发到codis server并且将结果返回到客户端</p>\n<h2 id=\"Proxy处理\"><a href=\"#Proxy处理\" class=\"headerlink\" title=\"Proxy处理\"></a>Proxy处理</h2><p>s.serverProxy也启动了两个协程，一个协程对router中连接池中的连接进行连接可用性检测，另一个协程是一个死循环，accept lproxy端口的连接，并且启动一个新的Session进行处理，代码流程如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(l net.Listener)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">        eh &lt;- err</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">        c, err := s.acceptConn(l)<span class=\"comment\">//accept连接</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        NewSession(c, s.config).Start(s.router)<span class=\"comment\">//启动一个新的session进行处理</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;(s.lproxy)<span class=\"comment\">//s为proxy,s.lproxy即19000端口的监听</span></span><br></pre></td></tr></table></figure></p>\n<p>首先介绍一下Request结构体，该结构体会贯穿整个流程<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Request <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Multi []*redis.Resp  <span class=\"comment\">//保存请求命令,按redis的resp协议类型将请求保存到Multi字段中</span></span><br><span class=\"line\">    Batch *sync.WaitGroup <span class=\"comment\">//返回响应时,会在Batch处等待,r.Batch.Wait(),所以可以做到当请求执行完成后才会执行返回函数</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Group *sync.WaitGroup</span><br><span class=\"line\"></span><br><span class=\"line\">    Broken *atomic2.Bool</span><br><span class=\"line\"></span><br><span class=\"line\">    OpStr <span class=\"keyword\">string</span></span><br><span class=\"line\">    OpFlag</span><br><span class=\"line\"></span><br><span class=\"line\">    Database <span class=\"keyword\">int32</span></span><br><span class=\"line\">    UnixNano <span class=\"keyword\">int64</span></span><br><span class=\"line\"></span><br><span class=\"line\">    *redis.Resp <span class=\"comment\">//保存响应数据,也是redis的resp协议类型</span></span><br><span class=\"line\">    Err error</span><br><span class=\"line\"></span><br><span class=\"line\">    Coalesce <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span> <span class=\"title\">error</span> //聚合函数,适用于<span class=\"title\">mget</span>/<span class=\"title\">mset</span>等需要聚合响应的操作命令</span></span><br><span class=\"line\"><span class=\"function\">&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>Start函数处理流程如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tasks := NewRequestChanBuffer(<span class=\"number\">1024</span>)<span class=\"comment\">//tasks是一个指向RequestChan的指针,RequestChan结构体中有一个data字段,data字段是个数组，保存1024个指向Request的指针</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    s.loopWriter(tasks)<span class=\"comment\">//从RequestChan的data中取出请求并且返回给客户端，如果是mget/mset这种需要聚合相应的请求,则会等待所有拆分的子请求执行完毕后执行聚合函数，然后将结果返回给客户端</span></span><br><span class=\"line\">    decrSessions()</span><br><span class=\"line\">&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    s.loopReader(tasks, d)<span class=\"comment\">//首先根据key计算该key分配到哪个slot.在此步骤中只会将slot对应的连接取出，然后将请求放到连接的input字段中。</span></span><br><span class=\"line\">    tasks.Close()</span><br><span class=\"line\">&#125;()</span><br></pre></td></tr></table></figure></p>\n<p>可以看到,s.loopWriter只是从RequestChan的data字段中取出请求并且返回给客户端，通过上文Request结构体的介绍，可以看到，通过在request的Batch执行wait操作，只有请求处理完成后loopWriter才会执行</p>\n<p>下边我们看loopReader的执行流程</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r := &amp;Request&#123;&#125;   <span class=\"comment\">//新建一个Request结构体，该结构体会贯穿请求的始终，请求字段，响应字段都放在Request中</span></span><br><span class=\"line\">    r.Multi = multi</span><br><span class=\"line\">    r.Batch = &amp;sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">    r.Database = s.database</span><br><span class=\"line\">    r.UnixNano = start.UnixNano()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> err := s.handleRequest(r, d); err != <span class=\"literal\">nil</span> &#123;  <span class=\"comment\">//执行handleRequest函数，处理请求</span></span><br><span class=\"line\">        r.Resp = redis.NewErrorf(<span class=\"string\">\"ERR handle request, %s\"</span>, err) </span><br><span class=\"line\">        tasks.PushBack(r)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> breakOnFailure &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        tasks.PushBack(r) <span class=\"comment\">//如果handleRequest执行成功，将请求r放入tasks(即上文的RequestChan)的data字段中。loopWriter会从该字段中获取请求并且返回给客户端</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>看handleRequest函数如何处理请求,重点是router的dispatch函数<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(s *Router)</span> <span class=\"title\">dispatch</span><span class=\"params\">(r *Request)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    hkey := getHashKey(r.Multi, r.OpStr)<span class=\"comment\">//hkey为请求的key</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> id = Hash(hkey) % MaxSlotNum <span class=\"comment\">//hash请求的key之后对1024取模,获取该key分配到哪个slot</span></span><br><span class=\"line\">    slot := &amp;s.slots[id] <span class=\"comment\">//slot都保存在router的slots数组中,获取对应的slot</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> slot.forward(r, hkey)<span class=\"comment\">//执行slot的forward函数</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>forward函数调用process函数，返回一个BackendConn结构,然后调用其PushBack函数将请求放入bc.input中<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(d *forwardSync)</span> <span class=\"title\">Forward</span><span class=\"params\">(s *Slot, r *Request, hkey []<span class=\"keyword\">byte</span>)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    s.lock.RLock()</span><br><span class=\"line\">    bc, err := d.process(s, r, hkey) <span class=\"comment\">//返回一个连接,并且将请求放入BackendConn的input中</span></span><br><span class=\"line\">    s.lock.RUnlock()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    bc.PushBack(r)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">bc.PushBack(r)函数如下:</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">PushBack</span><span class=\"params\">(r *Request)</span></span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Batch != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Batch.Add(<span class=\"number\">1</span>) <span class=\"comment\">//将请求的Batch执行add 1的操作，注意前文中的loopWriter会在Batch处等待</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    bc.input &lt;- r <span class=\"comment\">//将请求放入bc.input channel</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>至此可以看到,Proxy的处理流程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loopWriter-&gt;RuquestChan的data字段中读取请求并且返回。在Batch处等待</span><br><span class=\"line\"></span><br><span class=\"line\">loopReader-&gt;将请求放入RequestChan的data字段中，并且将请求放入bc.input channel中。在Batch处加1</span><br></pre></td></tr></table></figure></p>\n<p>很明显,Proxy并没有真正处理请求,肯定会有goroutine从bc.input中读取请求并且处理完成后在Batch处减1，这样当请求执行完成后,loopWriter就可以返回给客户端端响应了。</p>\n<h2 id=\"BackendConn的处理流程\"><a href=\"#BackendConn的处理流程\" class=\"headerlink\" title=\"BackendConn的处理流程\"></a>BackendConn的处理流程</h2><p>从上文得知,proxy结构体中有一个router字段，类型为Router,结构体类型如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Router <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\">    pool <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">        primary *sharedBackendConnPool <span class=\"comment\">//连接池</span></span><br><span class=\"line\">        replica *sharedBackendConnPool</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    slots [MaxSlotNum]Slot <span class=\"comment\">//slot</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Router的pool中管理连接池,执行fillSlot时会真正生成连接，放入Slot结构体的backend字段的bc字段中，Slot结构体如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Slot <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    id   <span class=\"keyword\">int</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    backend, migrate <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">        id <span class=\"keyword\">int</span></span><br><span class=\"line\">        bc *sharedBackendConn</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    method forwardMethod</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>我们看一下bc字段的结构体sharedBackendConn:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> sharedBackendConn <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    addr <span class=\"keyword\">string</span> <span class=\"comment\">//codis server的地址</span></span><br><span class=\"line\">    host []<span class=\"keyword\">byte</span> <span class=\"comment\">//codis server主机名</span></span><br><span class=\"line\">    port []<span class=\"keyword\">byte</span> <span class=\"comment\">//codis server的端口</span></span><br><span class=\"line\"></span><br><span class=\"line\">    owner *sharedBackendConnPool <span class=\"comment\">//属于哪个连接池</span></span><br><span class=\"line\">    conns [][]*BackendConn <span class=\"comment\">//二维数组,一般codis server会有16个db,第一个维度为0-15的数组,每个db可以有多个BackendConn连接</span></span><br><span class=\"line\"></span><br><span class=\"line\">    single []*BackendConn <span class=\"comment\">//如果每个db只有一个BackendConn连接，则直接放入single中。当每个db有多个连接时会从conns中选一个返回，而每个db只有一个连接时，直接从single中返回</span></span><br><span class=\"line\"></span><br><span class=\"line\">    refcnt <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>每个BackendConn中有一个 input chan *Request字段,是一个channel,channel中的内容为Request指针。也就是第二章节loopReader选取一个BackendConn后，会将请求放入input中。</p>\n<p>下边我们看看处理BackendConn input字段中数据的协程是如何启动并处理数据的。代码路径为pkg/proxy/backend.go的newBackendConn函数</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">NewBackendConn</span><span class=\"params\">(addr <span class=\"keyword\">string</span>, database <span class=\"keyword\">int</span>, config *Config)</span> *<span class=\"title\">BackendConn</span></span> &#123;</span><br><span class=\"line\">    bc := &amp;BackendConn&#123;</span><br><span class=\"line\">        addr: addr, config: config, database: database,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//1024长度的管道,存放1024个*Request</span></span><br><span class=\"line\">    bc.input = <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> *Request, <span class=\"number\">1024</span>)</span><br><span class=\"line\">    bc.retry.delay = &amp;DelayExp2&#123;</span><br><span class=\"line\">        Min: <span class=\"number\">50</span>, Max: <span class=\"number\">5000</span>,</span><br><span class=\"line\">        Unit: time.Millisecond,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">go</span> bc.run()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bc</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，在此处创建的BackendConn结构，并且初始化bc.input字段。连接池的建立是在proxy初始化启动的时候就会建立好。继续看bc.run()函数的处理流程<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">run</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d start service\"</span>,</span><br><span class=\"line\">        bc, bc.addr, bc.database)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> round := <span class=\"number\">0</span>; bc.closed.IsFalse(); round++ &#123;</span><br><span class=\"line\">        log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d round-[%d]\"</span>,</span><br><span class=\"line\">            bc, bc.addr, bc.database, round)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := bc.loopWriter(round); err != <span class=\"literal\">nil</span> &#123; <span class=\"comment\">//执行loopWriter函数，此处的loopWriter和第二章节的loopWriter只是名称相同，是两个不同的处理函数</span></span><br><span class=\"line\">            bc.delayBeforeRetry()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d stop and exit\"</span>,</span><br><span class=\"line\">        bc, bc.addr, bc.database)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">loopWriter</span><span class=\"params\">(round <span class=\"keyword\">int</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    c, tasks, err := bc.newBackendReader(round, bc.config) <span class=\"comment\">//调用newBackendReader函数。注意此处的tasks也是一个存放*Request的channel,用来此处的loopWriter和loopReader交流信息</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> r := <span class=\"keyword\">range</span> bc.input &#123; <span class=\"comment\">//可以看到,此处的loopWriter会从bc.input中取出数据并且处理</span></span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := p.EncodeMultiBulk(r.Multi); err != <span class=\"literal\">nil</span> &#123; <span class=\"comment\">//将请求编码并且发送到codis server</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := p.Flush(<span class=\"built_in\">len</span>(bc.input) == <span class=\"number\">0</span>); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            tasks &lt;- r  <span class=\"comment\">//将请求放入tasks这个channel中</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>注意此处的loopWriter会从bc.input中取出数据发送到codis server,bc.newBackendReader会起一个loopReader,从codis server中读取数据并且写到request结构体中，此处的loopReader和loopWriter通过tasks这个channel通信。<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">newBackendReader</span><span class=\"params\">(round <span class=\"keyword\">int</span>, config *Config)</span> <span class=\"params\">(*redis.Conn, <span class=\"keyword\">chan</span>&lt;- *Request, error)</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    tasks := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> *Request, config.BackendMaxPipeline)<span class=\"comment\">//创建task这个channel并且返回给loopWriter</span></span><br><span class=\"line\">    <span class=\"keyword\">go</span> bc.loopReader(tasks, c, round)<span class=\"comment\">//启动loopReader</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c, tasks, <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">loopReader</span><span class=\"params\">(tasks &lt;-<span class=\"keyword\">chan</span> *Request, c *redis.Conn, round <span class=\"keyword\">int</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">   \t...</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r := <span class=\"keyword\">range</span> tasks &#123;  <span class=\"comment\">//从tasks中取出响应</span></span><br><span class=\"line\">        resp, err := c.Decode()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        bc.setResponse(r, resp, <span class=\"literal\">nil</span>)<span class=\"comment\">//设置响应数据到request结构体中</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">setResponse</span><span class=\"params\">(r *Request, resp *redis.Resp, err error)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    r.Resp, r.Err = resp, err <span class=\"comment\">//Request的Resp字段设置为响应值</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Group != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Group.Done()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Batch != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Batch.Done() <span class=\"comment\">//注意此处会对Batch执行减1操作，这样proxy中的loopWriter可以聚合响应并返回</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>总结一下,BackendConn中的函数功能如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loopWriter-&gt;从bc.input中取出请求并且发给codis server,并且将请求放到tasks channel中</span><br><span class=\"line\"></span><br><span class=\"line\">loopReader-&gt;从tasks中取出请求，设置codis server的响应字段到Request的Resp字段中，并且将Batch执行减1操作</span><br></pre></td></tr></table></figure></p>\n<p>小结<br>一图胜千言，图片版权归李老师，如下</p>\n<p><img src=\"/img/codis1.png\" alt=\"codis\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"proxy启动\"><a href=\"#proxy启动\" class=\"headerlink\" title=\"proxy启动\"></a>proxy启动</h2><p>cmd/proxy/main.go文件</p>\n<p>解析配置文件之后重点是proxy.New(config)函数</p>\n<p>该函数中，首先会创建一个Proxy结构体，如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Proxy <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    mu sync.Mutex</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">    config *Config</span><br><span class=\"line\">    router *Router <span class=\"comment\">//Router中比较重要的是连接池和slots</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tlproxy net.Listener <span class=\"comment\">//19000端口的Listener</span></span><br><span class=\"line\">    ladmin net.Listener <span class=\"comment\">//11080端口的Listener</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>然后起两个协程,分别处理11080和19000端口的请求<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">go</span> s.serveAdmin()</span><br><span class=\"line\"><span class=\"keyword\">go</span> s.serveProxy()</span><br></pre></td></tr></table></figure></p>\n<p>我们重点看s.serveProxy()的处理流程，即redis client连接19000端口后proxy如何分发到codis server并且将结果返回到客户端</p>\n<h2 id=\"Proxy处理\"><a href=\"#Proxy处理\" class=\"headerlink\" title=\"Proxy处理\"></a>Proxy处理</h2><p>s.serverProxy也启动了两个协程，一个协程对router中连接池中的连接进行连接可用性检测，另一个协程是一个死循环，accept lproxy端口的连接，并且启动一个新的Session进行处理，代码流程如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(l net.Listener)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">defer</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">        eh &lt;- err</span><br><span class=\"line\">    &#125;()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">        c, err := s.acceptConn(l)<span class=\"comment\">//accept连接</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        NewSession(c, s.config).Start(s.router)<span class=\"comment\">//启动一个新的session进行处理</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;(s.lproxy)<span class=\"comment\">//s为proxy,s.lproxy即19000端口的监听</span></span><br></pre></td></tr></table></figure></p>\n<p>首先介绍一下Request结构体，该结构体会贯穿整个流程<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Request <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    Multi []*redis.Resp  <span class=\"comment\">//保存请求命令,按redis的resp协议类型将请求保存到Multi字段中</span></span><br><span class=\"line\">    Batch *sync.WaitGroup <span class=\"comment\">//返回响应时,会在Batch处等待,r.Batch.Wait(),所以可以做到当请求执行完成后才会执行返回函数</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Group *sync.WaitGroup</span><br><span class=\"line\"></span><br><span class=\"line\">    Broken *atomic2.Bool</span><br><span class=\"line\"></span><br><span class=\"line\">    OpStr <span class=\"keyword\">string</span></span><br><span class=\"line\">    OpFlag</span><br><span class=\"line\"></span><br><span class=\"line\">    Database <span class=\"keyword\">int32</span></span><br><span class=\"line\">    UnixNano <span class=\"keyword\">int64</span></span><br><span class=\"line\"></span><br><span class=\"line\">    *redis.Resp <span class=\"comment\">//保存响应数据,也是redis的resp协议类型</span></span><br><span class=\"line\">    Err error</span><br><span class=\"line\"></span><br><span class=\"line\">    Coalesce <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span> <span class=\"title\">error</span> //聚合函数,适用于<span class=\"title\">mget</span>/<span class=\"title\">mset</span>等需要聚合响应的操作命令</span></span><br><span class=\"line\"><span class=\"function\">&#125;</span></span><br></pre></td></tr></table></figure></p>\n<p>Start函数处理流程如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tasks := NewRequestChanBuffer(<span class=\"number\">1024</span>)<span class=\"comment\">//tasks是一个指向RequestChan的指针,RequestChan结构体中有一个data字段,data字段是个数组，保存1024个指向Request的指针</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    s.loopWriter(tasks)<span class=\"comment\">//从RequestChan的data中取出请求并且返回给客户端，如果是mget/mset这种需要聚合相应的请求,则会等待所有拆分的子请求执行完毕后执行聚合函数，然后将结果返回给客户端</span></span><br><span class=\"line\">    decrSessions()</span><br><span class=\"line\">&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    s.loopReader(tasks, d)<span class=\"comment\">//首先根据key计算该key分配到哪个slot.在此步骤中只会将slot对应的连接取出，然后将请求放到连接的input字段中。</span></span><br><span class=\"line\">    tasks.Close()</span><br><span class=\"line\">&#125;()</span><br></pre></td></tr></table></figure></p>\n<p>可以看到,s.loopWriter只是从RequestChan的data字段中取出请求并且返回给客户端，通过上文Request结构体的介绍，可以看到，通过在request的Batch执行wait操作，只有请求处理完成后loopWriter才会执行</p>\n<p>下边我们看loopReader的执行流程</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r := &amp;Request&#123;&#125;   <span class=\"comment\">//新建一个Request结构体，该结构体会贯穿请求的始终，请求字段，响应字段都放在Request中</span></span><br><span class=\"line\">    r.Multi = multi</span><br><span class=\"line\">    r.Batch = &amp;sync.WaitGroup&#123;&#125;</span><br><span class=\"line\">    r.Database = s.database</span><br><span class=\"line\">    r.UnixNano = start.UnixNano()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> err := s.handleRequest(r, d); err != <span class=\"literal\">nil</span> &#123;  <span class=\"comment\">//执行handleRequest函数，处理请求</span></span><br><span class=\"line\">        r.Resp = redis.NewErrorf(<span class=\"string\">\"ERR handle request, %s\"</span>, err) </span><br><span class=\"line\">        tasks.PushBack(r)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> breakOnFailure &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> err</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        tasks.PushBack(r) <span class=\"comment\">//如果handleRequest执行成功，将请求r放入tasks(即上文的RequestChan)的data字段中。loopWriter会从该字段中获取请求并且返回给客户端</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>看handleRequest函数如何处理请求,重点是router的dispatch函数<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(s *Router)</span> <span class=\"title\">dispatch</span><span class=\"params\">(r *Request)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    hkey := getHashKey(r.Multi, r.OpStr)<span class=\"comment\">//hkey为请求的key</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> id = Hash(hkey) % MaxSlotNum <span class=\"comment\">//hash请求的key之后对1024取模,获取该key分配到哪个slot</span></span><br><span class=\"line\">    slot := &amp;s.slots[id] <span class=\"comment\">//slot都保存在router的slots数组中,获取对应的slot</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> slot.forward(r, hkey)<span class=\"comment\">//执行slot的forward函数</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>forward函数调用process函数，返回一个BackendConn结构,然后调用其PushBack函数将请求放入bc.input中<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(d *forwardSync)</span> <span class=\"title\">Forward</span><span class=\"params\">(s *Slot, r *Request, hkey []<span class=\"keyword\">byte</span>)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    s.lock.RLock()</span><br><span class=\"line\">    bc, err := d.process(s, r, hkey) <span class=\"comment\">//返回一个连接,并且将请求放入BackendConn的input中</span></span><br><span class=\"line\">    s.lock.RUnlock()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    bc.PushBack(r)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">bc.PushBack(r)函数如下:</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">PushBack</span><span class=\"params\">(r *Request)</span></span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Batch != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Batch.Add(<span class=\"number\">1</span>) <span class=\"comment\">//将请求的Batch执行add 1的操作，注意前文中的loopWriter会在Batch处等待</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    bc.input &lt;- r <span class=\"comment\">//将请求放入bc.input channel</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>至此可以看到,Proxy的处理流程<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loopWriter-&gt;RuquestChan的data字段中读取请求并且返回。在Batch处等待</span><br><span class=\"line\"></span><br><span class=\"line\">loopReader-&gt;将请求放入RequestChan的data字段中，并且将请求放入bc.input channel中。在Batch处加1</span><br></pre></td></tr></table></figure></p>\n<p>很明显,Proxy并没有真正处理请求,肯定会有goroutine从bc.input中读取请求并且处理完成后在Batch处减1，这样当请求执行完成后,loopWriter就可以返回给客户端端响应了。</p>\n<h2 id=\"BackendConn的处理流程\"><a href=\"#BackendConn的处理流程\" class=\"headerlink\" title=\"BackendConn的处理流程\"></a>BackendConn的处理流程</h2><p>从上文得知,proxy结构体中有一个router字段，类型为Router,结构体类型如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Router <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\">    pool <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">        primary *sharedBackendConnPool <span class=\"comment\">//连接池</span></span><br><span class=\"line\">        replica *sharedBackendConnPool</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    slots [MaxSlotNum]Slot <span class=\"comment\">//slot</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>Router的pool中管理连接池,执行fillSlot时会真正生成连接，放入Slot结构体的backend字段的bc字段中，Slot结构体如下:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Slot <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    id   <span class=\"keyword\">int</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">    backend, migrate <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">        id <span class=\"keyword\">int</span></span><br><span class=\"line\">        bc *sharedBackendConn</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">    method forwardMethod</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>我们看一下bc字段的结构体sharedBackendConn:<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> sharedBackendConn <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">    addr <span class=\"keyword\">string</span> <span class=\"comment\">//codis server的地址</span></span><br><span class=\"line\">    host []<span class=\"keyword\">byte</span> <span class=\"comment\">//codis server主机名</span></span><br><span class=\"line\">    port []<span class=\"keyword\">byte</span> <span class=\"comment\">//codis server的端口</span></span><br><span class=\"line\"></span><br><span class=\"line\">    owner *sharedBackendConnPool <span class=\"comment\">//属于哪个连接池</span></span><br><span class=\"line\">    conns [][]*BackendConn <span class=\"comment\">//二维数组,一般codis server会有16个db,第一个维度为0-15的数组,每个db可以有多个BackendConn连接</span></span><br><span class=\"line\"></span><br><span class=\"line\">    single []*BackendConn <span class=\"comment\">//如果每个db只有一个BackendConn连接，则直接放入single中。当每个db有多个连接时会从conns中选一个返回，而每个db只有一个连接时，直接从single中返回</span></span><br><span class=\"line\"></span><br><span class=\"line\">    refcnt <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>每个BackendConn中有一个 input chan *Request字段,是一个channel,channel中的内容为Request指针。也就是第二章节loopReader选取一个BackendConn后，会将请求放入input中。</p>\n<p>下边我们看看处理BackendConn input字段中数据的协程是如何启动并处理数据的。代码路径为pkg/proxy/backend.go的newBackendConn函数</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">NewBackendConn</span><span class=\"params\">(addr <span class=\"keyword\">string</span>, database <span class=\"keyword\">int</span>, config *Config)</span> *<span class=\"title\">BackendConn</span></span> &#123;</span><br><span class=\"line\">    bc := &amp;BackendConn&#123;</span><br><span class=\"line\">        addr: addr, config: config, database: database,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//1024长度的管道,存放1024个*Request</span></span><br><span class=\"line\">    bc.input = <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> *Request, <span class=\"number\">1024</span>)</span><br><span class=\"line\">    bc.retry.delay = &amp;DelayExp2&#123;</span><br><span class=\"line\">        Min: <span class=\"number\">50</span>, Max: <span class=\"number\">5000</span>,</span><br><span class=\"line\">        Unit: time.Millisecond,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">go</span> bc.run()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> bc</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>可以看到，在此处创建的BackendConn结构，并且初始化bc.input字段。连接池的建立是在proxy初始化启动的时候就会建立好。继续看bc.run()函数的处理流程<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">run</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d start service\"</span>,</span><br><span class=\"line\">        bc, bc.addr, bc.database)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> round := <span class=\"number\">0</span>; bc.closed.IsFalse(); round++ &#123;</span><br><span class=\"line\">        log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d round-[%d]\"</span>,</span><br><span class=\"line\">            bc, bc.addr, bc.database, round)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := bc.loopWriter(round); err != <span class=\"literal\">nil</span> &#123; <span class=\"comment\">//执行loopWriter函数，此处的loopWriter和第二章节的loopWriter只是名称相同，是两个不同的处理函数</span></span><br><span class=\"line\">            bc.delayBeforeRetry()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.Warnf(<span class=\"string\">\"backend conn [%p] to %s, db-%d stop and exit\"</span>,</span><br><span class=\"line\">        bc, bc.addr, bc.database)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">loopWriter</span><span class=\"params\">(round <span class=\"keyword\">int</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    c, tasks, err := bc.newBackendReader(round, bc.config) <span class=\"comment\">//调用newBackendReader函数。注意此处的tasks也是一个存放*Request的channel,用来此处的loopWriter和loopReader交流信息</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> r := <span class=\"keyword\">range</span> bc.input &#123; <span class=\"comment\">//可以看到,此处的loopWriter会从bc.input中取出数据并且处理</span></span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := p.EncodeMultiBulk(r.Multi); err != <span class=\"literal\">nil</span> &#123; <span class=\"comment\">//将请求编码并且发送到codis server</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err := p.Flush(<span class=\"built_in\">len</span>(bc.input) == <span class=\"number\">0</span>); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            tasks &lt;- r  <span class=\"comment\">//将请求放入tasks这个channel中</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>注意此处的loopWriter会从bc.input中取出数据发送到codis server,bc.newBackendReader会起一个loopReader,从codis server中读取数据并且写到request结构体中，此处的loopReader和loopWriter通过tasks这个channel通信。<br><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">newBackendReader</span><span class=\"params\">(round <span class=\"keyword\">int</span>, config *Config)</span> <span class=\"params\">(*redis.Conn, <span class=\"keyword\">chan</span>&lt;- *Request, error)</span></span> &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    tasks := <span class=\"built_in\">make</span>(<span class=\"keyword\">chan</span> *Request, config.BackendMaxPipeline)<span class=\"comment\">//创建task这个channel并且返回给loopWriter</span></span><br><span class=\"line\">    <span class=\"keyword\">go</span> bc.loopReader(tasks, c, round)<span class=\"comment\">//启动loopReader</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c, tasks, <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">loopReader</span><span class=\"params\">(tasks &lt;-<span class=\"keyword\">chan</span> *Request, c *redis.Conn, round <span class=\"keyword\">int</span>)</span> <span class=\"params\">(err error)</span></span> &#123;</span><br><span class=\"line\">   \t...</span><br><span class=\"line\">    <span class=\"keyword\">for</span> r := <span class=\"keyword\">range</span> tasks &#123;  <span class=\"comment\">//从tasks中取出响应</span></span><br><span class=\"line\">        resp, err := c.Decode()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> bc.setResponse(r, <span class=\"literal\">nil</span>, fmt.Errorf(<span class=\"string\">\"backend conn failure, %s\"</span>, err))</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        bc.setResponse(r, resp, <span class=\"literal\">nil</span>)<span class=\"comment\">//设置响应数据到request结构体中</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">nil</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(bc *BackendConn)</span> <span class=\"title\">setResponse</span><span class=\"params\">(r *Request, resp *redis.Resp, err error)</span> <span class=\"title\">error</span></span> &#123;</span><br><span class=\"line\">    r.Resp, r.Err = resp, err <span class=\"comment\">//Request的Resp字段设置为响应值</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Group != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Group.Done()</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> r.Batch != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">        r.Batch.Done() <span class=\"comment\">//注意此处会对Batch执行减1操作，这样proxy中的loopWriter可以聚合响应并返回</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> err</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>总结一下,BackendConn中的函数功能如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loopWriter-&gt;从bc.input中取出请求并且发给codis server,并且将请求放到tasks channel中</span><br><span class=\"line\"></span><br><span class=\"line\">loopReader-&gt;从tasks中取出请求，设置codis server的响应字段到Request的Resp字段中，并且将Batch执行减1操作</span><br></pre></td></tr></table></figure></p>\n<p>小结<br>一图胜千言，图片版权归李老师，如下</p>\n<p><img src=\"/img/codis1.png\" alt=\"codis\"></p>\n"},{"title":"Sqlite如何实现ACID中的原子性","date":"2019-04-13T01:42:00.000Z","_content":"\n>这个文章序列关注Sqlite的原子性实现.首先翻译一篇官方文章,介绍Sqlite的 rollback journal,然后结合一些问题通过源码分析一下具体实现.后续几篇关注Sqlite3.7.0之后的另一种保证原子性的实现 WAL(write ahead log).\n> 注意Sqlite以静态或者动态库的形式提供给程序调用,并不是C/S模式.另外,Sqlite每个库都保存在一个单独的文件之中.通过attch命令能够将其他文件中的库引入.\n\n## Sqlite如何实现ACID中的原子性\n原文链接:https://www.sqlite.org/atomiccommit.html\n翻译中有些无关的省略了.具体信息可以参看原文\n\n### 简介\n关系型数据库需要实现ACID,其中A-Atomic commit,即单个事务中的语句要么全部执行要么一个都不执行.如果在事务的执行过程中操作系统crash或者掉电,事务仍旧能够保证原子性.本篇文章只适用于Sqlite配置为rollback mode的时候.(还有一种保证原子性的模式为开启wal-write ahead log,后文另述)\n\n### Sqlite实现中对硬件的一些假设\n磁盘以sector为单位进行写操作.如果要修改小于一个sector的区域,也得首先把包括待修改区域的整个sector读取出来,修改完毕后再将整个sector写回去.\n\n传统的机械硬盘读和写都是以一个sector为单位,在ssd中,读的单位要比写单位要小很多.Sqlite只关注最小的写单位,所以本文中sector都是指最小的写单位.\n\nSqlite 3.3.14之前默认一个sector的大小为512bytes...\n\nSqlite假设一个sector的写入并不是原子性的,从3.5.0版本开始,sqlite实现了一个新的接口VFS(virtual file system),VFS用来和底层的文件系统交互.VFS接口中有一个方法xDeviceCharacteristics,通过该方法可以获取到底层sector的写入是否是原子性的.如果是,则 **sqlite能够利用该特性做一些写入的优化**\n\nSqlite假设一个写请求并不会直接落盘而是被操作系统先缓存起来.所以在一些节点需要执行flush或者fsync将数据真正刷新到磁盘.\n\nSqlite假设一个文件写入时先更新文件大小然后写入具体内容,**因此Sqlite做了一些额外的工作去保证在更新文件大小和写入文件内容之间如果发生掉电的话不会导致数据库的损坏**.VFS中的xDeviceCharacteristics函数也能够获取到文件系统是否会首先写入内容然后更新大小（通过SQLITE_IOCAP_SAFE_APPEND这个属性）,如果具有该属性,Sqlite就不需要做额外的一些保护措施,减少磁盘I/O.\n\n**Sqlite假设文件的删除操作是原子性的,即如果删除过程中发生了掉电,机器恢复后要么完全看不到该文件,要么文件是完整的,不会出现删除了部分的情况(注意只是用户视角,即用户进程询问操作系统一个文件是否存在时,操作系统只会给出yes or no,而不会有部分存在的回复)**\n\nSqlite不会在数据文件中增加冗余信息去校验文件是否损坏.\n\nSqlite假设操作系统写入一个范围时不会因为掉电或os crash而改变该范围之外的数据.该功能称为 powersafe overwrite.\n\n### 单文件的提交\n首先全局观看sqlite在单文件状态下的原子性保证.后文讨论多文件状态下的原子性保证.\n#### 初始状态\n\n左边是用户进程的内存空间,中间是操作系统缓存,右边是磁盘存储.每个小框代表一个sector,蓝颜色的sector表明存储的是原始数据.\n\n![图0](/img/s0.gif)\n\n#### 获取一个读锁\n\n在写入数据库之前,首先会读取数据.即使是插入数据也得先读取**sqlite_master**获取表的schema和决定将数据存储于哪个位置.\n\n首先获取一个共享锁,一个数据库文件可以同时有多个共享锁,但是当存在共享锁时,其他连接获取不到写锁.\n\n注意共享锁存在于操作系统的缓存中,而非磁盘上.因此当操作系统crash或者掉电或者创建共享锁的进程退出时锁会自动释放\n\n![图1](/img/s1.gif)\n\n#### 从数据库文件读取信息\n\n获得共享锁后,首先从磁盘读取数据到操作系统的缓存,然后从操作系统缓存到用户空间内存中,\n\n通常只有部分pages会读取到,本例中我们共有8个page,但只读取了3个.真实场景中可能会有成千上万个pages\n\n![图2](/img/s2.gif)\n\n#### 获取一个reserved lock\n\n在写入之前首先获取一个reserved lock,注意此时其他连接仍然能够获取shared lock,但不能进一步获取reserved lock,即reserved lock在一个数据库文件中只能有一个存在.\n\n这个锁存在的意义在于说明有进程即将写入一个数据库文件,但是还没有开始写入.此时其他进程如果也尝试写入的话会失败(因为获取不到reserved lock)\n\n![图3](/img/s3.gif)\n\n#### 创建rollback journal file\n\n在修改数据库文件之前,Sqlite首先创建一个独立的rollback journal file,并且将要修改的pages写入rollback journal file.(**注意是以page为单位写入**)\n\nrollback journal file中绿色的部分是header,header中会包括数据库文件的原始大小(**即包括多少个page**).每一个page保存到rollback journal中时前边四字节会保存该page的page number.\n\n![图4](/img/s4.gif)\n\n图4中有两个地方需要注意:\n\n* rollback journal创建之后并没有实际落盘,只是保存在操作系统的缓存中\n* rollback journal以page为单位,但每个page前四字节会有一个page number的记录,后四字节有一个checksum\n\n#### 在用户空间修改数据库文件\n\n![图5](/img/s5.gif)\n\n修改用户进程空间内的数据库文件,注意不同的用户进程有自己的私有内存空间,因此此时的修改并不影响其他进程的读取操作\n\n#### 将rollback journal落盘\n\n将rollback journal刷新到磁盘,该步骤是保持原子性很关键的一步,保证即使掉电或者操作系统crash,Sqlite也能恢复到原来的状态.\n\n(**进行到该步也能看出reserved lock的作用,这种锁是一个中间状态,既能为即将写入做准备,又不影响其他进程的读取操作,提高并行度**)\n![图6](/img/s6.gif)\n\n该步需要刷两次盘,第一次将rollback journal的内容刷到磁盘,第二次在header中记录第一步中刷到磁盘的page个数,然后将header刷盘\n\n#### 获取排他锁\n\n![图7](/img/s7.gif)\n在实际写入数据库文件之前,需要获取一个排他锁.获取过程分两步\n * 获取一个pending lock\n * 将pending lock升级为排他锁\n\n获取到pending lock之后,在数据库文件上已经获取到共享锁的进程可以继续读取,但不允许其他进程继续获取共享锁.该锁存在的意义在于防止write starvation(即有大量的读取连接时,一直有新的共享锁产生,导致获取不到排他锁).当所有已经存在的共享锁都释放后,此时该pending lock即可以升级为排他锁\n\n#### 写入数据库文件\n\n![图8](/img/s8.gif)\n\n获取到排他锁后,说明已经没有其他进程在读取该数据库文件.此时可以安全的写入数据库文件.注意也只是写入操作系统的缓存中,并没有落盘 \n\n#### 数据库文件刷盘\n\n![图9](/img/s9.gif)\n\n此时将数据库文件刷新到磁盘.\n\n#### 删除rollback journal\n\n![图10](/img/s10.gif)\n\n因为数据库文件已经安全落盘,此时可以删除掉rollback journal.若删除之前系统crash或者掉电,则重启后会恢复到事务开始前的状态,如果删除之后系统crash或者掉电,因为数据库文件已经落盘,相当于事务已经执行完成.(**那么会不会在删除一半时系统crash或者掉电呢?注意上文中关于硬件的一些假设,删除操作必须是原子性的,即不会发生这种情况**)\n\n因为删除一个文件也是一个耗时的操作,因此Sqlite提供了两种方式减少删除过程的耗时.\n* 将一个文件truncate为0\n* 将journal file header清0.清0操作并不是原子性的,但只要header中有一个byte被清0,该文件就会被识别为无效的格式\n\n#### 释放锁\n\n![图11](/img/s11.gif)\n\n此时可以释放掉排他锁.\n\n注意图11中的用户空间缓存也已经被清除.但新版本的Sqlite并不会清除用户空间缓存,以免下一个事务开启式需要重新读取该数据.但在复用该缓存信息时需要首先获取一个共享锁然后检测是否在当前事务开启之前有其他事务已经修改过数据库文件.如果已经修改过则不能复用.检测修改的逻辑也很简单,数据库文件的第一个页中保存了一个计数器,通过比较该计数器即可知道是否发生过修改\n\n### 回滚\n\n#### 出错时\n![图12](/img/sr0.gif)\n\n\n假设将数据库文件刷盘时掉电,会出现图12所示的情况.我们本来需要修改三个page,但这时只修改成功一个page,另一个page只写了一部分,而第三部分还没开始写\n\n注意此时rollback journal已经安全落盘但还没删除\n\n#### hot rollback journal\n![图13](/img/sr1.gif)\n\n掉电或操作系统crash恢复后,Sqlite会首先获取一个共享锁,然后检测是否有hot rollback journal存在.注意hot rollback journal只有在一个事务没有提交完成时存在.那么如何检测是否是一个hot rollback journal呢,我们通过检测如下几点来决定:\n\n* rollback journal file存在\n* rollback journal file不为空\n* rollback journal file header格式正确,即没有被清0\n* rollback journal file 指定位置没有master journal file的名称,或者如果有一个master journal的名称并且这个master journal也存在(后文叙述,涉及到多文件的事务)\n\n一个hot journal的存在说明数据库处于一个不一致的状态.在读取之前需要先进行修复\n\n#### 获取排他锁\n![图14](/img/sr2.gif)\n\n进行数据库恢复之前先获取一个排他锁.防止多个进程同时修复一个数据库文件.\n\n(**注意此时不需要先获取reserved lock或者pending lock,此时需要立刻进行修复,不需要考虑其他进程的读取.但假设此时有其他进程持有shared lock,会直接获取到排他锁还是会等待shared lock失效?猜测应该为前者**)\n\n#### 回滚\n\n![图15](/img/sr3.gif)\n获取到排他锁后可以开始执行恢复.分两步:\n* 将rollback journal中的相应page写回到database file\n* rollback journal中有记录database file的原始大小,将database file truncate 到原始大小.\n\n此时数据库内容和大小都会恢复到原始状态\n\n#### 删除hot journal\n![图16](/img/sr4.gif)\n\n当数据库文件恢复并且落盘后,可以清除掉hot journal\n\n#### 继续读取\n![图17](/img/sr5.gif)\n\n将排他锁降级为共享锁.此时崩溃的事务好像没有发生过一样\n\n### 多文件事务\n\nSqlite允许一个数据库连接中通过attach database命令同时操作多个数据库文件.当多文件在一个事务中修改时,Sqlite保证其原子性.即要么所有文件中都更新成功,要么所有文件都不更新.\n\n#### 每个文件都有单独的rollback journal\n\n![图18](/img/sm0.gif)\n\n图中每个文件有单独的reserverd lock和rollback journal,类似单文件情形.但此时rollback journal 并没有刷盘,数据库文件也没有更新 \n\n#### master journal file\n\n![图19](/img/sm1.gif)\n\n下一步需要创建一个master journal file.文件名称仍然是使用sqlite3_open打开的原始数据库文件名称,但会增加一个-mjHHHHHHHH的后缀,HHHHHHHH是一个随机的32bit十六进制数字.每个master journal的的随机后缀都不相同\n\nmaster journal中并不保证数据库文件的原始内容,保存的是每一个rollback journal的完整路径和名称\n\nmaster journal创建完成后需要直接刷盘(**在Unix系统中,包括该master journal的目录也需要刷盘**)\n\nmaster journal的存在是为了保证多文件事务的原子性.但如果Sqlite中设置了pragma synchronous=off 或者 pragma mode=memory,则并不会创建master journal.当然在此配置下也不能保证完整性\n\n#### 更新rollback journal的header\n\n![图20](/img/sm2.gif)\n\n更新每一个rollback journal的header,将master journal的完整路径及名称写入rollback journal的header（单文件事务中该字段为空）.在更新header之前和之后都需要将rollback journal进行刷盘(**此处类似单文件事务中刷新纪录之后再刷新纪录的计数,Sqlite需要确保在header写入成功之前content已经写入成功**).\n\n#### 更新数据库文件 \n\n![图21](/img/sm3.gif)\n\n在每个数据库文件都获取到排他锁之后更新数据库文件并且刷盘\n\n#### 删除master journal file\n![图22](/img/sm4.gif)\n\n此时可以删除master journal file.如果此时发生了掉电或者操作系统crash,根据之前hot journal的认定规则,此时也不会进行回滚,虽然仍然存在各个数据库文件的rollback journal.\n\n#### 清除rollback journal file\n\n![图23](/img/sm5.gif)\n删除rollback journal并且释放排他锁.\n\n### 其他commit时的细节\n\n#### page和sector\n\nSqlite写入rollback journal时必须是按sector大小的整数倍写入.sector在大部分情况下为512bytes,page为4096bytes,此时按page写入没有什么问题.\n但是如果sector为4096bytes,而page为512bytes,此时即使只修改一个page,也会将该page属于的sector整个写入rollback journal.\n\n#### 处理journal中的垃圾内容\n\n前文中提到过Sqlite的一些硬件假设,其中一条为文件首先扩充大小然后将真正的内容写入.如果文件扩充大小之后,写入真正内容之前发生了掉电,此时journal中会包含一些垃圾信息,此时rollback会将垃圾信息也写入数据库文件,从而发生错误.\n\n为此Sqlite做了一些保护性措施,其一为在rollback journal的header中记录该rollback journal包括的page的个数,并且初始化为0.只有当真正的内容刷盘之后,会将header中的记录个数更新并且刷盘.注意header不论大小都会占用一个sector的大小,因此可以独立刷新,不影响journal的内容.\n\nSqlite默认是如下配置\n```\n\tPRAGMA synchronous=FULL;\n```\n如果修改该配置的值为NORMAL以下,则Sqlite对journal的刷盘流程修改为只刷新一次.如下:\n```\n\twrite content -> write header ->flush\n```\n虽然header的写入仍然在content之后,但不保证操作系统实际刷新时可能会先刷新header,再刷新content.因此sqlite在每个rollback journal content的page内容之后附加了4字节的checksum.即rollback journal的格式如下\n```\n\t| header | pgno|page content|checksum|pano|page content|checksum|\n```\nrollback时会检查每个page content的checksum是否正确,如果不正确则放弃该次rollback.\n\n#### cache spill\n当大量的更新导致用户空间的缓存不足以保存所有需要更新的page时会有cache spill的情况发生.\ncache spill首先刷新journal file到磁盘,然后获取一个排他锁, 然后写入数据库更新.此时因为更新还没有全部完成,需要在追加一个header到journal file,循环执行如上三个步骤(第二步获取排他锁因为已经完成,实际上不需要再次获取),直到所有更新完成.因为cache spill会增加占用排他锁的时间并且会有更多的io,会严重影响性能.因此应该尽量避免cache spill\n\n### 优化措施\n\nSqlite耗时大部分在io上, 因此本节主要考虑如何在保证原子性的前提下能够降低io\n\n#### 事务之间的缓存保存\n\n上文也提到过,在数据库文件的database file第一个page的24-27字节有一个counter字段,每次数据库发生更改之后都会更新该字段.因此sqlite在一个事务执行完成需要释放锁时,会首先获取该字段的值,当下一个事务获取锁之后会比较之前缓存的counter值和当前的counter值,据此决定是否可以复用该缓存\n\n#### 排他性访问模式\n\n适合于单进程访问的情况,不详述\n\n#### freelist page不写入journal\n\n当Sqlite删除一些数据后,只保存删除信息的page会放入freelist.后续的写入会首先从freelist中获取可用的page而不用增加数据库文件的大小\n\nSqlite中的freelist有两种类型,trunk page和leaf page.leaf page不包含任何有用的信息.因此如果Sqlite的修改涉及到leaf page,leaf page不需要写入journal(因为leaf page中没有任何有用信息).该步能够降低io\n\n#### 单页修改以及原子性的sector写入\n\n如果一个磁盘支持ector的原子性写入并且page大小等于sector,并且一次修改只涉及到一个page.那么此时会直接写database file而不用journal.\n\n#### safe append \n\n如果一个磁盘支持safe append,那么journal file的header部分写入的page records数量永远为-1,不需要二次刷盘.实际记录由journal的size大小计算得出.并且发生cache spill时也不需要在与原来的\bjournal后边追加header.直接追加content即可\n\n#### 持久化rollback journal\n```\nPRAGMA journal_mode=PERSIST;\n```\n当配置此项之后,commit事务时不删除journal file,而是将journal file的header清0.该方法会节省如下几步:\n* 不需要更新inode中的journal file文件大小\n* 不需要处理释放后的磁盘空间\n* 下一个事务可以直接覆盖该journal file而不是创建或者追加文件内容,覆盖会比追加更快\n* 不需要更新包括该文件的目录信息\n\n```\nPRAGMA journal_mode=TRUNCATE;\n```\n该模式会将一个文件大小truncate为0.由于不需要更新文件所属目录信息,因此truncate比delete要快.\n但truncate比persist模式还是会慢,因为覆盖文件要比追加文件快.\n\n### 测试Sqlite的原子性\n\n因为Sqlite开发者使用了大量的自动化的密集的'crash tests'模拟Sqlite在掉电或者系统crash时后的恢复情况,所以对Sqlite的可靠性很有信心.\n\nSqlite的'crash tests'使用一个修改过的vfs模拟系统crash或者掉电后的文件系统损坏.例如sector只写了一部分,写操作未完成导致pages中有垃圾信息,写操作乱序等等不同的节点.通过模拟不同的场景一遍遍测试Sqlite事务,验证其最终是否能够保持原子性.\n\n'crash tests'已经发现了许多Sqlite恢复机制中的微妙的bug(都已经修复),这些bug光靠代码分析和审查是很难发现的.(总之是Sqlite开发者对Sqlite的原子性保证很有信心)\n\n### 可能发生问题的一些情况\n\n#### 锁的实现\n\nSqlite使用文件系统锁去保证同时只有一个进程或者连接操作数据库文件.文件系统锁在VFS层实现并且不同的操作系统有不同的实现方法.如果文件系统锁实现的有问题导致同时有多个进程或连接修改同一个数据库文件就会发生严重的损坏.\n\n....(举例说明NFS这种网络文件系统就可能会导致发生损坏)\n\n#### 刷盘的实现\n\nSqlite在Unix使用fsync,windows使用FlushFileBuffers去刷盘,但是这两个函数在许多系统上可能并不可靠.例如我们收到反馈说Windows可以使用注册表禁用禁用掉FlushFileBuffers,一些老的Linux版本的fsync在有些文件系统下不执行任何操作.即使fsync和FlushFileBuffers能够正常工作,一些IDE磁盘执行之后也只是把数据保存在控制器缓存中而不是真正落盘.\n\n....(Mac相关的配置...)\n\n#### 文件删除操作不保证原子性\n\n文件删除操作从应用视角看需要保持原子性,即删除部分数据后掉电的话应用要么完全看不到该文件要么需要看到一个完整的文件,不能只看到删了部分的文件(rollback journal如果只删了一半,会执行恢复操作,但是因为journal已经不完整了,恢复的数据也会不完整)\n\n#### 文件中有垃圾数据\n\nSqlite的数据库文件就是一个普通的磁盘文件,如果文件中被其他进程写入垃圾数据,或者其他原因导致垃圾数据产生,会导致数据库文件不可用\n\n#### 删除或者重命名一个journal file\n\njournal file和数据库文件的命名有一定的关系,如果数据库文件或者journal file的名字被修改了,会导致没法roll back.\n\n(举了一些可能的例子....)\nSqlite将journal file刷盘的同时也会刷新journal file所在的目录,以免修改名称然后掉电导致重启后找不到该文件...\n\n### 未来的一些方向和结论\n\n虽然Sqlite保证原子性的这个机制bug越来越少,但最好还是保持警惕,发现问题后Sqlite开发者会尽快修改.\n\nSqlite开发者也在尽量优化提交过程.现在Sqlite都会对操作系统的VFS实现做一些悲观的假设,然后从Sqlite层面去保证正确性.例如现今许多现代的操作系统都能保证safe append和原子性的sector write,但这些功能必须很确定之后, 我们才会从Sqlite层面减少对这些功能做的一些正确性保证.\n\n\n\n","source":"_posts/Sqlite如何实现ACID中的原子性.md","raw":"---\ntitle: Sqlite如何实现ACID中的原子性\ndate: 2019-04-13 09:42:00\ntags: Sqlite\n---\n\n>这个文章序列关注Sqlite的原子性实现.首先翻译一篇官方文章,介绍Sqlite的 rollback journal,然后结合一些问题通过源码分析一下具体实现.后续几篇关注Sqlite3.7.0之后的另一种保证原子性的实现 WAL(write ahead log).\n> 注意Sqlite以静态或者动态库的形式提供给程序调用,并不是C/S模式.另外,Sqlite每个库都保存在一个单独的文件之中.通过attch命令能够将其他文件中的库引入.\n\n## Sqlite如何实现ACID中的原子性\n原文链接:https://www.sqlite.org/atomiccommit.html\n翻译中有些无关的省略了.具体信息可以参看原文\n\n### 简介\n关系型数据库需要实现ACID,其中A-Atomic commit,即单个事务中的语句要么全部执行要么一个都不执行.如果在事务的执行过程中操作系统crash或者掉电,事务仍旧能够保证原子性.本篇文章只适用于Sqlite配置为rollback mode的时候.(还有一种保证原子性的模式为开启wal-write ahead log,后文另述)\n\n### Sqlite实现中对硬件的一些假设\n磁盘以sector为单位进行写操作.如果要修改小于一个sector的区域,也得首先把包括待修改区域的整个sector读取出来,修改完毕后再将整个sector写回去.\n\n传统的机械硬盘读和写都是以一个sector为单位,在ssd中,读的单位要比写单位要小很多.Sqlite只关注最小的写单位,所以本文中sector都是指最小的写单位.\n\nSqlite 3.3.14之前默认一个sector的大小为512bytes...\n\nSqlite假设一个sector的写入并不是原子性的,从3.5.0版本开始,sqlite实现了一个新的接口VFS(virtual file system),VFS用来和底层的文件系统交互.VFS接口中有一个方法xDeviceCharacteristics,通过该方法可以获取到底层sector的写入是否是原子性的.如果是,则 **sqlite能够利用该特性做一些写入的优化**\n\nSqlite假设一个写请求并不会直接落盘而是被操作系统先缓存起来.所以在一些节点需要执行flush或者fsync将数据真正刷新到磁盘.\n\nSqlite假设一个文件写入时先更新文件大小然后写入具体内容,**因此Sqlite做了一些额外的工作去保证在更新文件大小和写入文件内容之间如果发生掉电的话不会导致数据库的损坏**.VFS中的xDeviceCharacteristics函数也能够获取到文件系统是否会首先写入内容然后更新大小（通过SQLITE_IOCAP_SAFE_APPEND这个属性）,如果具有该属性,Sqlite就不需要做额外的一些保护措施,减少磁盘I/O.\n\n**Sqlite假设文件的删除操作是原子性的,即如果删除过程中发生了掉电,机器恢复后要么完全看不到该文件,要么文件是完整的,不会出现删除了部分的情况(注意只是用户视角,即用户进程询问操作系统一个文件是否存在时,操作系统只会给出yes or no,而不会有部分存在的回复)**\n\nSqlite不会在数据文件中增加冗余信息去校验文件是否损坏.\n\nSqlite假设操作系统写入一个范围时不会因为掉电或os crash而改变该范围之外的数据.该功能称为 powersafe overwrite.\n\n### 单文件的提交\n首先全局观看sqlite在单文件状态下的原子性保证.后文讨论多文件状态下的原子性保证.\n#### 初始状态\n\n左边是用户进程的内存空间,中间是操作系统缓存,右边是磁盘存储.每个小框代表一个sector,蓝颜色的sector表明存储的是原始数据.\n\n![图0](/img/s0.gif)\n\n#### 获取一个读锁\n\n在写入数据库之前,首先会读取数据.即使是插入数据也得先读取**sqlite_master**获取表的schema和决定将数据存储于哪个位置.\n\n首先获取一个共享锁,一个数据库文件可以同时有多个共享锁,但是当存在共享锁时,其他连接获取不到写锁.\n\n注意共享锁存在于操作系统的缓存中,而非磁盘上.因此当操作系统crash或者掉电或者创建共享锁的进程退出时锁会自动释放\n\n![图1](/img/s1.gif)\n\n#### 从数据库文件读取信息\n\n获得共享锁后,首先从磁盘读取数据到操作系统的缓存,然后从操作系统缓存到用户空间内存中,\n\n通常只有部分pages会读取到,本例中我们共有8个page,但只读取了3个.真实场景中可能会有成千上万个pages\n\n![图2](/img/s2.gif)\n\n#### 获取一个reserved lock\n\n在写入之前首先获取一个reserved lock,注意此时其他连接仍然能够获取shared lock,但不能进一步获取reserved lock,即reserved lock在一个数据库文件中只能有一个存在.\n\n这个锁存在的意义在于说明有进程即将写入一个数据库文件,但是还没有开始写入.此时其他进程如果也尝试写入的话会失败(因为获取不到reserved lock)\n\n![图3](/img/s3.gif)\n\n#### 创建rollback journal file\n\n在修改数据库文件之前,Sqlite首先创建一个独立的rollback journal file,并且将要修改的pages写入rollback journal file.(**注意是以page为单位写入**)\n\nrollback journal file中绿色的部分是header,header中会包括数据库文件的原始大小(**即包括多少个page**).每一个page保存到rollback journal中时前边四字节会保存该page的page number.\n\n![图4](/img/s4.gif)\n\n图4中有两个地方需要注意:\n\n* rollback journal创建之后并没有实际落盘,只是保存在操作系统的缓存中\n* rollback journal以page为单位,但每个page前四字节会有一个page number的记录,后四字节有一个checksum\n\n#### 在用户空间修改数据库文件\n\n![图5](/img/s5.gif)\n\n修改用户进程空间内的数据库文件,注意不同的用户进程有自己的私有内存空间,因此此时的修改并不影响其他进程的读取操作\n\n#### 将rollback journal落盘\n\n将rollback journal刷新到磁盘,该步骤是保持原子性很关键的一步,保证即使掉电或者操作系统crash,Sqlite也能恢复到原来的状态.\n\n(**进行到该步也能看出reserved lock的作用,这种锁是一个中间状态,既能为即将写入做准备,又不影响其他进程的读取操作,提高并行度**)\n![图6](/img/s6.gif)\n\n该步需要刷两次盘,第一次将rollback journal的内容刷到磁盘,第二次在header中记录第一步中刷到磁盘的page个数,然后将header刷盘\n\n#### 获取排他锁\n\n![图7](/img/s7.gif)\n在实际写入数据库文件之前,需要获取一个排他锁.获取过程分两步\n * 获取一个pending lock\n * 将pending lock升级为排他锁\n\n获取到pending lock之后,在数据库文件上已经获取到共享锁的进程可以继续读取,但不允许其他进程继续获取共享锁.该锁存在的意义在于防止write starvation(即有大量的读取连接时,一直有新的共享锁产生,导致获取不到排他锁).当所有已经存在的共享锁都释放后,此时该pending lock即可以升级为排他锁\n\n#### 写入数据库文件\n\n![图8](/img/s8.gif)\n\n获取到排他锁后,说明已经没有其他进程在读取该数据库文件.此时可以安全的写入数据库文件.注意也只是写入操作系统的缓存中,并没有落盘 \n\n#### 数据库文件刷盘\n\n![图9](/img/s9.gif)\n\n此时将数据库文件刷新到磁盘.\n\n#### 删除rollback journal\n\n![图10](/img/s10.gif)\n\n因为数据库文件已经安全落盘,此时可以删除掉rollback journal.若删除之前系统crash或者掉电,则重启后会恢复到事务开始前的状态,如果删除之后系统crash或者掉电,因为数据库文件已经落盘,相当于事务已经执行完成.(**那么会不会在删除一半时系统crash或者掉电呢?注意上文中关于硬件的一些假设,删除操作必须是原子性的,即不会发生这种情况**)\n\n因为删除一个文件也是一个耗时的操作,因此Sqlite提供了两种方式减少删除过程的耗时.\n* 将一个文件truncate为0\n* 将journal file header清0.清0操作并不是原子性的,但只要header中有一个byte被清0,该文件就会被识别为无效的格式\n\n#### 释放锁\n\n![图11](/img/s11.gif)\n\n此时可以释放掉排他锁.\n\n注意图11中的用户空间缓存也已经被清除.但新版本的Sqlite并不会清除用户空间缓存,以免下一个事务开启式需要重新读取该数据.但在复用该缓存信息时需要首先获取一个共享锁然后检测是否在当前事务开启之前有其他事务已经修改过数据库文件.如果已经修改过则不能复用.检测修改的逻辑也很简单,数据库文件的第一个页中保存了一个计数器,通过比较该计数器即可知道是否发生过修改\n\n### 回滚\n\n#### 出错时\n![图12](/img/sr0.gif)\n\n\n假设将数据库文件刷盘时掉电,会出现图12所示的情况.我们本来需要修改三个page,但这时只修改成功一个page,另一个page只写了一部分,而第三部分还没开始写\n\n注意此时rollback journal已经安全落盘但还没删除\n\n#### hot rollback journal\n![图13](/img/sr1.gif)\n\n掉电或操作系统crash恢复后,Sqlite会首先获取一个共享锁,然后检测是否有hot rollback journal存在.注意hot rollback journal只有在一个事务没有提交完成时存在.那么如何检测是否是一个hot rollback journal呢,我们通过检测如下几点来决定:\n\n* rollback journal file存在\n* rollback journal file不为空\n* rollback journal file header格式正确,即没有被清0\n* rollback journal file 指定位置没有master journal file的名称,或者如果有一个master journal的名称并且这个master journal也存在(后文叙述,涉及到多文件的事务)\n\n一个hot journal的存在说明数据库处于一个不一致的状态.在读取之前需要先进行修复\n\n#### 获取排他锁\n![图14](/img/sr2.gif)\n\n进行数据库恢复之前先获取一个排他锁.防止多个进程同时修复一个数据库文件.\n\n(**注意此时不需要先获取reserved lock或者pending lock,此时需要立刻进行修复,不需要考虑其他进程的读取.但假设此时有其他进程持有shared lock,会直接获取到排他锁还是会等待shared lock失效?猜测应该为前者**)\n\n#### 回滚\n\n![图15](/img/sr3.gif)\n获取到排他锁后可以开始执行恢复.分两步:\n* 将rollback journal中的相应page写回到database file\n* rollback journal中有记录database file的原始大小,将database file truncate 到原始大小.\n\n此时数据库内容和大小都会恢复到原始状态\n\n#### 删除hot journal\n![图16](/img/sr4.gif)\n\n当数据库文件恢复并且落盘后,可以清除掉hot journal\n\n#### 继续读取\n![图17](/img/sr5.gif)\n\n将排他锁降级为共享锁.此时崩溃的事务好像没有发生过一样\n\n### 多文件事务\n\nSqlite允许一个数据库连接中通过attach database命令同时操作多个数据库文件.当多文件在一个事务中修改时,Sqlite保证其原子性.即要么所有文件中都更新成功,要么所有文件都不更新.\n\n#### 每个文件都有单独的rollback journal\n\n![图18](/img/sm0.gif)\n\n图中每个文件有单独的reserverd lock和rollback journal,类似单文件情形.但此时rollback journal 并没有刷盘,数据库文件也没有更新 \n\n#### master journal file\n\n![图19](/img/sm1.gif)\n\n下一步需要创建一个master journal file.文件名称仍然是使用sqlite3_open打开的原始数据库文件名称,但会增加一个-mjHHHHHHHH的后缀,HHHHHHHH是一个随机的32bit十六进制数字.每个master journal的的随机后缀都不相同\n\nmaster journal中并不保证数据库文件的原始内容,保存的是每一个rollback journal的完整路径和名称\n\nmaster journal创建完成后需要直接刷盘(**在Unix系统中,包括该master journal的目录也需要刷盘**)\n\nmaster journal的存在是为了保证多文件事务的原子性.但如果Sqlite中设置了pragma synchronous=off 或者 pragma mode=memory,则并不会创建master journal.当然在此配置下也不能保证完整性\n\n#### 更新rollback journal的header\n\n![图20](/img/sm2.gif)\n\n更新每一个rollback journal的header,将master journal的完整路径及名称写入rollback journal的header（单文件事务中该字段为空）.在更新header之前和之后都需要将rollback journal进行刷盘(**此处类似单文件事务中刷新纪录之后再刷新纪录的计数,Sqlite需要确保在header写入成功之前content已经写入成功**).\n\n#### 更新数据库文件 \n\n![图21](/img/sm3.gif)\n\n在每个数据库文件都获取到排他锁之后更新数据库文件并且刷盘\n\n#### 删除master journal file\n![图22](/img/sm4.gif)\n\n此时可以删除master journal file.如果此时发生了掉电或者操作系统crash,根据之前hot journal的认定规则,此时也不会进行回滚,虽然仍然存在各个数据库文件的rollback journal.\n\n#### 清除rollback journal file\n\n![图23](/img/sm5.gif)\n删除rollback journal并且释放排他锁.\n\n### 其他commit时的细节\n\n#### page和sector\n\nSqlite写入rollback journal时必须是按sector大小的整数倍写入.sector在大部分情况下为512bytes,page为4096bytes,此时按page写入没有什么问题.\n但是如果sector为4096bytes,而page为512bytes,此时即使只修改一个page,也会将该page属于的sector整个写入rollback journal.\n\n#### 处理journal中的垃圾内容\n\n前文中提到过Sqlite的一些硬件假设,其中一条为文件首先扩充大小然后将真正的内容写入.如果文件扩充大小之后,写入真正内容之前发生了掉电,此时journal中会包含一些垃圾信息,此时rollback会将垃圾信息也写入数据库文件,从而发生错误.\n\n为此Sqlite做了一些保护性措施,其一为在rollback journal的header中记录该rollback journal包括的page的个数,并且初始化为0.只有当真正的内容刷盘之后,会将header中的记录个数更新并且刷盘.注意header不论大小都会占用一个sector的大小,因此可以独立刷新,不影响journal的内容.\n\nSqlite默认是如下配置\n```\n\tPRAGMA synchronous=FULL;\n```\n如果修改该配置的值为NORMAL以下,则Sqlite对journal的刷盘流程修改为只刷新一次.如下:\n```\n\twrite content -> write header ->flush\n```\n虽然header的写入仍然在content之后,但不保证操作系统实际刷新时可能会先刷新header,再刷新content.因此sqlite在每个rollback journal content的page内容之后附加了4字节的checksum.即rollback journal的格式如下\n```\n\t| header | pgno|page content|checksum|pano|page content|checksum|\n```\nrollback时会检查每个page content的checksum是否正确,如果不正确则放弃该次rollback.\n\n#### cache spill\n当大量的更新导致用户空间的缓存不足以保存所有需要更新的page时会有cache spill的情况发生.\ncache spill首先刷新journal file到磁盘,然后获取一个排他锁, 然后写入数据库更新.此时因为更新还没有全部完成,需要在追加一个header到journal file,循环执行如上三个步骤(第二步获取排他锁因为已经完成,实际上不需要再次获取),直到所有更新完成.因为cache spill会增加占用排他锁的时间并且会有更多的io,会严重影响性能.因此应该尽量避免cache spill\n\n### 优化措施\n\nSqlite耗时大部分在io上, 因此本节主要考虑如何在保证原子性的前提下能够降低io\n\n#### 事务之间的缓存保存\n\n上文也提到过,在数据库文件的database file第一个page的24-27字节有一个counter字段,每次数据库发生更改之后都会更新该字段.因此sqlite在一个事务执行完成需要释放锁时,会首先获取该字段的值,当下一个事务获取锁之后会比较之前缓存的counter值和当前的counter值,据此决定是否可以复用该缓存\n\n#### 排他性访问模式\n\n适合于单进程访问的情况,不详述\n\n#### freelist page不写入journal\n\n当Sqlite删除一些数据后,只保存删除信息的page会放入freelist.后续的写入会首先从freelist中获取可用的page而不用增加数据库文件的大小\n\nSqlite中的freelist有两种类型,trunk page和leaf page.leaf page不包含任何有用的信息.因此如果Sqlite的修改涉及到leaf page,leaf page不需要写入journal(因为leaf page中没有任何有用信息).该步能够降低io\n\n#### 单页修改以及原子性的sector写入\n\n如果一个磁盘支持ector的原子性写入并且page大小等于sector,并且一次修改只涉及到一个page.那么此时会直接写database file而不用journal.\n\n#### safe append \n\n如果一个磁盘支持safe append,那么journal file的header部分写入的page records数量永远为-1,不需要二次刷盘.实际记录由journal的size大小计算得出.并且发生cache spill时也不需要在与原来的\bjournal后边追加header.直接追加content即可\n\n#### 持久化rollback journal\n```\nPRAGMA journal_mode=PERSIST;\n```\n当配置此项之后,commit事务时不删除journal file,而是将journal file的header清0.该方法会节省如下几步:\n* 不需要更新inode中的journal file文件大小\n* 不需要处理释放后的磁盘空间\n* 下一个事务可以直接覆盖该journal file而不是创建或者追加文件内容,覆盖会比追加更快\n* 不需要更新包括该文件的目录信息\n\n```\nPRAGMA journal_mode=TRUNCATE;\n```\n该模式会将一个文件大小truncate为0.由于不需要更新文件所属目录信息,因此truncate比delete要快.\n但truncate比persist模式还是会慢,因为覆盖文件要比追加文件快.\n\n### 测试Sqlite的原子性\n\n因为Sqlite开发者使用了大量的自动化的密集的'crash tests'模拟Sqlite在掉电或者系统crash时后的恢复情况,所以对Sqlite的可靠性很有信心.\n\nSqlite的'crash tests'使用一个修改过的vfs模拟系统crash或者掉电后的文件系统损坏.例如sector只写了一部分,写操作未完成导致pages中有垃圾信息,写操作乱序等等不同的节点.通过模拟不同的场景一遍遍测试Sqlite事务,验证其最终是否能够保持原子性.\n\n'crash tests'已经发现了许多Sqlite恢复机制中的微妙的bug(都已经修复),这些bug光靠代码分析和审查是很难发现的.(总之是Sqlite开发者对Sqlite的原子性保证很有信心)\n\n### 可能发生问题的一些情况\n\n#### 锁的实现\n\nSqlite使用文件系统锁去保证同时只有一个进程或者连接操作数据库文件.文件系统锁在VFS层实现并且不同的操作系统有不同的实现方法.如果文件系统锁实现的有问题导致同时有多个进程或连接修改同一个数据库文件就会发生严重的损坏.\n\n....(举例说明NFS这种网络文件系统就可能会导致发生损坏)\n\n#### 刷盘的实现\n\nSqlite在Unix使用fsync,windows使用FlushFileBuffers去刷盘,但是这两个函数在许多系统上可能并不可靠.例如我们收到反馈说Windows可以使用注册表禁用禁用掉FlushFileBuffers,一些老的Linux版本的fsync在有些文件系统下不执行任何操作.即使fsync和FlushFileBuffers能够正常工作,一些IDE磁盘执行之后也只是把数据保存在控制器缓存中而不是真正落盘.\n\n....(Mac相关的配置...)\n\n#### 文件删除操作不保证原子性\n\n文件删除操作从应用视角看需要保持原子性,即删除部分数据后掉电的话应用要么完全看不到该文件要么需要看到一个完整的文件,不能只看到删了部分的文件(rollback journal如果只删了一半,会执行恢复操作,但是因为journal已经不完整了,恢复的数据也会不完整)\n\n#### 文件中有垃圾数据\n\nSqlite的数据库文件就是一个普通的磁盘文件,如果文件中被其他进程写入垃圾数据,或者其他原因导致垃圾数据产生,会导致数据库文件不可用\n\n#### 删除或者重命名一个journal file\n\njournal file和数据库文件的命名有一定的关系,如果数据库文件或者journal file的名字被修改了,会导致没法roll back.\n\n(举了一些可能的例子....)\nSqlite将journal file刷盘的同时也会刷新journal file所在的目录,以免修改名称然后掉电导致重启后找不到该文件...\n\n### 未来的一些方向和结论\n\n虽然Sqlite保证原子性的这个机制bug越来越少,但最好还是保持警惕,发现问题后Sqlite开发者会尽快修改.\n\nSqlite开发者也在尽量优化提交过程.现在Sqlite都会对操作系统的VFS实现做一些悲观的假设,然后从Sqlite层面去保证正确性.例如现今许多现代的操作系统都能保证safe append和原子性的sector write,但这些功能必须很确定之后, 我们才会从Sqlite层面减少对这些功能做的一些正确性保证.\n\n\n\n","slug":"Sqlite如何实现ACID中的原子性","published":1,"updated":"2019-04-16T11:36:25.372Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zcl001sbms6m2m8ywpk","content":"<blockquote>\n<p>这个文章序列关注Sqlite的原子性实现.首先翻译一篇官方文章,介绍Sqlite的 rollback journal,然后结合一些问题通过源码分析一下具体实现.后续几篇关注Sqlite3.7.0之后的另一种保证原子性的实现 WAL(write ahead log).<br>注意Sqlite以静态或者动态库的形式提供给程序调用,并不是C/S模式.另外,Sqlite每个库都保存在一个单独的文件之中.通过attch命令能够将其他文件中的库引入.</p>\n</blockquote>\n<h2 id=\"Sqlite如何实现ACID中的原子性\"><a href=\"#Sqlite如何实现ACID中的原子性\" class=\"headerlink\" title=\"Sqlite如何实现ACID中的原子性\"></a>Sqlite如何实现ACID中的原子性</h2><p>原文链接:<a href=\"https://www.sqlite.org/atomiccommit.html\" target=\"_blank\" rel=\"noopener\">https://www.sqlite.org/atomiccommit.html</a><br>翻译中有些无关的省略了.具体信息可以参看原文</p>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>关系型数据库需要实现ACID,其中A-Atomic commit,即单个事务中的语句要么全部执行要么一个都不执行.如果在事务的执行过程中操作系统crash或者掉电,事务仍旧能够保证原子性.本篇文章只适用于Sqlite配置为rollback mode的时候.(还有一种保证原子性的模式为开启wal-write ahead log,后文另述)</p>\n<h3 id=\"Sqlite实现中对硬件的一些假设\"><a href=\"#Sqlite实现中对硬件的一些假设\" class=\"headerlink\" title=\"Sqlite实现中对硬件的一些假设\"></a>Sqlite实现中对硬件的一些假设</h3><p>磁盘以sector为单位进行写操作.如果要修改小于一个sector的区域,也得首先把包括待修改区域的整个sector读取出来,修改完毕后再将整个sector写回去.</p>\n<p>传统的机械硬盘读和写都是以一个sector为单位,在ssd中,读的单位要比写单位要小很多.Sqlite只关注最小的写单位,所以本文中sector都是指最小的写单位.</p>\n<p>Sqlite 3.3.14之前默认一个sector的大小为512bytes…</p>\n<p>Sqlite假设一个sector的写入并不是原子性的,从3.5.0版本开始,sqlite实现了一个新的接口VFS(virtual file system),VFS用来和底层的文件系统交互.VFS接口中有一个方法xDeviceCharacteristics,通过该方法可以获取到底层sector的写入是否是原子性的.如果是,则 <strong>sqlite能够利用该特性做一些写入的优化</strong></p>\n<p>Sqlite假设一个写请求并不会直接落盘而是被操作系统先缓存起来.所以在一些节点需要执行flush或者fsync将数据真正刷新到磁盘.</p>\n<p>Sqlite假设一个文件写入时先更新文件大小然后写入具体内容,<strong>因此Sqlite做了一些额外的工作去保证在更新文件大小和写入文件内容之间如果发生掉电的话不会导致数据库的损坏</strong>.VFS中的xDeviceCharacteristics函数也能够获取到文件系统是否会首先写入内容然后更新大小（通过SQLITE_IOCAP_SAFE_APPEND这个属性）,如果具有该属性,Sqlite就不需要做额外的一些保护措施,减少磁盘I/O.</p>\n<p><strong>Sqlite假设文件的删除操作是原子性的,即如果删除过程中发生了掉电,机器恢复后要么完全看不到该文件,要么文件是完整的,不会出现删除了部分的情况(注意只是用户视角,即用户进程询问操作系统一个文件是否存在时,操作系统只会给出yes or no,而不会有部分存在的回复)</strong></p>\n<p>Sqlite不会在数据文件中增加冗余信息去校验文件是否损坏.</p>\n<p>Sqlite假设操作系统写入一个范围时不会因为掉电或os crash而改变该范围之外的数据.该功能称为 powersafe overwrite.</p>\n<h3 id=\"单文件的提交\"><a href=\"#单文件的提交\" class=\"headerlink\" title=\"单文件的提交\"></a>单文件的提交</h3><p>首先全局观看sqlite在单文件状态下的原子性保证.后文讨论多文件状态下的原子性保证.</p>\n<h4 id=\"初始状态\"><a href=\"#初始状态\" class=\"headerlink\" title=\"初始状态\"></a>初始状态</h4><p>左边是用户进程的内存空间,中间是操作系统缓存,右边是磁盘存储.每个小框代表一个sector,蓝颜色的sector表明存储的是原始数据.</p>\n<p><img src=\"/img/s0.gif\" alt=\"图0\"></p>\n<h4 id=\"获取一个读锁\"><a href=\"#获取一个读锁\" class=\"headerlink\" title=\"获取一个读锁\"></a>获取一个读锁</h4><p>在写入数据库之前,首先会读取数据.即使是插入数据也得先读取<strong>sqlite_master</strong>获取表的schema和决定将数据存储于哪个位置.</p>\n<p>首先获取一个共享锁,一个数据库文件可以同时有多个共享锁,但是当存在共享锁时,其他连接获取不到写锁.</p>\n<p>注意共享锁存在于操作系统的缓存中,而非磁盘上.因此当操作系统crash或者掉电或者创建共享锁的进程退出时锁会自动释放</p>\n<p><img src=\"/img/s1.gif\" alt=\"图1\"></p>\n<h4 id=\"从数据库文件读取信息\"><a href=\"#从数据库文件读取信息\" class=\"headerlink\" title=\"从数据库文件读取信息\"></a>从数据库文件读取信息</h4><p>获得共享锁后,首先从磁盘读取数据到操作系统的缓存,然后从操作系统缓存到用户空间内存中,</p>\n<p>通常只有部分pages会读取到,本例中我们共有8个page,但只读取了3个.真实场景中可能会有成千上万个pages</p>\n<p><img src=\"/img/s2.gif\" alt=\"图2\"></p>\n<h4 id=\"获取一个reserved-lock\"><a href=\"#获取一个reserved-lock\" class=\"headerlink\" title=\"获取一个reserved lock\"></a>获取一个reserved lock</h4><p>在写入之前首先获取一个reserved lock,注意此时其他连接仍然能够获取shared lock,但不能进一步获取reserved lock,即reserved lock在一个数据库文件中只能有一个存在.</p>\n<p>这个锁存在的意义在于说明有进程即将写入一个数据库文件,但是还没有开始写入.此时其他进程如果也尝试写入的话会失败(因为获取不到reserved lock)</p>\n<p><img src=\"/img/s3.gif\" alt=\"图3\"></p>\n<h4 id=\"创建rollback-journal-file\"><a href=\"#创建rollback-journal-file\" class=\"headerlink\" title=\"创建rollback journal file\"></a>创建rollback journal file</h4><p>在修改数据库文件之前,Sqlite首先创建一个独立的rollback journal file,并且将要修改的pages写入rollback journal file.(<strong>注意是以page为单位写入</strong>)</p>\n<p>rollback journal file中绿色的部分是header,header中会包括数据库文件的原始大小(<strong>即包括多少个page</strong>).每一个page保存到rollback journal中时前边四字节会保存该page的page number.</p>\n<p><img src=\"/img/s4.gif\" alt=\"图4\"></p>\n<p>图4中有两个地方需要注意:</p>\n<ul>\n<li>rollback journal创建之后并没有实际落盘,只是保存在操作系统的缓存中</li>\n<li>rollback journal以page为单位,但每个page前四字节会有一个page number的记录,后四字节有一个checksum</li>\n</ul>\n<h4 id=\"在用户空间修改数据库文件\"><a href=\"#在用户空间修改数据库文件\" class=\"headerlink\" title=\"在用户空间修改数据库文件\"></a>在用户空间修改数据库文件</h4><p><img src=\"/img/s5.gif\" alt=\"图5\"></p>\n<p>修改用户进程空间内的数据库文件,注意不同的用户进程有自己的私有内存空间,因此此时的修改并不影响其他进程的读取操作</p>\n<h4 id=\"将rollback-journal落盘\"><a href=\"#将rollback-journal落盘\" class=\"headerlink\" title=\"将rollback journal落盘\"></a>将rollback journal落盘</h4><p>将rollback journal刷新到磁盘,该步骤是保持原子性很关键的一步,保证即使掉电或者操作系统crash,Sqlite也能恢复到原来的状态.</p>\n<p>(<strong>进行到该步也能看出reserved lock的作用,这种锁是一个中间状态,既能为即将写入做准备,又不影响其他进程的读取操作,提高并行度</strong>)<br><img src=\"/img/s6.gif\" alt=\"图6\"></p>\n<p>该步需要刷两次盘,第一次将rollback journal的内容刷到磁盘,第二次在header中记录第一步中刷到磁盘的page个数,然后将header刷盘</p>\n<h4 id=\"获取排他锁\"><a href=\"#获取排他锁\" class=\"headerlink\" title=\"获取排他锁\"></a>获取排他锁</h4><p><img src=\"/img/s7.gif\" alt=\"图7\"><br>在实际写入数据库文件之前,需要获取一个排他锁.获取过程分两步</p>\n<ul>\n<li>获取一个pending lock</li>\n<li>将pending lock升级为排他锁</li>\n</ul>\n<p>获取到pending lock之后,在数据库文件上已经获取到共享锁的进程可以继续读取,但不允许其他进程继续获取共享锁.该锁存在的意义在于防止write starvation(即有大量的读取连接时,一直有新的共享锁产生,导致获取不到排他锁).当所有已经存在的共享锁都释放后,此时该pending lock即可以升级为排他锁</p>\n<h4 id=\"写入数据库文件\"><a href=\"#写入数据库文件\" class=\"headerlink\" title=\"写入数据库文件\"></a>写入数据库文件</h4><p><img src=\"/img/s8.gif\" alt=\"图8\"></p>\n<p>获取到排他锁后,说明已经没有其他进程在读取该数据库文件.此时可以安全的写入数据库文件.注意也只是写入操作系统的缓存中,并没有落盘 </p>\n<h4 id=\"数据库文件刷盘\"><a href=\"#数据库文件刷盘\" class=\"headerlink\" title=\"数据库文件刷盘\"></a>数据库文件刷盘</h4><p><img src=\"/img/s9.gif\" alt=\"图9\"></p>\n<p>此时将数据库文件刷新到磁盘.</p>\n<h4 id=\"删除rollback-journal\"><a href=\"#删除rollback-journal\" class=\"headerlink\" title=\"删除rollback journal\"></a>删除rollback journal</h4><p><img src=\"/img/s10.gif\" alt=\"图10\"></p>\n<p>因为数据库文件已经安全落盘,此时可以删除掉rollback journal.若删除之前系统crash或者掉电,则重启后会恢复到事务开始前的状态,如果删除之后系统crash或者掉电,因为数据库文件已经落盘,相当于事务已经执行完成.(<strong>那么会不会在删除一半时系统crash或者掉电呢?注意上文中关于硬件的一些假设,删除操作必须是原子性的,即不会发生这种情况</strong>)</p>\n<p>因为删除一个文件也是一个耗时的操作,因此Sqlite提供了两种方式减少删除过程的耗时.</p>\n<ul>\n<li>将一个文件truncate为0</li>\n<li>将journal file header清0.清0操作并不是原子性的,但只要header中有一个byte被清0,该文件就会被识别为无效的格式</li>\n</ul>\n<h4 id=\"释放锁\"><a href=\"#释放锁\" class=\"headerlink\" title=\"释放锁\"></a>释放锁</h4><p><img src=\"/img/s11.gif\" alt=\"图11\"></p>\n<p>此时可以释放掉排他锁.</p>\n<p>注意图11中的用户空间缓存也已经被清除.但新版本的Sqlite并不会清除用户空间缓存,以免下一个事务开启式需要重新读取该数据.但在复用该缓存信息时需要首先获取一个共享锁然后检测是否在当前事务开启之前有其他事务已经修改过数据库文件.如果已经修改过则不能复用.检测修改的逻辑也很简单,数据库文件的第一个页中保存了一个计数器,通过比较该计数器即可知道是否发生过修改</p>\n<h3 id=\"回滚\"><a href=\"#回滚\" class=\"headerlink\" title=\"回滚\"></a>回滚</h3><h4 id=\"出错时\"><a href=\"#出错时\" class=\"headerlink\" title=\"出错时\"></a>出错时</h4><p><img src=\"/img/sr0.gif\" alt=\"图12\"></p>\n<p>假设将数据库文件刷盘时掉电,会出现图12所示的情况.我们本来需要修改三个page,但这时只修改成功一个page,另一个page只写了一部分,而第三部分还没开始写</p>\n<p>注意此时rollback journal已经安全落盘但还没删除</p>\n<h4 id=\"hot-rollback-journal\"><a href=\"#hot-rollback-journal\" class=\"headerlink\" title=\"hot rollback journal\"></a>hot rollback journal</h4><p><img src=\"/img/sr1.gif\" alt=\"图13\"></p>\n<p>掉电或操作系统crash恢复后,Sqlite会首先获取一个共享锁,然后检测是否有hot rollback journal存在.注意hot rollback journal只有在一个事务没有提交完成时存在.那么如何检测是否是一个hot rollback journal呢,我们通过检测如下几点来决定:</p>\n<ul>\n<li>rollback journal file存在</li>\n<li>rollback journal file不为空</li>\n<li>rollback journal file header格式正确,即没有被清0</li>\n<li>rollback journal file 指定位置没有master journal file的名称,或者如果有一个master journal的名称并且这个master journal也存在(后文叙述,涉及到多文件的事务)</li>\n</ul>\n<p>一个hot journal的存在说明数据库处于一个不一致的状态.在读取之前需要先进行修复</p>\n<h4 id=\"获取排他锁-1\"><a href=\"#获取排他锁-1\" class=\"headerlink\" title=\"获取排他锁\"></a>获取排他锁</h4><p><img src=\"/img/sr2.gif\" alt=\"图14\"></p>\n<p>进行数据库恢复之前先获取一个排他锁.防止多个进程同时修复一个数据库文件.</p>\n<p>(<strong>注意此时不需要先获取reserved lock或者pending lock,此时需要立刻进行修复,不需要考虑其他进程的读取.但假设此时有其他进程持有shared lock,会直接获取到排他锁还是会等待shared lock失效?猜测应该为前者</strong>)</p>\n<h4 id=\"回滚-1\"><a href=\"#回滚-1\" class=\"headerlink\" title=\"回滚\"></a>回滚</h4><p><img src=\"/img/sr3.gif\" alt=\"图15\"><br>获取到排他锁后可以开始执行恢复.分两步:</p>\n<ul>\n<li>将rollback journal中的相应page写回到database file</li>\n<li>rollback journal中有记录database file的原始大小,将database file truncate 到原始大小.</li>\n</ul>\n<p>此时数据库内容和大小都会恢复到原始状态</p>\n<h4 id=\"删除hot-journal\"><a href=\"#删除hot-journal\" class=\"headerlink\" title=\"删除hot journal\"></a>删除hot journal</h4><p><img src=\"/img/sr4.gif\" alt=\"图16\"></p>\n<p>当数据库文件恢复并且落盘后,可以清除掉hot journal</p>\n<h4 id=\"继续读取\"><a href=\"#继续读取\" class=\"headerlink\" title=\"继续读取\"></a>继续读取</h4><p><img src=\"/img/sr5.gif\" alt=\"图17\"></p>\n<p>将排他锁降级为共享锁.此时崩溃的事务好像没有发生过一样</p>\n<h3 id=\"多文件事务\"><a href=\"#多文件事务\" class=\"headerlink\" title=\"多文件事务\"></a>多文件事务</h3><p>Sqlite允许一个数据库连接中通过attach database命令同时操作多个数据库文件.当多文件在一个事务中修改时,Sqlite保证其原子性.即要么所有文件中都更新成功,要么所有文件都不更新.</p>\n<h4 id=\"每个文件都有单独的rollback-journal\"><a href=\"#每个文件都有单独的rollback-journal\" class=\"headerlink\" title=\"每个文件都有单独的rollback journal\"></a>每个文件都有单独的rollback journal</h4><p><img src=\"/img/sm0.gif\" alt=\"图18\"></p>\n<p>图中每个文件有单独的reserverd lock和rollback journal,类似单文件情形.但此时rollback journal 并没有刷盘,数据库文件也没有更新 </p>\n<h4 id=\"master-journal-file\"><a href=\"#master-journal-file\" class=\"headerlink\" title=\"master journal file\"></a>master journal file</h4><p><img src=\"/img/sm1.gif\" alt=\"图19\"></p>\n<p>下一步需要创建一个master journal file.文件名称仍然是使用sqlite3_open打开的原始数据库文件名称,但会增加一个-mjHHHHHHHH的后缀,HHHHHHHH是一个随机的32bit十六进制数字.每个master journal的的随机后缀都不相同</p>\n<p>master journal中并不保证数据库文件的原始内容,保存的是每一个rollback journal的完整路径和名称</p>\n<p>master journal创建完成后需要直接刷盘(<strong>在Unix系统中,包括该master journal的目录也需要刷盘</strong>)</p>\n<p>master journal的存在是为了保证多文件事务的原子性.但如果Sqlite中设置了pragma synchronous=off 或者 pragma mode=memory,则并不会创建master journal.当然在此配置下也不能保证完整性</p>\n<h4 id=\"更新rollback-journal的header\"><a href=\"#更新rollback-journal的header\" class=\"headerlink\" title=\"更新rollback journal的header\"></a>更新rollback journal的header</h4><p><img src=\"/img/sm2.gif\" alt=\"图20\"></p>\n<p>更新每一个rollback journal的header,将master journal的完整路径及名称写入rollback journal的header（单文件事务中该字段为空）.在更新header之前和之后都需要将rollback journal进行刷盘(<strong>此处类似单文件事务中刷新纪录之后再刷新纪录的计数,Sqlite需要确保在header写入成功之前content已经写入成功</strong>).</p>\n<h4 id=\"更新数据库文件\"><a href=\"#更新数据库文件\" class=\"headerlink\" title=\"更新数据库文件\"></a>更新数据库文件</h4><p><img src=\"/img/sm3.gif\" alt=\"图21\"></p>\n<p>在每个数据库文件都获取到排他锁之后更新数据库文件并且刷盘</p>\n<h4 id=\"删除master-journal-file\"><a href=\"#删除master-journal-file\" class=\"headerlink\" title=\"删除master journal file\"></a>删除master journal file</h4><p><img src=\"/img/sm4.gif\" alt=\"图22\"></p>\n<p>此时可以删除master journal file.如果此时发生了掉电或者操作系统crash,根据之前hot journal的认定规则,此时也不会进行回滚,虽然仍然存在各个数据库文件的rollback journal.</p>\n<h4 id=\"清除rollback-journal-file\"><a href=\"#清除rollback-journal-file\" class=\"headerlink\" title=\"清除rollback journal file\"></a>清除rollback journal file</h4><p><img src=\"/img/sm5.gif\" alt=\"图23\"><br>删除rollback journal并且释放排他锁.</p>\n<h3 id=\"其他commit时的细节\"><a href=\"#其他commit时的细节\" class=\"headerlink\" title=\"其他commit时的细节\"></a>其他commit时的细节</h3><h4 id=\"page和sector\"><a href=\"#page和sector\" class=\"headerlink\" title=\"page和sector\"></a>page和sector</h4><p>Sqlite写入rollback journal时必须是按sector大小的整数倍写入.sector在大部分情况下为512bytes,page为4096bytes,此时按page写入没有什么问题.<br>但是如果sector为4096bytes,而page为512bytes,此时即使只修改一个page,也会将该page属于的sector整个写入rollback journal.</p>\n<h4 id=\"处理journal中的垃圾内容\"><a href=\"#处理journal中的垃圾内容\" class=\"headerlink\" title=\"处理journal中的垃圾内容\"></a>处理journal中的垃圾内容</h4><p>前文中提到过Sqlite的一些硬件假设,其中一条为文件首先扩充大小然后将真正的内容写入.如果文件扩充大小之后,写入真正内容之前发生了掉电,此时journal中会包含一些垃圾信息,此时rollback会将垃圾信息也写入数据库文件,从而发生错误.</p>\n<p>为此Sqlite做了一些保护性措施,其一为在rollback journal的header中记录该rollback journal包括的page的个数,并且初始化为0.只有当真正的内容刷盘之后,会将header中的记录个数更新并且刷盘.注意header不论大小都会占用一个sector的大小,因此可以独立刷新,不影响journal的内容.</p>\n<p>Sqlite默认是如下配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA synchronous=FULL;</span><br></pre></td></tr></table></figure></p>\n<p>如果修改该配置的值为NORMAL以下,则Sqlite对journal的刷盘流程修改为只刷新一次.如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">write content -&gt; write header -&gt;flush</span><br></pre></td></tr></table></figure></p>\n<p>虽然header的写入仍然在content之后,但不保证操作系统实际刷新时可能会先刷新header,再刷新content.因此sqlite在每个rollback journal content的page内容之后附加了4字节的checksum.即rollback journal的格式如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| header | pgno|page content|checksum|pano|page content|checksum|</span><br></pre></td></tr></table></figure></p>\n<p>rollback时会检查每个page content的checksum是否正确,如果不正确则放弃该次rollback.</p>\n<h4 id=\"cache-spill\"><a href=\"#cache-spill\" class=\"headerlink\" title=\"cache spill\"></a>cache spill</h4><p>当大量的更新导致用户空间的缓存不足以保存所有需要更新的page时会有cache spill的情况发生.<br>cache spill首先刷新journal file到磁盘,然后获取一个排他锁, 然后写入数据库更新.此时因为更新还没有全部完成,需要在追加一个header到journal file,循环执行如上三个步骤(第二步获取排他锁因为已经完成,实际上不需要再次获取),直到所有更新完成.因为cache spill会增加占用排他锁的时间并且会有更多的io,会严重影响性能.因此应该尽量避免cache spill</p>\n<h3 id=\"优化措施\"><a href=\"#优化措施\" class=\"headerlink\" title=\"优化措施\"></a>优化措施</h3><p>Sqlite耗时大部分在io上, 因此本节主要考虑如何在保证原子性的前提下能够降低io</p>\n<h4 id=\"事务之间的缓存保存\"><a href=\"#事务之间的缓存保存\" class=\"headerlink\" title=\"事务之间的缓存保存\"></a>事务之间的缓存保存</h4><p>上文也提到过,在数据库文件的database file第一个page的24-27字节有一个counter字段,每次数据库发生更改之后都会更新该字段.因此sqlite在一个事务执行完成需要释放锁时,会首先获取该字段的值,当下一个事务获取锁之后会比较之前缓存的counter值和当前的counter值,据此决定是否可以复用该缓存</p>\n<h4 id=\"排他性访问模式\"><a href=\"#排他性访问模式\" class=\"headerlink\" title=\"排他性访问模式\"></a>排他性访问模式</h4><p>适合于单进程访问的情况,不详述</p>\n<h4 id=\"freelist-page不写入journal\"><a href=\"#freelist-page不写入journal\" class=\"headerlink\" title=\"freelist page不写入journal\"></a>freelist page不写入journal</h4><p>当Sqlite删除一些数据后,只保存删除信息的page会放入freelist.后续的写入会首先从freelist中获取可用的page而不用增加数据库文件的大小</p>\n<p>Sqlite中的freelist有两种类型,trunk page和leaf page.leaf page不包含任何有用的信息.因此如果Sqlite的修改涉及到leaf page,leaf page不需要写入journal(因为leaf page中没有任何有用信息).该步能够降低io</p>\n<h4 id=\"单页修改以及原子性的sector写入\"><a href=\"#单页修改以及原子性的sector写入\" class=\"headerlink\" title=\"单页修改以及原子性的sector写入\"></a>单页修改以及原子性的sector写入</h4><p>如果一个磁盘支持ector的原子性写入并且page大小等于sector,并且一次修改只涉及到一个page.那么此时会直接写database file而不用journal.</p>\n<h4 id=\"safe-append\"><a href=\"#safe-append\" class=\"headerlink\" title=\"safe append\"></a>safe append</h4><p>如果一个磁盘支持safe append,那么journal file的header部分写入的page records数量永远为-1,不需要二次刷盘.实际记录由journal的size大小计算得出.并且发生cache spill时也不需要在与原来的\bjournal后边追加header.直接追加content即可</p>\n<h4 id=\"持久化rollback-journal\"><a href=\"#持久化rollback-journal\" class=\"headerlink\" title=\"持久化rollback journal\"></a>持久化rollback journal</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=PERSIST;</span><br></pre></td></tr></table></figure>\n<p>当配置此项之后,commit事务时不删除journal file,而是将journal file的header清0.该方法会节省如下几步:</p>\n<ul>\n<li>不需要更新inode中的journal file文件大小</li>\n<li>不需要处理释放后的磁盘空间</li>\n<li>下一个事务可以直接覆盖该journal file而不是创建或者追加文件内容,覆盖会比追加更快</li>\n<li>不需要更新包括该文件的目录信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=TRUNCATE;</span><br></pre></td></tr></table></figure>\n<p>该模式会将一个文件大小truncate为0.由于不需要更新文件所属目录信息,因此truncate比delete要快.<br>但truncate比persist模式还是会慢,因为覆盖文件要比追加文件快.</p>\n<h3 id=\"测试Sqlite的原子性\"><a href=\"#测试Sqlite的原子性\" class=\"headerlink\" title=\"测试Sqlite的原子性\"></a>测试Sqlite的原子性</h3><p>因为Sqlite开发者使用了大量的自动化的密集的’crash tests’模拟Sqlite在掉电或者系统crash时后的恢复情况,所以对Sqlite的可靠性很有信心.</p>\n<p>Sqlite的’crash tests’使用一个修改过的vfs模拟系统crash或者掉电后的文件系统损坏.例如sector只写了一部分,写操作未完成导致pages中有垃圾信息,写操作乱序等等不同的节点.通过模拟不同的场景一遍遍测试Sqlite事务,验证其最终是否能够保持原子性.</p>\n<p>‘crash tests’已经发现了许多Sqlite恢复机制中的微妙的bug(都已经修复),这些bug光靠代码分析和审查是很难发现的.(总之是Sqlite开发者对Sqlite的原子性保证很有信心)</p>\n<h3 id=\"可能发生问题的一些情况\"><a href=\"#可能发生问题的一些情况\" class=\"headerlink\" title=\"可能发生问题的一些情况\"></a>可能发生问题的一些情况</h3><h4 id=\"锁的实现\"><a href=\"#锁的实现\" class=\"headerlink\" title=\"锁的实现\"></a>锁的实现</h4><p>Sqlite使用文件系统锁去保证同时只有一个进程或者连接操作数据库文件.文件系统锁在VFS层实现并且不同的操作系统有不同的实现方法.如果文件系统锁实现的有问题导致同时有多个进程或连接修改同一个数据库文件就会发生严重的损坏.</p>\n<p>….(举例说明NFS这种网络文件系统就可能会导致发生损坏)</p>\n<h4 id=\"刷盘的实现\"><a href=\"#刷盘的实现\" class=\"headerlink\" title=\"刷盘的实现\"></a>刷盘的实现</h4><p>Sqlite在Unix使用fsync,windows使用FlushFileBuffers去刷盘,但是这两个函数在许多系统上可能并不可靠.例如我们收到反馈说Windows可以使用注册表禁用禁用掉FlushFileBuffers,一些老的Linux版本的fsync在有些文件系统下不执行任何操作.即使fsync和FlushFileBuffers能够正常工作,一些IDE磁盘执行之后也只是把数据保存在控制器缓存中而不是真正落盘.</p>\n<p>….(Mac相关的配置…)</p>\n<h4 id=\"文件删除操作不保证原子性\"><a href=\"#文件删除操作不保证原子性\" class=\"headerlink\" title=\"文件删除操作不保证原子性\"></a>文件删除操作不保证原子性</h4><p>文件删除操作从应用视角看需要保持原子性,即删除部分数据后掉电的话应用要么完全看不到该文件要么需要看到一个完整的文件,不能只看到删了部分的文件(rollback journal如果只删了一半,会执行恢复操作,但是因为journal已经不完整了,恢复的数据也会不完整)</p>\n<h4 id=\"文件中有垃圾数据\"><a href=\"#文件中有垃圾数据\" class=\"headerlink\" title=\"文件中有垃圾数据\"></a>文件中有垃圾数据</h4><p>Sqlite的数据库文件就是一个普通的磁盘文件,如果文件中被其他进程写入垃圾数据,或者其他原因导致垃圾数据产生,会导致数据库文件不可用</p>\n<h4 id=\"删除或者重命名一个journal-file\"><a href=\"#删除或者重命名一个journal-file\" class=\"headerlink\" title=\"删除或者重命名一个journal file\"></a>删除或者重命名一个journal file</h4><p>journal file和数据库文件的命名有一定的关系,如果数据库文件或者journal file的名字被修改了,会导致没法roll back.</p>\n<p>(举了一些可能的例子….)<br>Sqlite将journal file刷盘的同时也会刷新journal file所在的目录,以免修改名称然后掉电导致重启后找不到该文件…</p>\n<h3 id=\"未来的一些方向和结论\"><a href=\"#未来的一些方向和结论\" class=\"headerlink\" title=\"未来的一些方向和结论\"></a>未来的一些方向和结论</h3><p>虽然Sqlite保证原子性的这个机制bug越来越少,但最好还是保持警惕,发现问题后Sqlite开发者会尽快修改.</p>\n<p>Sqlite开发者也在尽量优化提交过程.现在Sqlite都会对操作系统的VFS实现做一些悲观的假设,然后从Sqlite层面去保证正确性.例如现今许多现代的操作系统都能保证safe append和原子性的sector write,但这些功能必须很确定之后, 我们才会从Sqlite层面减少对这些功能做的一些正确性保证.</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>这个文章序列关注Sqlite的原子性实现.首先翻译一篇官方文章,介绍Sqlite的 rollback journal,然后结合一些问题通过源码分析一下具体实现.后续几篇关注Sqlite3.7.0之后的另一种保证原子性的实现 WAL(write ahead log).<br>注意Sqlite以静态或者动态库的形式提供给程序调用,并不是C/S模式.另外,Sqlite每个库都保存在一个单独的文件之中.通过attch命令能够将其他文件中的库引入.</p>\n</blockquote>\n<h2 id=\"Sqlite如何实现ACID中的原子性\"><a href=\"#Sqlite如何实现ACID中的原子性\" class=\"headerlink\" title=\"Sqlite如何实现ACID中的原子性\"></a>Sqlite如何实现ACID中的原子性</h2><p>原文链接:<a href=\"https://www.sqlite.org/atomiccommit.html\" target=\"_blank\" rel=\"noopener\">https://www.sqlite.org/atomiccommit.html</a><br>翻译中有些无关的省略了.具体信息可以参看原文</p>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>关系型数据库需要实现ACID,其中A-Atomic commit,即单个事务中的语句要么全部执行要么一个都不执行.如果在事务的执行过程中操作系统crash或者掉电,事务仍旧能够保证原子性.本篇文章只适用于Sqlite配置为rollback mode的时候.(还有一种保证原子性的模式为开启wal-write ahead log,后文另述)</p>\n<h3 id=\"Sqlite实现中对硬件的一些假设\"><a href=\"#Sqlite实现中对硬件的一些假设\" class=\"headerlink\" title=\"Sqlite实现中对硬件的一些假设\"></a>Sqlite实现中对硬件的一些假设</h3><p>磁盘以sector为单位进行写操作.如果要修改小于一个sector的区域,也得首先把包括待修改区域的整个sector读取出来,修改完毕后再将整个sector写回去.</p>\n<p>传统的机械硬盘读和写都是以一个sector为单位,在ssd中,读的单位要比写单位要小很多.Sqlite只关注最小的写单位,所以本文中sector都是指最小的写单位.</p>\n<p>Sqlite 3.3.14之前默认一个sector的大小为512bytes…</p>\n<p>Sqlite假设一个sector的写入并不是原子性的,从3.5.0版本开始,sqlite实现了一个新的接口VFS(virtual file system),VFS用来和底层的文件系统交互.VFS接口中有一个方法xDeviceCharacteristics,通过该方法可以获取到底层sector的写入是否是原子性的.如果是,则 <strong>sqlite能够利用该特性做一些写入的优化</strong></p>\n<p>Sqlite假设一个写请求并不会直接落盘而是被操作系统先缓存起来.所以在一些节点需要执行flush或者fsync将数据真正刷新到磁盘.</p>\n<p>Sqlite假设一个文件写入时先更新文件大小然后写入具体内容,<strong>因此Sqlite做了一些额外的工作去保证在更新文件大小和写入文件内容之间如果发生掉电的话不会导致数据库的损坏</strong>.VFS中的xDeviceCharacteristics函数也能够获取到文件系统是否会首先写入内容然后更新大小（通过SQLITE_IOCAP_SAFE_APPEND这个属性）,如果具有该属性,Sqlite就不需要做额外的一些保护措施,减少磁盘I/O.</p>\n<p><strong>Sqlite假设文件的删除操作是原子性的,即如果删除过程中发生了掉电,机器恢复后要么完全看不到该文件,要么文件是完整的,不会出现删除了部分的情况(注意只是用户视角,即用户进程询问操作系统一个文件是否存在时,操作系统只会给出yes or no,而不会有部分存在的回复)</strong></p>\n<p>Sqlite不会在数据文件中增加冗余信息去校验文件是否损坏.</p>\n<p>Sqlite假设操作系统写入一个范围时不会因为掉电或os crash而改变该范围之外的数据.该功能称为 powersafe overwrite.</p>\n<h3 id=\"单文件的提交\"><a href=\"#单文件的提交\" class=\"headerlink\" title=\"单文件的提交\"></a>单文件的提交</h3><p>首先全局观看sqlite在单文件状态下的原子性保证.后文讨论多文件状态下的原子性保证.</p>\n<h4 id=\"初始状态\"><a href=\"#初始状态\" class=\"headerlink\" title=\"初始状态\"></a>初始状态</h4><p>左边是用户进程的内存空间,中间是操作系统缓存,右边是磁盘存储.每个小框代表一个sector,蓝颜色的sector表明存储的是原始数据.</p>\n<p><img src=\"/img/s0.gif\" alt=\"图0\"></p>\n<h4 id=\"获取一个读锁\"><a href=\"#获取一个读锁\" class=\"headerlink\" title=\"获取一个读锁\"></a>获取一个读锁</h4><p>在写入数据库之前,首先会读取数据.即使是插入数据也得先读取<strong>sqlite_master</strong>获取表的schema和决定将数据存储于哪个位置.</p>\n<p>首先获取一个共享锁,一个数据库文件可以同时有多个共享锁,但是当存在共享锁时,其他连接获取不到写锁.</p>\n<p>注意共享锁存在于操作系统的缓存中,而非磁盘上.因此当操作系统crash或者掉电或者创建共享锁的进程退出时锁会自动释放</p>\n<p><img src=\"/img/s1.gif\" alt=\"图1\"></p>\n<h4 id=\"从数据库文件读取信息\"><a href=\"#从数据库文件读取信息\" class=\"headerlink\" title=\"从数据库文件读取信息\"></a>从数据库文件读取信息</h4><p>获得共享锁后,首先从磁盘读取数据到操作系统的缓存,然后从操作系统缓存到用户空间内存中,</p>\n<p>通常只有部分pages会读取到,本例中我们共有8个page,但只读取了3个.真实场景中可能会有成千上万个pages</p>\n<p><img src=\"/img/s2.gif\" alt=\"图2\"></p>\n<h4 id=\"获取一个reserved-lock\"><a href=\"#获取一个reserved-lock\" class=\"headerlink\" title=\"获取一个reserved lock\"></a>获取一个reserved lock</h4><p>在写入之前首先获取一个reserved lock,注意此时其他连接仍然能够获取shared lock,但不能进一步获取reserved lock,即reserved lock在一个数据库文件中只能有一个存在.</p>\n<p>这个锁存在的意义在于说明有进程即将写入一个数据库文件,但是还没有开始写入.此时其他进程如果也尝试写入的话会失败(因为获取不到reserved lock)</p>\n<p><img src=\"/img/s3.gif\" alt=\"图3\"></p>\n<h4 id=\"创建rollback-journal-file\"><a href=\"#创建rollback-journal-file\" class=\"headerlink\" title=\"创建rollback journal file\"></a>创建rollback journal file</h4><p>在修改数据库文件之前,Sqlite首先创建一个独立的rollback journal file,并且将要修改的pages写入rollback journal file.(<strong>注意是以page为单位写入</strong>)</p>\n<p>rollback journal file中绿色的部分是header,header中会包括数据库文件的原始大小(<strong>即包括多少个page</strong>).每一个page保存到rollback journal中时前边四字节会保存该page的page number.</p>\n<p><img src=\"/img/s4.gif\" alt=\"图4\"></p>\n<p>图4中有两个地方需要注意:</p>\n<ul>\n<li>rollback journal创建之后并没有实际落盘,只是保存在操作系统的缓存中</li>\n<li>rollback journal以page为单位,但每个page前四字节会有一个page number的记录,后四字节有一个checksum</li>\n</ul>\n<h4 id=\"在用户空间修改数据库文件\"><a href=\"#在用户空间修改数据库文件\" class=\"headerlink\" title=\"在用户空间修改数据库文件\"></a>在用户空间修改数据库文件</h4><p><img src=\"/img/s5.gif\" alt=\"图5\"></p>\n<p>修改用户进程空间内的数据库文件,注意不同的用户进程有自己的私有内存空间,因此此时的修改并不影响其他进程的读取操作</p>\n<h4 id=\"将rollback-journal落盘\"><a href=\"#将rollback-journal落盘\" class=\"headerlink\" title=\"将rollback journal落盘\"></a>将rollback journal落盘</h4><p>将rollback journal刷新到磁盘,该步骤是保持原子性很关键的一步,保证即使掉电或者操作系统crash,Sqlite也能恢复到原来的状态.</p>\n<p>(<strong>进行到该步也能看出reserved lock的作用,这种锁是一个中间状态,既能为即将写入做准备,又不影响其他进程的读取操作,提高并行度</strong>)<br><img src=\"/img/s6.gif\" alt=\"图6\"></p>\n<p>该步需要刷两次盘,第一次将rollback journal的内容刷到磁盘,第二次在header中记录第一步中刷到磁盘的page个数,然后将header刷盘</p>\n<h4 id=\"获取排他锁\"><a href=\"#获取排他锁\" class=\"headerlink\" title=\"获取排他锁\"></a>获取排他锁</h4><p><img src=\"/img/s7.gif\" alt=\"图7\"><br>在实际写入数据库文件之前,需要获取一个排他锁.获取过程分两步</p>\n<ul>\n<li>获取一个pending lock</li>\n<li>将pending lock升级为排他锁</li>\n</ul>\n<p>获取到pending lock之后,在数据库文件上已经获取到共享锁的进程可以继续读取,但不允许其他进程继续获取共享锁.该锁存在的意义在于防止write starvation(即有大量的读取连接时,一直有新的共享锁产生,导致获取不到排他锁).当所有已经存在的共享锁都释放后,此时该pending lock即可以升级为排他锁</p>\n<h4 id=\"写入数据库文件\"><a href=\"#写入数据库文件\" class=\"headerlink\" title=\"写入数据库文件\"></a>写入数据库文件</h4><p><img src=\"/img/s8.gif\" alt=\"图8\"></p>\n<p>获取到排他锁后,说明已经没有其他进程在读取该数据库文件.此时可以安全的写入数据库文件.注意也只是写入操作系统的缓存中,并没有落盘 </p>\n<h4 id=\"数据库文件刷盘\"><a href=\"#数据库文件刷盘\" class=\"headerlink\" title=\"数据库文件刷盘\"></a>数据库文件刷盘</h4><p><img src=\"/img/s9.gif\" alt=\"图9\"></p>\n<p>此时将数据库文件刷新到磁盘.</p>\n<h4 id=\"删除rollback-journal\"><a href=\"#删除rollback-journal\" class=\"headerlink\" title=\"删除rollback journal\"></a>删除rollback journal</h4><p><img src=\"/img/s10.gif\" alt=\"图10\"></p>\n<p>因为数据库文件已经安全落盘,此时可以删除掉rollback journal.若删除之前系统crash或者掉电,则重启后会恢复到事务开始前的状态,如果删除之后系统crash或者掉电,因为数据库文件已经落盘,相当于事务已经执行完成.(<strong>那么会不会在删除一半时系统crash或者掉电呢?注意上文中关于硬件的一些假设,删除操作必须是原子性的,即不会发生这种情况</strong>)</p>\n<p>因为删除一个文件也是一个耗时的操作,因此Sqlite提供了两种方式减少删除过程的耗时.</p>\n<ul>\n<li>将一个文件truncate为0</li>\n<li>将journal file header清0.清0操作并不是原子性的,但只要header中有一个byte被清0,该文件就会被识别为无效的格式</li>\n</ul>\n<h4 id=\"释放锁\"><a href=\"#释放锁\" class=\"headerlink\" title=\"释放锁\"></a>释放锁</h4><p><img src=\"/img/s11.gif\" alt=\"图11\"></p>\n<p>此时可以释放掉排他锁.</p>\n<p>注意图11中的用户空间缓存也已经被清除.但新版本的Sqlite并不会清除用户空间缓存,以免下一个事务开启式需要重新读取该数据.但在复用该缓存信息时需要首先获取一个共享锁然后检测是否在当前事务开启之前有其他事务已经修改过数据库文件.如果已经修改过则不能复用.检测修改的逻辑也很简单,数据库文件的第一个页中保存了一个计数器,通过比较该计数器即可知道是否发生过修改</p>\n<h3 id=\"回滚\"><a href=\"#回滚\" class=\"headerlink\" title=\"回滚\"></a>回滚</h3><h4 id=\"出错时\"><a href=\"#出错时\" class=\"headerlink\" title=\"出错时\"></a>出错时</h4><p><img src=\"/img/sr0.gif\" alt=\"图12\"></p>\n<p>假设将数据库文件刷盘时掉电,会出现图12所示的情况.我们本来需要修改三个page,但这时只修改成功一个page,另一个page只写了一部分,而第三部分还没开始写</p>\n<p>注意此时rollback journal已经安全落盘但还没删除</p>\n<h4 id=\"hot-rollback-journal\"><a href=\"#hot-rollback-journal\" class=\"headerlink\" title=\"hot rollback journal\"></a>hot rollback journal</h4><p><img src=\"/img/sr1.gif\" alt=\"图13\"></p>\n<p>掉电或操作系统crash恢复后,Sqlite会首先获取一个共享锁,然后检测是否有hot rollback journal存在.注意hot rollback journal只有在一个事务没有提交完成时存在.那么如何检测是否是一个hot rollback journal呢,我们通过检测如下几点来决定:</p>\n<ul>\n<li>rollback journal file存在</li>\n<li>rollback journal file不为空</li>\n<li>rollback journal file header格式正确,即没有被清0</li>\n<li>rollback journal file 指定位置没有master journal file的名称,或者如果有一个master journal的名称并且这个master journal也存在(后文叙述,涉及到多文件的事务)</li>\n</ul>\n<p>一个hot journal的存在说明数据库处于一个不一致的状态.在读取之前需要先进行修复</p>\n<h4 id=\"获取排他锁-1\"><a href=\"#获取排他锁-1\" class=\"headerlink\" title=\"获取排他锁\"></a>获取排他锁</h4><p><img src=\"/img/sr2.gif\" alt=\"图14\"></p>\n<p>进行数据库恢复之前先获取一个排他锁.防止多个进程同时修复一个数据库文件.</p>\n<p>(<strong>注意此时不需要先获取reserved lock或者pending lock,此时需要立刻进行修复,不需要考虑其他进程的读取.但假设此时有其他进程持有shared lock,会直接获取到排他锁还是会等待shared lock失效?猜测应该为前者</strong>)</p>\n<h4 id=\"回滚-1\"><a href=\"#回滚-1\" class=\"headerlink\" title=\"回滚\"></a>回滚</h4><p><img src=\"/img/sr3.gif\" alt=\"图15\"><br>获取到排他锁后可以开始执行恢复.分两步:</p>\n<ul>\n<li>将rollback journal中的相应page写回到database file</li>\n<li>rollback journal中有记录database file的原始大小,将database file truncate 到原始大小.</li>\n</ul>\n<p>此时数据库内容和大小都会恢复到原始状态</p>\n<h4 id=\"删除hot-journal\"><a href=\"#删除hot-journal\" class=\"headerlink\" title=\"删除hot journal\"></a>删除hot journal</h4><p><img src=\"/img/sr4.gif\" alt=\"图16\"></p>\n<p>当数据库文件恢复并且落盘后,可以清除掉hot journal</p>\n<h4 id=\"继续读取\"><a href=\"#继续读取\" class=\"headerlink\" title=\"继续读取\"></a>继续读取</h4><p><img src=\"/img/sr5.gif\" alt=\"图17\"></p>\n<p>将排他锁降级为共享锁.此时崩溃的事务好像没有发生过一样</p>\n<h3 id=\"多文件事务\"><a href=\"#多文件事务\" class=\"headerlink\" title=\"多文件事务\"></a>多文件事务</h3><p>Sqlite允许一个数据库连接中通过attach database命令同时操作多个数据库文件.当多文件在一个事务中修改时,Sqlite保证其原子性.即要么所有文件中都更新成功,要么所有文件都不更新.</p>\n<h4 id=\"每个文件都有单独的rollback-journal\"><a href=\"#每个文件都有单独的rollback-journal\" class=\"headerlink\" title=\"每个文件都有单独的rollback journal\"></a>每个文件都有单独的rollback journal</h4><p><img src=\"/img/sm0.gif\" alt=\"图18\"></p>\n<p>图中每个文件有单独的reserverd lock和rollback journal,类似单文件情形.但此时rollback journal 并没有刷盘,数据库文件也没有更新 </p>\n<h4 id=\"master-journal-file\"><a href=\"#master-journal-file\" class=\"headerlink\" title=\"master journal file\"></a>master journal file</h4><p><img src=\"/img/sm1.gif\" alt=\"图19\"></p>\n<p>下一步需要创建一个master journal file.文件名称仍然是使用sqlite3_open打开的原始数据库文件名称,但会增加一个-mjHHHHHHHH的后缀,HHHHHHHH是一个随机的32bit十六进制数字.每个master journal的的随机后缀都不相同</p>\n<p>master journal中并不保证数据库文件的原始内容,保存的是每一个rollback journal的完整路径和名称</p>\n<p>master journal创建完成后需要直接刷盘(<strong>在Unix系统中,包括该master journal的目录也需要刷盘</strong>)</p>\n<p>master journal的存在是为了保证多文件事务的原子性.但如果Sqlite中设置了pragma synchronous=off 或者 pragma mode=memory,则并不会创建master journal.当然在此配置下也不能保证完整性</p>\n<h4 id=\"更新rollback-journal的header\"><a href=\"#更新rollback-journal的header\" class=\"headerlink\" title=\"更新rollback journal的header\"></a>更新rollback journal的header</h4><p><img src=\"/img/sm2.gif\" alt=\"图20\"></p>\n<p>更新每一个rollback journal的header,将master journal的完整路径及名称写入rollback journal的header（单文件事务中该字段为空）.在更新header之前和之后都需要将rollback journal进行刷盘(<strong>此处类似单文件事务中刷新纪录之后再刷新纪录的计数,Sqlite需要确保在header写入成功之前content已经写入成功</strong>).</p>\n<h4 id=\"更新数据库文件\"><a href=\"#更新数据库文件\" class=\"headerlink\" title=\"更新数据库文件\"></a>更新数据库文件</h4><p><img src=\"/img/sm3.gif\" alt=\"图21\"></p>\n<p>在每个数据库文件都获取到排他锁之后更新数据库文件并且刷盘</p>\n<h4 id=\"删除master-journal-file\"><a href=\"#删除master-journal-file\" class=\"headerlink\" title=\"删除master journal file\"></a>删除master journal file</h4><p><img src=\"/img/sm4.gif\" alt=\"图22\"></p>\n<p>此时可以删除master journal file.如果此时发生了掉电或者操作系统crash,根据之前hot journal的认定规则,此时也不会进行回滚,虽然仍然存在各个数据库文件的rollback journal.</p>\n<h4 id=\"清除rollback-journal-file\"><a href=\"#清除rollback-journal-file\" class=\"headerlink\" title=\"清除rollback journal file\"></a>清除rollback journal file</h4><p><img src=\"/img/sm5.gif\" alt=\"图23\"><br>删除rollback journal并且释放排他锁.</p>\n<h3 id=\"其他commit时的细节\"><a href=\"#其他commit时的细节\" class=\"headerlink\" title=\"其他commit时的细节\"></a>其他commit时的细节</h3><h4 id=\"page和sector\"><a href=\"#page和sector\" class=\"headerlink\" title=\"page和sector\"></a>page和sector</h4><p>Sqlite写入rollback journal时必须是按sector大小的整数倍写入.sector在大部分情况下为512bytes,page为4096bytes,此时按page写入没有什么问题.<br>但是如果sector为4096bytes,而page为512bytes,此时即使只修改一个page,也会将该page属于的sector整个写入rollback journal.</p>\n<h4 id=\"处理journal中的垃圾内容\"><a href=\"#处理journal中的垃圾内容\" class=\"headerlink\" title=\"处理journal中的垃圾内容\"></a>处理journal中的垃圾内容</h4><p>前文中提到过Sqlite的一些硬件假设,其中一条为文件首先扩充大小然后将真正的内容写入.如果文件扩充大小之后,写入真正内容之前发生了掉电,此时journal中会包含一些垃圾信息,此时rollback会将垃圾信息也写入数据库文件,从而发生错误.</p>\n<p>为此Sqlite做了一些保护性措施,其一为在rollback journal的header中记录该rollback journal包括的page的个数,并且初始化为0.只有当真正的内容刷盘之后,会将header中的记录个数更新并且刷盘.注意header不论大小都会占用一个sector的大小,因此可以独立刷新,不影响journal的内容.</p>\n<p>Sqlite默认是如下配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA synchronous=FULL;</span><br></pre></td></tr></table></figure></p>\n<p>如果修改该配置的值为NORMAL以下,则Sqlite对journal的刷盘流程修改为只刷新一次.如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">write content -&gt; write header -&gt;flush</span><br></pre></td></tr></table></figure></p>\n<p>虽然header的写入仍然在content之后,但不保证操作系统实际刷新时可能会先刷新header,再刷新content.因此sqlite在每个rollback journal content的page内容之后附加了4字节的checksum.即rollback journal的格式如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| header | pgno|page content|checksum|pano|page content|checksum|</span><br></pre></td></tr></table></figure></p>\n<p>rollback时会检查每个page content的checksum是否正确,如果不正确则放弃该次rollback.</p>\n<h4 id=\"cache-spill\"><a href=\"#cache-spill\" class=\"headerlink\" title=\"cache spill\"></a>cache spill</h4><p>当大量的更新导致用户空间的缓存不足以保存所有需要更新的page时会有cache spill的情况发生.<br>cache spill首先刷新journal file到磁盘,然后获取一个排他锁, 然后写入数据库更新.此时因为更新还没有全部完成,需要在追加一个header到journal file,循环执行如上三个步骤(第二步获取排他锁因为已经完成,实际上不需要再次获取),直到所有更新完成.因为cache spill会增加占用排他锁的时间并且会有更多的io,会严重影响性能.因此应该尽量避免cache spill</p>\n<h3 id=\"优化措施\"><a href=\"#优化措施\" class=\"headerlink\" title=\"优化措施\"></a>优化措施</h3><p>Sqlite耗时大部分在io上, 因此本节主要考虑如何在保证原子性的前提下能够降低io</p>\n<h4 id=\"事务之间的缓存保存\"><a href=\"#事务之间的缓存保存\" class=\"headerlink\" title=\"事务之间的缓存保存\"></a>事务之间的缓存保存</h4><p>上文也提到过,在数据库文件的database file第一个page的24-27字节有一个counter字段,每次数据库发生更改之后都会更新该字段.因此sqlite在一个事务执行完成需要释放锁时,会首先获取该字段的值,当下一个事务获取锁之后会比较之前缓存的counter值和当前的counter值,据此决定是否可以复用该缓存</p>\n<h4 id=\"排他性访问模式\"><a href=\"#排他性访问模式\" class=\"headerlink\" title=\"排他性访问模式\"></a>排他性访问模式</h4><p>适合于单进程访问的情况,不详述</p>\n<h4 id=\"freelist-page不写入journal\"><a href=\"#freelist-page不写入journal\" class=\"headerlink\" title=\"freelist page不写入journal\"></a>freelist page不写入journal</h4><p>当Sqlite删除一些数据后,只保存删除信息的page会放入freelist.后续的写入会首先从freelist中获取可用的page而不用增加数据库文件的大小</p>\n<p>Sqlite中的freelist有两种类型,trunk page和leaf page.leaf page不包含任何有用的信息.因此如果Sqlite的修改涉及到leaf page,leaf page不需要写入journal(因为leaf page中没有任何有用信息).该步能够降低io</p>\n<h4 id=\"单页修改以及原子性的sector写入\"><a href=\"#单页修改以及原子性的sector写入\" class=\"headerlink\" title=\"单页修改以及原子性的sector写入\"></a>单页修改以及原子性的sector写入</h4><p>如果一个磁盘支持ector的原子性写入并且page大小等于sector,并且一次修改只涉及到一个page.那么此时会直接写database file而不用journal.</p>\n<h4 id=\"safe-append\"><a href=\"#safe-append\" class=\"headerlink\" title=\"safe append\"></a>safe append</h4><p>如果一个磁盘支持safe append,那么journal file的header部分写入的page records数量永远为-1,不需要二次刷盘.实际记录由journal的size大小计算得出.并且发生cache spill时也不需要在与原来的\bjournal后边追加header.直接追加content即可</p>\n<h4 id=\"持久化rollback-journal\"><a href=\"#持久化rollback-journal\" class=\"headerlink\" title=\"持久化rollback journal\"></a>持久化rollback journal</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=PERSIST;</span><br></pre></td></tr></table></figure>\n<p>当配置此项之后,commit事务时不删除journal file,而是将journal file的header清0.该方法会节省如下几步:</p>\n<ul>\n<li>不需要更新inode中的journal file文件大小</li>\n<li>不需要处理释放后的磁盘空间</li>\n<li>下一个事务可以直接覆盖该journal file而不是创建或者追加文件内容,覆盖会比追加更快</li>\n<li>不需要更新包括该文件的目录信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PRAGMA journal_mode=TRUNCATE;</span><br></pre></td></tr></table></figure>\n<p>该模式会将一个文件大小truncate为0.由于不需要更新文件所属目录信息,因此truncate比delete要快.<br>但truncate比persist模式还是会慢,因为覆盖文件要比追加文件快.</p>\n<h3 id=\"测试Sqlite的原子性\"><a href=\"#测试Sqlite的原子性\" class=\"headerlink\" title=\"测试Sqlite的原子性\"></a>测试Sqlite的原子性</h3><p>因为Sqlite开发者使用了大量的自动化的密集的’crash tests’模拟Sqlite在掉电或者系统crash时后的恢复情况,所以对Sqlite的可靠性很有信心.</p>\n<p>Sqlite的’crash tests’使用一个修改过的vfs模拟系统crash或者掉电后的文件系统损坏.例如sector只写了一部分,写操作未完成导致pages中有垃圾信息,写操作乱序等等不同的节点.通过模拟不同的场景一遍遍测试Sqlite事务,验证其最终是否能够保持原子性.</p>\n<p>‘crash tests’已经发现了许多Sqlite恢复机制中的微妙的bug(都已经修复),这些bug光靠代码分析和审查是很难发现的.(总之是Sqlite开发者对Sqlite的原子性保证很有信心)</p>\n<h3 id=\"可能发生问题的一些情况\"><a href=\"#可能发生问题的一些情况\" class=\"headerlink\" title=\"可能发生问题的一些情况\"></a>可能发生问题的一些情况</h3><h4 id=\"锁的实现\"><a href=\"#锁的实现\" class=\"headerlink\" title=\"锁的实现\"></a>锁的实现</h4><p>Sqlite使用文件系统锁去保证同时只有一个进程或者连接操作数据库文件.文件系统锁在VFS层实现并且不同的操作系统有不同的实现方法.如果文件系统锁实现的有问题导致同时有多个进程或连接修改同一个数据库文件就会发生严重的损坏.</p>\n<p>….(举例说明NFS这种网络文件系统就可能会导致发生损坏)</p>\n<h4 id=\"刷盘的实现\"><a href=\"#刷盘的实现\" class=\"headerlink\" title=\"刷盘的实现\"></a>刷盘的实现</h4><p>Sqlite在Unix使用fsync,windows使用FlushFileBuffers去刷盘,但是这两个函数在许多系统上可能并不可靠.例如我们收到反馈说Windows可以使用注册表禁用禁用掉FlushFileBuffers,一些老的Linux版本的fsync在有些文件系统下不执行任何操作.即使fsync和FlushFileBuffers能够正常工作,一些IDE磁盘执行之后也只是把数据保存在控制器缓存中而不是真正落盘.</p>\n<p>….(Mac相关的配置…)</p>\n<h4 id=\"文件删除操作不保证原子性\"><a href=\"#文件删除操作不保证原子性\" class=\"headerlink\" title=\"文件删除操作不保证原子性\"></a>文件删除操作不保证原子性</h4><p>文件删除操作从应用视角看需要保持原子性,即删除部分数据后掉电的话应用要么完全看不到该文件要么需要看到一个完整的文件,不能只看到删了部分的文件(rollback journal如果只删了一半,会执行恢复操作,但是因为journal已经不完整了,恢复的数据也会不完整)</p>\n<h4 id=\"文件中有垃圾数据\"><a href=\"#文件中有垃圾数据\" class=\"headerlink\" title=\"文件中有垃圾数据\"></a>文件中有垃圾数据</h4><p>Sqlite的数据库文件就是一个普通的磁盘文件,如果文件中被其他进程写入垃圾数据,或者其他原因导致垃圾数据产生,会导致数据库文件不可用</p>\n<h4 id=\"删除或者重命名一个journal-file\"><a href=\"#删除或者重命名一个journal-file\" class=\"headerlink\" title=\"删除或者重命名一个journal file\"></a>删除或者重命名一个journal file</h4><p>journal file和数据库文件的命名有一定的关系,如果数据库文件或者journal file的名字被修改了,会导致没法roll back.</p>\n<p>(举了一些可能的例子….)<br>Sqlite将journal file刷盘的同时也会刷新journal file所在的目录,以免修改名称然后掉电导致重启后找不到该文件…</p>\n<h3 id=\"未来的一些方向和结论\"><a href=\"#未来的一些方向和结论\" class=\"headerlink\" title=\"未来的一些方向和结论\"></a>未来的一些方向和结论</h3><p>虽然Sqlite保证原子性的这个机制bug越来越少,但最好还是保持警惕,发现问题后Sqlite开发者会尽快修改.</p>\n<p>Sqlite开发者也在尽量优化提交过程.现在Sqlite都会对操作系统的VFS实现做一些悲观的假设,然后从Sqlite层面去保证正确性.例如现今许多现代的操作系统都能保证safe append和原子性的sector write,但这些功能必须很确定之后, 我们才会从Sqlite层面减少对这些功能做的一些正确性保证.</p>\n"},{"title":"Redis有序集合指令学习","date":"2018-07-11T05:21:01.000Z","_content":"## ZADD\nZADD key [NX|XX] [CH] [INCR]score member [score member ...]\n\n将元素及对应分值添加到一个有序集合中\n\nNX:不更新已经存在的key,只增加新元素\n\nXX:只更新已经存在的key,不增加新元素\n\nCH:abbr:changed.不指定时只返回新增的元素个数,指定时返回新增的和更新的元素个数之和\n\nINCR:参考zincrby\n\n```c\n//通过第二个参数区分是zadd还是zincrby\nvoid zaddCommand(client *c) {\n    zaddGenericCommand(c,ZADD_NONE);\n}\n```\n\n```c\n/* This generic command implements both ZADD and ZINCRBY. */\n//zadd和zincrby两个命令都是调用这个函数\nvoid zaddGenericCommand(client *c, int flags) {\n    static char *nanerr = \"resulting score is not a number (NaN)\";\n    robj *key = c->argv[1];\n    robj *zobj;\n    sds ele;\n    double score = 0, *scores = NULL;\n    int j, elements;\n    int scoreidx = 0;\n    /* The following vars are used in order to track what the command actually\n     * did during the execution, to reply to the client and to trigger the\n     * notification of keyspace change. */\n    int added = 0;      /* Number of new elements added. */\n    int updated = 0;    /* Number of elements with updated score. */\n    int processed = 0;  /* Number of elements processed, may remain zero with\n                           options like XX. */\n\n    /* Parse options. At the end 'scoreidx' is set to the argument position\n     * of the score of the first score-element pair. */\n    scoreidx = 2;//从第二个参数开始处理.先处理nx,xx,ch,incr参数\n    while(scoreidx < c->argc) {\n        char *opt = c->argv[scoreidx]->ptr;\n        if (!strcasecmp(opt,\"nx\")) flags |= ZADD_NX;\n        else if (!strcasecmp(opt,\"xx\")) flags |= ZADD_XX;\n        else if (!strcasecmp(opt,\"ch\")) flags |= ZADD_CH;\n        else if (!strcasecmp(opt,\"incr\")) flags |= ZADD_INCR;\n        else break;\n        scoreidx++;\n    }\n\n    /* Turn options into simple to check vars. */\n    //从flag中取出相应的标志赋给独立的变量\n    int incr = (flags & ZADD_INCR) != 0;\n    int nx = (flags & ZADD_NX) != 0;\n    int xx = (flags & ZADD_XX) != 0;\n    int ch = (flags & ZADD_CH) != 0;\n\n    /* After the options, we expect to have an even number of args, since\n     * we expect any number of score-element pairs. */\n    //member和score是一一对应的,所以肯定是2的倍数.所以如果不是2的倍数或者根本\n    //没有member和score,直接返回命令语法错误\n    elements = c->argc-scoreidx;\n    if (elements % 2 || !elements) {\n        addReply(c,shared.syntaxerr);\n        return;\n    }\n    //elements赋值为有多少对<element,score>\n    elements /= 2; /* Now this holds the number of score-element pairs. */\n\n    /* Check for incompatible options. */\n    //nx和xxflag互斥,二者不能同时出现\n    if (nx && xx) {\n        addReplyError(c,\n            \"XX and NX options at the same time are not compatible\");\n        return;\n    }\n    //若有incr标志,则只能有一对<element,score>\n    //为什么不能是多对?\n    if (incr && elements > 1) {\n        addReplyError(c,\n            \"INCR option supports a single increment-element pair\");\n        return;\n    }\n\n    /* Start parsing all the scores, we need to emit any syntax error\n     * before executing additions to the sorted set, as the command should\n     * either execute fully or nothing at all. */\n    //依次检查每一个分数值\n    scores = zmalloc(sizeof(double)*elements);\n    for (j = 0; j < elements; j++) {\n        //该函数中会检查score是否是合法的double类型的值\n        if (getDoubleFromObjectOrReply(c,c->argv[scoreidx+j*2],&scores[j],NULL)\n            != C_OK) goto cleanup;\n    }\n\n    /* Lookup the key and create the sorted set if does not exist. */\n    //根据key查找对应的有序集合的value\n    zobj = lookupKeyWrite(c->db,key);\n    //key不存在\n    if (zobj == NULL) {\n        //如果设置了xx这个flag,直接返回错误\n        if (xx) goto reply_to_client; /* No key + XX option: nothing to do. */\n        //根据redis的配置,如果有序集合设置了不使用ziplist存储或者说第一个插入元素的长度大于\n        //设置的最大ziplist的元素长度值,则使用跳跃表存储否则使用ziplist\n        if (server.zset_max_ziplist_entries == 0 ||\n            server.zset_max_ziplist_value < sdslen(c->argv[scoreidx+1]->ptr))\n        {\n            zobj = createZsetObject();\n        } else {\n            zobj = createZsetZiplistObject();\n        }\n        //把key,zobj插入字典\n        dbAdd(c->db,key,zobj);\n    //key存在\n    } else {\n        //如果不是有序集合,直接返回错误\n        if (zobj->type != OBJ_ZSET) {\n            addReply(c,shared.wrongtypeerr);\n            goto cleanup;\n        }\n    }\n\n    //elements是<member,score>对数\n    for (j = 0; j < elements; j++) {\n        double newscore;\n        score = scores[j];\n        //retflags设置为前文中的flags变量\n        int retflags = flags;\n\n        ele = c->argv[scoreidx+1+j*2]->ptr;\n        //每次遍历,score是分数,ele是member.调用zsetadd插入zobj\n        int retval = zsetAdd(zobj, score, ele, &retflags, &newscore);\n        if (retval == 0) {\n            addReplyError(c,nanerr);\n            goto cleanup;\n        }\n        //根据retflags,即一个元素是更新还是新加入,还是未做处理(即member存在,并且\n        //score值与新设置的一致),更新相应的计数变量(这些变量最后会返回给客户端)\n        if (retflags & ZADD_ADDED) added++;\n        if (retflags & ZADD_UPDATED) updated++;\n        if (!(retflags & ZADD_NOP)) processed++;\n        score = newscore;\n    }\n    server.dirty += (added+updated);\n//通过命令中的flag,返回给客户端不同的值\nreply_to_client:\n    if (incr) { /* ZINCRBY or INCR option. */\n        if (processed)\n            addReplyDouble(c,score);\n        else\n            addReply(c,shared.nullbulk);\n    } else { /* ZADD. */\n        addReplyLongLong(c,ch ? added+updated : added);\n    }\n\n//如果有更新或者新加,需要执行相应的watch key的通知及keyspace的通知\ncleanup:\n    zfree(scores);\n    if (added || updated) {\n        signalModifiedKey(c->db,key);\n        notifyKeyspaceEvent(NOTIFY_ZSET,\n            incr ? \"zincr\" : \"zadd\", key, c->db->id);\n    }\n}\n```\n\n## ZINCRBY \n\nZINCRBY key increment member\n\n如果key存在,就给相应member的score增加increment\n\n否则直接给key设置分数为increment\n\n```c\n\n//与zadd调用同一个函数,相当于zadd key incr,把incr flag置位\nvoid zincrbyCommand(client *c) {\n    zaddGenericCommand(c,ZADD_INCR);\n}\n```\n\n## ZCARD\nZCARD key\n\n返回有序集合的元素个数\n```c\nvoid zcardCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    //查找key对应的value\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //通过zsetLength获取zobj中的元素个数\n    addReplyLongLong(c,zsetLength(zobj));\n}\n```\n\n```c\nunsigned int zsetLength(const robj *zobj) {\n    int length = -1;\n    //如果是ziplist,通过zzlLength函数获取长度\n    //如果长度字段中的值小于UINT16_MAX，直接返回长度。否则需要遍历获取长度\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        length = zzlLength(zobj->ptr);\n    //如果是skiplist,直接返回zsl->length\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        length = ((const zset*)zobj->ptr)->zsl->length;\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return length;\n}\n```\n\n## ZCOUNT\nZCOUNT key min max\n\n返回key中score值在min和max之间的元素个数\n\n其中min和max可以加(,如 zcount key (5 (10 \n\n加左括号表示不包含。不加表示包含\n\n```c\nvoid zcountCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    zrangespec range;\n    int count = 0;\n\n    /* Parse the range arguments */\n    //判定范围.并将最大最小及是否包含写入range结构体中\n    if (zslParseRange(c->argv[2],c->argv[3],&range) != C_OK) {\n        addReplyError(c,\"min or max is not a float\");\n        return;\n    }\n\n    /* Lookup the sorted set */\n    if ((zobj = lookupKeyReadOrReply(c, key, shared.czero)) == NULL ||\n        checkType(c, zobj, OBJ_ZSET)) return;\n    //判断zobj底层编码是ziplist还是skiplist\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n        double score;\n        //找出第一个在范围之内的元素\n        /* Use the first element in range as the starting point */\n        eptr = zzlFirstInRange(zl,&range);\n\n        /* No \"first\" element */\n        if (eptr == NULL) {\n            addReply(c, shared.czero);\n            return;\n        }\n\n        /* First element is in range */\n        //ziplist中member和score是两个entry,并且member之后保存着score\n        //整体顺序是按score从小到大排列,score相同时,按member的字典序排列\n        sptr = ziplistNext(zl,eptr);\n        //所以此处从第一个元素的下一个entry处获取score\n        score = zzlGetScore(sptr);\n        serverAssertWithInfo(c,zobj,zslValueLteMax(score,&range));\n\n        /* Iterate over elements in range */\n        //迭代这个ziplist,如果score满足要求,则count++并且继续迭代,否则跳出\n        //最后会返回count\n        while (eptr) {\n            score = zzlGetScore(sptr);\n\n            /* Abort when the node is no longer in range. */\n            if (!zslValueLteMax(score,&range)) {\n                break;\n            } else {\n                count++;\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        zskiplistNode *zn;\n        unsigned long rank;\n        //如果是跳表,也是先取出第一个元素\n        /* Find first element in range */\n        zn = zslFirstInRange(zsl, &range);\n\n        /* Use rank of first element, if any, to determine preliminary count */\n        if (zn != NULL) {\n            //获取第一个元素的排名\n            rank = zslGetRank(zsl, zn->score, zn->ele);\n            count = (zsl->length - (rank - 1));\n            //如果最大值大于zsl中的最大值,则此count就是要找的个数\n            /* Find last element in range */\n            zn = zslLastInRange(zsl, &range);\n\n            /* Use rank of last element, if any, to determine the actual count */\n            if (zn != NULL) {\n                //如果最大值小于zsl中的最大值，则首先找到最后一个元素的rank\n                rank = zslGetRank(zsl, zn->score, zn->ele);\n                //重新计算count,与之前的计算公式合并之后为\n                //count = (zsl->length-(rankmin-1))-(zsl->length-rankmax))\n                //      = rankmax-rankmin+1\n                count -= (zsl->length - rank);\n            }\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    //返回count\n    addReplyLongLong(c, count);\n}\n```\n\n## ZRANGEBYSCORE\nZRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]\n\n获取有序结合中分值位于 min和max之间的所有元素\n\nwithscores:将member 和 score一起返回 \n\nlimit offset count:从偏移offset开始获取count个元素\n\nmin和max可以为 -inf,+inf,分别表示负无穷和正无穷\n\n```c\n\n//入口函数\nvoid zrangebyscoreCommand(client *c) {\n    genericZrangebyscoreCommand(c,0);\n}\n\n```\n\n```c\n/* This command implements ZRANGEBYSCORE, ZREVRANGEBYSCORE. */\nvoid genericZrangebyscoreCommand(client *c, int reverse) {\n    zrangespec range;\n    robj *key = c->argv[1];\n    robj *zobj;\n    long offset = 0, limit = -1;\n    int withscores = 0;\n    unsigned long rangelen = 0;\n    void *replylen = NULL;\n    int minidx, maxidx;\n    //该函数同时用于zrangbyscore和zrevrangebyscore\n    //二者通过函数中的reverse参数标识\n    //正序时第二个参数是min，第三个参数是max,逆序反之\n    /* Parse the range arguments. */\n    if (reverse) {\n        /* Range is given as [max,min] */\n        maxidx = 2; minidx = 3;\n    } else {\n        /* Range is given as [min,max] */\n        minidx = 2; maxidx = 3;\n    }\n    //将参数解析出来赋值到range变量\n    if (zslParseRange(c->argv[minidx],c->argv[maxidx],&range) != C_OK) {\n        addReplyError(c,\"min or max is not a float\");\n        return;\n    }\n\n    /* Parse optional extra arguments. Note that ZCOUNT will exactly have\n     * 4 arguments, so we'll never enter the following code path. */\n    if (c->argc > 4) {\n        int remaining = c->argc - 4;\n        int pos = 4;\n        //解析withscores和limit参数\n        while (remaining) {\n            if (remaining >= 1 && !strcasecmp(c->argv[pos]->ptr,\"withscores\")) {\n                pos++; remaining--;\n                withscores = 1;\n            } else if (remaining >= 3 && !strcasecmp(c->argv[pos]->ptr,\"limit\")) {\n                if ((getLongFromObjectOrReply(c, c->argv[pos+1], &offset, NULL)\n                        != C_OK) ||\n                    (getLongFromObjectOrReply(c, c->argv[pos+2], &limit, NULL)\n                        != C_OK))\n                {\n                    return;\n                }\n                pos += 3; remaining -= 3;\n            } else {\n                addReply(c,shared.syntaxerr);\n                return;\n            }\n        }\n    }\n\n    /* Ok, lookup the key and get the range */\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.emptymultibulk)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //按zset底层编码是ziplist还是skiplist分别处理\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n        unsigned char *vstr;\n        unsigned int vlen;\n        long long vlong;\n        double score;\n\n        /* If reversed, get the last node in range as starting point. */\n        //按正序还是逆序分别取最后一个值或者第一个值\n        if (reverse) {\n            eptr = zzlLastInRange(zl,&range);\n        } else {\n            eptr = zzlFirstInRange(zl,&range);\n        }\n\n        /* No \"first\" element in the specified interval. */\n        if (eptr == NULL) {\n            addReply(c, shared.emptymultibulk);\n            return;\n        }\n\n        /* Get score pointer for the first element. */\n        serverAssertWithInfo(c,zobj,eptr != NULL);\n        sptr = ziplistNext(zl,eptr);\n\n        /* We don't know in advance how many matching elements there are in the\n         * list, so we push this object that will represent the multi-bulk\n         * length in the output buffer, and will \"fix\" it later */\n        replylen = addDeferredMultiBulkLength(c);\n\n        /* If there is an offset, just traverse the number of elements without\n         * checking the score because that is done in the next loop. */\n        //如果有offset,先偏移相应的元素\n        //注意此处zzlNext传入了两个指针,会一次偏移一个<member,score>对\n        //注意此处offset初始值是0,如果没指定则不会进入此处循环\n        while (eptr && offset--) {\n            if (reverse) {\n                zzlPrev(zl,&eptr,&sptr);\n            } else {\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n\n        //如果有limit,则进入循环.取limit次.limit的初始值为-1,即使没指定,也会进入循环\n        //直到eptr为null或者循环中break掉\n        while (eptr && limit--) {\n            score = zzlGetScore(sptr);\n\n            /* Abort when the node is no longer in range. */\n            //不在范围之内时break掉\n            if (reverse) {\n                if (!zslValueGteMin(score,&range)) break;\n            } else {\n                if (!zslValueLteMax(score,&range)) break;\n            }\n\n            /* We know the element exists, so ziplistGet should always succeed */\n            serverAssertWithInfo(c,zobj,ziplistGet(eptr,&vstr,&vlen,&vlong));\n            //取出相应的值.可能为str,赋值给vstr,长度为vlen,或者为整型,赋值给vlong\n            rangelen++;\n            if (vstr == NULL) {\n                addReplyBulkLongLong(c,vlong);\n            } else {\n                addReplyBulkCBuffer(c,vstr,vlen);\n            }\n            //如果设置了withscores标志,则返回分数\n            if (withscores) {\n                addReplyDouble(c,score);\n            }\n            //开始迭代下一个节点\n            /* Move to next node */\n            if (reverse) {\n                zzlPrev(zl,&eptr,&sptr);\n            } else {\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        zskiplistNode *ln;\n\n        //同ziplist,先查找起始或最终节点\n        /* If reversed, get the last node in range as starting point. */\n        if (reverse) {\n            ln = zslLastInRange(zsl,&range);\n        } else {\n            ln = zslFirstInRange(zsl,&range);\n        }\n\n        /* No \"first\" element in the specified interval. */\n        if (ln == NULL) {\n            addReply(c, shared.emptymultibulk);\n            return;\n        }\n\n        /* We don't know in advance how many matching elements there are in the\n         * list, so we push this object that will represent the multi-bulk\n         * length in the output buffer, and will \"fix\" it later */\n        //返回客户端时先返回元素个数,但此处并不知道需要返回多少个元素,所以先占个位置\n        //replylen是存储len字段的指针\n        replylen = addDeferredMultiBulkLength(c);\n\n        /* If there is an offset, just traverse the number of elements without\n         * checking the score because that is done in the next loop. */\n        //处理offset.向前或向后skip\n        while (ln && offset--) {\n            if (reverse) {\n                ln = ln->backward;\n            } else {\n                ln = ln->level[0].forward;\n            }\n        }\n\n        //处理limit\n        while (ln && limit--) {\n            /* Abort when the node is no longer in range. */\n            if (reverse) {\n                if (!zslValueGteMin(ln->score,&range)) break;\n            } else {\n                if (!zslValueLteMax(ln->score,&range)) break;\n            }\n\n            rangelen++;\n            addReplyBulkCBuffer(c,ln->ele,sdslen(ln->ele));\n\n            if (withscores) {\n                addReplyDouble(c,ln->score);\n            }\n\n            /* Move to next node */\n            if (reverse) {\n                ln = ln->backward;\n            } else {\n                ln = ln->level[0].forward;\n            }\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    //如果有withscores参数,返回给客户端的字符串数量是2倍\n    if (withscores) {\n        rangelen *= 2;\n    }\n    //将rangelen放入replylen指向的位置,返回给客户端\n    setDeferredMultiBulkLength(c, replylen, rangelen);\n}\n```\n\n## ZRANK\nZRANK key member\n\n返回有序集合中元素member的rank\n\n以0为起始rank,元素分数从低到高\n\nzrevrank,元素分数从高到低\n\n```c\nvoid zrankGenericCommand(client *c, int reverse) {\n    robj *key = c->argv[1];\n    robj *ele = c->argv[2];\n    robj *zobj;\n    long rank;\n    //通过key找出有序集合的value zobj\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.nullbulk)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n\n    serverAssertWithInfo(c,ele,sdsEncodedObject(ele));\n    //在zobj中查找ele(第二个参数member)\n    rank = zsetRank(zobj,ele->ptr,reverse);\n    if (rank >= 0) {\n        addReplyLongLong(c,rank);\n    } else {\n        addReply(c,shared.nullbulk);\n    }\n}\n\nvoid zrankCommand(client *c) {\n    zrankGenericCommand(c, 0);\n}\n```\n```c\nlong zsetRank(robj *zobj, sds ele, int reverse) {\n    unsigned long llen;\n    unsigned long rank;\n\n    llen = zsetLength(zobj);\n    //ziplist从前往后遍历,比较entry中的元素与ele,每次将rank++\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n\n        eptr = ziplistIndex(zl,0);\n        serverAssert(eptr != NULL);\n        sptr = ziplistNext(zl,eptr);\n        serverAssert(sptr != NULL);\n\n        rank = 1;\n        while(eptr != NULL) {\n            if (ziplistCompare(eptr,(unsigned char*)ele,sdslen(ele)))\n                break;\n            rank++;\n            zzlNext(zl,&eptr,&sptr);\n        }\n\n        if (eptr != NULL) {\n            //如果是逆序取,直接将llen-rank就是逆向的rank\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    //skiplist通过zslGetRank获取rank,具体过程为跳表查找,将相应路过节点的span相加\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        dictEntry *de;\n        double score;\n\n        de = dictFind(zs->dict,ele);\n        if (de != NULL) {\n            score = *(double*)dictGetVal(de);\n            rank = zslGetRank(zsl,score,ele);\n            /* Existing elements always have a rank. */\n            serverAssert(rank != 0);\n            //逆向取rank\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n}\n```\n\n## ZREM\nZREM key member [member ...]\n\n从有序集合中删除相应的member\n\n\n```c\nvoid zremCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    int deleted = 0, keyremoved = 0, j;\n    //根据key找到对应的zobj\n    if ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //依次删除相应的元素,每次删除之后检查zset是否为空,如果为空,删掉该key,并且break\n    for (j = 2; j < c->argc; j++) {\n        if (zsetDel(zobj,c->argv[j]->ptr)) deleted++;\n        if (zsetLength(zobj) == 0) {\n            dbDelete(c->db,key);\n            keyremoved = 1;\n            break;\n        }\n    }\n    //如果确实有member被删除掉,通知keyspace zrem事件\n    //如果zset整个都被删除了,通知keyspace del事件\n    if (deleted) {\n        notifyKeyspaceEvent(NOTIFY_ZSET,\"zrem\",key,c->db->id);\n        if (keyremoved)\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\"del\",key,c->db->id);\n        signalModifiedKey(c->db,key);\n        server.dirty += deleted;\n    }\n    //返回给客户端实际删除的member个数\n    addReplyLongLong(c,deleted);\n}\n```\n\n```c\n/* Delete the element 'ele' from the sorted set, returning 1 if the element\n * existed and was deleted, 0 otherwise (the element was not there). */\nint zsetDel(robj *zobj, sds ele) {\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *eptr;\n        //ziplist先找到ele所在位置的指针eptr\n        if ((eptr = zzlFind(zobj->ptr,ele,NULL)) != NULL) {\n            //将该元素删除.ziplist删除时会resize,此处将删除之后ziplist的指针复值给zobj->ptr\n            zobj->ptr = zzlDelete(zobj->ptr,eptr);\n            return 1;\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        dictEntry *de;\n        double score;\n        //skiplist现将zobj->ptr->dict相应的ele删除掉。此处并未真实删除\n        //而是将ele所在的dictEntry返回\n        de = dictUnlink(zs->dict,ele);\n        if (de != NULL) {\n            /* Get the score in order to delete from the skiplist later. */\n            //通过dictEntry获取score\n            score = *(double*)dictGetVal(de);\n\n            /* Delete from the hash table and later from the skiplist.\n             * Note that the order is important: deleting from the skiplist\n             * actually releases the SDS string representing the element,\n             * which is shared between the skiplist and the hash table, so\n             * we need to delete from the skiplist as the final step. */\n            //此处将dict中的key和value实际free掉\n            dictFreeUnlinkedEntry(zs->dict,de);\n\n            /* Delete from skiplist. */\n            //从skiplist中删除元素.ele这个sds在hash和skiplist共享.从skiplist中删除时\n            //会释放此sds,所以必须先删除dict中的元素再删除skiplist中的元素\n            int retval = zslDelete(zs->zsl,score,ele,NULL);\n            serverAssert(retval);\n            //如果hash表中元素使用率小于10%,进行dict的resize\n            if (htNeedsResize(zs->dict)) dictResize(zs->dict);\n            return 1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return 0; /* No such element found. */\n}\n```","source":"_posts/Redis有序集合指令学习.md","raw":"---\ntitle: Redis有序集合指令学习\ndate: 2018-07-11 13:21:01\ntags: Redis\n---\n## ZADD\nZADD key [NX|XX] [CH] [INCR]score member [score member ...]\n\n将元素及对应分值添加到一个有序集合中\n\nNX:不更新已经存在的key,只增加新元素\n\nXX:只更新已经存在的key,不增加新元素\n\nCH:abbr:changed.不指定时只返回新增的元素个数,指定时返回新增的和更新的元素个数之和\n\nINCR:参考zincrby\n\n```c\n//通过第二个参数区分是zadd还是zincrby\nvoid zaddCommand(client *c) {\n    zaddGenericCommand(c,ZADD_NONE);\n}\n```\n\n```c\n/* This generic command implements both ZADD and ZINCRBY. */\n//zadd和zincrby两个命令都是调用这个函数\nvoid zaddGenericCommand(client *c, int flags) {\n    static char *nanerr = \"resulting score is not a number (NaN)\";\n    robj *key = c->argv[1];\n    robj *zobj;\n    sds ele;\n    double score = 0, *scores = NULL;\n    int j, elements;\n    int scoreidx = 0;\n    /* The following vars are used in order to track what the command actually\n     * did during the execution, to reply to the client and to trigger the\n     * notification of keyspace change. */\n    int added = 0;      /* Number of new elements added. */\n    int updated = 0;    /* Number of elements with updated score. */\n    int processed = 0;  /* Number of elements processed, may remain zero with\n                           options like XX. */\n\n    /* Parse options. At the end 'scoreidx' is set to the argument position\n     * of the score of the first score-element pair. */\n    scoreidx = 2;//从第二个参数开始处理.先处理nx,xx,ch,incr参数\n    while(scoreidx < c->argc) {\n        char *opt = c->argv[scoreidx]->ptr;\n        if (!strcasecmp(opt,\"nx\")) flags |= ZADD_NX;\n        else if (!strcasecmp(opt,\"xx\")) flags |= ZADD_XX;\n        else if (!strcasecmp(opt,\"ch\")) flags |= ZADD_CH;\n        else if (!strcasecmp(opt,\"incr\")) flags |= ZADD_INCR;\n        else break;\n        scoreidx++;\n    }\n\n    /* Turn options into simple to check vars. */\n    //从flag中取出相应的标志赋给独立的变量\n    int incr = (flags & ZADD_INCR) != 0;\n    int nx = (flags & ZADD_NX) != 0;\n    int xx = (flags & ZADD_XX) != 0;\n    int ch = (flags & ZADD_CH) != 0;\n\n    /* After the options, we expect to have an even number of args, since\n     * we expect any number of score-element pairs. */\n    //member和score是一一对应的,所以肯定是2的倍数.所以如果不是2的倍数或者根本\n    //没有member和score,直接返回命令语法错误\n    elements = c->argc-scoreidx;\n    if (elements % 2 || !elements) {\n        addReply(c,shared.syntaxerr);\n        return;\n    }\n    //elements赋值为有多少对<element,score>\n    elements /= 2; /* Now this holds the number of score-element pairs. */\n\n    /* Check for incompatible options. */\n    //nx和xxflag互斥,二者不能同时出现\n    if (nx && xx) {\n        addReplyError(c,\n            \"XX and NX options at the same time are not compatible\");\n        return;\n    }\n    //若有incr标志,则只能有一对<element,score>\n    //为什么不能是多对?\n    if (incr && elements > 1) {\n        addReplyError(c,\n            \"INCR option supports a single increment-element pair\");\n        return;\n    }\n\n    /* Start parsing all the scores, we need to emit any syntax error\n     * before executing additions to the sorted set, as the command should\n     * either execute fully or nothing at all. */\n    //依次检查每一个分数值\n    scores = zmalloc(sizeof(double)*elements);\n    for (j = 0; j < elements; j++) {\n        //该函数中会检查score是否是合法的double类型的值\n        if (getDoubleFromObjectOrReply(c,c->argv[scoreidx+j*2],&scores[j],NULL)\n            != C_OK) goto cleanup;\n    }\n\n    /* Lookup the key and create the sorted set if does not exist. */\n    //根据key查找对应的有序集合的value\n    zobj = lookupKeyWrite(c->db,key);\n    //key不存在\n    if (zobj == NULL) {\n        //如果设置了xx这个flag,直接返回错误\n        if (xx) goto reply_to_client; /* No key + XX option: nothing to do. */\n        //根据redis的配置,如果有序集合设置了不使用ziplist存储或者说第一个插入元素的长度大于\n        //设置的最大ziplist的元素长度值,则使用跳跃表存储否则使用ziplist\n        if (server.zset_max_ziplist_entries == 0 ||\n            server.zset_max_ziplist_value < sdslen(c->argv[scoreidx+1]->ptr))\n        {\n            zobj = createZsetObject();\n        } else {\n            zobj = createZsetZiplistObject();\n        }\n        //把key,zobj插入字典\n        dbAdd(c->db,key,zobj);\n    //key存在\n    } else {\n        //如果不是有序集合,直接返回错误\n        if (zobj->type != OBJ_ZSET) {\n            addReply(c,shared.wrongtypeerr);\n            goto cleanup;\n        }\n    }\n\n    //elements是<member,score>对数\n    for (j = 0; j < elements; j++) {\n        double newscore;\n        score = scores[j];\n        //retflags设置为前文中的flags变量\n        int retflags = flags;\n\n        ele = c->argv[scoreidx+1+j*2]->ptr;\n        //每次遍历,score是分数,ele是member.调用zsetadd插入zobj\n        int retval = zsetAdd(zobj, score, ele, &retflags, &newscore);\n        if (retval == 0) {\n            addReplyError(c,nanerr);\n            goto cleanup;\n        }\n        //根据retflags,即一个元素是更新还是新加入,还是未做处理(即member存在,并且\n        //score值与新设置的一致),更新相应的计数变量(这些变量最后会返回给客户端)\n        if (retflags & ZADD_ADDED) added++;\n        if (retflags & ZADD_UPDATED) updated++;\n        if (!(retflags & ZADD_NOP)) processed++;\n        score = newscore;\n    }\n    server.dirty += (added+updated);\n//通过命令中的flag,返回给客户端不同的值\nreply_to_client:\n    if (incr) { /* ZINCRBY or INCR option. */\n        if (processed)\n            addReplyDouble(c,score);\n        else\n            addReply(c,shared.nullbulk);\n    } else { /* ZADD. */\n        addReplyLongLong(c,ch ? added+updated : added);\n    }\n\n//如果有更新或者新加,需要执行相应的watch key的通知及keyspace的通知\ncleanup:\n    zfree(scores);\n    if (added || updated) {\n        signalModifiedKey(c->db,key);\n        notifyKeyspaceEvent(NOTIFY_ZSET,\n            incr ? \"zincr\" : \"zadd\", key, c->db->id);\n    }\n}\n```\n\n## ZINCRBY \n\nZINCRBY key increment member\n\n如果key存在,就给相应member的score增加increment\n\n否则直接给key设置分数为increment\n\n```c\n\n//与zadd调用同一个函数,相当于zadd key incr,把incr flag置位\nvoid zincrbyCommand(client *c) {\n    zaddGenericCommand(c,ZADD_INCR);\n}\n```\n\n## ZCARD\nZCARD key\n\n返回有序集合的元素个数\n```c\nvoid zcardCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    //查找key对应的value\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //通过zsetLength获取zobj中的元素个数\n    addReplyLongLong(c,zsetLength(zobj));\n}\n```\n\n```c\nunsigned int zsetLength(const robj *zobj) {\n    int length = -1;\n    //如果是ziplist,通过zzlLength函数获取长度\n    //如果长度字段中的值小于UINT16_MAX，直接返回长度。否则需要遍历获取长度\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        length = zzlLength(zobj->ptr);\n    //如果是skiplist,直接返回zsl->length\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        length = ((const zset*)zobj->ptr)->zsl->length;\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return length;\n}\n```\n\n## ZCOUNT\nZCOUNT key min max\n\n返回key中score值在min和max之间的元素个数\n\n其中min和max可以加(,如 zcount key (5 (10 \n\n加左括号表示不包含。不加表示包含\n\n```c\nvoid zcountCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    zrangespec range;\n    int count = 0;\n\n    /* Parse the range arguments */\n    //判定范围.并将最大最小及是否包含写入range结构体中\n    if (zslParseRange(c->argv[2],c->argv[3],&range) != C_OK) {\n        addReplyError(c,\"min or max is not a float\");\n        return;\n    }\n\n    /* Lookup the sorted set */\n    if ((zobj = lookupKeyReadOrReply(c, key, shared.czero)) == NULL ||\n        checkType(c, zobj, OBJ_ZSET)) return;\n    //判断zobj底层编码是ziplist还是skiplist\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n        double score;\n        //找出第一个在范围之内的元素\n        /* Use the first element in range as the starting point */\n        eptr = zzlFirstInRange(zl,&range);\n\n        /* No \"first\" element */\n        if (eptr == NULL) {\n            addReply(c, shared.czero);\n            return;\n        }\n\n        /* First element is in range */\n        //ziplist中member和score是两个entry,并且member之后保存着score\n        //整体顺序是按score从小到大排列,score相同时,按member的字典序排列\n        sptr = ziplistNext(zl,eptr);\n        //所以此处从第一个元素的下一个entry处获取score\n        score = zzlGetScore(sptr);\n        serverAssertWithInfo(c,zobj,zslValueLteMax(score,&range));\n\n        /* Iterate over elements in range */\n        //迭代这个ziplist,如果score满足要求,则count++并且继续迭代,否则跳出\n        //最后会返回count\n        while (eptr) {\n            score = zzlGetScore(sptr);\n\n            /* Abort when the node is no longer in range. */\n            if (!zslValueLteMax(score,&range)) {\n                break;\n            } else {\n                count++;\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        zskiplistNode *zn;\n        unsigned long rank;\n        //如果是跳表,也是先取出第一个元素\n        /* Find first element in range */\n        zn = zslFirstInRange(zsl, &range);\n\n        /* Use rank of first element, if any, to determine preliminary count */\n        if (zn != NULL) {\n            //获取第一个元素的排名\n            rank = zslGetRank(zsl, zn->score, zn->ele);\n            count = (zsl->length - (rank - 1));\n            //如果最大值大于zsl中的最大值,则此count就是要找的个数\n            /* Find last element in range */\n            zn = zslLastInRange(zsl, &range);\n\n            /* Use rank of last element, if any, to determine the actual count */\n            if (zn != NULL) {\n                //如果最大值小于zsl中的最大值，则首先找到最后一个元素的rank\n                rank = zslGetRank(zsl, zn->score, zn->ele);\n                //重新计算count,与之前的计算公式合并之后为\n                //count = (zsl->length-(rankmin-1))-(zsl->length-rankmax))\n                //      = rankmax-rankmin+1\n                count -= (zsl->length - rank);\n            }\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    //返回count\n    addReplyLongLong(c, count);\n}\n```\n\n## ZRANGEBYSCORE\nZRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]\n\n获取有序结合中分值位于 min和max之间的所有元素\n\nwithscores:将member 和 score一起返回 \n\nlimit offset count:从偏移offset开始获取count个元素\n\nmin和max可以为 -inf,+inf,分别表示负无穷和正无穷\n\n```c\n\n//入口函数\nvoid zrangebyscoreCommand(client *c) {\n    genericZrangebyscoreCommand(c,0);\n}\n\n```\n\n```c\n/* This command implements ZRANGEBYSCORE, ZREVRANGEBYSCORE. */\nvoid genericZrangebyscoreCommand(client *c, int reverse) {\n    zrangespec range;\n    robj *key = c->argv[1];\n    robj *zobj;\n    long offset = 0, limit = -1;\n    int withscores = 0;\n    unsigned long rangelen = 0;\n    void *replylen = NULL;\n    int minidx, maxidx;\n    //该函数同时用于zrangbyscore和zrevrangebyscore\n    //二者通过函数中的reverse参数标识\n    //正序时第二个参数是min，第三个参数是max,逆序反之\n    /* Parse the range arguments. */\n    if (reverse) {\n        /* Range is given as [max,min] */\n        maxidx = 2; minidx = 3;\n    } else {\n        /* Range is given as [min,max] */\n        minidx = 2; maxidx = 3;\n    }\n    //将参数解析出来赋值到range变量\n    if (zslParseRange(c->argv[minidx],c->argv[maxidx],&range) != C_OK) {\n        addReplyError(c,\"min or max is not a float\");\n        return;\n    }\n\n    /* Parse optional extra arguments. Note that ZCOUNT will exactly have\n     * 4 arguments, so we'll never enter the following code path. */\n    if (c->argc > 4) {\n        int remaining = c->argc - 4;\n        int pos = 4;\n        //解析withscores和limit参数\n        while (remaining) {\n            if (remaining >= 1 && !strcasecmp(c->argv[pos]->ptr,\"withscores\")) {\n                pos++; remaining--;\n                withscores = 1;\n            } else if (remaining >= 3 && !strcasecmp(c->argv[pos]->ptr,\"limit\")) {\n                if ((getLongFromObjectOrReply(c, c->argv[pos+1], &offset, NULL)\n                        != C_OK) ||\n                    (getLongFromObjectOrReply(c, c->argv[pos+2], &limit, NULL)\n                        != C_OK))\n                {\n                    return;\n                }\n                pos += 3; remaining -= 3;\n            } else {\n                addReply(c,shared.syntaxerr);\n                return;\n            }\n        }\n    }\n\n    /* Ok, lookup the key and get the range */\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.emptymultibulk)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //按zset底层编码是ziplist还是skiplist分别处理\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n        unsigned char *vstr;\n        unsigned int vlen;\n        long long vlong;\n        double score;\n\n        /* If reversed, get the last node in range as starting point. */\n        //按正序还是逆序分别取最后一个值或者第一个值\n        if (reverse) {\n            eptr = zzlLastInRange(zl,&range);\n        } else {\n            eptr = zzlFirstInRange(zl,&range);\n        }\n\n        /* No \"first\" element in the specified interval. */\n        if (eptr == NULL) {\n            addReply(c, shared.emptymultibulk);\n            return;\n        }\n\n        /* Get score pointer for the first element. */\n        serverAssertWithInfo(c,zobj,eptr != NULL);\n        sptr = ziplistNext(zl,eptr);\n\n        /* We don't know in advance how many matching elements there are in the\n         * list, so we push this object that will represent the multi-bulk\n         * length in the output buffer, and will \"fix\" it later */\n        replylen = addDeferredMultiBulkLength(c);\n\n        /* If there is an offset, just traverse the number of elements without\n         * checking the score because that is done in the next loop. */\n        //如果有offset,先偏移相应的元素\n        //注意此处zzlNext传入了两个指针,会一次偏移一个<member,score>对\n        //注意此处offset初始值是0,如果没指定则不会进入此处循环\n        while (eptr && offset--) {\n            if (reverse) {\n                zzlPrev(zl,&eptr,&sptr);\n            } else {\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n\n        //如果有limit,则进入循环.取limit次.limit的初始值为-1,即使没指定,也会进入循环\n        //直到eptr为null或者循环中break掉\n        while (eptr && limit--) {\n            score = zzlGetScore(sptr);\n\n            /* Abort when the node is no longer in range. */\n            //不在范围之内时break掉\n            if (reverse) {\n                if (!zslValueGteMin(score,&range)) break;\n            } else {\n                if (!zslValueLteMax(score,&range)) break;\n            }\n\n            /* We know the element exists, so ziplistGet should always succeed */\n            serverAssertWithInfo(c,zobj,ziplistGet(eptr,&vstr,&vlen,&vlong));\n            //取出相应的值.可能为str,赋值给vstr,长度为vlen,或者为整型,赋值给vlong\n            rangelen++;\n            if (vstr == NULL) {\n                addReplyBulkLongLong(c,vlong);\n            } else {\n                addReplyBulkCBuffer(c,vstr,vlen);\n            }\n            //如果设置了withscores标志,则返回分数\n            if (withscores) {\n                addReplyDouble(c,score);\n            }\n            //开始迭代下一个节点\n            /* Move to next node */\n            if (reverse) {\n                zzlPrev(zl,&eptr,&sptr);\n            } else {\n                zzlNext(zl,&eptr,&sptr);\n            }\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        zskiplistNode *ln;\n\n        //同ziplist,先查找起始或最终节点\n        /* If reversed, get the last node in range as starting point. */\n        if (reverse) {\n            ln = zslLastInRange(zsl,&range);\n        } else {\n            ln = zslFirstInRange(zsl,&range);\n        }\n\n        /* No \"first\" element in the specified interval. */\n        if (ln == NULL) {\n            addReply(c, shared.emptymultibulk);\n            return;\n        }\n\n        /* We don't know in advance how many matching elements there are in the\n         * list, so we push this object that will represent the multi-bulk\n         * length in the output buffer, and will \"fix\" it later */\n        //返回客户端时先返回元素个数,但此处并不知道需要返回多少个元素,所以先占个位置\n        //replylen是存储len字段的指针\n        replylen = addDeferredMultiBulkLength(c);\n\n        /* If there is an offset, just traverse the number of elements without\n         * checking the score because that is done in the next loop. */\n        //处理offset.向前或向后skip\n        while (ln && offset--) {\n            if (reverse) {\n                ln = ln->backward;\n            } else {\n                ln = ln->level[0].forward;\n            }\n        }\n\n        //处理limit\n        while (ln && limit--) {\n            /* Abort when the node is no longer in range. */\n            if (reverse) {\n                if (!zslValueGteMin(ln->score,&range)) break;\n            } else {\n                if (!zslValueLteMax(ln->score,&range)) break;\n            }\n\n            rangelen++;\n            addReplyBulkCBuffer(c,ln->ele,sdslen(ln->ele));\n\n            if (withscores) {\n                addReplyDouble(c,ln->score);\n            }\n\n            /* Move to next node */\n            if (reverse) {\n                ln = ln->backward;\n            } else {\n                ln = ln->level[0].forward;\n            }\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    //如果有withscores参数,返回给客户端的字符串数量是2倍\n    if (withscores) {\n        rangelen *= 2;\n    }\n    //将rangelen放入replylen指向的位置,返回给客户端\n    setDeferredMultiBulkLength(c, replylen, rangelen);\n}\n```\n\n## ZRANK\nZRANK key member\n\n返回有序集合中元素member的rank\n\n以0为起始rank,元素分数从低到高\n\nzrevrank,元素分数从高到低\n\n```c\nvoid zrankGenericCommand(client *c, int reverse) {\n    robj *key = c->argv[1];\n    robj *ele = c->argv[2];\n    robj *zobj;\n    long rank;\n    //通过key找出有序集合的value zobj\n    if ((zobj = lookupKeyReadOrReply(c,key,shared.nullbulk)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n\n    serverAssertWithInfo(c,ele,sdsEncodedObject(ele));\n    //在zobj中查找ele(第二个参数member)\n    rank = zsetRank(zobj,ele->ptr,reverse);\n    if (rank >= 0) {\n        addReplyLongLong(c,rank);\n    } else {\n        addReply(c,shared.nullbulk);\n    }\n}\n\nvoid zrankCommand(client *c) {\n    zrankGenericCommand(c, 0);\n}\n```\n```c\nlong zsetRank(robj *zobj, sds ele, int reverse) {\n    unsigned long llen;\n    unsigned long rank;\n\n    llen = zsetLength(zobj);\n    //ziplist从前往后遍历,比较entry中的元素与ele,每次将rank++\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n\n        eptr = ziplistIndex(zl,0);\n        serverAssert(eptr != NULL);\n        sptr = ziplistNext(zl,eptr);\n        serverAssert(sptr != NULL);\n\n        rank = 1;\n        while(eptr != NULL) {\n            if (ziplistCompare(eptr,(unsigned char*)ele,sdslen(ele)))\n                break;\n            rank++;\n            zzlNext(zl,&eptr,&sptr);\n        }\n\n        if (eptr != NULL) {\n            //如果是逆序取,直接将llen-rank就是逆向的rank\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    //skiplist通过zslGetRank获取rank,具体过程为跳表查找,将相应路过节点的span相加\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        dictEntry *de;\n        double score;\n\n        de = dictFind(zs->dict,ele);\n        if (de != NULL) {\n            score = *(double*)dictGetVal(de);\n            rank = zslGetRank(zsl,score,ele);\n            /* Existing elements always have a rank. */\n            serverAssert(rank != 0);\n            //逆向取rank\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n}\n```\n\n## ZREM\nZREM key member [member ...]\n\n从有序集合中删除相应的member\n\n\n```c\nvoid zremCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    int deleted = 0, keyremoved = 0, j;\n    //根据key找到对应的zobj\n    if ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n    //依次删除相应的元素,每次删除之后检查zset是否为空,如果为空,删掉该key,并且break\n    for (j = 2; j < c->argc; j++) {\n        if (zsetDel(zobj,c->argv[j]->ptr)) deleted++;\n        if (zsetLength(zobj) == 0) {\n            dbDelete(c->db,key);\n            keyremoved = 1;\n            break;\n        }\n    }\n    //如果确实有member被删除掉,通知keyspace zrem事件\n    //如果zset整个都被删除了,通知keyspace del事件\n    if (deleted) {\n        notifyKeyspaceEvent(NOTIFY_ZSET,\"zrem\",key,c->db->id);\n        if (keyremoved)\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\"del\",key,c->db->id);\n        signalModifiedKey(c->db,key);\n        server.dirty += deleted;\n    }\n    //返回给客户端实际删除的member个数\n    addReplyLongLong(c,deleted);\n}\n```\n\n```c\n/* Delete the element 'ele' from the sorted set, returning 1 if the element\n * existed and was deleted, 0 otherwise (the element was not there). */\nint zsetDel(robj *zobj, sds ele) {\n    if (zobj->encoding == OBJ_ENCODING_ZIPLIST) {\n        unsigned char *eptr;\n        //ziplist先找到ele所在位置的指针eptr\n        if ((eptr = zzlFind(zobj->ptr,ele,NULL)) != NULL) {\n            //将该元素删除.ziplist删除时会resize,此处将删除之后ziplist的指针复值给zobj->ptr\n            zobj->ptr = zzlDelete(zobj->ptr,eptr);\n            return 1;\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        dictEntry *de;\n        double score;\n        //skiplist现将zobj->ptr->dict相应的ele删除掉。此处并未真实删除\n        //而是将ele所在的dictEntry返回\n        de = dictUnlink(zs->dict,ele);\n        if (de != NULL) {\n            /* Get the score in order to delete from the skiplist later. */\n            //通过dictEntry获取score\n            score = *(double*)dictGetVal(de);\n\n            /* Delete from the hash table and later from the skiplist.\n             * Note that the order is important: deleting from the skiplist\n             * actually releases the SDS string representing the element,\n             * which is shared between the skiplist and the hash table, so\n             * we need to delete from the skiplist as the final step. */\n            //此处将dict中的key和value实际free掉\n            dictFreeUnlinkedEntry(zs->dict,de);\n\n            /* Delete from skiplist. */\n            //从skiplist中删除元素.ele这个sds在hash和skiplist共享.从skiplist中删除时\n            //会释放此sds,所以必须先删除dict中的元素再删除skiplist中的元素\n            int retval = zslDelete(zs->zsl,score,ele,NULL);\n            serverAssert(retval);\n            //如果hash表中元素使用率小于10%,进行dict的resize\n            if (htNeedsResize(zs->dict)) dictResize(zs->dict);\n            return 1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return 0; /* No such element found. */\n}\n```","slug":"Redis有序集合指令学习","published":1,"updated":"2019-02-19T06:33:28.119Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvw65zd1001ubms6wospre08","content":"<h2 id=\"ZADD\"><a href=\"#ZADD\" class=\"headerlink\" title=\"ZADD\"></a>ZADD</h2><p>ZADD key [NX|XX] [CH] [INCR]score member [score member …]</p>\n<p>将元素及对应分值添加到一个有序集合中</p>\n<p>NX:不更新已经存在的key,只增加新元素</p>\n<p>XX:只更新已经存在的key,不增加新元素</p>\n<p>CH:abbr:changed.不指定时只返回新增的元素个数,指定时返回新增的和更新的元素个数之和</p>\n<p>INCR:参考zincrby</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//通过第二个参数区分是zadd还是zincrby</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zaddCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zaddGenericCommand(c,ZADD_NONE);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* This generic command implements both ZADD and ZINCRBY. */</span></span><br><span class=\"line\"><span class=\"comment\">//zadd和zincrby两个命令都是调用这个函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zaddGenericCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> flags)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">char</span> *nanerr = <span class=\"string\">\"resulting score is not a number (NaN)\"</span>;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    sds ele;</span><br><span class=\"line\">    <span class=\"keyword\">double</span> score = <span class=\"number\">0</span>, *scores = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> j, elements;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> scoreidx = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">/* The following vars are used in order to track what the command actually</span></span><br><span class=\"line\"><span class=\"comment\">     * did during the execution, to reply to the client and to trigger the</span></span><br><span class=\"line\"><span class=\"comment\">     * notification of keyspace change. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> added = <span class=\"number\">0</span>;      <span class=\"comment\">/* Number of new elements added. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> updated = <span class=\"number\">0</span>;    <span class=\"comment\">/* Number of elements with updated score. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> processed = <span class=\"number\">0</span>;  <span class=\"comment\">/* Number of elements processed, may remain zero with</span></span><br><span class=\"line\"><span class=\"comment\">                           options like XX. */</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse options. At the end 'scoreidx' is set to the argument position</span></span><br><span class=\"line\"><span class=\"comment\">     * of the score of the first score-element pair. */</span></span><br><span class=\"line\">    scoreidx = <span class=\"number\">2</span>;<span class=\"comment\">//从第二个参数开始处理.先处理nx,xx,ch,incr参数</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(scoreidx &lt; c-&gt;argc) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">char</span> *opt = c-&gt;argv[scoreidx]-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"nx\"</span>)) flags |= ZADD_NX;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"xx\"</span>)) flags |= ZADD_XX;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"ch\"</span>)) flags |= ZADD_CH;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"incr\"</span>)) flags |= ZADD_INCR;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        scoreidx++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Turn options into simple to check vars. */</span></span><br><span class=\"line\">    <span class=\"comment\">//从flag中取出相应的标志赋给独立的变量</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> incr = (flags &amp; ZADD_INCR) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> nx = (flags &amp; ZADD_NX) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> xx = (flags &amp; ZADD_XX) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> ch = (flags &amp; ZADD_CH) != <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* After the options, we expect to have an even number of args, since</span></span><br><span class=\"line\"><span class=\"comment\">     * we expect any number of score-element pairs. */</span></span><br><span class=\"line\">    <span class=\"comment\">//member和score是一一对应的,所以肯定是2的倍数.所以如果不是2的倍数或者根本</span></span><br><span class=\"line\">    <span class=\"comment\">//没有member和score,直接返回命令语法错误</span></span><br><span class=\"line\">    elements = c-&gt;argc-scoreidx;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (elements % <span class=\"number\">2</span> || !elements) &#123;</span><br><span class=\"line\">        addReply(c,shared.syntaxerr);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//elements赋值为有多少对&lt;element,score&gt;</span></span><br><span class=\"line\">    elements /= <span class=\"number\">2</span>; <span class=\"comment\">/* Now this holds the number of score-element pairs. */</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Check for incompatible options. */</span></span><br><span class=\"line\">    <span class=\"comment\">//nx和xxflag互斥,二者不能同时出现</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (nx &amp;&amp; xx) &#123;</span><br><span class=\"line\">        addReplyError(c,</span><br><span class=\"line\">            <span class=\"string\">\"XX and NX options at the same time are not compatible\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//若有incr标志,则只能有一对&lt;element,score&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">//为什么不能是多对?</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (incr &amp;&amp; elements &gt; <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        addReplyError(c,</span><br><span class=\"line\">            <span class=\"string\">\"INCR option supports a single increment-element pair\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Start parsing all the scores, we need to emit any syntax error</span></span><br><span class=\"line\"><span class=\"comment\">     * before executing additions to the sorted set, as the command should</span></span><br><span class=\"line\"><span class=\"comment\">     * either execute fully or nothing at all. */</span></span><br><span class=\"line\">    <span class=\"comment\">//依次检查每一个分数值</span></span><br><span class=\"line\">    scores = zmalloc(<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">double</span>)*elements);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; elements; j++) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//该函数中会检查score是否是合法的double类型的值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (getDoubleFromObjectOrReply(c,c-&gt;argv[scoreidx+j*<span class=\"number\">2</span>],&amp;scores[j],<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">            != C_OK) <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Lookup the key and create the sorted set if does not exist. */</span></span><br><span class=\"line\">    <span class=\"comment\">//根据key查找对应的有序集合的value</span></span><br><span class=\"line\">    zobj = lookupKeyWrite(c-&gt;db,key);</span><br><span class=\"line\">    <span class=\"comment\">//key不存在</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果设置了xx这个flag,直接返回错误</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (xx) <span class=\"keyword\">goto</span> reply_to_client; <span class=\"comment\">/* No key + XX option: nothing to do. */</span></span><br><span class=\"line\">        <span class=\"comment\">//根据redis的配置,如果有序集合设置了不使用ziplist存储或者说第一个插入元素的长度大于</span></span><br><span class=\"line\">        <span class=\"comment\">//设置的最大ziplist的元素长度值,则使用跳跃表存储否则使用ziplist</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (server.zset_max_ziplist_entries == <span class=\"number\">0</span> ||</span><br><span class=\"line\">            server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[scoreidx+<span class=\"number\">1</span>]-&gt;ptr))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            zobj = createZsetObject();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            zobj = createZsetZiplistObject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//把key,zobj插入字典</span></span><br><span class=\"line\">        dbAdd(c-&gt;db,key,zobj);</span><br><span class=\"line\">    <span class=\"comment\">//key存在</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果不是有序集合,直接返回错误</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zobj-&gt;type != OBJ_ZSET) &#123;</span><br><span class=\"line\">            addReply(c,shared.wrongtypeerr);</span><br><span class=\"line\">            <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//elements是&lt;member,score&gt;对数</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; elements; j++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> newscore;</span><br><span class=\"line\">        score = scores[j];</span><br><span class=\"line\">        <span class=\"comment\">//retflags设置为前文中的flags变量</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> retflags = flags;</span><br><span class=\"line\"></span><br><span class=\"line\">        ele = c-&gt;argv[scoreidx+<span class=\"number\">1</span>+j*<span class=\"number\">2</span>]-&gt;ptr;</span><br><span class=\"line\">        <span class=\"comment\">//每次遍历,score是分数,ele是member.调用zsetadd插入zobj</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> retval = zsetAdd(zobj, score, ele, &amp;retflags, &amp;newscore);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retval == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            addReplyError(c,nanerr);</span><br><span class=\"line\">            <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//根据retflags,即一个元素是更新还是新加入,还是未做处理(即member存在,并且</span></span><br><span class=\"line\">        <span class=\"comment\">//score值与新设置的一致),更新相应的计数变量(这些变量最后会返回给客户端)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retflags &amp; ZADD_ADDED) added++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retflags &amp; ZADD_UPDATED) updated++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!(retflags &amp; ZADD_NOP)) processed++;</span><br><span class=\"line\">        score = newscore;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    server.dirty += (added+updated);</span><br><span class=\"line\"><span class=\"comment\">//通过命令中的flag,返回给客户端不同的值</span></span><br><span class=\"line\">reply_to_client:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (incr) &#123; <span class=\"comment\">/* ZINCRBY or INCR option. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (processed)</span><br><span class=\"line\">            addReplyDouble(c,score);</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            addReply(c,shared.nullbulk);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123; <span class=\"comment\">/* ZADD. */</span></span><br><span class=\"line\">        addReplyLongLong(c,ch ? added+updated : added);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//如果有更新或者新加,需要执行相应的watch key的通知及keyspace的通知</span></span><br><span class=\"line\">cleanup:</span><br><span class=\"line\">    zfree(scores);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (added || updated) &#123;</span><br><span class=\"line\">        signalModifiedKey(c-&gt;db,key);</span><br><span class=\"line\">        notifyKeyspaceEvent(NOTIFY_ZSET,</span><br><span class=\"line\">            incr ? <span class=\"string\">\"zincr\"</span> : <span class=\"string\">\"zadd\"</span>, key, c-&gt;db-&gt;id);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZINCRBY\"><a href=\"#ZINCRBY\" class=\"headerlink\" title=\"ZINCRBY\"></a>ZINCRBY</h2><p>ZINCRBY key increment member</p>\n<p>如果key存在,就给相应member的score增加increment</p>\n<p>否则直接给key设置分数为increment</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与zadd调用同一个函数,相当于zadd key incr,把incr flag置位</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zincrbyCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zaddGenericCommand(c,ZADD_INCR);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZCARD\"><a href=\"#ZCARD\" class=\"headerlink\" title=\"ZCARD\"></a>ZCARD</h2><p>ZCARD key</p>\n<p>返回有序集合的元素个数<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zcardCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"comment\">//查找key对应的value</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//通过zsetLength获取zobj中的元素个数</span></span><br><span class=\"line\">    addReplyLongLong(c,zsetLength(zobj));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">zsetLength</span><span class=\"params\">(<span class=\"keyword\">const</span> robj *zobj)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> length = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"comment\">//如果是ziplist,通过zzlLength函数获取长度</span></span><br><span class=\"line\">    <span class=\"comment\">//如果长度字段中的值小于UINT16_MAX，直接返回长度。否则需要遍历获取长度</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        length = zzlLength(zobj-&gt;ptr);</span><br><span class=\"line\">    <span class=\"comment\">//如果是skiplist,直接返回zsl-&gt;length</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        length = ((<span class=\"keyword\">const</span> zset*)zobj-&gt;ptr)-&gt;zsl-&gt;length;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> length;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZCOUNT\"><a href=\"#ZCOUNT\" class=\"headerlink\" title=\"ZCOUNT\"></a>ZCOUNT</h2><p>ZCOUNT key min max</p>\n<p>返回key中score值在min和max之间的元素个数</p>\n<p>其中min和max可以加(,如 zcount key (5 (10 </p>\n<p>加左括号表示不包含。不加表示包含</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zcountCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    zrangespec range;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse the range arguments */</span></span><br><span class=\"line\">    <span class=\"comment\">//判定范围.并将最大最小及是否包含写入range结构体中</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zslParseRange(c-&gt;argv[<span class=\"number\">2</span>],c-&gt;argv[<span class=\"number\">3</span>],&amp;range) != C_OK) &#123;</span><br><span class=\"line\">        addReplyError(c,<span class=\"string\">\"min or max is not a float\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Lookup the sorted set */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c, key, shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c, zobj, OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//判断zobj底层编码是ziplist还是skiplist</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\">        <span class=\"comment\">//找出第一个在范围之内的元素</span></span><br><span class=\"line\">        <span class=\"comment\">/* Use the first element in range as the starting point */</span></span><br><span class=\"line\">        eptr = zzlFirstInRange(zl,&amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.czero);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* First element is in range */</span></span><br><span class=\"line\">        <span class=\"comment\">//ziplist中member和score是两个entry,并且member之后保存着score</span></span><br><span class=\"line\">        <span class=\"comment\">//整体顺序是按score从小到大排列,score相同时,按member的字典序排列</span></span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\">        <span class=\"comment\">//所以此处从第一个元素的下一个entry处获取score</span></span><br><span class=\"line\">        score = zzlGetScore(sptr);</span><br><span class=\"line\">        serverAssertWithInfo(c,zobj,zslValueLteMax(score,&amp;range));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Iterate over elements in range */</span></span><br><span class=\"line\">        <span class=\"comment\">//迭代这个ziplist,如果score满足要求,则count++并且继续迭代,否则跳出</span></span><br><span class=\"line\">        <span class=\"comment\">//最后会返回count</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr) &#123;</span><br><span class=\"line\">            score = zzlGetScore(sptr);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!zslValueLteMax(score,&amp;range)) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                count++;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        zskiplistNode *zn;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\">        <span class=\"comment\">//如果是跳表,也是先取出第一个元素</span></span><br><span class=\"line\">        <span class=\"comment\">/* Find first element in range */</span></span><br><span class=\"line\">        zn = zslFirstInRange(zsl, &amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Use rank of first element, if any, to determine preliminary count */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zn != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//获取第一个元素的排名</span></span><br><span class=\"line\">            rank = zslGetRank(zsl, zn-&gt;score, zn-&gt;ele);</span><br><span class=\"line\">            count = (zsl-&gt;length - (rank - <span class=\"number\">1</span>));</span><br><span class=\"line\">            <span class=\"comment\">//如果最大值大于zsl中的最大值,则此count就是要找的个数</span></span><br><span class=\"line\">            <span class=\"comment\">/* Find last element in range */</span></span><br><span class=\"line\">            zn = zslLastInRange(zsl, &amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Use rank of last element, if any, to determine the actual count */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (zn != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">//如果最大值小于zsl中的最大值，则首先找到最后一个元素的rank</span></span><br><span class=\"line\">                rank = zslGetRank(zsl, zn-&gt;score, zn-&gt;ele);</span><br><span class=\"line\">                <span class=\"comment\">//重新计算count,与之前的计算公式合并之后为</span></span><br><span class=\"line\">                <span class=\"comment\">//count = (zsl-&gt;length-(rankmin-1))-(zsl-&gt;length-rankmax))</span></span><br><span class=\"line\">                <span class=\"comment\">//      = rankmax-rankmin+1</span></span><br><span class=\"line\">                count -= (zsl-&gt;length - rank);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//返回count</span></span><br><span class=\"line\">    addReplyLongLong(c, count);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZRANGEBYSCORE\"><a href=\"#ZRANGEBYSCORE\" class=\"headerlink\" title=\"ZRANGEBYSCORE\"></a>ZRANGEBYSCORE</h2><p>ZRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]</p>\n<p>获取有序结合中分值位于 min和max之间的所有元素</p>\n<p>withscores:将member 和 score一起返回 </p>\n<p>limit offset count:从偏移offset开始获取count个元素</p>\n<p>min和max可以为 -inf,+inf,分别表示负无穷和正无穷</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入口函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrangebyscoreCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    genericZrangebyscoreCommand(c,<span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* This command implements ZRANGEBYSCORE, ZREVRANGEBYSCORE. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">genericZrangebyscoreCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    zrangespec range;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> offset = <span class=\"number\">0</span>, limit = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> withscores = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rangelen = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span> *replylen = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> minidx, maxidx;</span><br><span class=\"line\">    <span class=\"comment\">//该函数同时用于zrangbyscore和zrevrangebyscore</span></span><br><span class=\"line\">    <span class=\"comment\">//二者通过函数中的reverse参数标识</span></span><br><span class=\"line\">    <span class=\"comment\">//正序时第二个参数是min，第三个参数是max,逆序反之</span></span><br><span class=\"line\">    <span class=\"comment\">/* Parse the range arguments. */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* Range is given as [max,min] */</span></span><br><span class=\"line\">        maxidx = <span class=\"number\">2</span>; minidx = <span class=\"number\">3</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* Range is given as [min,max] */</span></span><br><span class=\"line\">        minidx = <span class=\"number\">2</span>; maxidx = <span class=\"number\">3</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//将参数解析出来赋值到range变量</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zslParseRange(c-&gt;argv[minidx],c-&gt;argv[maxidx],&amp;range) != C_OK) &#123;</span><br><span class=\"line\">        addReplyError(c,<span class=\"string\">\"min or max is not a float\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse optional extra arguments. Note that ZCOUNT will exactly have</span></span><br><span class=\"line\"><span class=\"comment\">     * 4 arguments, so we'll never enter the following code path. */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (c-&gt;argc &gt; <span class=\"number\">4</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> remaining = c-&gt;argc - <span class=\"number\">4</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pos = <span class=\"number\">4</span>;</span><br><span class=\"line\">        <span class=\"comment\">//解析withscores和limit参数</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (remaining) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (remaining &gt;= <span class=\"number\">1</span> &amp;&amp; !strcasecmp(c-&gt;argv[pos]-&gt;ptr,<span class=\"string\">\"withscores\"</span>)) &#123;</span><br><span class=\"line\">                pos++; remaining--;</span><br><span class=\"line\">                withscores = <span class=\"number\">1</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (remaining &gt;= <span class=\"number\">3</span> &amp;&amp; !strcasecmp(c-&gt;argv[pos]-&gt;ptr,<span class=\"string\">\"limit\"</span>)) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> ((getLongFromObjectOrReply(c, c-&gt;argv[pos+<span class=\"number\">1</span>], &amp;offset, <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">                        != C_OK) ||</span><br><span class=\"line\">                    (getLongFromObjectOrReply(c, c-&gt;argv[pos+<span class=\"number\">2</span>], &amp;limit, <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">                        != C_OK))</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                pos += <span class=\"number\">3</span>; remaining -= <span class=\"number\">3</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                addReply(c,shared.syntaxerr);</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Ok, lookup the key and get the range */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.emptymultibulk)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//按zset底层编码是ziplist还是skiplist分别处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *vstr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> vlen;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> vlong;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If reversed, get the last node in range as starting point. */</span></span><br><span class=\"line\">        <span class=\"comment\">//按正序还是逆序分别取最后一个值或者第一个值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">            eptr = zzlLastInRange(zl,&amp;range);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            eptr = zzlFirstInRange(zl,&amp;range);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element in the specified interval. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.emptymultibulk);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Get score pointer for the first element. */</span></span><br><span class=\"line\">        serverAssertWithInfo(c,zobj,eptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* We don't know in advance how many matching elements there are in the</span></span><br><span class=\"line\"><span class=\"comment\">         * list, so we push this object that will represent the multi-bulk</span></span><br><span class=\"line\"><span class=\"comment\">         * length in the output buffer, and will \"fix\" it later */</span></span><br><span class=\"line\">        replylen = addDeferredMultiBulkLength(c);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If there is an offset, just traverse the number of elements without</span></span><br><span class=\"line\"><span class=\"comment\">         * checking the score because that is done in the next loop. */</span></span><br><span class=\"line\">        <span class=\"comment\">//如果有offset,先偏移相应的元素</span></span><br><span class=\"line\">        <span class=\"comment\">//注意此处zzlNext传入了两个指针,会一次偏移一个&lt;member,score&gt;对</span></span><br><span class=\"line\">        <span class=\"comment\">//注意此处offset初始值是0,如果没指定则不会进入此处循环</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr &amp;&amp; offset--) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                zzlPrev(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果有limit,则进入循环.取limit次.limit的初始值为-1,即使没指定,也会进入循环</span></span><br><span class=\"line\">        <span class=\"comment\">//直到eptr为null或者循环中break掉</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr &amp;&amp; limit--) &#123;</span><br><span class=\"line\">            score = zzlGetScore(sptr);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"comment\">//不在范围之内时break掉</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueGteMin(score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueLteMax(score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* We know the element exists, so ziplistGet should always succeed */</span></span><br><span class=\"line\">            serverAssertWithInfo(c,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong));</span><br><span class=\"line\">            <span class=\"comment\">//取出相应的值.可能为str,赋值给vstr,长度为vlen,或者为整型,赋值给vlong</span></span><br><span class=\"line\">            rangelen++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (vstr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">                addReplyBulkLongLong(c,vlong);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                addReplyBulkCBuffer(c,vstr,vlen);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果设置了withscores标志,则返回分数</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">                addReplyDouble(c,score);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//开始迭代下一个节点</span></span><br><span class=\"line\">            <span class=\"comment\">/* Move to next node */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                zzlPrev(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        zskiplistNode *ln;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//同ziplist,先查找起始或最终节点</span></span><br><span class=\"line\">        <span class=\"comment\">/* If reversed, get the last node in range as starting point. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">            ln = zslLastInRange(zsl,&amp;range);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            ln = zslFirstInRange(zsl,&amp;range);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element in the specified interval. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ln == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.emptymultibulk);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* We don't know in advance how many matching elements there are in the</span></span><br><span class=\"line\"><span class=\"comment\">         * list, so we push this object that will represent the multi-bulk</span></span><br><span class=\"line\"><span class=\"comment\">         * length in the output buffer, and will \"fix\" it later */</span></span><br><span class=\"line\">        <span class=\"comment\">//返回客户端时先返回元素个数,但此处并不知道需要返回多少个元素,所以先占个位置</span></span><br><span class=\"line\">        <span class=\"comment\">//replylen是存储len字段的指针</span></span><br><span class=\"line\">        replylen = addDeferredMultiBulkLength(c);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If there is an offset, just traverse the number of elements without</span></span><br><span class=\"line\"><span class=\"comment\">         * checking the score because that is done in the next loop. */</span></span><br><span class=\"line\">        <span class=\"comment\">//处理offset.向前或向后skip</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (ln &amp;&amp; offset--) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                ln = ln-&gt;backward;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                ln = ln-&gt;level[<span class=\"number\">0</span>].forward;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//处理limit</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (ln &amp;&amp; limit--) &#123;</span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueGteMin(ln-&gt;score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueLteMax(ln-&gt;score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            rangelen++;</span><br><span class=\"line\">            addReplyBulkCBuffer(c,ln-&gt;ele,sdslen(ln-&gt;ele));</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">                addReplyDouble(c,ln-&gt;score);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Move to next node */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                ln = ln-&gt;backward;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                ln = ln-&gt;level[<span class=\"number\">0</span>].forward;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//如果有withscores参数,返回给客户端的字符串数量是2倍</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">        rangelen *= <span class=\"number\">2</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//将rangelen放入replylen指向的位置,返回给客户端</span></span><br><span class=\"line\">    setDeferredMultiBulkLength(c, replylen, rangelen);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZRANK\"><a href=\"#ZRANK\" class=\"headerlink\" title=\"ZRANK\"></a>ZRANK</h2><p>ZRANK key member</p>\n<p>返回有序集合中元素member的rank</p>\n<p>以0为起始rank,元素分数从低到高</p>\n<p>zrevrank,元素分数从高到低</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrankGenericCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *ele = c-&gt;argv[<span class=\"number\">2</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\">    <span class=\"comment\">//通过key找出有序集合的value zobj</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.nullbulk)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    serverAssertWithInfo(c,ele,sdsEncodedObject(ele));</span><br><span class=\"line\">    <span class=\"comment\">//在zobj中查找ele(第二个参数member)</span></span><br><span class=\"line\">    rank = zsetRank(zobj,ele-&gt;ptr,reverse);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (rank &gt;= <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        addReplyLongLong(c,rank);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        addReply(c,shared.nullbulk);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrankCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zrankGenericCommand(c, <span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">zsetRank</span><span class=\"params\">(robj *zobj, sds ele, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> llen;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\"></span><br><span class=\"line\">    llen = zsetLength(zobj);</span><br><span class=\"line\">    <span class=\"comment\">//ziplist从前往后遍历,比较entry中的元素与ele,每次将rank++</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\"></span><br><span class=\"line\">        eptr = ziplistIndex(zl,<span class=\"number\">0</span>);</span><br><span class=\"line\">        serverAssert(eptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\">        serverAssert(sptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        rank = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(eptr != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ziplistCompare(eptr,(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span>*)ele,sdslen(ele)))</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            rank++;</span><br><span class=\"line\">            zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//如果是逆序取,直接将llen-rank就是逆向的rank</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> llen-rank;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> rank<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"comment\">//skiplist通过zslGetRank获取rank,具体过程为跳表查找,将相应路过节点的span相加</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        dictEntry *de;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\"></span><br><span class=\"line\">        de = dictFind(zs-&gt;dict,ele);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (de != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            score = *(<span class=\"keyword\">double</span>*)dictGetVal(de);</span><br><span class=\"line\">            rank = zslGetRank(zsl,score,ele);</span><br><span class=\"line\">            <span class=\"comment\">/* Existing elements always have a rank. */</span></span><br><span class=\"line\">            serverAssert(rank != <span class=\"number\">0</span>);</span><br><span class=\"line\">            <span class=\"comment\">//逆向取rank</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> llen-rank;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> rank<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZREM\"><a href=\"#ZREM\" class=\"headerlink\" title=\"ZREM\"></a>ZREM</h2><p>ZREM key member [member …]</p>\n<p>从有序集合中删除相应的member</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zremCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> deleted = <span class=\"number\">0</span>, keyremoved = <span class=\"number\">0</span>, j;</span><br><span class=\"line\">    <span class=\"comment\">//根据key找到对应的zobj</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//依次删除相应的元素,每次删除之后检查zset是否为空,如果为空,删掉该key,并且break</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">2</span>; j &lt; c-&gt;argc; j++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zsetDel(zobj,c-&gt;argv[j]-&gt;ptr)) deleted++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zsetLength(zobj) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            dbDelete(c-&gt;db,key);</span><br><span class=\"line\">            keyremoved = <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//如果确实有member被删除掉,通知keyspace zrem事件</span></span><br><span class=\"line\">    <span class=\"comment\">//如果zset整个都被删除了,通知keyspace del事件</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (deleted) &#123;</span><br><span class=\"line\">        notifyKeyspaceEvent(NOTIFY_ZSET,<span class=\"string\">\"zrem\"</span>,key,c-&gt;db-&gt;id);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (keyremoved)</span><br><span class=\"line\">            notifyKeyspaceEvent(NOTIFY_GENERIC,<span class=\"string\">\"del\"</span>,key,c-&gt;db-&gt;id);</span><br><span class=\"line\">        signalModifiedKey(c-&gt;db,key);</span><br><span class=\"line\">        server.dirty += deleted;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//返回给客户端实际删除的member个数</span></span><br><span class=\"line\">    addReplyLongLong(c,deleted);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* Delete the element 'ele' from the sorted set, returning 1 if the element</span></span><br><span class=\"line\"><span class=\"comment\"> * existed and was deleted, 0 otherwise (the element was not there). */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">zsetDel</span><span class=\"params\">(robj *zobj, sds ele)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr;</span><br><span class=\"line\">        <span class=\"comment\">//ziplist先找到ele所在位置的指针eptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((eptr = zzlFind(zobj-&gt;ptr,ele,<span class=\"literal\">NULL</span>)) != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//将该元素删除.ziplist删除时会resize,此处将删除之后ziplist的指针复值给zobj-&gt;ptr</span></span><br><span class=\"line\">            zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        dictEntry *de;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\">        <span class=\"comment\">//skiplist现将zobj-&gt;ptr-&gt;dict相应的ele删除掉。此处并未真实删除</span></span><br><span class=\"line\">        <span class=\"comment\">//而是将ele所在的dictEntry返回</span></span><br><span class=\"line\">        de = dictUnlink(zs-&gt;dict,ele);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (de != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">/* Get the score in order to delete from the skiplist later. */</span></span><br><span class=\"line\">            <span class=\"comment\">//通过dictEntry获取score</span></span><br><span class=\"line\">            score = *(<span class=\"keyword\">double</span>*)dictGetVal(de);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Delete from the hash table and later from the skiplist.</span></span><br><span class=\"line\"><span class=\"comment\">             * Note that the order is important: deleting from the skiplist</span></span><br><span class=\"line\"><span class=\"comment\">             * actually releases the SDS string representing the element,</span></span><br><span class=\"line\"><span class=\"comment\">             * which is shared between the skiplist and the hash table, so</span></span><br><span class=\"line\"><span class=\"comment\">             * we need to delete from the skiplist as the final step. */</span></span><br><span class=\"line\">            <span class=\"comment\">//此处将dict中的key和value实际free掉</span></span><br><span class=\"line\">            dictFreeUnlinkedEntry(zs-&gt;dict,de);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Delete from skiplist. */</span></span><br><span class=\"line\">            <span class=\"comment\">//从skiplist中删除元素.ele这个sds在hash和skiplist共享.从skiplist中删除时</span></span><br><span class=\"line\">            <span class=\"comment\">//会释放此sds,所以必须先删除dict中的元素再删除skiplist中的元素</span></span><br><span class=\"line\">            <span class=\"keyword\">int</span> retval = zslDelete(zs-&gt;zsl,score,ele,<span class=\"literal\">NULL</span>);</span><br><span class=\"line\">            serverAssert(retval);</span><br><span class=\"line\">            <span class=\"comment\">//如果hash表中元素使用率小于10%,进行dict的resize</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (htNeedsResize(zs-&gt;dict)) dictResize(zs-&gt;dict);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>; <span class=\"comment\">/* No such element found. */</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"ZADD\"><a href=\"#ZADD\" class=\"headerlink\" title=\"ZADD\"></a>ZADD</h2><p>ZADD key [NX|XX] [CH] [INCR]score member [score member …]</p>\n<p>将元素及对应分值添加到一个有序集合中</p>\n<p>NX:不更新已经存在的key,只增加新元素</p>\n<p>XX:只更新已经存在的key,不增加新元素</p>\n<p>CH:abbr:changed.不指定时只返回新增的元素个数,指定时返回新增的和更新的元素个数之和</p>\n<p>INCR:参考zincrby</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//通过第二个参数区分是zadd还是zincrby</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zaddCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zaddGenericCommand(c,ZADD_NONE);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* This generic command implements both ZADD and ZINCRBY. */</span></span><br><span class=\"line\"><span class=\"comment\">//zadd和zincrby两个命令都是调用这个函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zaddGenericCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> flags)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">char</span> *nanerr = <span class=\"string\">\"resulting score is not a number (NaN)\"</span>;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    sds ele;</span><br><span class=\"line\">    <span class=\"keyword\">double</span> score = <span class=\"number\">0</span>, *scores = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> j, elements;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> scoreidx = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"comment\">/* The following vars are used in order to track what the command actually</span></span><br><span class=\"line\"><span class=\"comment\">     * did during the execution, to reply to the client and to trigger the</span></span><br><span class=\"line\"><span class=\"comment\">     * notification of keyspace change. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> added = <span class=\"number\">0</span>;      <span class=\"comment\">/* Number of new elements added. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> updated = <span class=\"number\">0</span>;    <span class=\"comment\">/* Number of elements with updated score. */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> processed = <span class=\"number\">0</span>;  <span class=\"comment\">/* Number of elements processed, may remain zero with</span></span><br><span class=\"line\"><span class=\"comment\">                           options like XX. */</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse options. At the end 'scoreidx' is set to the argument position</span></span><br><span class=\"line\"><span class=\"comment\">     * of the score of the first score-element pair. */</span></span><br><span class=\"line\">    scoreidx = <span class=\"number\">2</span>;<span class=\"comment\">//从第二个参数开始处理.先处理nx,xx,ch,incr参数</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span>(scoreidx &lt; c-&gt;argc) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">char</span> *opt = c-&gt;argv[scoreidx]-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"nx\"</span>)) flags |= ZADD_NX;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"xx\"</span>)) flags |= ZADD_XX;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"ch\"</span>)) flags |= ZADD_CH;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (!strcasecmp(opt,<span class=\"string\">\"incr\"</span>)) flags |= ZADD_INCR;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        scoreidx++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Turn options into simple to check vars. */</span></span><br><span class=\"line\">    <span class=\"comment\">//从flag中取出相应的标志赋给独立的变量</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> incr = (flags &amp; ZADD_INCR) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> nx = (flags &amp; ZADD_NX) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> xx = (flags &amp; ZADD_XX) != <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> ch = (flags &amp; ZADD_CH) != <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* After the options, we expect to have an even number of args, since</span></span><br><span class=\"line\"><span class=\"comment\">     * we expect any number of score-element pairs. */</span></span><br><span class=\"line\">    <span class=\"comment\">//member和score是一一对应的,所以肯定是2的倍数.所以如果不是2的倍数或者根本</span></span><br><span class=\"line\">    <span class=\"comment\">//没有member和score,直接返回命令语法错误</span></span><br><span class=\"line\">    elements = c-&gt;argc-scoreidx;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (elements % <span class=\"number\">2</span> || !elements) &#123;</span><br><span class=\"line\">        addReply(c,shared.syntaxerr);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//elements赋值为有多少对&lt;element,score&gt;</span></span><br><span class=\"line\">    elements /= <span class=\"number\">2</span>; <span class=\"comment\">/* Now this holds the number of score-element pairs. */</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Check for incompatible options. */</span></span><br><span class=\"line\">    <span class=\"comment\">//nx和xxflag互斥,二者不能同时出现</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (nx &amp;&amp; xx) &#123;</span><br><span class=\"line\">        addReplyError(c,</span><br><span class=\"line\">            <span class=\"string\">\"XX and NX options at the same time are not compatible\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//若有incr标志,则只能有一对&lt;element,score&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">//为什么不能是多对?</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (incr &amp;&amp; elements &gt; <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        addReplyError(c,</span><br><span class=\"line\">            <span class=\"string\">\"INCR option supports a single increment-element pair\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Start parsing all the scores, we need to emit any syntax error</span></span><br><span class=\"line\"><span class=\"comment\">     * before executing additions to the sorted set, as the command should</span></span><br><span class=\"line\"><span class=\"comment\">     * either execute fully or nothing at all. */</span></span><br><span class=\"line\">    <span class=\"comment\">//依次检查每一个分数值</span></span><br><span class=\"line\">    scores = zmalloc(<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">double</span>)*elements);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; elements; j++) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//该函数中会检查score是否是合法的double类型的值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (getDoubleFromObjectOrReply(c,c-&gt;argv[scoreidx+j*<span class=\"number\">2</span>],&amp;scores[j],<span class=\"literal\">NULL</span>)</span><br><span class=\"line\">            != C_OK) <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Lookup the key and create the sorted set if does not exist. */</span></span><br><span class=\"line\">    <span class=\"comment\">//根据key查找对应的有序集合的value</span></span><br><span class=\"line\">    zobj = lookupKeyWrite(c-&gt;db,key);</span><br><span class=\"line\">    <span class=\"comment\">//key不存在</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果设置了xx这个flag,直接返回错误</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (xx) <span class=\"keyword\">goto</span> reply_to_client; <span class=\"comment\">/* No key + XX option: nothing to do. */</span></span><br><span class=\"line\">        <span class=\"comment\">//根据redis的配置,如果有序集合设置了不使用ziplist存储或者说第一个插入元素的长度大于</span></span><br><span class=\"line\">        <span class=\"comment\">//设置的最大ziplist的元素长度值,则使用跳跃表存储否则使用ziplist</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (server.zset_max_ziplist_entries == <span class=\"number\">0</span> ||</span><br><span class=\"line\">            server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[scoreidx+<span class=\"number\">1</span>]-&gt;ptr))</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            zobj = createZsetObject();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            zobj = createZsetZiplistObject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//把key,zobj插入字典</span></span><br><span class=\"line\">        dbAdd(c-&gt;db,key,zobj);</span><br><span class=\"line\">    <span class=\"comment\">//key存在</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果不是有序集合,直接返回错误</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zobj-&gt;type != OBJ_ZSET) &#123;</span><br><span class=\"line\">            addReply(c,shared.wrongtypeerr);</span><br><span class=\"line\">            <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//elements是&lt;member,score&gt;对数</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; elements; j++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> newscore;</span><br><span class=\"line\">        score = scores[j];</span><br><span class=\"line\">        <span class=\"comment\">//retflags设置为前文中的flags变量</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> retflags = flags;</span><br><span class=\"line\"></span><br><span class=\"line\">        ele = c-&gt;argv[scoreidx+<span class=\"number\">1</span>+j*<span class=\"number\">2</span>]-&gt;ptr;</span><br><span class=\"line\">        <span class=\"comment\">//每次遍历,score是分数,ele是member.调用zsetadd插入zobj</span></span><br><span class=\"line\">        <span class=\"keyword\">int</span> retval = zsetAdd(zobj, score, ele, &amp;retflags, &amp;newscore);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retval == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            addReplyError(c,nanerr);</span><br><span class=\"line\">            <span class=\"keyword\">goto</span> cleanup;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//根据retflags,即一个元素是更新还是新加入,还是未做处理(即member存在,并且</span></span><br><span class=\"line\">        <span class=\"comment\">//score值与新设置的一致),更新相应的计数变量(这些变量最后会返回给客户端)</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retflags &amp; ZADD_ADDED) added++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (retflags &amp; ZADD_UPDATED) updated++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!(retflags &amp; ZADD_NOP)) processed++;</span><br><span class=\"line\">        score = newscore;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    server.dirty += (added+updated);</span><br><span class=\"line\"><span class=\"comment\">//通过命令中的flag,返回给客户端不同的值</span></span><br><span class=\"line\">reply_to_client:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (incr) &#123; <span class=\"comment\">/* ZINCRBY or INCR option. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (processed)</span><br><span class=\"line\">            addReplyDouble(c,score);</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            addReply(c,shared.nullbulk);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123; <span class=\"comment\">/* ZADD. */</span></span><br><span class=\"line\">        addReplyLongLong(c,ch ? added+updated : added);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//如果有更新或者新加,需要执行相应的watch key的通知及keyspace的通知</span></span><br><span class=\"line\">cleanup:</span><br><span class=\"line\">    zfree(scores);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (added || updated) &#123;</span><br><span class=\"line\">        signalModifiedKey(c-&gt;db,key);</span><br><span class=\"line\">        notifyKeyspaceEvent(NOTIFY_ZSET,</span><br><span class=\"line\">            incr ? <span class=\"string\">\"zincr\"</span> : <span class=\"string\">\"zadd\"</span>, key, c-&gt;db-&gt;id);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZINCRBY\"><a href=\"#ZINCRBY\" class=\"headerlink\" title=\"ZINCRBY\"></a>ZINCRBY</h2><p>ZINCRBY key increment member</p>\n<p>如果key存在,就给相应member的score增加increment</p>\n<p>否则直接给key设置分数为increment</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//与zadd调用同一个函数,相当于zadd key incr,把incr flag置位</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zincrbyCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zaddGenericCommand(c,ZADD_INCR);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZCARD\"><a href=\"#ZCARD\" class=\"headerlink\" title=\"ZCARD\"></a>ZCARD</h2><p>ZCARD key</p>\n<p>返回有序集合的元素个数<br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zcardCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"comment\">//查找key对应的value</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//通过zsetLength获取zobj中的元素个数</span></span><br><span class=\"line\">    addReplyLongLong(c,zsetLength(zobj));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> <span class=\"title\">zsetLength</span><span class=\"params\">(<span class=\"keyword\">const</span> robj *zobj)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> length = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"comment\">//如果是ziplist,通过zzlLength函数获取长度</span></span><br><span class=\"line\">    <span class=\"comment\">//如果长度字段中的值小于UINT16_MAX，直接返回长度。否则需要遍历获取长度</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        length = zzlLength(zobj-&gt;ptr);</span><br><span class=\"line\">    <span class=\"comment\">//如果是skiplist,直接返回zsl-&gt;length</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        length = ((<span class=\"keyword\">const</span> zset*)zobj-&gt;ptr)-&gt;zsl-&gt;length;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> length;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZCOUNT\"><a href=\"#ZCOUNT\" class=\"headerlink\" title=\"ZCOUNT\"></a>ZCOUNT</h2><p>ZCOUNT key min max</p>\n<p>返回key中score值在min和max之间的元素个数</p>\n<p>其中min和max可以加(,如 zcount key (5 (10 </p>\n<p>加左括号表示不包含。不加表示包含</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zcountCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    zrangespec range;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse the range arguments */</span></span><br><span class=\"line\">    <span class=\"comment\">//判定范围.并将最大最小及是否包含写入range结构体中</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zslParseRange(c-&gt;argv[<span class=\"number\">2</span>],c-&gt;argv[<span class=\"number\">3</span>],&amp;range) != C_OK) &#123;</span><br><span class=\"line\">        addReplyError(c,<span class=\"string\">\"min or max is not a float\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Lookup the sorted set */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c, key, shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c, zobj, OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//判断zobj底层编码是ziplist还是skiplist</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\">        <span class=\"comment\">//找出第一个在范围之内的元素</span></span><br><span class=\"line\">        <span class=\"comment\">/* Use the first element in range as the starting point */</span></span><br><span class=\"line\">        eptr = zzlFirstInRange(zl,&amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.czero);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* First element is in range */</span></span><br><span class=\"line\">        <span class=\"comment\">//ziplist中member和score是两个entry,并且member之后保存着score</span></span><br><span class=\"line\">        <span class=\"comment\">//整体顺序是按score从小到大排列,score相同时,按member的字典序排列</span></span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\">        <span class=\"comment\">//所以此处从第一个元素的下一个entry处获取score</span></span><br><span class=\"line\">        score = zzlGetScore(sptr);</span><br><span class=\"line\">        serverAssertWithInfo(c,zobj,zslValueLteMax(score,&amp;range));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Iterate over elements in range */</span></span><br><span class=\"line\">        <span class=\"comment\">//迭代这个ziplist,如果score满足要求,则count++并且继续迭代,否则跳出</span></span><br><span class=\"line\">        <span class=\"comment\">//最后会返回count</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr) &#123;</span><br><span class=\"line\">            score = zzlGetScore(sptr);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!zslValueLteMax(score,&amp;range)) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                count++;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        zskiplistNode *zn;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\">        <span class=\"comment\">//如果是跳表,也是先取出第一个元素</span></span><br><span class=\"line\">        <span class=\"comment\">/* Find first element in range */</span></span><br><span class=\"line\">        zn = zslFirstInRange(zsl, &amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Use rank of first element, if any, to determine preliminary count */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zn != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//获取第一个元素的排名</span></span><br><span class=\"line\">            rank = zslGetRank(zsl, zn-&gt;score, zn-&gt;ele);</span><br><span class=\"line\">            count = (zsl-&gt;length - (rank - <span class=\"number\">1</span>));</span><br><span class=\"line\">            <span class=\"comment\">//如果最大值大于zsl中的最大值,则此count就是要找的个数</span></span><br><span class=\"line\">            <span class=\"comment\">/* Find last element in range */</span></span><br><span class=\"line\">            zn = zslLastInRange(zsl, &amp;range);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Use rank of last element, if any, to determine the actual count */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (zn != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">//如果最大值小于zsl中的最大值，则首先找到最后一个元素的rank</span></span><br><span class=\"line\">                rank = zslGetRank(zsl, zn-&gt;score, zn-&gt;ele);</span><br><span class=\"line\">                <span class=\"comment\">//重新计算count,与之前的计算公式合并之后为</span></span><br><span class=\"line\">                <span class=\"comment\">//count = (zsl-&gt;length-(rankmin-1))-(zsl-&gt;length-rankmax))</span></span><br><span class=\"line\">                <span class=\"comment\">//      = rankmax-rankmin+1</span></span><br><span class=\"line\">                count -= (zsl-&gt;length - rank);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//返回count</span></span><br><span class=\"line\">    addReplyLongLong(c, count);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZRANGEBYSCORE\"><a href=\"#ZRANGEBYSCORE\" class=\"headerlink\" title=\"ZRANGEBYSCORE\"></a>ZRANGEBYSCORE</h2><p>ZRANGEBYSCORE key min max [WITHSCORES][LIMIT offset count]</p>\n<p>获取有序结合中分值位于 min和max之间的所有元素</p>\n<p>withscores:将member 和 score一起返回 </p>\n<p>limit offset count:从偏移offset开始获取count个元素</p>\n<p>min和max可以为 -inf,+inf,分别表示负无穷和正无穷</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//入口函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrangebyscoreCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    genericZrangebyscoreCommand(c,<span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* This command implements ZRANGEBYSCORE, ZREVRANGEBYSCORE. */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">genericZrangebyscoreCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    zrangespec range;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> offset = <span class=\"number\">0</span>, limit = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> withscores = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rangelen = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span> *replylen = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> minidx, maxidx;</span><br><span class=\"line\">    <span class=\"comment\">//该函数同时用于zrangbyscore和zrevrangebyscore</span></span><br><span class=\"line\">    <span class=\"comment\">//二者通过函数中的reverse参数标识</span></span><br><span class=\"line\">    <span class=\"comment\">//正序时第二个参数是min，第三个参数是max,逆序反之</span></span><br><span class=\"line\">    <span class=\"comment\">/* Parse the range arguments. */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* Range is given as [max,min] */</span></span><br><span class=\"line\">        maxidx = <span class=\"number\">2</span>; minidx = <span class=\"number\">3</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/* Range is given as [min,max] */</span></span><br><span class=\"line\">        minidx = <span class=\"number\">2</span>; maxidx = <span class=\"number\">3</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//将参数解析出来赋值到range变量</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zslParseRange(c-&gt;argv[minidx],c-&gt;argv[maxidx],&amp;range) != C_OK) &#123;</span><br><span class=\"line\">        addReplyError(c,<span class=\"string\">\"min or max is not a float\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Parse optional extra arguments. Note that ZCOUNT will exactly have</span></span><br><span class=\"line\"><span class=\"comment\">     * 4 arguments, so we'll never enter the following code path. */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (c-&gt;argc &gt; <span class=\"number\">4</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> remaining = c-&gt;argc - <span class=\"number\">4</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> pos = <span class=\"number\">4</span>;</span><br><span class=\"line\">        <span class=\"comment\">//解析withscores和limit参数</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (remaining) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (remaining &gt;= <span class=\"number\">1</span> &amp;&amp; !strcasecmp(c-&gt;argv[pos]-&gt;ptr,<span class=\"string\">\"withscores\"</span>)) &#123;</span><br><span class=\"line\">                pos++; remaining--;</span><br><span class=\"line\">                withscores = <span class=\"number\">1</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (remaining &gt;= <span class=\"number\">3</span> &amp;&amp; !strcasecmp(c-&gt;argv[pos]-&gt;ptr,<span class=\"string\">\"limit\"</span>)) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> ((getLongFromObjectOrReply(c, c-&gt;argv[pos+<span class=\"number\">1</span>], &amp;offset, <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">                        != C_OK) ||</span><br><span class=\"line\">                    (getLongFromObjectOrReply(c, c-&gt;argv[pos+<span class=\"number\">2</span>], &amp;limit, <span class=\"literal\">NULL</span>)</span><br><span class=\"line\">                        != C_OK))</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                pos += <span class=\"number\">3</span>; remaining -= <span class=\"number\">3</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                addReply(c,shared.syntaxerr);</span><br><span class=\"line\">                <span class=\"keyword\">return</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Ok, lookup the key and get the range */</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.emptymultibulk)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//按zset底层编码是ziplist还是skiplist分别处理</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *vstr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">int</span> vlen;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> vlong;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If reversed, get the last node in range as starting point. */</span></span><br><span class=\"line\">        <span class=\"comment\">//按正序还是逆序分别取最后一个值或者第一个值</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">            eptr = zzlLastInRange(zl,&amp;range);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            eptr = zzlFirstInRange(zl,&amp;range);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element in the specified interval. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.emptymultibulk);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* Get score pointer for the first element. */</span></span><br><span class=\"line\">        serverAssertWithInfo(c,zobj,eptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* We don't know in advance how many matching elements there are in the</span></span><br><span class=\"line\"><span class=\"comment\">         * list, so we push this object that will represent the multi-bulk</span></span><br><span class=\"line\"><span class=\"comment\">         * length in the output buffer, and will \"fix\" it later */</span></span><br><span class=\"line\">        replylen = addDeferredMultiBulkLength(c);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If there is an offset, just traverse the number of elements without</span></span><br><span class=\"line\"><span class=\"comment\">         * checking the score because that is done in the next loop. */</span></span><br><span class=\"line\">        <span class=\"comment\">//如果有offset,先偏移相应的元素</span></span><br><span class=\"line\">        <span class=\"comment\">//注意此处zzlNext传入了两个指针,会一次偏移一个&lt;member,score&gt;对</span></span><br><span class=\"line\">        <span class=\"comment\">//注意此处offset初始值是0,如果没指定则不会进入此处循环</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr &amp;&amp; offset--) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                zzlPrev(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果有limit,则进入循环.取limit次.limit的初始值为-1,即使没指定,也会进入循环</span></span><br><span class=\"line\">        <span class=\"comment\">//直到eptr为null或者循环中break掉</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (eptr &amp;&amp; limit--) &#123;</span><br><span class=\"line\">            score = zzlGetScore(sptr);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"comment\">//不在范围之内时break掉</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueGteMin(score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueLteMax(score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* We know the element exists, so ziplistGet should always succeed */</span></span><br><span class=\"line\">            serverAssertWithInfo(c,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong));</span><br><span class=\"line\">            <span class=\"comment\">//取出相应的值.可能为str,赋值给vstr,长度为vlen,或者为整型,赋值给vlong</span></span><br><span class=\"line\">            rangelen++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (vstr == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">                addReplyBulkLongLong(c,vlong);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                addReplyBulkCBuffer(c,vstr,vlen);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//如果设置了withscores标志,则返回分数</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">                addReplyDouble(c,score);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">//开始迭代下一个节点</span></span><br><span class=\"line\">            <span class=\"comment\">/* Move to next node */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                zzlPrev(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        zskiplistNode *ln;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//同ziplist,先查找起始或最终节点</span></span><br><span class=\"line\">        <span class=\"comment\">/* If reversed, get the last node in range as starting point. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">            ln = zslLastInRange(zsl,&amp;range);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            ln = zslFirstInRange(zsl,&amp;range);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* No \"first\" element in the specified interval. */</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ln == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            addReply(c, shared.emptymultibulk);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* We don't know in advance how many matching elements there are in the</span></span><br><span class=\"line\"><span class=\"comment\">         * list, so we push this object that will represent the multi-bulk</span></span><br><span class=\"line\"><span class=\"comment\">         * length in the output buffer, and will \"fix\" it later */</span></span><br><span class=\"line\">        <span class=\"comment\">//返回客户端时先返回元素个数,但此处并不知道需要返回多少个元素,所以先占个位置</span></span><br><span class=\"line\">        <span class=\"comment\">//replylen是存储len字段的指针</span></span><br><span class=\"line\">        replylen = addDeferredMultiBulkLength(c);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">/* If there is an offset, just traverse the number of elements without</span></span><br><span class=\"line\"><span class=\"comment\">         * checking the score because that is done in the next loop. */</span></span><br><span class=\"line\">        <span class=\"comment\">//处理offset.向前或向后skip</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (ln &amp;&amp; offset--) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                ln = ln-&gt;backward;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                ln = ln-&gt;level[<span class=\"number\">0</span>].forward;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//处理limit</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (ln &amp;&amp; limit--) &#123;</span><br><span class=\"line\">            <span class=\"comment\">/* Abort when the node is no longer in range. */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueGteMin(ln-&gt;score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!zslValueLteMax(ln-&gt;score,&amp;range)) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            rangelen++;</span><br><span class=\"line\">            addReplyBulkCBuffer(c,ln-&gt;ele,sdslen(ln-&gt;ele));</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">                addReplyDouble(c,ln-&gt;score);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Move to next node */</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse) &#123;</span><br><span class=\"line\">                ln = ln-&gt;backward;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                ln = ln-&gt;level[<span class=\"number\">0</span>].forward;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//如果有withscores参数,返回给客户端的字符串数量是2倍</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (withscores) &#123;</span><br><span class=\"line\">        rangelen *= <span class=\"number\">2</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//将rangelen放入replylen指向的位置,返回给客户端</span></span><br><span class=\"line\">    setDeferredMultiBulkLength(c, replylen, rangelen);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZRANK\"><a href=\"#ZRANK\" class=\"headerlink\" title=\"ZRANK\"></a>ZRANK</h2><p>ZRANK key member</p>\n<p>返回有序集合中元素member的rank</p>\n<p>以0为起始rank,元素分数从低到高</p>\n<p>zrevrank,元素分数从高到低</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrankGenericCommand</span><span class=\"params\">(client *c, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *ele = c-&gt;argv[<span class=\"number\">2</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\">    <span class=\"comment\">//通过key找出有序集合的value zobj</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyReadOrReply(c,key,shared.nullbulk)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    serverAssertWithInfo(c,ele,sdsEncodedObject(ele));</span><br><span class=\"line\">    <span class=\"comment\">//在zobj中查找ele(第二个参数member)</span></span><br><span class=\"line\">    rank = zsetRank(zobj,ele-&gt;ptr,reverse);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (rank &gt;= <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        addReplyLongLong(c,rank);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        addReply(c,shared.nullbulk);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zrankCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    zrankGenericCommand(c, <span class=\"number\">0</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">zsetRank</span><span class=\"params\">(robj *zobj, sds ele, <span class=\"keyword\">int</span> reverse)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> llen;</span><br><span class=\"line\">    <span class=\"keyword\">unsigned</span> <span class=\"keyword\">long</span> rank;</span><br><span class=\"line\"></span><br><span class=\"line\">    llen = zsetLength(zobj);</span><br><span class=\"line\">    <span class=\"comment\">//ziplist从前往后遍历,比较entry中的元素与ele,每次将rank++</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *zl = zobj-&gt;ptr;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr, *sptr;</span><br><span class=\"line\"></span><br><span class=\"line\">        eptr = ziplistIndex(zl,<span class=\"number\">0</span>);</span><br><span class=\"line\">        serverAssert(eptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">        sptr = ziplistNext(zl,eptr);</span><br><span class=\"line\">        serverAssert(sptr != <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        rank = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(eptr != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ziplistCompare(eptr,(<span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span>*)ele,sdslen(ele)))</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            rank++;</span><br><span class=\"line\">            zzlNext(zl,&amp;eptr,&amp;sptr);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (eptr != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//如果是逆序取,直接将llen-rank就是逆向的rank</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> llen-rank;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> rank<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"comment\">//skiplist通过zslGetRank获取rank,具体过程为跳表查找,将相应路过节点的span相加</span></span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        zskiplist *zsl = zs-&gt;zsl;</span><br><span class=\"line\">        dictEntry *de;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\"></span><br><span class=\"line\">        de = dictFind(zs-&gt;dict,ele);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (de != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            score = *(<span class=\"keyword\">double</span>*)dictGetVal(de);</span><br><span class=\"line\">            rank = zslGetRank(zsl,score,ele);</span><br><span class=\"line\">            <span class=\"comment\">/* Existing elements always have a rank. */</span></span><br><span class=\"line\">            serverAssert(rank != <span class=\"number\">0</span>);</span><br><span class=\"line\">            <span class=\"comment\">//逆向取rank</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (reverse)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> llen-rank;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> rank<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ZREM\"><a href=\"#ZREM\" class=\"headerlink\" title=\"ZREM\"></a>ZREM</h2><p>ZREM key member [member …]</p>\n<p>从有序集合中删除相应的member</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">zremCommand</span><span class=\"params\">(client *c)</span> </span>&#123;</span><br><span class=\"line\">    robj *key = c-&gt;argv[<span class=\"number\">1</span>];</span><br><span class=\"line\">    robj *zobj;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> deleted = <span class=\"number\">0</span>, keyremoved = <span class=\"number\">0</span>, j;</span><br><span class=\"line\">    <span class=\"comment\">//根据key找到对应的zobj</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == <span class=\"literal\">NULL</span> ||</span><br><span class=\"line\">        checkType(c,zobj,OBJ_ZSET)) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"comment\">//依次删除相应的元素,每次删除之后检查zset是否为空,如果为空,删掉该key,并且break</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (j = <span class=\"number\">2</span>; j &lt; c-&gt;argc; j++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zsetDel(zobj,c-&gt;argv[j]-&gt;ptr)) deleted++;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (zsetLength(zobj) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            dbDelete(c-&gt;db,key);</span><br><span class=\"line\">            keyremoved = <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//如果确实有member被删除掉,通知keyspace zrem事件</span></span><br><span class=\"line\">    <span class=\"comment\">//如果zset整个都被删除了,通知keyspace del事件</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (deleted) &#123;</span><br><span class=\"line\">        notifyKeyspaceEvent(NOTIFY_ZSET,<span class=\"string\">\"zrem\"</span>,key,c-&gt;db-&gt;id);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (keyremoved)</span><br><span class=\"line\">            notifyKeyspaceEvent(NOTIFY_GENERIC,<span class=\"string\">\"del\"</span>,key,c-&gt;db-&gt;id);</span><br><span class=\"line\">        signalModifiedKey(c-&gt;db,key);</span><br><span class=\"line\">        server.dirty += deleted;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//返回给客户端实际删除的member个数</span></span><br><span class=\"line\">    addReplyLongLong(c,deleted);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* Delete the element 'ele' from the sorted set, returning 1 if the element</span></span><br><span class=\"line\"><span class=\"comment\"> * existed and was deleted, 0 otherwise (the element was not there). */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">zsetDel</span><span class=\"params\">(robj *zobj, sds ele)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">unsigned</span> <span class=\"keyword\">char</span> *eptr;</span><br><span class=\"line\">        <span class=\"comment\">//ziplist先找到ele所在位置的指针eptr</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((eptr = zzlFind(zobj-&gt;ptr,ele,<span class=\"literal\">NULL</span>)) != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//将该元素删除.ziplist删除时会resize,此处将删除之后ziplist的指针复值给zobj-&gt;ptr</span></span><br><span class=\"line\">            zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123;</span><br><span class=\"line\">        zset *zs = zobj-&gt;ptr;</span><br><span class=\"line\">        dictEntry *de;</span><br><span class=\"line\">        <span class=\"keyword\">double</span> score;</span><br><span class=\"line\">        <span class=\"comment\">//skiplist现将zobj-&gt;ptr-&gt;dict相应的ele删除掉。此处并未真实删除</span></span><br><span class=\"line\">        <span class=\"comment\">//而是将ele所在的dictEntry返回</span></span><br><span class=\"line\">        de = dictUnlink(zs-&gt;dict,ele);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (de != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">/* Get the score in order to delete from the skiplist later. */</span></span><br><span class=\"line\">            <span class=\"comment\">//通过dictEntry获取score</span></span><br><span class=\"line\">            score = *(<span class=\"keyword\">double</span>*)dictGetVal(de);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Delete from the hash table and later from the skiplist.</span></span><br><span class=\"line\"><span class=\"comment\">             * Note that the order is important: deleting from the skiplist</span></span><br><span class=\"line\"><span class=\"comment\">             * actually releases the SDS string representing the element,</span></span><br><span class=\"line\"><span class=\"comment\">             * which is shared between the skiplist and the hash table, so</span></span><br><span class=\"line\"><span class=\"comment\">             * we need to delete from the skiplist as the final step. */</span></span><br><span class=\"line\">            <span class=\"comment\">//此处将dict中的key和value实际free掉</span></span><br><span class=\"line\">            dictFreeUnlinkedEntry(zs-&gt;dict,de);</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">/* Delete from skiplist. */</span></span><br><span class=\"line\">            <span class=\"comment\">//从skiplist中删除元素.ele这个sds在hash和skiplist共享.从skiplist中删除时</span></span><br><span class=\"line\">            <span class=\"comment\">//会释放此sds,所以必须先删除dict中的元素再删除skiplist中的元素</span></span><br><span class=\"line\">            <span class=\"keyword\">int</span> retval = zslDelete(zs-&gt;zsl,score,ele,<span class=\"literal\">NULL</span>);</span><br><span class=\"line\">            serverAssert(retval);</span><br><span class=\"line\">            <span class=\"comment\">//如果hash表中元素使用率小于10%,进行dict的resize</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (htNeedsResize(zs-&gt;dict)) dictResize(zs-&gt;dict);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        serverPanic(<span class=\"string\">\"Unknown sorted set encoding\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>; <span class=\"comment\">/* No such element found. */</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjvw65z9b0005bms6udsmnojj","tag_id":"cjvw65z970003bms66cixvni6","_id":"cjvw65z9i0008bms6g59pb214"},{"post_id":"cjvw65z8y0001bms655opvvqr","tag_id":"cjvw65z970003bms66cixvni6","_id":"cjvw65z9j000abms6cmblja2s"},{"post_id":"cjvw65z940002bms6ajm914lj","tag_id":"cjvw65z970003bms66cixvni6","_id":"cjvw65z9m000dbms65fjgiztr"},{"post_id":"cjvw65z990004bms687o8v4l8","tag_id":"cjvw65z970003bms66cixvni6","_id":"cjvw65z9p000hbms67nryzk50"},{"post_id":"cjvw65z9d0006bms69z2on2dk","tag_id":"cjvw65z9p000gbms6g0kh13pi","_id":"cjvw65z9s000mbms6c9xga1zl"},{"post_id":"cjvw65z9s000lbms6w2ldzcj5","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65z9u000pbms6190bffcm"},{"post_id":"cjvw65z9i0009bms6fk2fapwt","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65z9v000rbms6h8ve0l70"},{"post_id":"cjvw65z9k000bbms6g16w4wfd","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65z9y000vbms6hl5f0zno"},{"post_id":"cjvw65z9m000ebms6pk1gs597","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65za0000ybms6n0b9unng"},{"post_id":"cjvw65z9o000fbms6m4bsbo21","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65za10010bms6a0sqpae7"},{"post_id":"cjvw65z9q000ibms6ju4frh5c","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65za10012bms6oysldf7n"},{"post_id":"cjvw65z9r000jbms6mujz2b0g","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65za20014bms6dx9oqnnd"},{"post_id":"cjvw65z9t000nbms6qzyvltk1","tag_id":"cjvw65za20013bms6aebxe2td","_id":"cjvw65za30016bms6po307d89"},{"post_id":"cjvw65z9u000qbms6cvqhjc3c","tag_id":"cjvw65za20013bms6aebxe2td","_id":"cjvw65za40018bms6aowdn8pa"},{"post_id":"cjvw65z9v000sbms694zro3ah","tag_id":"cjvw65za30017bms6h9ylxyfw","_id":"cjvw65za5001abms6e9e8dtds"},{"post_id":"cjvw65z9x000ubms6yz3elos1","tag_id":"cjvw65za30017bms6h9ylxyfw","_id":"cjvw65za6001cbms6g1i7ezuj"},{"post_id":"cjvw65z9y000wbms6klaor2tw","tag_id":"cjvw65za30017bms6h9ylxyfw","_id":"cjvw65za7001dbms6mok5jyjq"},{"post_id":"cjvw65zbb001ebms6v0uu2kkr","tag_id":"cjvw65z9p000gbms6g0kh13pi","_id":"cjvw65zbc001gbms63buyne01"},{"post_id":"cjvw65zbb001fbms6e2p1dwdq","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65zbc001ibms6yv39313f"},{"post_id":"cjvw65zbc001hbms6yaolhos2","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65zbd001kbms6mvpxjndt"},{"post_id":"cjvw65zbd001jbms6ezc8t4pt","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65zbe001mbms6t8y4cz3a"},{"post_id":"cjvw65zbd001lbms66qt1d4hc","tag_id":"cjvw65zbe001obms6fu9fpf7j","_id":"cjvw65zbf001qbms6najnfl10"},{"post_id":"cjvw65zbe001nbms672kpndsv","tag_id":"cjvw65zbf001pbms62xbtuw20","_id":"cjvw65zbg001rbms618j03erp"},{"post_id":"cjvw65zcl001sbms6m2m8ywpk","tag_id":"cjvw65zbe001obms6fu9fpf7j","_id":"cjvw65zco001tbms65yg62seo"},{"post_id":"cjvw65zd1001ubms6wospre08","tag_id":"cjvw65z9r000kbms6pgpj6xqf","_id":"cjvw65zd2001vbms6a38oinhd"}],"Tag":[{"name":"Mysql","_id":"cjvw65z970003bms66cixvni6"},{"name":"NGINX","_id":"cjvw65z9p000gbms6g0kh13pi"},{"name":"Redis","_id":"cjvw65z9r000kbms6pgpj6xqf"},{"name":"go","_id":"cjvw65za20013bms6aebxe2td"},{"name":"architecture","_id":"cjvw65za30017bms6h9ylxyfw"},{"name":"Sqlite","_id":"cjvw65zbe001obms6fu9fpf7j"},{"name":"codis","_id":"cjvw65zbf001pbms62xbtuw20"}]}}